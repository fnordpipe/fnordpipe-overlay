diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/base/macros.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/base/macros.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/base/macros.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/base/macros.h	2017-01-15 10:56:31.037591151 +0100
@@ -0,0 +1,12 @@
+#ifndef CERT_TRANS_BASE_MACROS_H_
+#define CERT_TRANS_BASE_MACROS_H_
+
+
+// A macro to disallow the copy constructor and operator= functions
+// This should be used in the private: declarations for a class
+#define DISALLOW_COPY_AND_ASSIGN(TypeName) \
+  TypeName(const TypeName&) = delete;      \
+  void operator=(const TypeName&) = delete
+
+
+#endif  // CERT_TRANS_BASE_MACROS_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/base/notification.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/base/notification.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/base/notification.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/base/notification.cc	2017-01-15 10:56:31.037591151 +0100
@@ -0,0 +1,45 @@
+#include "base/notification.h"
+
+#include <glog/logging.h>
+
+using std::chrono::milliseconds;
+using std::lock_guard;
+using std::mutex;
+using std::unique_lock;
+
+namespace cert_trans {
+
+
+void Notification::Notify() {
+  lock_guard<mutex> lock(lock_);
+  CHECK(!notified_);
+  notified_ = true;
+  // *Do* notify this under lock, because otherwise someone can delete this
+  // Notification while the thread calling into Notify() is still here.
+  // (This removes the TSAN "noise" about the pthread_cond_broadcast /
+  // pthread_cond_destroy race.)
+  cv_.notify_all();
+}
+
+
+bool Notification::HasBeenNotified() const {
+  lock_guard<mutex> lock(lock_);
+  return notified_;
+}
+
+
+void Notification::WaitForNotification() const {
+  unique_lock<mutex> lock(lock_);
+  cv_.wait(lock, [this]() { return notified_; });
+}
+
+
+bool Notification::WaitForNotificationWithTimeout(
+    const milliseconds& timeout) const {
+  unique_lock<mutex> lock(lock_);
+  cv_.wait_for(lock, timeout, [this]() { return notified_; });
+  return notified_;
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/base/notification.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/base/notification.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/base/notification.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/base/notification.h	2017-01-15 10:56:31.037591151 +0100
@@ -0,0 +1,40 @@
+#ifndef CERT_TRANS_BASE_NOTIFICATION_H_
+#define CERT_TRANS_BASE_NOTIFICATION_H_
+
+#include <chrono>
+#include <condition_variable>
+#include <mutex>
+
+#include "base/macros.h"
+
+namespace cert_trans {
+
+
+class Notification {
+ public:
+  Notification() : notified_(false) {
+  }
+
+  void Notify();
+
+  bool HasBeenNotified() const;
+
+  void WaitForNotification() const;
+
+  // Returns true if Notify() has been called, or false if the timeout
+  // expired.
+  bool WaitForNotificationWithTimeout(
+      const std::chrono::milliseconds& timeout) const;
+
+ private:
+  mutable std::mutex lock_;
+  mutable std::condition_variable cv_;
+  bool notified_;
+
+  DISALLOW_COPY_AND_ASSIGN(Notification);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_BASE_NOTIFICATION_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/base/notification_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/base/notification_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/base/notification_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/base/notification_test.cc	2017-01-15 10:56:31.037591151 +0100
@@ -0,0 +1,41 @@
+#include <gtest/gtest.h>
+
+#include "base/notification.h"
+#include "util/testing.h"
+
+using std::chrono::milliseconds;
+
+namespace {
+
+
+TEST(NotificationTest, BasicTests) {
+  cert_trans::Notification notifier;
+
+  ASSERT_FALSE(notifier.HasBeenNotified());
+  EXPECT_FALSE(notifier.WaitForNotificationWithTimeout(milliseconds(0)));
+  EXPECT_FALSE(notifier.WaitForNotificationWithTimeout(milliseconds(10)));
+  notifier.Notify();
+  notifier.WaitForNotification();
+  EXPECT_TRUE(notifier.WaitForNotificationWithTimeout(milliseconds(0)));
+  EXPECT_TRUE(notifier.WaitForNotificationWithTimeout(milliseconds(10)));
+  ASSERT_TRUE(notifier.HasBeenNotified());
+}
+
+
+TEST(NotificationDeathTest, NotifyOnce) {
+  cert_trans::Notification notifier;
+
+  ASSERT_FALSE(notifier.HasBeenNotified());
+  notifier.Notify();
+  ASSERT_TRUE(notifier.HasBeenNotified());
+  EXPECT_DEATH(notifier.Notify(), "Check failed: !notified_");
+}
+
+
+}  // namespace
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/base/time_support.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/base/time_support.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/base/time_support.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/base/time_support.h	2017-01-15 10:56:31.037591151 +0100
@@ -0,0 +1,16 @@
+#ifndef CERT_TRANS_BASE_TIME_SUPPORT_H_
+#define CERT_TRANS_BASE_TIME_SUPPORT_H_
+
+namespace cert_trans {
+
+
+static const int64_t kNumMillisPerSecond = 1000LL;
+
+static const int64_t kNumMicrosPerMilli = 1000LL;
+static const int64_t kNumMicrosPerSecond =
+    kNumMillisPerSecond * kNumMicrosPerMilli;
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_BASE_TIME_SUPPORT_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/async_log_client.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/async_log_client.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/async_log_client.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/async_log_client.cc	2017-01-15 10:56:31.037591151 +0100
@@ -0,0 +1,527 @@
+#include "client/async_log_client.h"
+
+#include <event2/http.h>
+#include <glog/logging.h>
+#include <algorithm>
+#include <iterator>
+#include <memory>
+
+#include "log/cert.h"
+#include "proto/cert_serializer.h"
+#include "proto/serializer.h"
+#include "util/json_wrapper.h"
+
+using cert_trans::AsyncLogClient;
+using cert_trans::Cert;
+using cert_trans::CertChain;
+using cert_trans::PreCertChain;
+using cert_trans::URL;
+using cert_trans::UrlFetcher;
+using cert_trans::serialization::DeserializeResult;
+using ct::DigitallySigned;
+using ct::MerkleAuditProof;
+using ct::SignedCertificateTimestamp;
+using ct::SignedTreeHead;
+using std::back_inserter;
+using std::bind;
+using std::move;
+using std::placeholders::_1;
+using std::string;
+using std::to_string;
+using std::unique_ptr;
+using std::vector;
+
+namespace {
+
+
+string UriEncode(const string& input) {
+  const unique_ptr<char, void (*)(void*)> output(
+      evhttp_uriencode(input.data(), input.size(), false), &free);
+
+  return output.get();
+}
+
+
+// Do some common checks, calls the callback with the appropriate
+// error if something is wrong.
+bool SanityCheck(UrlFetcher::Response* resp,
+                 const AsyncLogClient::Callback& done, util::Task* task) {
+  // TODO(pphaneuf): We should report errors better. The easiest way
+  // would be for this to use util::Task as well, so it could simply
+  // pass on the status.
+  if (!task->status().ok() || resp->status_code != HTTP_OK) {
+    done(AsyncLogClient::UNKNOWN_ERROR);
+    return false;
+  }
+
+  return true;
+}
+
+
+void DoneGetSTH(UrlFetcher::Response* resp, SignedTreeHead* sth,
+                const AsyncLogClient::Callback& done, util::Task* task) {
+  unique_ptr<UrlFetcher::Response> resp_deleter(CHECK_NOTNULL(resp));
+  unique_ptr<util::Task> task_deleter(CHECK_NOTNULL(task));
+
+  LOG_IF(INFO, !task->status().ok()) << "DoneGetSTH: " << task->status();
+
+  if (!SanityCheck(resp, done, task)) {
+    return;
+  }
+
+  JsonObject jresponse(resp->body);
+  if (!jresponse.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  JsonInt tree_size(jresponse, "tree_size");
+  if (!tree_size.Ok() || tree_size.Value() < 0)
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  JsonInt timestamp(jresponse, "timestamp");
+  if (!timestamp.Ok() || timestamp.Value() < 0)
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  JsonString root_hash(jresponse, "sha256_root_hash");
+  if (!root_hash.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  JsonString jsignature(jresponse, "tree_head_signature");
+  if (!jsignature.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+  DigitallySigned signature;
+  if (Deserializer::DeserializeDigitallySigned(jsignature.FromBase64(),
+                                               &signature) !=
+      DeserializeResult::OK)
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  sth->Clear();
+  sth->set_version(ct::V1);
+  sth->set_tree_size(tree_size.Value());
+  sth->set_timestamp(timestamp.Value());
+  sth->set_sha256_root_hash(root_hash.FromBase64());
+  sth->mutable_signature()->CopyFrom(signature);
+
+  return done(AsyncLogClient::OK);
+}
+
+
+void DoneGetRoots(UrlFetcher::Response* resp, vector<unique_ptr<Cert>>* roots,
+                  const AsyncLogClient::Callback& done, util::Task* task) {
+  unique_ptr<UrlFetcher::Response> resp_deleter(CHECK_NOTNULL(resp));
+  unique_ptr<util::Task> task_deleter(CHECK_NOTNULL(task));
+
+  if (!SanityCheck(resp, done, task)) {
+    return;
+  }
+
+  JsonObject jresponse(resp->body);
+  if (!jresponse.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  JsonArray jroots(jresponse, "certificates");
+  if (!jroots.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  vector<unique_ptr<Cert>> retval;
+  for (int i = 0; i < jroots.Length(); ++i) {
+    JsonString jcert(jroots, i);
+    if (!jcert.Ok())
+      return done(AsyncLogClient::BAD_RESPONSE);
+
+    unique_ptr<Cert> cert(Cert::FromDerString(jcert.FromBase64()));
+    if (!cert) {
+      return done(AsyncLogClient::BAD_RESPONSE);
+    }
+
+    retval.push_back(move(cert));
+  }
+
+  roots->swap(retval);
+
+  return done(AsyncLogClient::OK);
+}
+
+
+void DoneGetEntries(UrlFetcher::Response* resp,
+                    vector<AsyncLogClient::Entry>* entries,
+                    const AsyncLogClient::Callback& done, util::Task* task) {
+  unique_ptr<UrlFetcher::Response> resp_deleter(CHECK_NOTNULL(resp));
+  unique_ptr<util::Task> task_deleter(CHECK_NOTNULL(task));
+
+  if (!SanityCheck(resp, done, task)) {
+    return;
+  }
+
+  JsonObject jresponse(resp->body);
+  if (!jresponse.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  JsonArray jentries(jresponse, "entries");
+  if (!jentries.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  vector<AsyncLogClient::Entry> new_entries;
+  new_entries.reserve(jentries.Length());
+
+  for (int n = 0; n < jentries.Length(); ++n) {
+    JsonObject entry(jentries, n);
+    if (!entry.Ok()) {
+      return done(AsyncLogClient::BAD_RESPONSE);
+    }
+
+    JsonString leaf_input(entry, "leaf_input");
+    if (!leaf_input.Ok()) {
+      return done(AsyncLogClient::BAD_RESPONSE);
+    }
+
+    AsyncLogClient::Entry log_entry;
+    if (Deserializer::DeserializeMerkleTreeLeaf(leaf_input.FromBase64(),
+                                                &log_entry.leaf) !=
+        DeserializeResult::OK) {
+      return done(AsyncLogClient::BAD_RESPONSE);
+    }
+
+    JsonString extra_data(entry, "extra_data");
+    if (!extra_data.Ok()) {
+      return done(AsyncLogClient::BAD_RESPONSE);
+    }
+
+    // This is an optional non-standard extension, used only by the log
+    // internally when running in clustered mode.
+    JsonString sct_data(entry, "sct");
+    if (sct_data.Ok()) {
+      unique_ptr<SignedCertificateTimestamp> sct(
+          new SignedCertificateTimestamp);
+      if (Deserializer::DeserializeSCT(sct_data.FromBase64(), sct.get()) !=
+          DeserializeResult::OK) {
+        return done(AsyncLogClient::BAD_RESPONSE);
+      }
+      log_entry.sct = move(sct);
+    }
+
+    switch (log_entry.leaf.timestamped_entry().entry_type()) {
+      case ct::X509_ENTRY:
+        DeserializeX509Chain(extra_data.FromBase64(),
+                             log_entry.entry.mutable_x509_entry());
+        break;
+      case ct::PRECERT_ENTRY:
+        DeserializePrecertChainEntry(extra_data.FromBase64(),
+                                     log_entry.entry.mutable_precert_entry());
+        break;
+      case ct::X_JSON_ENTRY:
+        // nothing to do
+        break;
+      default:
+        LOG(FATAL) << "Don't understand entry type: "
+                   << log_entry.leaf.timestamped_entry().entry_type();
+    }
+
+    new_entries.emplace_back(move(log_entry));
+  }
+
+  entries->reserve(entries->size() + new_entries.size());
+  move(new_entries.begin(), new_entries.end(), back_inserter(*entries));
+
+  return done(AsyncLogClient::OK);
+}
+
+
+void DoneQueryInclusionProof(UrlFetcher::Response* resp,
+                             const SignedTreeHead& sth,
+                             MerkleAuditProof* proof,
+                             const AsyncLogClient::Callback& done,
+                             util::Task* task) {
+  unique_ptr<UrlFetcher::Response> resp_deleter(CHECK_NOTNULL(resp));
+  unique_ptr<util::Task> task_deleter(CHECK_NOTNULL(task));
+
+  if (!SanityCheck(resp, done, task)) {
+    return;
+  }
+
+  JsonObject jresponse(resp->body);
+  if (!jresponse.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  JsonInt leaf_index(jresponse, "leaf_index");
+  if (!leaf_index.Ok() || leaf_index.Value() < 0)
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  JsonArray audit_path(jresponse, "audit_path");
+  if (!audit_path.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  vector<string> path_nodes;
+  for (int n = 0; n < audit_path.Length(); ++n) {
+    JsonString path_node(audit_path, n);
+    CHECK(path_node.Ok());
+    path_nodes.push_back(path_node.FromBase64());
+  }
+
+  proof->Clear();
+  proof->set_version(ct::V1);
+  proof->set_tree_size(sth.tree_size());
+  proof->set_timestamp(sth.timestamp());
+  proof->mutable_tree_head_signature()->CopyFrom(sth.signature());
+  proof->set_leaf_index(leaf_index.Value());
+  for (vector<string>::const_iterator it = path_nodes.begin();
+       it != path_nodes.end(); ++it) {
+    proof->add_path_node(*it);
+  }
+
+  return done(AsyncLogClient::OK);
+}
+
+
+void DoneGetSTHConsistency(UrlFetcher::Response* resp, vector<string>* proof,
+                           const AsyncLogClient::Callback& done,
+                           util::Task* task) {
+  unique_ptr<UrlFetcher::Response> resp_deleter(CHECK_NOTNULL(resp));
+  unique_ptr<util::Task> task_deleter(CHECK_NOTNULL(task));
+
+  if (!SanityCheck(resp, done, task)) {
+    return;
+  }
+
+  JsonObject jresponse(resp->body);
+  if (!jresponse.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  JsonArray jproof(jresponse, "consistency");
+  if (!jproof.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  vector<string> entries;
+  for (int i = 0; i < jproof.Length(); ++i) {
+    JsonString entry(jproof, i);
+    if (!entry.Ok())
+      return done(AsyncLogClient::BAD_RESPONSE);
+
+    entries.push_back(entry.FromBase64());
+  }
+
+  proof->reserve(proof->size() + entries.size());
+  move(entries.begin(), entries.end(), back_inserter(*proof));
+
+  return done(AsyncLogClient::OK);
+}
+
+
+void DoneInternalAddChain(UrlFetcher::Response* resp,
+                          SignedCertificateTimestamp* sct,
+                          const AsyncLogClient::Callback& done,
+                          util::Task* task) {
+  unique_ptr<UrlFetcher::Response> resp_deleter(CHECK_NOTNULL(resp));
+  unique_ptr<util::Task> task_deleter(CHECK_NOTNULL(task));
+
+  if (!SanityCheck(resp, done, task)) {
+    return;
+  }
+
+  JsonObject jresponse(resp->body);
+  if (!jresponse.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  if (!jresponse.IsType(json_type_object))
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  JsonString id(jresponse, "id");
+  if (!id.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  JsonInt timestamp(jresponse, "timestamp");
+  if (!timestamp.Ok() || timestamp.Value() < 0)
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  JsonString extensions(jresponse, "extensions");
+  if (!extensions.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  JsonString jsignature(jresponse, "signature");
+  if (!jsignature.Ok())
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  DigitallySigned signature;
+  if (Deserializer::DeserializeDigitallySigned(jsignature.FromBase64(),
+                                               &signature) !=
+      DeserializeResult::OK)
+    return done(AsyncLogClient::BAD_RESPONSE);
+
+  sct->Clear();
+  sct->set_version(ct::V1);
+  sct->mutable_id()->set_key_id(id.FromBase64());
+  sct->set_timestamp(timestamp.Value());
+  sct->set_extensions(extensions.FromBase64());
+  sct->mutable_signature()->CopyFrom(signature);
+
+  return done(AsyncLogClient::OK);
+}
+
+
+URL NormalizeURL(const string& server_url) {
+  URL retval(server_url);
+  string newpath(retval.Path());
+
+  if (newpath.empty() || newpath.back() != '/')
+    newpath.append("/");
+
+  newpath.append("ct/v1/");
+
+  retval.SetPath(newpath);
+
+  return retval;
+}
+
+
+}  // namespace
+
+namespace cert_trans {
+
+
+AsyncLogClient::AsyncLogClient(util::Executor* const executor,
+                               UrlFetcher* fetcher, const string& server_url)
+    : executor_(CHECK_NOTNULL(executor)),
+      fetcher_(CHECK_NOTNULL(fetcher)),
+      server_url_(NormalizeURL(server_url)) {
+}
+
+
+void AsyncLogClient::GetSTH(SignedTreeHead* sth, const Callback& done) {
+  UrlFetcher::Response* const resp(new UrlFetcher::Response);
+  fetcher_->Fetch(GetURL("get-sth"), resp,
+                  new util::Task(bind(DoneGetSTH, resp, sth, done, _1),
+                                 executor_));
+}
+
+
+void AsyncLogClient::GetRoots(vector<unique_ptr<Cert>>* roots,
+                              const Callback& done) {
+  UrlFetcher::Response* const resp(new UrlFetcher::Response);
+
+  fetcher_->Fetch(GetURL("get-roots"), resp,
+                  new util::Task(bind(DoneGetRoots, resp, roots, done, _1),
+                                 executor_));
+}
+
+
+void AsyncLogClient::GetEntries(int first, int last, vector<Entry>* entries,
+                                const Callback& done) {
+  return InternalGetEntries(first, last, entries, false /* request_scts */,
+                            done);
+}
+
+
+void AsyncLogClient::GetEntriesAndSCTs(int first, int last,
+                                       vector<Entry>* entries,
+                                       const Callback& done) {
+  return InternalGetEntries(first, last, entries, true /* request_scts */,
+                            done);
+}
+
+
+void AsyncLogClient::InternalGetEntries(int first, int last,
+                                        vector<Entry>* entries,
+                                        bool request_scts,
+                                        const Callback& done) {
+  CHECK_GE(first, 0);
+  CHECK_GE(last, 0);
+
+  if (last < first) {
+    done(INVALID_INPUT);
+    return;
+  }
+
+  URL url(GetURL("get-entries"));
+  url.SetQuery("start=" + to_string(first) + "&end=" + to_string(last) +
+               (request_scts ? "&include_scts=true" : ""));
+
+  UrlFetcher::Response* const resp(new UrlFetcher::Response);
+  fetcher_->Fetch(url, resp,
+                  new util::Task(bind(DoneGetEntries, resp, entries, done, _1),
+                                 executor_));
+}
+
+
+void AsyncLogClient::QueryInclusionProof(const SignedTreeHead& sth,
+                                         const std::string& merkle_leaf_hash,
+                                         MerkleAuditProof* proof,
+                                         const Callback& done) {
+  CHECK_GE(sth.tree_size(), 0);
+
+  URL url(GetURL("get-proof-by-hash"));
+  url.SetQuery("hash=" + UriEncode(util::ToBase64(merkle_leaf_hash)) +
+               "&tree_size=" + to_string(sth.tree_size()));
+
+  UrlFetcher::Response* const resp(new UrlFetcher::Response);
+  fetcher_->Fetch(url, resp, new util::Task(bind(DoneQueryInclusionProof, resp,
+                                                 sth, proof, done, _1),
+                                            executor_));
+}
+
+
+void AsyncLogClient::GetSTHConsistency(int64_t first, int64_t second,
+                                       vector<string>* proof,
+                                       const Callback& done) {
+  CHECK_GE(first, 0);
+  CHECK_GE(second, 0);
+
+  URL url(GetURL("get-sth-consistency"));
+  url.SetQuery("first=" + to_string(first) + "&second=" + to_string(second));
+
+  UrlFetcher::Response* const resp(new UrlFetcher::Response);
+  fetcher_->Fetch(url, resp, new util::Task(bind(DoneGetSTHConsistency, resp,
+                                                 proof, done, _1),
+                                            executor_));
+}
+
+
+void AsyncLogClient::AddCertChain(const CertChain& cert_chain,
+                                  SignedCertificateTimestamp* sct,
+                                  const Callback& done) {
+  InternalAddChain(cert_chain, sct, false, done);
+}
+
+
+void AsyncLogClient::AddPreCertChain(const PreCertChain& pre_cert_chain,
+                                     SignedCertificateTimestamp* sct,
+                                     const Callback& done) {
+  InternalAddChain(pre_cert_chain, sct, true, done);
+}
+
+
+URL AsyncLogClient::GetURL(const std::string& subpath) const {
+  URL retval(server_url_);
+  CHECK(!retval.Path().empty());
+  CHECK_EQ(retval.Path().back(), '/');
+  retval.SetPath(retval.Path() + subpath);
+  return retval;
+}
+
+
+void AsyncLogClient::InternalAddChain(const CertChain& cert_chain,
+                                      SignedCertificateTimestamp* sct,
+                                      bool pre_cert, const Callback& done) {
+  if (!cert_chain.IsLoaded())
+    return done(INVALID_INPUT);
+
+  JsonArray jchain;
+  for (size_t n = 0; n < cert_chain.Length(); ++n) {
+    string cert;
+    CHECK_EQ(util::Status::OK, cert_chain.CertAt(n)->DerEncoding(&cert));
+    jchain.AddBase64(cert);
+  }
+
+  JsonObject jsend;
+  jsend.Add("chain", jchain);
+
+  UrlFetcher::Request req(GetURL(pre_cert ? "add-pre-chain" : "add-chain"));
+  req.verb = UrlFetcher::Verb::POST;
+  req.body = jsend.ToString();
+
+  UrlFetcher::Response* const resp(new UrlFetcher::Response);
+  fetcher_->Fetch(req, resp, new util::Task(bind(DoneInternalAddChain, resp,
+                                                 sct, done, _1),
+                                            executor_));
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/async_log_client.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/async_log_client.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/async_log_client.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/async_log_client.h	2017-01-15 10:56:31.037591151 +0100
@@ -0,0 +1,113 @@
+#ifndef CERT_TRANS_CLIENT_ASYNC_LOG_CLIENT_H_
+#define CERT_TRANS_CLIENT_ASYNC_LOG_CLIENT_H_
+
+#include <stdint.h>
+#include <functional>
+#include <memory>
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "base/macros.h"
+#include "net/url_fetcher.h"
+#include "proto/ct.pb.h"
+
+namespace util {
+class Executor;
+}  // namespace util
+
+namespace cert_trans {
+
+
+class Cert;
+class CertChain;
+class PreCertChain;
+
+
+class AsyncLogClient {
+ public:
+  enum Status {
+    OK,
+    BAD_RESPONSE,
+    UNKNOWN_ERROR,
+    INVALID_INPUT,
+  };
+
+  struct Entry {
+    Entry() = default;
+    Entry(Entry&& src)
+        : leaf(src.leaf), entry(src.entry), sct(std::move(src.sct)) {
+    }
+
+    ct::MerkleTreeLeaf leaf;
+    ct::LogEntry entry;
+    std::unique_ptr<ct::SignedCertificateTimestamp> sct;
+  };
+
+  typedef std::function<void(Status)> Callback;
+
+  // The "executor" will be used to run callbacks.
+  // TODO(pphaneuf): The executor would not be necessary if we
+  // converted this API to use util::Task.
+  // TODO(pphaneuf): Might also want to take a URL object directly,
+  // instead of a string?
+  AsyncLogClient(util::Executor* const executor, UrlFetcher* fetcher,
+                 const std::string& server_uri);
+
+  void GetSTH(ct::SignedTreeHead* sth, const Callback& done);
+
+  // This does not clear "roots" before appending to it.
+  void GetRoots(std::vector<std::unique_ptr<Cert>>* roots,
+                const Callback& done);
+
+  // This does not clear "entries" before appending the retrieved
+  // entries.
+  void GetEntries(int first, int last, std::vector<Entry>* entries,
+                  const Callback& done);
+
+  // This is NON-standard, and only works with this log implementation.
+  // It's intended for internal use when running in a clustered configuration.
+  // This does not clear "entries" before appending the retrieved
+  // entries.
+  void GetEntriesAndSCTs(int first, int last, std::vector<Entry>* entries,
+                         const Callback& done);
+
+  void QueryInclusionProof(const ct::SignedTreeHead& sth,
+                           const std::string& merkle_leaf_hash,
+                           ct::MerkleAuditProof* proof, const Callback& done);
+
+  // This does not clear "proof" before appending to it.
+  void GetSTHConsistency(int64_t first, int64_t second,
+                         std::vector<std::string>* proof,
+                         const Callback& done);
+
+  // Note: these methods can call "done" inline (before they return),
+  // if there is a problem with the (pre-)certificate chain.
+  void AddCertChain(const CertChain& cert_chain,
+                    ct::SignedCertificateTimestamp* sct, const Callback& done);
+  void AddPreCertChain(const PreCertChain& pre_cert_chain,
+                       ct::SignedCertificateTimestamp* sct,
+                       const Callback& done);
+
+ private:
+  URL GetURL(const std::string& subpath) const;
+
+  void InternalGetEntries(int first, int last, std::vector<Entry>* entries,
+                          bool request_scts, const Callback& done);
+
+  void InternalAddChain(const CertChain& cert_chain,
+                        ct::SignedCertificateTimestamp* sct, bool pre_cert,
+                        const Callback& done);
+
+  util::Executor* const executor_;
+  UrlFetcher* const fetcher_;
+  const URL server_url_;
+
+  DISALLOW_COPY_AND_ASSIGN(AsyncLogClient);
+};
+
+
+}  // namespace cert_trans
+
+
+#endif  // CERT_TRANS_CLIENT_ASYNC_LOG_CLIENT_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/client.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/client.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/client.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/client.cc	2017-01-15 10:56:31.037591151 +0100
@@ -0,0 +1,116 @@
+#include "client/client.h"
+
+#include <arpa/inet.h>
+#include <glog/logging.h>
+#include <netdb.h>
+#include <netinet/in.h>
+#include <stddef.h>
+#include <stdint.h>
+#include <sys/socket.h>
+#include <unistd.h>
+
+#ifdef __MACH__
+// does not exist on MacOS
+#define MSG_NOSIGNAL 0
+#endif
+
+using std::string;
+
+Client::Client(const string& server, const string& port)
+    : server_(server), port_(port), fd_(-1) {
+}
+
+Client::~Client() {
+  Disconnect();
+}
+
+bool Client::Connect() {
+  CHECK(!Connected());
+
+  static const addrinfo server_addr_hints = {
+    AI_ADDRCONFIG, /* ai_flags */
+    AF_UNSPEC,     /* ai_family */
+    SOCK_STREAM,   /* ai_socktype */
+    IPPROTO_TCP    /* ai_protocol */
+  };
+
+  struct addrinfo* server_addr;
+
+  const int ret = getaddrinfo(server_.c_str(), port_.c_str(),
+                              &server_addr_hints, &server_addr);
+  CHECK_EQ(0, ret) << "Invalid server address '" << server_
+                   << "' and/or port '" << port_ << "': "
+                   << gai_strerror(ret);
+
+  bool is_connected = false;
+  while (!is_connected && server_addr != NULL) {
+    fd_ = socket(server_addr->ai_family,
+                 server_addr->ai_socktype,
+                 server_addr->ai_protocol);
+    PCHECK(fd_ >= 0) << "Socket creation failed";
+
+    if (connect(fd_, server_addr->ai_addr, server_addr->ai_addrlen) == 0) {
+      is_connected = true;
+    } else {
+      server_addr = server_addr->ai_next; // Try next address
+    }
+  }
+  freeaddrinfo(server_addr);
+
+  if (!is_connected) {
+    PLOG(ERROR) << "Connection to [" << server_ << "]:" << port_ << " failed";
+    Disconnect();
+    return false;
+  }
+  LOG(INFO) << "Connected to [" << server_ << "]:" << port_;
+  return true;
+}
+
+bool Client::Connected() const {
+  return fd_ > 0;
+}
+
+void Client::Disconnect() {
+  if (fd_ > 0) {
+    close(fd_);
+    LOG(INFO) << "Disconnected from [" << server_ << "]:" << port_;
+    fd_ = -1;
+  }
+}
+
+bool Client::Write(const string& data) {
+  CHECK(Connected());
+  int n = send(fd_, data.data(), data.length(), MSG_NOSIGNAL);
+  if (n <= 0) {
+    PCHECK(errno == EPIPE) << "Send failed";
+    LOG(ERROR) << "Remote server closed the connection.";
+    Disconnect();
+    return false;
+  }
+
+  CHECK_EQ(data.length(), (unsigned)n);
+
+  VLOG(1) << "wrote " << data.length() << " bytes";
+  return true;
+}
+
+bool Client::Read(size_t length, string* result) {
+  CHECK(Connected());
+  char* buf = new char[length];
+  for (size_t offset = 0; offset < length;) {
+    int n = recv(fd_, buf + offset, length - offset, MSG_NOSIGNAL);
+    if (n <= 0) {
+      PCHECK(errno == EPIPE) << "Read failed";
+      LOG(ERROR) << "Remote server closed the connection.";
+      Disconnect();
+      delete[] buf;
+      return false;
+    }
+
+    offset += n;
+  }
+  result->assign(string(buf, length));
+  delete[] buf;
+  VLOG(1) << "read " << length << " bytes";
+  return true;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/client.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/client.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/client.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/client.h	2017-01-15 10:56:31.037591151 +0100
@@ -0,0 +1,43 @@
+#ifndef CERT_TRANS_CLIENT_CLIENT_H_
+#define CERT_TRANS_CLIENT_CLIENT_H_
+
+#include <stdint.h>
+#include <string>
+
+#include "base/macros.h"
+
+// Socket creation for client connections.
+class Client {
+ public:
+  Client(const std::string& server, const std::string& port);
+
+  ~Client();
+
+  // Create a TCP socket and attempt to connect to server:port.
+  // The Connect()-Disconnect() sequence can be called repeatedly.
+  bool Connect();
+
+  int fd() const {
+    return fd_;
+  }
+
+  // The remote end may have closed the socket, in which
+  // case this will still return true, but the next read/write
+  // will fail and disconnect.
+  bool Connected() const;
+
+  void Disconnect();
+
+  bool Write(const std::string& data);
+
+  bool Read(size_t length, std::string* result);
+
+ private:
+  const std::string server_;
+  const std::string port_;
+  int fd_;
+
+  DISALLOW_COPY_AND_ASSIGN(Client);
+};
+
+#endif  // CERT_TRANS_CLIENT_CLIENT_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/ct.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/ct.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/ct.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/ct.cc	2017-01-15 10:56:31.037591151 +0100
@@ -0,0 +1,991 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include <event2/thread.h>
+#include <fcntl.h>
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <openssl/asn1.h>
+#include <openssl/bio.h>
+#include <openssl/bn.h>
+#include <openssl/err.h>
+#include <openssl/evp.h>
+#include <openssl/pem.h>
+#include <openssl/ssl.h>
+#include <openssl/x509.h>
+#include <openssl/x509v3.h>
+#include <stdio.h>
+#include <fstream>
+#include <iostream>
+#include <memory>
+#include <sstream>
+#include <string>
+
+#include "client/http_log_client.h"
+#include "client/ssl_client.h"
+#include "log/cert.h"
+#include "log/cert_submission_handler.h"
+#include "log/ct_extensions.h"
+#include "log/log_signer.h"
+#include "log/log_verifier.h"
+#include "merkletree/merkle_tree.h"
+#include "merkletree/merkle_verifier.h"
+#include "merkletree/serial_hasher.h"
+#include "proto/cert_serializer.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+#include "util/init.h"
+#include "util/openssl_scoped_types.h"
+#include "util/read_key.h"
+#include "util/util.h"
+
+DEFINE_string(ssl_client_trusted_cert_dir, "",
+              "Trusted root certificates for the ssl client");
+DEFINE_string(ct_server_public_key, "",
+              "PEM-encoded public key file of the CT log server");
+DEFINE_string(ssl_server, "", "SSL server to connect to");
+DEFINE_string(ssl_server_port, "https", "SSL server port");
+DEFINE_string(ct_server_submission, "",
+              "Certificate chain to submit to a CT log server. "
+              "The file must consist of concatenated PEM certificates.");
+DEFINE_string(ct_server, "", "CT log server to connect to");
+DEFINE_string(ct_server_response_out, "",
+              "Output file for the Signed Certificate Timestamp received from "
+              "the CT log server");
+DEFINE_bool(precert, false, "The submission is a CA precertificate chain");
+DEFINE_string(sct_token, "",
+              "Input file containing the SCT of the certificate");
+DEFINE_string(ssl_client_ct_data_in, "",
+              "Input file for reading the SSLClientCTData");
+DEFINE_string(ssl_client_ct_data_out, "",
+              "Output file for recording the server's leaf certificate, "
+              "as well as all received and validated SCTs.");
+DEFINE_string(certificate_out, "",
+              "Output file for the superfluous certificate");
+DEFINE_string(tls_extension_data_out, "",
+              "Output file for TLS extension data");
+DEFINE_string(extensions_config_out, "",
+              "Output configuration file to append the sct to. Appends the "
+              "sct to the end of the file, so the relevant section should be "
+              "last in the configuration file.");
+DEFINE_bool(ssl_client_require_sct, true,
+            "Fail the SSL handshake if "
+            "the server presents no valid SCT token");
+DEFINE_bool(ssl_client_expect_handshake_failure, false,
+            "Expect the handshake to fail. If this is set to true, then "
+            "the program exits with 0 iff there is a handshake failure. "
+            "Used for testing.");
+DEFINE_string(certificate_chain_in, "",
+              "Certificate chain to analyze, "
+              "in PEM format");
+DEFINE_string(sct_in, "", "SCT to wrap");
+DEFINE_int32(get_first, 0, "First entry to retrieve with the 'get' command");
+DEFINE_int32(get_last, 0, "Last entry to retrieve with the 'get' command");
+DEFINE_string(certificate_base, "",
+              "Base name for retrieved certificates - "
+              "files will be <base><entry>.<cert>.der");
+DEFINE_uint64(timestamp, 0,
+              "The timestamp to be used in the monitor actions "
+              "verify_sth and confirm_tree.");
+DEFINE_string(sth1, "", "File containing first STH");
+DEFINE_string(sth2, "", "File containing second STH");
+DEFINE_uint64(monitor_sleep_time_secs, 60,
+              "Amount of time the monitor shall "
+              "sleep between probing for a new STH.");
+
+
+static const char kUsage[] =
+    " <command> ...\n"
+    "Known commands:\n"
+    "connect - connect to an SSL server\n"
+    "upload - upload a submission to a CT log server\n"
+    "certificate - make a superfluous proof certificate\n"
+    "extension_data - convert an audit proof to TLS extension format\n"
+    "configure_proof - write the proof in an X509v3 configuration file\n"
+    "diagnose_chain - print info about the SCTs the cert chain carries\n"
+    "wrap - take an SCT and certificate chain and wrap them as if they were\n"
+    "       retrieved via 'connect'\n"
+    "wrap_embedded - take a certificate chain with an embedded SCT and wrap\n"
+    "                them as if they were retrieved via 'connect'\n"
+    "get_roots - get roots from the log\n"
+    "get_entries - get entries from the log\n"
+    "sth - get the current STH from the log\n"
+    "consistency - get and check consistency of two STHs\n"
+    "Use --help to display command-line flag options\n";
+
+using cert_trans::AsyncLogClient;
+using cert_trans::Cert;
+using cert_trans::CertChain;
+using cert_trans::CertSubmissionHandler;
+using cert_trans::HTTPLogClient;
+using cert_trans::PreCertChain;
+using cert_trans::ReadPublicKey;
+using cert_trans::SSLClient;
+using cert_trans::ScopedASN1_OCTET_STRING;
+using cert_trans::ScopedBIGNUM;
+using cert_trans::ScopedBIO;
+using cert_trans::ScopedEVP_PKEY;
+using cert_trans::ScopedRSA;
+using cert_trans::ScopedX509;
+using cert_trans::ScopedX509_NAME;
+using cert_trans::TbsCertificate;
+using cert_trans::serialization::SerializeResult;
+using cert_trans::serialization::DeserializeResult;
+using ct::LogEntry;
+using ct::MerkleAuditProof;
+using ct::SSLClientCTData;
+using ct::SignedCertificateTimestamp;
+using ct::SignedCertificateTimestampList;
+using ct::SignedTreeHead;
+using std::shared_ptr;
+using std::string;
+using std::unique_ptr;
+using std::vector;
+using util::Status;
+using util::StatusOr;
+
+// SCTs presented to clients have to be encoded as a list.
+// Helper method for encoding a single SCT.
+static string SCTToList(const string& serialized_sct) {
+  SignedCertificateTimestampList sct_list;
+  sct_list.add_sct_list(serialized_sct);
+  string result;
+  CHECK_EQ(SerializeResult::OK,
+           Serializer::SerializeSCTList(sct_list, &result));
+  return result;
+}
+
+static LogVerifier* GetLogVerifierFromFlags() {
+  CHECK(!FLAGS_ct_server_public_key.empty()) <<
+    "Please give a CT server public key file with --ct_server_public_key";
+
+  StatusOr<EVP_PKEY*> pkey(ReadPublicKey(FLAGS_ct_server_public_key));
+  CHECK(pkey.ok()) << "could not read CT server public key file: "
+                   << pkey.status();
+
+  return new LogVerifier(new LogSigVerifier(pkey.ValueOrDie()),
+                         new MerkleVerifier(
+                             unique_ptr<Sha256Hasher>(new Sha256Hasher)));
+}
+
+// Adds the data to the cert as an extension, formatted as a single
+// ASN.1 octet string.
+static void AddOctetExtension(X509* cert, int nid, const unsigned char* data,
+                              int data_len, int critical) {
+  // The extension as a single octet string.
+  ScopedASN1_OCTET_STRING inner(ASN1_OCTET_STRING_new());
+  CHECK_NOTNULL(inner.get());
+  CHECK_EQ(1, ASN1_OCTET_STRING_set(inner.get(), data, data_len));
+  int buf_len = i2d_ASN1_OCTET_STRING(inner.get(), NULL);
+  CHECK_GT(buf_len, 0);
+
+  unsigned char buf[buf_len];
+  unsigned char* p = buf;
+
+  CHECK_EQ(buf_len, i2d_ASN1_OCTET_STRING(inner.get(), &p));
+
+  // The outer, opaque octet string.
+  ScopedASN1_OCTET_STRING asn1_data(ASN1_OCTET_STRING_new());
+  CHECK_NOTNULL(asn1_data.get());
+  CHECK_EQ(1, ASN1_OCTET_STRING_set(asn1_data.get(), buf, buf_len));
+
+  X509_EXTENSION* ext =
+      X509_EXTENSION_create_by_NID(NULL, nid, critical, asn1_data.get());
+  CHECK_EQ(1, X509_add_ext(cert, ext, -1));
+}
+
+// Reconstructs a LogEntry from the given precert chain.
+// Used for verifying a Precert SCT.
+// Returns true iff the LogEntry was correctly populated.
+static bool PrecertChainToEntry(const cert_trans::PreCertChain& chain,
+                                LogEntry* entry) {
+  if (!chain.IsLoaded()) {
+    LOG(ERROR) << "Chain not loaded.";
+    return false;
+  }
+
+  const StatusOr<bool> has_poison =
+      chain.LeafCert()->HasExtension(cert_trans::NID_ctPoison);
+  if (!has_poison.ok()) {
+    LOG(ERROR) << "Failed to test for poison extension.";
+    return false;
+  }
+
+  if (!has_poison.ValueOrDie()) {
+    LOG(ERROR) << "Leaf cert doesn't seem to be a Precertificate (no Poison).";
+    return false;
+  }
+
+  if (chain.Length() < 2) {
+    LOG(ERROR) << "Need issuer.";
+    return false;
+  }
+
+  entry->set_type(ct::PRECERT_ENTRY);
+  string key_hash;
+  if (!chain.CertAt(1)->SPKISha256Digest(&key_hash).ok()) {
+    LOG(ERROR) << "Failed to get SPKISha256.";
+    return false;
+  }
+
+  entry->mutable_precert_entry()->mutable_pre_cert()->set_issuer_key_hash(
+      key_hash);
+
+  TbsCertificate tbs(*chain.LeafCert());
+  if (!tbs.IsLoaded()) {
+    LOG(ERROR) << "Failed to get TbsCertificate.";
+    return false;
+  }
+  // DeleteExtension can return NOT_FOUND but we checked the extension exists
+  // above so this is not expected.
+  if (!tbs.DeleteExtension(cert_trans::NID_ctPoison).ok()) {
+    LOG(ERROR) << "Failed to delete poison extension.";
+    return false;
+  }
+
+  string tbs_der;
+  if (!tbs.DerEncoding(&tbs_der).ok()) {
+    LOG(ERROR) << "Couldn't serialize TbsCertificate to DER.";
+    return false;
+  }
+
+  entry->mutable_precert_entry()->mutable_pre_cert()->set_tbs_certificate(
+      tbs_der);
+  return true;
+}
+
+static bool VerifySCTAndPopulateSSLClientCTData(
+    const SignedCertificateTimestamp& sct, SSLClientCTData* ct_data) {
+  SSLClientCTData::SCTInfo* sct_info = ct_data->add_attached_sct_info();
+  sct_info->mutable_sct()->CopyFrom(sct);
+  const unique_ptr<LogVerifier> verifier(GetLogVerifierFromFlags());
+  string merkle_leaf;
+  LogVerifier::LogVerifyResult result =
+      verifier->VerifySignedCertificateTimestamp(
+          ct_data->reconstructed_entry(), sct, &merkle_leaf);
+  if (result != LogVerifier::VERIFY_OK) {
+    LOG(ERROR) << "Verifier returned '" << LogVerifier::VerifyResultString(result)
+               << "' (" << result << ")";
+    return false;
+  }
+
+  sct_info->set_merkle_leaf_hash(merkle_leaf);
+
+  return true;
+}
+
+// Checks an SCT issued for an X.509 Certificate.
+static bool CheckSCT(const SignedCertificateTimestamp& sct,
+                     const CertChain& chain, SSLClientCTData* ct_data) {
+  LogEntry entry;
+  if (!CertSubmissionHandler::X509ChainToEntry(chain, &entry)) {
+    LOG(ERROR) << "Failed to reconstruct log entry input from chain";
+    return false;
+  }
+  ct_data->mutable_reconstructed_entry()->CopyFrom(entry);
+  return VerifySCTAndPopulateSSLClientCTData(sct, ct_data);
+}
+
+// Checks an SCT issued for a Precert.
+static bool CheckSCT(const SignedCertificateTimestamp& sct,
+                     const PreCertChain& chain, SSLClientCTData* ct_data) {
+  LogEntry entry;
+  if (!PrecertChainToEntry(chain, &entry)) {
+    LOG(ERROR) << "Failed to reconstruct log entry input from precert chain";
+    return false;
+  }
+  ct_data->mutable_reconstructed_entry()->CopyFrom(entry);
+  return VerifySCTAndPopulateSSLClientCTData(sct, ct_data);
+}
+
+void WriteFile(const std::string& file, const std::string& contents,
+               const char* name) {
+  if (file.empty()) {
+    LOG(WARNING) << "No response file specified; " << name
+                 << " will not be saved.";
+    return;
+  }
+  std::ofstream out(file.c_str(), std::ios::out | std::ios::binary);
+  PCHECK(out.good()) << "Could not open file " << file << " for writing";
+  out.write(contents.data(), contents.size());
+  out.close();
+  LOG(INFO) << name << " saved in " << file;
+}
+
+// Returns true if the server responds with a token; false if
+// it responds with an error.
+// 0 - ok
+// 1 - server says no
+// 2 - server unavailable
+static int Upload() {
+  // Contents should be concatenated PEM entries.
+  string contents;
+  string submission_file = FLAGS_ct_server_submission;
+  PCHECK(util::ReadBinaryFile(submission_file, &contents))
+      << "Could not read CT log server submission from " << submission_file;
+
+  LOG(INFO) << "Uploading certificate submission from " << submission_file;
+  LOG(INFO) << submission_file << " is " << contents.length() << " bytes.";
+
+  HTTPLogClient client(FLAGS_ct_server);
+  const StatusOr<SignedCertificateTimestamp> sct(
+      client.UploadSubmission(contents, FLAGS_precert));
+
+  if (!sct.status().ok()) {
+    LOG(ERROR) << "Submission failed: " << sct.status();
+    return 1;
+  }
+
+  // Verify the SCT if we can:
+  if (FLAGS_precert) {
+    SSLClientCTData ct_data;
+    PreCertChain chain(contents);
+    // Need the issuing cert, otherwise we can't calculate its hash...
+    if (chain.Length() > 1) {
+      CHECK(CheckSCT(sct.ValueOrDie(), chain, &ct_data));
+    } else {
+      LOG(WARNING) << "Unable to verify Precert SCT without issuing "
+                   << "certificate in chain.";
+    }
+  } else {
+    // SCT for a vanilla X.509 Cert.
+    SSLClientCTData ct_data;
+    CertChain chain(contents);
+    // FIXME: this'll fail if we're uploading a cert which already has an
+    // embedded SCT in it, and the issuing cert is not included in the chain
+    // since we'll need to create the precert entry under the covers.
+    CHECK(CheckSCT(sct.ValueOrDie(), chain, &ct_data));
+  }
+
+  // TODO(ekasper): Process the |contents| bundle so that we can verify
+  // the token.
+
+  string proof;
+  if (Serializer::SerializeSCT(sct.ValueOrDie(), &proof) !=
+      SerializeResult::OK) {
+    LOG(ERROR) << "Failed to serialize the server token";
+    return 1;
+  }
+  WriteFile(FLAGS_ct_server_response_out, proof, "SCT token");
+  return 0;
+}
+
+// FIXME: fix all the memory leaks in this code.
+static void MakeCert() {
+  string sct;
+  PCHECK(util::ReadBinaryFile(FLAGS_sct_token, &sct))
+      << "Could not read SCT data from " << FLAGS_sct_token;
+
+  string cert_file = FLAGS_certificate_out;
+
+  int cert_fd = open(cert_file.c_str(), O_CREAT | O_TRUNC | O_WRONLY, 0666);
+  PCHECK(cert_fd > 0) << "Could not open certificate file " << cert_file
+                      << " for writing.";
+
+  ScopedBIO out(BIO_new_fd(cert_fd, BIO_CLOSE));
+
+  ScopedX509 x(X509_new());
+
+  // X509v3 (== 2)
+  X509_set_version(x.get(), 2);
+
+  // Random 128 bit serial number
+  ScopedBIGNUM serial(BN_new());
+  BN_rand(serial.get(), 128, 0, 0);
+  BN_to_ASN1_INTEGER(serial.get(), X509_get_serialNumber(x.get()));
+
+  // Set signature algorithm
+  // FIXME: is there an opaque way to get the algorithm structure?
+  // FIXME: Sort out const/non-const OpenssL/BoringSSL mismatch.
+  x->cert_info->signature->algorithm = const_cast<ASN1_OBJECT*>(OBJ_nid2obj(NID_sha1WithRSAEncryption));
+  x->cert_info->signature->parameter = NULL;
+
+  // Set the start date to now
+  X509_gmtime_adj(X509_get_notBefore(x.get()), 0);
+  // End date to now + 1 second
+  X509_gmtime_adj(X509_get_notAfter(x.get()), 1);
+
+  // Create the issuer name
+  ScopedX509_NAME issuer(X509_NAME_new());
+  X509_NAME_add_entry_by_NID(
+      issuer.get(), NID_commonName, V_ASN1_PRINTABLESTRING,
+      const_cast<unsigned char*>(
+          reinterpret_cast<const unsigned char*>("Test")),
+      4, 0, -1);
+  X509_set_issuer_name(x.get(), issuer.release());
+
+  // Create the subject name
+  ScopedX509_NAME subject(X509_NAME_new());
+  X509_NAME_add_entry_by_NID(
+      subject.get(), NID_commonName, V_ASN1_PRINTABLESTRING,
+      const_cast<unsigned char*>(
+          reinterpret_cast<const unsigned char*>("tseT")),
+      4, 0, -1);
+  X509_set_subject_name(x.get(), subject.release());
+
+  // Public key
+  ScopedRSA rsa(RSA_new());
+  static const unsigned char bits[1] = {3};
+  rsa->n = BN_bin2bn(bits, 1, NULL);
+  rsa->e = BN_bin2bn(bits, 1, NULL);
+  ScopedEVP_PKEY evp_pkey(EVP_PKEY_new());
+  EVP_PKEY_assign_RSA(evp_pkey.get(), rsa.release());
+  X509_PUBKEY_set(&X509_get_X509_PUBKEY(x), evp_pkey.release());
+
+  // And finally, the proof in an extension
+  const string serialized_sct_list(SCTToList(sct));
+  AddOctetExtension(x.get(), cert_trans::NID_ctSignedCertificateTimestampList,
+                    reinterpret_cast<const unsigned char*>(
+                        serialized_sct_list.data()),
+                    serialized_sct_list.size(), 1);
+
+  CHECK_GT(i2d_X509_bio(out.get(), x.get()), 0);
+}
+
+// A sample tool for CAs showing how to add the CT proof as an extension.
+// We write the CT proof to the certificate config, so that we can
+// sign using the standard openssl signing flow.
+// Input:
+// (1) an X509v3 configuration file
+// (2) A binary proof file.
+// Output:
+// Append the following line to the end of the file.
+// (This means the relevant section should be last in the configuration.)
+// 1.2.3.1=DER:[raw encoding of proof]
+static void WriteProofToConfig() {
+  CHECK(!FLAGS_sct_token.empty()) << google::ProgramUsage();
+  CHECK(!FLAGS_extensions_config_out.empty()) << google::ProgramUsage();
+
+  string sct;
+
+  PCHECK(util::ReadBinaryFile(FLAGS_sct_token, &sct))
+      << "Could not read SCT data from " << FLAGS_sct_token;
+
+  string serialized_sct_list = SCTToList(sct);
+
+  string conf_file = FLAGS_extensions_config_out;
+
+  std::ofstream conf_out(conf_file.c_str(), std::ios::app);
+  PCHECK(conf_out.good()) << "Could not open extensions configuration file "
+                          << conf_file << " for writing.";
+
+  conf_out << string(cert_trans::kEmbeddedSCTListOID)
+           << "=ASN1:FORMAT:HEX,OCTETSTRING:";
+
+  conf_out << util::HexString(serialized_sct_list) << std::endl;
+  conf_out.close();
+}
+
+static const char kPEMLabel[] = "SERVERINFO FOR SIGNED CERTIFICATE TIMESTAMP";
+
+// Wrap the proof in the format expected by the TLS extension,
+// so that we can feed it to OpenSSL.
+static void ProofToExtensionData() {
+  CHECK(!FLAGS_sct_token.empty()) << google::ProgramUsage();
+  CHECK(!FLAGS_tls_extension_data_out.empty()) << google::ProgramUsage();
+
+  string serialized_sct;
+  PCHECK(util::ReadBinaryFile(FLAGS_sct_token, &serialized_sct))
+      << "Could not read SCT data from " << FLAGS_sct_token;
+  std::ifstream proof_in(FLAGS_sct_token.c_str(),
+                         std::ios::in | std::ios::binary);
+  PCHECK(proof_in.good()) << "Could not read SCT data from "
+                          << FLAGS_sct_token;
+
+  // Count proof length.
+  proof_in.seekg(0, std::ios::end);
+  int proof_length = proof_in.tellg();
+  // Rewind.
+  proof_in.seekg(0, std::ios::beg);
+
+  // Read the proof
+  char* buf = new char[proof_length];
+  proof_in.read(buf, proof_length);
+  CHECK_EQ(proof_in.gcount(), proof_length);
+
+  SignedCertificateTimestampList sctlist;
+  sctlist.add_sct_list(buf, proof_length);
+  delete[] buf;
+
+  string sctliststr;
+  CHECK_EQ(Serializer::SerializeSCTList(sctlist, &sctliststr),
+           SerializeResult::OK);
+
+  std::ostringstream extension_data_out;
+
+  // Write the extension type (18), MSB first.
+  extension_data_out << '\0' << '\x12';
+
+  // Write the length, MSB first.
+  extension_data_out << static_cast<unsigned char>(sctliststr.length() >> 8)
+                     << static_cast<unsigned char>(sctliststr.length());
+
+  // Now write the proof.
+  extension_data_out.write(sctliststr.data(), sctliststr.length());
+  CHECK(!extension_data_out.bad());
+
+  proof_in.close();
+
+  FILE* out = fopen(FLAGS_tls_extension_data_out.c_str(), "w");
+  PCHECK(out != NULL) << "Could not open extension data file "
+                      << FLAGS_tls_extension_data_out
+                      << " for writing:" << strerror(errno);
+
+// Work around broken PEM_write() declaration in older OpenSSL versions.
+#if OPENSSL_VERSION_NUMBER < 0x10002000L
+  PEM_write(out, const_cast<char*>(kPEMLabel), const_cast<char*>(""),
+            const_cast<unsigned char*>(reinterpret_cast<const unsigned char*>(
+                extension_data_out.str().data())),
+            extension_data_out.str().length());
+#else
+  PEM_write(out, kPEMLabel, "", reinterpret_cast<const unsigned char*>(
+                                    extension_data_out.str().data()),
+            extension_data_out.str().length());
+#endif
+
+  fclose(out);
+}
+
+static void WriteSSLClientCTData(const SSLClientCTData& ct_data,
+                                 const string& ct_data_out_file) {
+  std::ofstream checkpoint_out(ct_data_out_file.c_str(),
+                               std::ios::out | std::ios::binary);
+  PCHECK(checkpoint_out.good()) << "Could not open checkpoint file "
+                                << ct_data_out_file << " for writing";
+  string serialized_data;
+  CHECK(ct_data.SerializeToString(&serialized_data));
+  checkpoint_out << serialized_data;
+  checkpoint_out.close();
+}
+
+// Return values upon completion
+//  0: handshake ok
+//  1: handshake error
+//  2: connection error
+static SSLClient::HandshakeResult Connect() {
+  LogVerifier* verifier = GetLogVerifierFromFlags();
+
+  CHECK(!FLAGS_ssl_server.empty()) << "Must specify --ssl_server";
+  CHECK(!FLAGS_ssl_server_port.empty()) << "Must specify --ssl_server_port";
+
+  SSLClient client(FLAGS_ssl_server, FLAGS_ssl_server_port,
+                   FLAGS_ssl_client_trusted_cert_dir, verifier);
+
+  SSLClient::HandshakeResult result;
+
+  if (FLAGS_ssl_client_require_sct)
+    result = client.SSLConnectStrict();
+  else
+    result = client.SSLConnect();
+
+  if (result == SSLClient::OK) {
+    SSLClientCTData ct_data;
+    client.GetSSLClientCTData(&ct_data);
+    if (ct_data.attached_sct_info_size() > 0) {
+      LOG(INFO) << "Received " << ct_data.attached_sct_info_size() << " SCTs";
+      VLOG(1) << "Received SCTs:";
+      for (int i = 0; i < ct_data.attached_sct_info_size(); ++i)
+        VLOG(1) << ct_data.attached_sct_info(i).DebugString();
+      if (!FLAGS_ssl_client_ct_data_out.empty())
+        WriteSSLClientCTData(ct_data, FLAGS_ssl_client_ct_data_out);
+    }
+  }
+  return result;
+}
+
+enum AuditResult {
+  // At least one SCT has a valid proof.
+  // (Should be unusual to have more than one SCT from the same log,
+  // but we audit them all and try to see if any are valid).
+  PROOF_OK = 0,
+  // No SCTs have valid proofs.
+  PROOF_NOT_FOUND = 1,
+  CT_SERVER_UNAVAILABLE = 2,
+};
+
+static AuditResult Audit() {
+  string serialized_data;
+  PCHECK(util::ReadBinaryFile(FLAGS_ssl_client_ct_data_in, &serialized_data))
+      << "Could not read CT data from " << FLAGS_ssl_client_ct_data_in;
+  SSLClientCTData ct_data;
+  CHECK(ct_data.ParseFromString(serialized_data))
+      << "Failed to parse the stored certificate CT data";
+  CHECK(ct_data.has_reconstructed_entry());
+  CHECK_GT(ct_data.attached_sct_info_size(), 0);
+
+  LogVerifier* verifier = GetLogVerifierFromFlags();
+  string key_id = verifier->KeyID();
+
+  AuditResult audit_result = PROOF_NOT_FOUND;
+
+  for (int i = 0; i < ct_data.attached_sct_info_size(); ++i) {
+    LOG(INFO) << "Signed Certificate Timestamp number " << i + 1 << ":\n"
+              << ct_data.attached_sct_info(i).sct().DebugString();
+
+    string sct_id = ct_data.attached_sct_info(i).sct().id().key_id();
+    if (sct_id != key_id) {
+      LOG(WARNING) << "Audit skipped: log server Key ID " << sct_id
+                   << " does not match verifier's ID";
+      continue;
+    }
+
+    HTTPLogClient client(FLAGS_ct_server);
+
+    LOG(INFO) << "info = " << ct_data.attached_sct_info(i).DebugString();
+    const StatusOr<MerkleAuditProof> proof_http(client.QueryAuditProof(
+        ct_data.attached_sct_info(i).merkle_leaf_hash()));
+
+    if (!proof_http.status().ok()) {
+      LOG(ERROR) << "QueryAuditProof failed: " << proof_http.status();
+      continue;
+    }
+
+    MerkleAuditProof proof(proof_http.ValueOrDie());
+    // HTTP protocol does not supply this.
+    proof.mutable_id()->set_key_id(sct_id);
+
+    LOG(INFO) << "Received proof:\n" << proof.DebugString();
+    LogVerifier::LogVerifyResult res =
+        verifier->VerifyMerkleAuditProof(ct_data.reconstructed_entry(),
+                                         ct_data.attached_sct_info(i).sct(),
+                                         proof);
+    if (res != LogVerifier::VERIFY_OK) {
+      LOG(ERROR) << "Verify error: " << LogVerifier::VerifyResultString(res);
+      LOG(ERROR) << "Retrieved Merkle proof is invalid.";
+      continue;
+    }
+    LOG(INFO) << "Proof verified.";
+    audit_result = PROOF_OK;
+  }
+  delete verifier;
+  return audit_result;
+}
+
+static int CheckConsistency() {
+  HTTPLogClient client(FLAGS_ct_server);
+  unique_ptr<LogVerifier> verifier(GetLogVerifierFromFlags());
+
+  string sth1_str;
+  PCHECK(util::ReadBinaryFile(FLAGS_sth1, &sth1_str)) << "Can't read STH file "
+                                                      << FLAGS_sth1;
+  SignedTreeHead sth1;
+  CHECK(sth1.ParseFromString(sth1_str));
+  string sth2_str;
+  PCHECK(util::ReadBinaryFile(FLAGS_sth2, &sth2_str)) << "Can't read STH file "
+                                                      << FLAGS_sth2;
+  SignedTreeHead sth2;
+  CHECK(sth2.ParseFromString(sth2_str));
+
+  const StatusOr<vector<string>> proof(
+      client.GetSTHConsistency(sth1.tree_size(), sth2.tree_size()));
+  CHECK_EQ(Status::OK, proof.status());
+
+  if (!verifier->VerifyConsistency(sth1, sth2, proof.ValueOrDie())) {
+    LOG(ERROR) << "Consistency proof does not verify";
+    return 1;
+  }
+
+  LOG(INFO) << "Consistency proof verifies";
+
+  return 0;
+}
+
+static void DiagnoseCertChain() {
+  string cert_file = FLAGS_certificate_chain_in;
+  CHECK(!cert_file.empty()) << "Please give a certificate chain with "
+                            << "--certificate_chain_in";
+  string pem_chain;
+  PCHECK(util::ReadBinaryFile(cert_file, &pem_chain))
+      << "Could not read certificate chain from " << cert_file;
+  CertChain chain(pem_chain);
+  CHECK(chain.IsLoaded()) << cert_file
+                          << " is not a valid PEM-encoded certificate chain";
+
+
+  const StatusOr<bool> has_timestamp_list = chain.LeafCert()->HasExtension(
+      cert_trans::NID_ctEmbeddedSignedCertificateTimestampList);
+  if (!has_timestamp_list.ok() || !has_timestamp_list.ValueOrDie()) {
+    LOG(ERROR) << "Certificate has no embedded SCTs";
+    return;
+  }
+
+  LOG(INFO) << "Embedded proof extension found in certificate";
+
+  unique_ptr<LogVerifier> verifier;
+  LogEntry entry;
+  if (FLAGS_ct_server_public_key.empty()) {
+    LOG(WARNING) << "No log server public key given, skipping verification";
+  } else {
+    verifier.reset(GetLogVerifierFromFlags());
+    CertSubmissionHandler::X509ChainToEntry(chain, &entry);
+  }
+
+  string serialized_scts;
+  util::Status status = chain.LeafCert()->OctetStringExtensionData(
+      cert_trans::NID_ctEmbeddedSignedCertificateTimestampList,
+      &serialized_scts);
+  if (!status.ok()) {
+    LOG(ERROR) << "SCT extension data is missing / invalid.";
+    return;
+  }
+
+  LOG(INFO) << "Embedded SCT extension length is " << serialized_scts.length()
+            << " bytes";
+
+  SignedCertificateTimestampList sct_list;
+  if (Deserializer::DeserializeSCTList(serialized_scts, &sct_list) !=
+      DeserializeResult::OK) {
+    LOG(ERROR) << "Failed to parse SCT list from certificate";
+    return;
+  }
+
+  LOG(INFO) << "Certificate has " << sct_list.sct_list_size() << " SCTs";
+  for (int i = 0; i < sct_list.sct_list_size(); ++i) {
+    SignedCertificateTimestamp sct;
+    if (Deserializer::DeserializeSCT(sct_list.sct_list(i), &sct) !=
+        DeserializeResult::OK) {
+      LOG(ERROR) << "Failed to parse SCT number " << i + 1;
+      continue;
+    }
+    LOG(INFO) << "SCT number " << i + 1 << ":\n" << sct.DebugString();
+    if (verifier) {
+      if (sct.id().key_id() != verifier->KeyID()) {
+        LOG(WARNING) << "SCT key ID does not match verifier's ID, skipping";
+        continue;
+      } else {
+        LogVerifier::LogVerifyResult res =
+            verifier->VerifySignedCertificateTimestamp(entry, sct);
+        if (res == LogVerifier::VERIFY_OK)
+          LOG(INFO) << "SCT verified";
+        else
+          LOG(ERROR) << "SCT verification failed: "
+                     << LogVerifier::VerifyResultString(res);
+      }
+    }
+  }
+}
+
+// Wrap an SCT in an SSLClientCTData as if it came from an SSL server.
+void Wrap() {
+  string serialized_data;
+  PCHECK(util::ReadBinaryFile(FLAGS_sct_in, &serialized_data))
+      << "Could not read SCT data from " << FLAGS_sct_in;
+  SignedCertificateTimestamp sct;
+  CHECK_EQ(Deserializer::DeserializeSCT(serialized_data, &sct),
+           DeserializeResult::OK);
+
+  // FIXME(benl): This code is shared with DiagnoseCertChain().
+  string cert_file = FLAGS_certificate_chain_in;
+  CHECK(!cert_file.empty()) << "Please give a certificate chain with "
+                            << "--certificate_chain_in";
+  string pem_chain;
+  PCHECK(util::ReadBinaryFile(cert_file, &pem_chain))
+      << "Could not read certificate chain from " << cert_file;
+  CertChain chain(pem_chain);
+  CHECK(chain.IsLoaded()) << cert_file
+                          << " is not a valid PEM-encoded certificate chain";
+
+  SSLClientCTData ct_data;
+  CHECK(CheckSCT(sct, chain, &ct_data));
+
+  WriteSSLClientCTData(ct_data, FLAGS_ssl_client_ct_data_out);
+}
+
+// Wrap an embedded SCT in an SSLClientCTData as if it came from an SSL server.
+void WrapEmbedded() {
+  // FIXME(benl): This code is shared with DiagnoseCertChain().
+  string cert_file = FLAGS_certificate_chain_in;
+  CHECK(!cert_file.empty()) << "Please give a certificate chain with "
+                            << "--certificate_chain_in";
+  string pem_chain;
+  PCHECK(util::ReadBinaryFile(cert_file, &pem_chain))
+      << "Could not read certificate chain from " << cert_file;
+  CertChain chain(pem_chain);
+  CHECK(chain.IsLoaded()) << cert_file
+                          << " is not a valid PEM-encoded certificate chain";
+  CHECK(chain.LeafCert()
+            ->HasExtension(
+                cert_trans::NID_ctEmbeddedSignedCertificateTimestampList)
+            .ValueOrDie());
+
+  string serialized_scts;
+  CHECK_EQ(::util::Status::OK,
+           chain.LeafCert()->OctetStringExtensionData(
+               cert_trans::NID_ctEmbeddedSignedCertificateTimestampList,
+               &serialized_scts));
+  SignedCertificateTimestampList sct_list;
+  CHECK_EQ(DeserializeResult::OK,
+           Deserializer::DeserializeSCTList(serialized_scts, &sct_list));
+
+  // FIXME(benl): handle multiple SCTs!
+  CHECK_EQ(1, sct_list.sct_list().size());
+
+  SignedCertificateTimestamp sct;
+  CHECK_EQ(Deserializer::DeserializeSCT(sct_list.sct_list(0), &sct),
+           DeserializeResult::OK);
+
+  SSLClientCTData ct_data;
+  CHECK(CheckSCT(sct, chain, &ct_data));
+
+  WriteSSLClientCTData(ct_data, FLAGS_ssl_client_ct_data_out);
+}
+
+static void WriteCertificate(const std::string& cert, int entry,
+                             int cert_number, const char* type) {
+  std::ostringstream outname;
+  outname << FLAGS_certificate_base << entry << '.' << cert_number << '.'
+          << type << ".der";
+  std::ofstream out(outname.str().c_str(), std::ios::binary | std::ios::trunc);
+  CHECK(out.good());
+  out << cert;
+}
+
+void GetEntries() {
+  CHECK_NE(FLAGS_ct_server, "");
+  HTTPLogClient client(FLAGS_ct_server);
+  const StatusOr<vector<AsyncLogClient::Entry>> entries(
+      client.GetEntries(FLAGS_get_first, FLAGS_get_last));
+  CHECK_EQ(entries.status(), Status::OK);
+
+  CHECK(!FLAGS_certificate_base.empty());
+
+  int e = FLAGS_get_first;
+  for (vector<AsyncLogClient::Entry>::const_iterator
+           entry = entries.ValueOrDie().begin();
+       entry != entries.ValueOrDie().end(); ++entry, ++e) {
+    if (entry->leaf.timestamped_entry().entry_type() == ct::X509_ENTRY) {
+      WriteCertificate(entry->leaf.timestamped_entry().signed_entry().x509(),
+                       e, 0, "x509");
+      const ct::X509ChainEntry& x509chain = entry->entry.x509_entry();
+      for (int n = 0; n < x509chain.certificate_chain_size(); ++n)
+        WriteCertificate(x509chain.certificate_chain(n), e, n + 1, "x509");
+    } else {
+      CHECK_EQ(entry->leaf.timestamped_entry().entry_type(),
+               ct::PRECERT_ENTRY);
+      WriteCertificate(entry->leaf.timestamped_entry()
+                           .signed_entry()
+                           .precert()
+                           .tbs_certificate(),
+                       e, 0, "pre");
+      const ct::PrecertChainEntry& precertchain = entry->entry.precert_entry();
+      for (int n = 0; n < precertchain.precertificate_chain_size(); ++n)
+        WriteCertificate(precertchain.precertificate_chain(n), e, n + 1,
+                         "x509");
+    }
+  }
+}
+
+int GetRoots() {
+  HTTPLogClient client(FLAGS_ct_server);
+
+  const StatusOr<vector<unique_ptr<Cert>>> roots(client.GetRoots());
+  CHECK_EQ(roots.status(), Status::OK);
+
+  LOG(INFO) << "number of certs: " << roots.ValueOrDie().size();
+  for (vector<unique_ptr<Cert>>::const_iterator it =
+           roots.ValueOrDie().begin();
+       it != roots.ValueOrDie().end(); ++it) {
+    string pem_cert;
+    CHECK_EQ((*it)->PemEncoding(&pem_cert), util::Status::OK);
+    std::cout << pem_cert;
+  }
+
+  std::cout << std::endl;
+
+  return 0;
+}
+
+int GetSTH() {
+  CHECK_NE(FLAGS_ct_server, "");
+
+  HTTPLogClient client(FLAGS_ct_server);
+
+  const StatusOr<SignedTreeHead> sth(client.GetSTH());
+  CHECK_EQ(sth.status(), Status::OK);
+
+  const unique_ptr<LogVerifier> verifier(GetLogVerifierFromFlags());
+
+  // Allow for 10 seconds of clock skew
+  uint64_t latest = ((uint64_t)time(NULL) + 10) * 1000;
+  const LogVerifier::LogVerifyResult result =
+      verifier->VerifySignedTreeHead(sth.ValueOrDie(), 0, latest);
+
+  LOG(INFO) << "STH is " << sth.ValueOrDie().DebugString();
+
+  if (result != LogVerifier::VERIFY_OK) {
+    if (result == LogVerifier::INVALID_TIMESTAMP)
+      LOG(ERROR) << "STH has bad timestamp (" << sth.ValueOrDie().timestamp()
+                 << ")";
+    else if (result == LogVerifier::INVALID_SIGNATURE)
+      LOG(ERROR) << "STH signature doesn't validate";
+    else
+      LOG(ERROR) << "STH validation failed with unknown error " << result;
+    return 1;
+  }
+
+  string sth_str;
+  CHECK(sth.ValueOrDie().SerializeToString(&sth_str));
+  WriteFile(FLAGS_ct_server_response_out, sth_str, "STH");
+
+  return 0;
+}
+
+
+// Exit code upon normal exit:
+// 0: success
+// 1: failure
+// - for log server: connection failed or the server replied with an error
+// - for SSL server: connection failed, handshake failed when success was
+//                   expected or vice versa
+// 2: initial connection to the (log/ssl) server failed
+// Exit code upon abnormal exit (CHECK failures): != 0
+// (on UNIX, 134 is expected)
+int main(int argc, char** argv) {
+  google::SetUsageMessage(argv[0] + string(kUsage));
+  util::InitCT(&argc, &argv);
+  ConfigureSerializerForV1CT();
+
+  const string main_command(argv[0]);
+  if (argc < 2) {
+    std::cout << google::ProgramUsage();
+    return 1;
+  }
+
+  const string cmd(argv[1]);
+
+  int ret = 0;
+  if (cmd == "connect") {
+    bool want_fail = FLAGS_ssl_client_expect_handshake_failure;
+    SSLClient::HandshakeResult result = Connect();
+    if ((!want_fail && result != SSLClient::OK) ||
+        (want_fail && result != SSLClient::HANDSHAKE_FAILED))
+      ret = 1;
+  } else if (cmd == "upload") {
+    ret = Upload();
+  } else if (cmd == "audit") {
+    ret = Audit();
+  } else if (cmd == "consistency") {
+    ret = CheckConsistency();
+  } else if (cmd == "certificate") {
+    MakeCert();
+  } else if (cmd == "extension_data") {
+    ProofToExtensionData();
+  } else if (cmd == "configure_proof") {
+    WriteProofToConfig();
+  } else if (cmd == "diagnose_chain") {
+    DiagnoseCertChain();
+  } else if (cmd == "wrap") {
+    Wrap();
+  } else if (cmd == "wrap_embedded") {
+    WrapEmbedded();
+  } else if (cmd == "get_entries") {
+    GetEntries();
+  } else if (cmd == "get_roots") {
+    ret = GetRoots();
+  } else if (cmd == "sth") {
+    ret = GetSTH();
+  } else {
+    std::cout << google::ProgramUsage();
+    ret = 1;
+  }
+
+  return ret;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/fix-chain.py src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/fix-chain.py
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/fix-chain.py	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/fix-chain.py	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,280 @@
+#!/usr/bin/env python
+
+# Given a certificate chain that the log won't accept, try to fix it up
+# into one that will be accepted.
+
+# Based on pyasn1 example code.
+
+from base64 import b64encode
+from ct.crypto.pem import PemError
+from ct.crypto.pem import from_pem
+from pyasn1 import debug
+# Why doesn't this work?
+#from pyasn1.codec.ber import stDumpRawValue
+from pyasn1.codec.der import decoder
+from pyasn1.codec.der import encoder
+from pyasn1.error import PyAsn1Error
+from pyasn1.type import namedtype
+from pyasn1.type import univ
+from pyasn1_modules import pem
+from pyasn1_modules import rfc2459
+from pyasn1_modules import rfc2315
+import sys
+from urllib2 import urlopen
+
+if len(sys.argv) != 2:
+  print """Usage:
+  $ %s somecertificates.pem""" % sys.argv[0]
+  sys.exit(-1)
+
+cStart = '-----BEGIN CERTIFICATE-----'
+cEnd = '-----END CERTIFICATE-----'
+
+certType = rfc2459.Certificate()
+
+# RFC 2459 is not sufficient for X509v3 certificates, extra stuff here.
+# RFC 5280 4.2.2.1
+
+id_pe_authorityInfoAccess = univ.ObjectIdentifier('1.3.6.1.5.5.7.1.1')
+
+class AccessDescription(univ.Sequence):
+  """
+     AccessDescription  ::=  SEQUENCE {
+                accessMethod          OBJECT IDENTIFIER,
+                accessLocation        GeneralName  }
+  """
+  componentType = namedtype.NamedTypes(
+    namedtype.NamedType('accessMethod', univ.ObjectIdentifier()),
+    namedtype.NamedType('accessLocation', rfc2459.GeneralName()))
+
+class AuthorityInfoAccessSyntax(univ.SequenceOf):
+  """
+  AuthorityInfoAccessSyntax  ::=
+             SEQUENCE SIZE (1..MAX) OF AccessDescription
+  """
+  # FIXME: SIZE not encoded.
+  componentType = AccessDescription()
+
+id_ad_caIssuers = univ.ObjectIdentifier('1.3.6.1.5.5.7.48.2')
+
+# End of RFC 5280 4.2.2.1
+
+def getIssuersFromAIA(cert):
+  tbs = cert.getComponentByName('tbsCertificate')
+  extensions = tbs.getComponentByName('extensions') or []
+
+  allIssuers = []
+  for extension in extensions:
+    oid = extension.getComponentByName('extnID')
+    if oid != id_pe_authorityInfoAccess:
+      continue
+    
+    print extension.prettyPrint()
+
+    value, rest = decoder.decode(extension.getComponentByName('extnValue'),
+                                 asn1Spec=univ.OctetString())
+    assert rest == ""
+    aia, rest = decoder.decode(value, asn1Spec=AuthorityInfoAccessSyntax())
+    assert rest == ""
+
+    print aia.prettyPrint()
+
+    for ad in aia:
+      oid = ad.getComponentByName('accessMethod')
+      if oid != id_ad_caIssuers:
+        continue
+      
+      print ad.prettyPrint()
+
+      loc = ad.getComponentByName('accessLocation').\
+        getComponentByName('uniformResourceIdentifier')
+      print type(loc), loc
+
+      certHandle = urlopen(str(loc))
+      # RFC 5280 says this should either be 'application/pkix-cert' or
+      # 'application/pkcs7-mime' (in which case the result should be a
+      # "certs-only" PCKS#7 response, as specified in RFC 2797). Of
+      # course, we see other values, so just try both formats.
+      print certHandle.info().gettype()
+      issuer = certHandle.read()
+
+      # Have we got an (incorrect, but let's fix it) PEM encoded cert?
+      if issuer.startswith('-----'):
+        try:
+          (issuer, _) = from_pem(issuer, ['CERTIFICATE'])
+        except PemError as e:
+          print "PEM decode failed:", e
+          print "For cert:", issuer
+
+      # Is it a certificate?
+      try:
+        cert, rest = decoder.decode(issuer, asn1Spec=certType)
+        assert rest == ""
+        allIssuers.append(cert)
+        continue
+      except PyAsn1Error as e:
+        # On failure, try the next thing
+        print "Cert decode failed:", e
+        pass
+
+      # If not, it had better be PKCS#7 "certs-only"
+      try:
+        pkcs7, rest = decoder.decode(issuer, asn1Spec=rfc2315.ContentInfo())
+        assert rest == ""
+        assert pkcs7.getComponentByName('contentType') == rfc2315.signedData
+        signedData = decoder.decode(pkcs7.getComponentByName('content'),
+                                    asn1Spec=rfc2315.SignedData())
+      except PyAsn1Error as e:
+        # Give up
+        print "PKCS#7 decode also failed:", e
+        print "Skipping issuer URL:", loc
+        continue
+
+      for signedDatum in signedData:
+        # FIXME: why does this happen? Example is at
+        # http://crt.usertrust.com/AddTrustExternalCARoot.p7c.
+        if signedDatum == '':
+          print "** Skipping strange Any('') in PKCS7 **"
+          continue
+        certs = signedDatum.getComponentByName('certificates')
+        for c in certs:
+          cert = c.getComponentByName('certificate')
+          allIssuers.append(cert)
+  return allIssuers
+
+# Note that this is a non-standard encoding of the DN, but unlike the
+# standard encoding it captures nesting information. That is,
+# attributes that are within a single RelativeDistinguishedName are
+# surrounded by [].
+def DNToString(dn):
+  rdns = dn.getComponent()
+  ret = ''
+  for rdn in rdns:
+    ret += '['
+    
+    for attr in rdn:
+      attrType = attr.getComponentByName('type')
+
+      if attrType == rfc2459.emailAddress:
+        val, rest = decoder.decode(attr.getComponentByName('value'),
+                                   asn1Spec=rfc2459.Pkcs9email())
+        assert rest == ""
+
+        # Strictly speaking, this is IA5, not ASCII.
+        val = str(val).decode('ascii')
+      else:
+        val, rest = decoder.decode(attr.getComponentByName('value'),
+                                   asn1Spec=rfc2459.X520name())
+        assert rest == ""
+      
+        valt = val.getName()
+        val = val.getComponent()
+      
+        if valt == 'printableString':
+          val = str(val)
+        elif valt == 'teletexString':
+          # Strictly this is a T.61 string. T.61 no longer exists as a
+          # standard and some certs mark ISO 8859-1 as
+          # teletexString. And we should never see this, but we do.
+          val = str(val).decode('iso8859-1')
+        elif valt == 'utf8String':
+          val = str(val)
+        else:
+          print valt
+          assert False
+        
+      assert val is not None
+      
+      ret += '/' + str(attrType) + '=' + val
+      
+    ret += ']'
+    
+  return ret
+
+certs = {}
+inChain = []
+
+certfile = open(sys.argv[1])
+
+while 1:
+  idx, substrate = pem.readPemBlocksFromFile(certfile, (cStart, cEnd))
+  if not substrate:
+    break
+
+  cert, rest = decoder.decode(substrate, asn1Spec=certType)
+  assert rest == ""
+
+  tbs = cert.getComponentByName('tbsCertificate')
+
+  subjectDN = tbs.getComponentByName('subject')
+  print DNToString(subjectDN)
+
+  certs[DNToString(subjectDN)] = cert
+  inChain.append(cert)
+
+#for subject, cert in certs.iteritems():
+#  print subject
+
+# Assume the first cert in the chain is the final cert
+outChain = [inChain[0]]
+
+while True:
+  assert len(outChain) < 100
+  
+  cert = outChain[-1]
+
+  tbs = cert.getComponentByName('tbsCertificate')
+
+  subjectDN = tbs.getComponentByName('subject')
+  print 'subject:', DNToString(subjectDN)
+
+  issuerDN = tbs.getComponentByName('issuer')
+  #print issuerDN.prettyPrint()
+  issuerDNstr = DNToString(issuerDN)
+  print 'issuer:', issuerDNstr
+
+  print
+
+  if issuerDN == subjectDN:
+    break
+
+  if issuerDNstr in certs:
+    issuer = certs[issuerDNstr]
+  else:
+    issuers = getIssuersFromAIA(cert)
+    if len(issuers) == 0:
+      print "Can't get issuer, giving up"
+      break
+
+    issuer = None
+    for i in issuers:
+      tbs = i.getComponentByName('tbsCertificate')
+      subjectDN = tbs.getComponentByName('subject')
+      print 'issuer subject:', DNToString(subjectDN)
+      if subjectDN == issuerDN:
+        issuer = i
+        break
+
+  assert issuer is not None
+
+  outChain.append(issuer)
+
+if len(outChain) == 1:
+  tbs = outChain[0].getComponentByName('tbsCertificate')
+
+  subjectDN = tbs.getComponentByName('subject')
+  issuerDN = tbs.getComponentByName('issuer')
+  if subjectDN == issuerDN:
+    print "Chain consists of 1 self-signed certificate"
+    exit(1)
+
+for cert in outChain:
+    print cStart
+    b64 = b64encode(encoder.encode(cert))
+    for n in range(0, len(b64), 64):
+      print b64[n:n+64]
+    print cEnd
+
+print('*** %d PEM cert(s) deserialized, fixed chain is %d long' % (
+  len(inChain),
+  len(outChain)))
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/get_issuers.py src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/get_issuers.py
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/get_issuers.py	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/get_issuers.py	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,111 @@
+#!/usr/bin/env python
+
+# Get the issuers for the supplied certificates from the AIA
+# extension. Note that this is not very clever and may supply
+# intermediates that are not needed and fail to supply intermediates
+# that are needed.
+
+# Based on pyasn1 example code.
+
+from base64 import b64encode
+from pyasn1.codec.der import decoder
+from pyasn1.codec.der import encoder
+from pyasn1.type import namedtype
+from pyasn1.type import univ
+from pyasn1_modules import pem
+from pyasn1_modules import rfc2459
+import sys
+from urllib2 import urlopen
+
+if len(sys.argv) != 1:
+  print """Usage:
+  $ %s < somecertificates.pem""" % sys.argv[0]
+  sys.exit(-1)
+
+cStart = '-----BEGIN CERTIFICATE-----'
+cEnd = '-----END CERTIFICATE-----'
+
+certType = rfc2459.Certificate()
+
+# RFC 2459 is not sufficient for X509v3 certificates, extra stuff here.
+# RFC 5280 4.2.2.1
+
+id_pe_authorityInfoAccess = univ.ObjectIdentifier('1.3.6.1.5.5.7.1.1')
+
+class AccessDescription(univ.Sequence):
+  """
+     AccessDescription  ::=  SEQUENCE {
+                accessMethod          OBJECT IDENTIFIER,
+                accessLocation        GeneralName  }
+  """
+  componentType = namedtype.NamedTypes(
+    namedtype.NamedType('accessMethod', univ.ObjectIdentifier()),
+    namedtype.NamedType('accessLocation', rfc2459.GeneralName()))
+
+class AuthorityInfoAccessSyntax(univ.SequenceOf):
+  """
+  AuthorityInfoAccessSyntax  ::=
+             SEQUENCE SIZE (1..MAX) OF AccessDescription
+  """
+  # FIXME: SIZE not encoded.
+  componentType = AccessDescription()
+
+id_ad_caIssuers = univ.ObjectIdentifier('1.3.6.1.5.5.7.48.2')
+
+# End of RFC 5280 4.2.2.1
+
+certCnt = 0
+
+while 1:
+  idx, substrate = pem.readPemBlocksFromFile(
+    sys.stdin, (cStart, cEnd)
+    )
+  if not substrate:
+    break
+
+  cert, rest = decoder.decode(substrate, asn1Spec=certType)
+
+  if rest: substrate = substrate[:-len(rest)]
+
+  print cert.prettyPrint()
+
+  tbs = cert.getComponentByName('tbsCertificate')
+  extensions = tbs.getComponentByName('extensions') or []
+
+  for extension in extensions:
+    oid = extension.getComponentByName('extnID')
+    if oid != id_pe_authorityInfoAccess:
+      continue
+    
+    print extension.prettyPrint()
+
+    value, rest = decoder.decode(extension.getComponentByName('extnValue'),
+                                 asn1Spec=univ.OctetString())
+    assert rest == ""
+    aia, rest = decoder.decode(value, asn1Spec=AuthorityInfoAccessSyntax())
+    assert rest == ""
+
+    print aia.prettyPrint()
+
+    for ad in aia:
+      oid = ad.getComponentByName('accessMethod')
+      if oid != id_ad_caIssuers:
+        continue
+      
+      print ad.prettyPrint()
+
+      loc = ad.getComponentByName('accessLocation').\
+        getComponentByName('uniformResourceIdentifier')
+      print type(loc), loc
+
+      certHandle = urlopen(str(loc))
+      cert = certHandle.read()
+      print cStart
+      b64 = b64encode(cert)
+      for n in range(0, len(b64), 64):
+        print b64[n:n+64]
+      print cEnd
+    
+  certCnt = certCnt + 1
+
+print('*** %s PEM cert(s) de/serialized' % certCnt)
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/http_log_client.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/http_log_client.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/http_log_client.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/http_log_client.cc	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,176 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "client/http_log_client.h"
+
+#include <event2/buffer.h>
+#include <glog/logging.h>
+#include <functional>
+#include <memory>
+
+#include "log/cert.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+#include "util/json_wrapper.h"
+#include "util/util.h"
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::AsyncLogClient;
+using cert_trans::Cert;
+using cert_trans::CertChain;
+using cert_trans::HTTPLogClient;
+using cert_trans::PreCertChain;
+using cert_trans::ThreadPool;
+using ct::MerkleAuditProof;
+using ct::SignedCertificateTimestamp;
+using ct::SignedTreeHead;
+using std::bind;
+using std::placeholders::_1;
+using std::string;
+using std::unique_ptr;
+using std::vector;
+using util::Status;
+using util::StatusOr;
+
+namespace {
+
+
+void DoneRequest(AsyncLogClient::Status status, AsyncLogClient::Status* retval,
+                 bool* done) {
+  *retval = status;
+  *done = true;
+}
+
+
+}  // namespace
+
+HTTPLogClient::HTTPLogClient(const string& server)
+    : base_(new libevent::Base()),
+      pool_(),
+      fetcher_(base_.get(), &pool_),
+      client_(base_.get(), &fetcher_, server) {
+}
+
+StatusOr<SignedCertificateTimestamp> HTTPLogClient::UploadSubmission(
+    const string& submission, bool pre) {
+  SignedCertificateTimestamp sct;
+  AsyncLogClient::Status status(AsyncLogClient::UNKNOWN_ERROR);
+  bool done(false);
+
+  if (pre) {
+    PreCertChain pre_cert_chain(submission);
+    client_.AddPreCertChain(pre_cert_chain, &sct,
+                            bind(&DoneRequest, _1, &status, &done));
+  } else {
+    CertChain cert_chain(submission);
+    client_.AddCertChain(cert_chain, &sct,
+                         bind(&DoneRequest, _1, &status, &done));
+  }
+
+  while (!done) {
+    base_->DispatchOnce();
+  }
+
+  if (status == AsyncLogClient::OK) {
+    return sct;
+  }
+
+  return Status::UNKNOWN;
+}
+
+
+StatusOr<SignedTreeHead> HTTPLogClient::GetSTH() {
+  SignedTreeHead sth;
+  AsyncLogClient::Status status(AsyncLogClient::UNKNOWN_ERROR);
+  bool done(false);
+
+  client_.GetSTH(&sth, bind(&DoneRequest, _1, &status, &done));
+  while (!done) {
+    base_->DispatchOnce();
+  }
+
+  if (status == AsyncLogClient::OK) {
+    return sth;
+  }
+
+  return Status::UNKNOWN;
+}
+
+
+StatusOr<vector<unique_ptr<Cert>>> HTTPLogClient::GetRoots() {
+  vector<unique_ptr<Cert>> roots;
+  AsyncLogClient::Status status(AsyncLogClient::UNKNOWN_ERROR);
+  bool done(false);
+
+  client_.GetRoots(&roots, bind(&DoneRequest, _1, &status, &done));
+  while (!done) {
+    base_->DispatchOnce();
+  }
+
+  if (status == AsyncLogClient::OK) {
+    return move(roots);
+  }
+
+  return Status::UNKNOWN;
+}
+
+StatusOr<MerkleAuditProof> HTTPLogClient::QueryAuditProof(
+    const string& merkle_leaf_hash) {
+  const StatusOr<SignedTreeHead> sth(GetSTH());
+  if (!sth.status().ok()) {
+    return sth.status();
+  }
+
+  MerkleAuditProof proof;
+  AsyncLogClient::Status status(AsyncLogClient::UNKNOWN_ERROR);
+  bool done(false);
+  client_.QueryInclusionProof(sth.ValueOrDie(), merkle_leaf_hash, &proof,
+                              bind(&DoneRequest, _1, &status, &done));
+
+  while (!done) {
+    base_->DispatchOnce();
+  }
+
+  if (status == AsyncLogClient::OK) {
+    return proof;
+  }
+
+  return Status::UNKNOWN;
+}
+
+StatusOr<vector<AsyncLogClient::Entry>> HTTPLogClient::GetEntries(int first,
+                                                                  int last) {
+  vector<AsyncLogClient::Entry> entries;
+  AsyncLogClient::Status status(AsyncLogClient::UNKNOWN_ERROR);
+  bool done(false);
+
+  client_.GetEntries(first, last, &entries,
+                     bind(&DoneRequest, _1, &status, &done));
+  while (!done) {
+    base_->DispatchOnce();
+  }
+
+  if (status == AsyncLogClient::OK) {
+    return move(entries);
+  }
+
+  return Status::UNKNOWN;
+}
+
+StatusOr<vector<string>> HTTPLogClient::GetSTHConsistency(int64_t size1,
+                                                          int64_t size2) {
+  vector<string> proof;
+  AsyncLogClient::Status status(AsyncLogClient::UNKNOWN_ERROR);
+  bool done(false);
+
+  client_.GetSTHConsistency(size1, size2, &proof,
+                            bind(&DoneRequest, _1, &status, &done));
+  while (!done) {
+    base_->DispatchOnce();
+  }
+
+  if (status == AsyncLogClient::OK) {
+    return proof;
+  }
+
+  return Status::UNKNOWN;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/http_log_client.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/http_log_client.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/http_log_client.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/http_log_client.h	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,52 @@
+#ifndef CERT_TRANS_CLIENT_HTTP_LOG_CLIENT_H_
+#define CERT_TRANS_CLIENT_HTTP_LOG_CLIENT_H_
+
+#include <stdint.h>
+#include <memory>
+#include <string>
+
+#include "base/macros.h"
+#include "client/async_log_client.h"
+#include "proto/ct.pb.h"
+#include "util/libevent_wrapper.h"
+#include "util/statusor.h"
+#include "util/thread_pool.h"
+
+namespace cert_trans {
+
+class Cert;
+
+
+class HTTPLogClient {
+ public:
+  explicit HTTPLogClient(const std::string& server);
+
+  util::StatusOr<ct::SignedCertificateTimestamp> UploadSubmission(
+      const std::string& submission, bool pre);
+
+  util::StatusOr<ct::SignedTreeHead> GetSTH();
+
+  util::StatusOr<std::vector<std::unique_ptr<Cert>>> GetRoots();
+
+  util::StatusOr<ct::MerkleAuditProof> QueryAuditProof(
+      const std::string& merkle_leaf_hash);
+
+  util::StatusOr<std::vector<std::string>> GetSTHConsistency(int64_t size1,
+                                                             int64_t size2);
+
+  util::StatusOr<std::vector<AsyncLogClient::Entry>> GetEntries(int first,
+                                                                int last);
+
+ private:
+  const std::unique_ptr<libevent::Base> base_;
+  ThreadPool pool_;
+  UrlFetcher fetcher_;
+  AsyncLogClient client_;
+
+  DISALLOW_COPY_AND_ASSIGN(HTTPLogClient);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_CLIENT_HTTP_LOG_CLIENT_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/ssl_client.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/ssl_client.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/ssl_client.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/ssl_client.cc	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,316 @@
+#include "client/ssl_client.h"
+
+#include <glog/logging.h>
+#include <openssl/bio.h>
+#include <openssl/ssl.h>
+#include <openssl/x509.h>
+
+#include "client/client.h"
+#include "log/cert.h"
+#include "log/cert_submission_handler.h"
+#include "log/ct_extensions.h"
+#include "log/log_verifier.h"
+#include "merkletree/serial_hasher.h"
+#include "proto/serializer.h"
+
+using cert_trans::serialization::DeserializeResult;
+using ct::LogEntry;
+using ct::SSLClientCTData;
+using ct::SignedCertificateTimestamp;
+using ct::SignedCertificateTimestampList;
+using std::string;
+using std::unique_ptr;
+using util::StatusOr;
+using util::error::Code;
+
+namespace cert_trans {
+namespace {
+
+const uint16_t CT_EXTENSION_TYPE = 18;
+
+} // namespace
+
+
+// static
+int SSLClient::ExtensionCallback(SSL*, unsigned ext_type,
+                                 const unsigned char* in, size_t inlen, int*,
+                                 void* arg) {
+  char pem_name[100];
+  unsigned char ext_buf[4 + 65536];
+
+  /* Reconstruct the type/len fields prior to extension data */
+  ext_buf[0] = ext_type >> 8;
+  ext_buf[1] = ext_type & 0xFF;
+  ext_buf[2] = inlen >> 8;
+  ext_buf[3] = inlen & 0xFF;
+  memcpy(ext_buf + 4, in, inlen);
+
+  BIO_snprintf(pem_name, sizeof(pem_name), "SERVERINFO FOR EXTENSION %d",
+               ext_type);
+
+// Work around broken PEM_write() declaration in older OpenSSL versions.
+#if OPENSSL_VERSION_NUMBER < 0x10002000L
+  PEM_write(stdout, pem_name, const_cast<char*>(""), ext_buf, 4 + inlen);
+#else
+  PEM_write(stdout, pem_name, "", ext_buf, 4 + inlen);
+#endif
+
+  CHECK_EQ(ext_type, CT_EXTENSION_TYPE);
+
+  VerifyCallbackArgs* args = reinterpret_cast<VerifyCallbackArgs*>(arg);
+  CHECK_NOTNULL(args);
+
+  CHECK(args->ct_extension.empty());
+  args->ct_extension = string(reinterpret_cast<const char*>(in), inlen);
+
+  return 1;
+}
+
+// TODO(ekasper): handle Cert::Status errors.
+SSLClient::SSLClient(const string& server, const string& port,
+                     const string& ca_dir, LogVerifier* verifier)
+    : client_(server, port),
+      ctx_(CHECK_NOTNULL(SSL_CTX_new(TLSv1_client_method()))),
+      verify_args_(verifier),
+      connected_(false) {
+  // SSL_VERIFY_PEER makes the connection abort immediately
+  // if verification fails.
+  SSL_CTX_set_verify(ctx_.get(), SSL_VERIFY_PEER, NULL);
+  // Set trusted CA certs.
+  if (!ca_dir.empty()) {
+    CHECK_EQ(1,
+             SSL_CTX_load_verify_locations(ctx_.get(), NULL, ca_dir.c_str()))
+        << "Unable to load trusted CA certificates.";
+  } else {
+    SSL_CTX_set_default_verify_paths(ctx_.get());
+    LOG(INFO) << "Using system trusted CA certificates.";
+  }
+
+  SSL_CTX_set_cert_verify_callback(ctx_.get(), &VerifyCallback, &verify_args_);
+
+#if OPENSSL_VERSION_NUMBER >= 0x10002000L
+  SSL_CTX_add_client_custom_ext(ctx_.get(), CT_EXTENSION_TYPE, NULL, NULL,
+                                NULL, ExtensionCallback, &verify_args_);
+#else
+  LOG(WARNING) << "OpenSSL version is too low to check the Certificate "
+                  "Transparency TLS extension";
+#endif
+}
+
+SSLClient::~SSLClient() {
+  Disconnect();
+}
+
+bool SSLClient::Connected() const {
+  return connected_;
+}
+
+void SSLClient::Disconnect() {
+  if (ssl_) {
+    SSL_shutdown(ssl_.get());
+    LOG(INFO) << "SSL session finished";
+    ssl_.reset();
+  }
+  client_.Disconnect();
+  connected_ = false;
+}
+
+void SSLClient::GetSSLClientCTData(SSLClientCTData* data) const {
+  CHECK(Connected());
+  data->CopyFrom(verify_args_.ct_data);
+}
+
+// FIXME(ekasper): This code assumes in several places that a certificate has
+// *either* embedded proofs *or* regular proofs in a superfluous certificate
+// *or* regular proofs in a TLS extension but not several at the same time.
+// It's of course for example entirely possible that a cert with an embedded
+// proof is re-submitted (or submitted to another log) and the server attaches
+// that proof too, but let's not complicate things for now.
+// static
+LogVerifier::LogVerifyResult SSLClient::VerifySCT(const string& token,
+                                                  LogVerifier* verifier,
+                                                  SSLClientCTData* data) {
+  CHECK(data->has_reconstructed_entry());
+  SignedCertificateTimestamp local_sct;
+  // Skip over bad SCTs. These could be either badly encoded ones, or
+  // SCTs whose version we don't understand.
+  if (Deserializer::DeserializeSCT(token, &local_sct) != DeserializeResult::OK)
+    return LogVerifier::INVALID_FORMAT;
+
+  string merkle_leaf;
+  LogVerifier::LogVerifyResult result =
+      verifier->VerifySignedCertificateTimestamp(data->reconstructed_entry(),
+                                                 local_sct, &merkle_leaf);
+  if (result != LogVerifier::VERIFY_OK)
+    return result;
+  SSLClientCTData::SCTInfo* sct_info = data->add_attached_sct_info();
+  sct_info->set_merkle_leaf_hash(merkle_leaf);
+  sct_info->mutable_sct()->CopyFrom(local_sct);
+  return LogVerifier::VERIFY_OK;
+}
+
+// static
+int SSLClient::VerifyCallback(X509_STORE_CTX* ctx, void* arg) {
+  VerifyCallbackArgs* args = reinterpret_cast<VerifyCallbackArgs*>(arg);
+  CHECK_NOTNULL(args);
+  LogVerifier* verifier(args->verifier.get());
+  CHECK_NOTNULL(verifier);
+
+  int vfy = X509_verify_cert(ctx);
+  if (vfy != 1) {
+    int error = X509_STORE_CTX_get_error(ctx);
+    LOG(ERROR) << "Certificate verification failed: "
+               << X509_verify_cert_error_string(error);
+    return vfy;
+  }
+
+  // If verify passed then surely we must have a cert.
+  CHECK_NOTNULL(ctx->cert);
+
+  CertChain chain, input_chain;
+  // ctx->untrusted is the input chain.
+  // ctx->chain is the chain of X509s that OpenSSL constructed and verified.
+  CHECK_NOTNULL(ctx->chain);
+  int chain_size = sk_X509_num(ctx->chain);
+  // Should contain at least the leaf.
+  CHECK_GE(chain_size, 1);
+  for (int i = 0; i < chain_size; ++i) {
+    chain.AddCert(
+        Cert::FromX509(ScopedX509(X509_dup(sk_X509_value(ctx->chain, i)))));
+  }
+
+  CHECK_NOTNULL(ctx->untrusted);
+  chain_size = sk_X509_num(ctx->untrusted);
+  // Should contain at least the leaf.
+  CHECK_GE(chain_size, 1);
+  for (int i = 0; i < chain_size; ++i) {
+    input_chain.AddCert(Cert::FromX509(
+        ScopedX509(X509_dup(sk_X509_value(ctx->untrusted, i)))));
+  }
+
+  string serialized_scts;
+  // First, see if the cert has an embedded proof.
+  const StatusOr<bool> has_embedded_proof = chain.LeafCert()->HasExtension(
+      cert_trans::NID_ctEmbeddedSignedCertificateTimestampList);
+
+  // Pull out the superfluous cert extension if it exists for use later
+  // Let's assume the superfluous cert is always last in the chain.
+  const StatusOr<bool> superf_has_timestamp_list =
+      input_chain.Length() > 1
+          ? input_chain.LastCert()->HasExtension(
+                cert_trans::NID_ctSignedCertificateTimestampList)
+          : util::Status::UNKNOWN;
+
+  // First check for embedded proof, if not present then look for the proof in
+  // a superfluous cert.
+  if (has_embedded_proof.ok() && has_embedded_proof.ValueOrDie()) {
+    LOG(INFO) << "Embedded proof extension found in certificate, "
+              << "verifying...";
+    util::Status status = chain.LeafCert()->OctetStringExtensionData(
+        cert_trans::NID_ctEmbeddedSignedCertificateTimestampList,
+        &serialized_scts);
+    if (!status.ok()) {
+      // Any error here is likely OpenSSL acting up, so just die. Previously
+      // was CHECK_EQ(FALSE..., which meant fail check if not an error and not
+      // false
+      CHECK_EQ(Code::NOT_FOUND, status.CanonicalCode());
+      LOG(ERROR) << "Failed to parse extension data: corrupt cert?";
+    }
+  } else if (superf_has_timestamp_list.ok() &&
+             superf_has_timestamp_list.ValueOrDie()) {
+    LOG(INFO) << "Proof extension found in certificate, verifying...";
+    util::Status status = input_chain.LastCert()->OctetStringExtensionData(
+        cert_trans::NID_ctSignedCertificateTimestampList, &serialized_scts);
+    if (!status.ok()) {
+      // Any error here is likely OpenSSL acting up, so just die.
+      CHECK_EQ(Code::NOT_FOUND, status.CanonicalCode());
+      LOG(ERROR) << "Failed to parse extension data: corrupt cert?";
+    }
+  }
+
+  // FIXME(benl): we should check all SCTs.
+  if (serialized_scts.empty() && !args->ct_extension.empty())
+    serialized_scts = args->ct_extension;
+
+  if (!serialized_scts.empty()) {
+    LogEntry entry;
+    if (!CertSubmissionHandler::X509ChainToEntry(chain, &entry)) {
+      LOG(ERROR) << "Failed to reconstruct log entry input from chain";
+    } else {
+      args->ct_data.mutable_reconstructed_entry()->CopyFrom(entry);
+      args->ct_data.set_certificate_sha256_hash(
+          Sha256Hasher::Sha256Digest(Serializer::LeafData(entry)));
+      // Only writes the checkpoint if verification succeeds.
+      // Note: an optimized client could only verify the signature if it's
+      // a certificate it hasn't seen before.
+      SignedCertificateTimestampList sct_list;
+      if (Deserializer::DeserializeSCTList(serialized_scts, &sct_list) !=
+          DeserializeResult::OK) {
+        LOG(ERROR) << "Failed to parse SCT list.";
+      } else {
+        LOG(INFO) << "Received " << sct_list.sct_list_size() << " SCTs";
+        for (int i = 0; i < sct_list.sct_list_size(); ++i) {
+          LogVerifier::LogVerifyResult result =
+              VerifySCT(sct_list.sct_list(i), verifier, &args->ct_data);
+
+          if (result == LogVerifier::VERIFY_OK) {
+            LOG(INFO) << "SCT number " << i + 1 << " verified";
+            args->sct_verified = true;
+          } else {
+            LOG(ERROR) << "Verification for SCT number " << i + 1
+                       << " failed: "
+                       << LogVerifier::VerifyResultString(result);
+          }
+        }  // end for
+      }
+    }
+  }  // end if (!serialized_scts.empty())
+
+  if (!args->sct_verified && args->require_sct) {
+    LOG(ERROR) << "No valid SCT found";
+    return 0;
+  }
+
+  return 1;
+}
+
+void SSLClient::ResetVerifyCallbackArgs(bool strict) {
+  verify_args_.sct_verified = false;
+  verify_args_.require_sct = strict;
+  verify_args_.ct_data.CopyFrom(SSLClientCTData::default_instance());
+}
+
+SSLClient::HandshakeResult SSLClient::SSLConnect(bool strict) {
+  if (!client_.Connect())
+    return SERVER_UNAVAILABLE;
+
+  ssl_.reset(SSL_new(ctx_.get()));
+  CHECK_NOTNULL(ssl_.get());
+  ScopedBIO bio(BIO_new_socket(client_.fd(), BIO_NOCLOSE));
+  CHECK_NOTNULL(bio.get());
+  {
+    BIO* const b(bio.release());
+    // Takes ownership of bio.
+    SSL_set_bio(ssl_.get(), b, b);
+  }
+
+  ResetVerifyCallbackArgs(strict);
+  int ret = SSL_connect(ssl_.get());
+  HandshakeResult result;
+  if (ret == 1) {
+    LOG(INFO) << "Handshake successful. SSL session started";
+    connected_ = true;
+    DCHECK(!verify_args_.require_sct || verify_args_.sct_verified);
+    result = OK;
+  } else {
+    // TODO(ekasper): look into OpenSSL error stack to determine
+    // the error reason. Could be unrelated to SCT verification.
+    LOG(ERROR) << "SSL handshake failed";
+    result = HANDSHAKE_FAILED;
+    Disconnect();
+  }
+  return result;
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/ssl_client.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/ssl_client.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/ssl_client.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/ssl_client.h	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,113 @@
+#ifndef CERT_TRANS_CLIENT_SSL_CLIENT_H_
+#define CERT_TRANS_CLIENT_SSL_CLIENT_H_
+
+#include <openssl/ssl.h>
+#include <openssl/x509.h>
+
+#include "base/macros.h"
+#include "client/client.h"
+#include "client/ssl_client.h"
+#include "log/log_verifier.h"
+#include "proto/ct.pb.h"
+#include "util/openssl_scoped_ssl_types.h"
+
+class LogVerifier;
+
+namespace cert_trans {
+
+
+class SSLClient {
+ public:
+  // Takes ownership of the verifier. This client can currently
+  // only verify SCTs from a single log at a time.
+  // TODO(ekasper): implement a proper multi-log auditor.
+  SSLClient(const std::string& server, const std::string& port,
+            const std::string& ca_dir, LogVerifier* verifier);
+
+  ~SSLClient();
+
+  enum HandshakeResult {
+    OK = 0,
+    HANDSHAKE_FAILED = 1,
+    SERVER_UNAVAILABLE = 2,
+  };
+
+  HandshakeResult SSLConnect() {
+    return SSLConnect(false);
+  }
+
+  // Same as above but won't proceed without an SCT.
+  HandshakeResult SSLConnectStrict() {
+    return SSLConnect(true);
+  }
+
+  bool Connected() const;
+
+  void Disconnect();
+
+  void GetSSLClientCTData(ct::SSLClientCTData* data) const;
+
+  // Need a static wrapper for the callback.
+  static LogVerifier::LogVerifyResult VerifySCT(const std::string& token,
+                                                LogVerifier* verifier,
+                                                ct::SSLClientCTData* data);
+
+  // Custom verification callback for verifying the SCT token
+  // in a superfluous certificate. Return values:
+  // With TLS extension support:
+  //  1 - cert verified (SCT might still be in TLS extension which is
+  //      parsed in a later callback; we record whether it was verified
+  //       in the callback args)
+  // other values - cert verification errors.
+  // Without TLS extension support, strict mode
+  // 1 - cert and SCT verified
+  // other values - everything else
+  // Without TLS extension support, standard mode
+  // 1 - cert verified (we record whether an SCT was also verified in the
+  //     callback args)
+  // other values - cert verification error
+  static int VerifyCallback(X509_STORE_CTX* ctx, void* arg);
+
+  static int ExtensionCallback(SSL* s, unsigned ext_type,
+                               const unsigned char* in, size_t inlen, int* al,
+                               void* arg);
+
+ private:
+  Client client_;
+  cert_trans::ScopedSSL_CTX ctx_;
+  cert_trans::ScopedSSL ssl_;
+  struct VerifyCallbackArgs {
+    VerifyCallbackArgs(LogVerifier* log_verifier)
+        : verifier(log_verifier),
+          sct_verified(false),
+          require_sct(false),
+          ct_data() {
+    }
+
+    // The verifier for checking log proofs.
+    std::unique_ptr<LogVerifier> verifier;
+    // SCT verification result.
+    bool sct_verified;
+    bool require_sct;
+    std::string ct_extension;
+    // The resulting (partial) entry - the client reconstructs
+    // the signed part of the entry (i.e., type and leaf certificate)
+    // and all valid SCTs.
+    ct::SSLClientCTData ct_data;
+  };
+
+  VerifyCallbackArgs verify_args_;
+  bool connected_;
+
+  // Call before each handshake.
+  void ResetVerifyCallbackArgs(bool strict);
+
+  HandshakeResult SSLConnect(bool strict);
+
+  DISALLOW_COPY_AND_ASSIGN(SSLClient);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_CLIENT_SSL_CLIENT_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/upload_server_cert.sh src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/upload_server_cert.sh
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/client/upload_server_cert.sh	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/client/upload_server_cert.sh	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,28 @@
+#!/bin/sh
+
+# Upload whatever cert the named server presents to the pilot log
+
+set -e
+
+export PYTHONPATH=${PYTHONPATH}:../python
+SERVER=$1
+PUBKEY=$2 # PEM encoded file
+#CT_SERVER='ct.googleapis.com/pilot'
+CT_SERVER='http://localhost:6962'
+TMP=`mktemp /tmp/cert.XXXXXX`
+
+openssl s_client -connect $SERVER:443 -showcerts < /dev/null | tee $TMP
+
+if ./ct --ct_server=$CT_SERVER --logtostderr --ct_server_submission=$TMP --ct_server_public_key=$PUBKEY upload
+then
+    echo Done
+else
+    echo Try fixing the chain
+    TMP2=`mktemp /tmp/cert.XXXXXX`
+    ./fix-chain.py $TMP | tee $TMP2
+    ./ct --ct_server=$CT_SERVER --logtostderr --ct_server_submission=$TMP2 --ct_server_public_key=$PUBKEY upload
+    rm $TMP2
+fi
+
+rm $TMP
+
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/continuous_fetcher.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/continuous_fetcher.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/continuous_fetcher.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/continuous_fetcher.cc	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,173 @@
+#include "fetcher/continuous_fetcher.h"
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+
+#include "fetcher/fetcher.h"
+#include "fetcher/peer_group.h"
+#include "log/log_verifier.h"
+
+using std::bind;
+using std::chrono::seconds;
+using std::lock_guard;
+using std::map;
+using std::move;
+using std::mutex;
+using std::placeholders::_1;
+using std::shared_ptr;
+using std::string;
+using std::unique_lock;
+using std::unique_ptr;
+using util::Executor;
+using util::Task;
+
+DEFINE_int32(delay_between_fetches_seconds, 30, "delay between fetches");
+
+namespace cert_trans {
+
+namespace {
+
+
+class ContinuousFetcherImpl : public ContinuousFetcher {
+ public:
+  ContinuousFetcherImpl(libevent::Base* base, Executor* executor, Database* db,
+                        const LogVerifier* log_verifier, bool fetch_scts);
+
+  void AddPeer(const string& node_id, const shared_ptr<Peer>& peer) override;
+  void RemovePeer(const string& node_id) override;
+
+ private:
+  void StartFetch(const unique_lock<mutex>& lock);
+  void FetchDone(Task* task);
+  void FetchDelayDone(Task* task);
+
+  libevent::Base* const base_;
+  Executor* const executor_;
+  Database* const db_;
+  const LogVerifier* const log_verifier_;
+  const bool fetch_scts_;
+
+  mutex lock_;
+  map<string, shared_ptr<Peer>> peers_;
+
+  bool restart_fetch_;
+  unique_ptr<Task> fetch_task_;
+
+  DISALLOW_COPY_AND_ASSIGN(ContinuousFetcherImpl);
+};
+
+
+ContinuousFetcherImpl::ContinuousFetcherImpl(
+    libevent::Base* base, Executor* executor, Database* db,
+    const LogVerifier* const log_verifier, bool fetch_scts)
+    : base_(CHECK_NOTNULL(base)),
+      executor_(CHECK_NOTNULL(executor)),
+      db_(CHECK_NOTNULL(db)),
+      log_verifier_(CHECK_NOTNULL(log_verifier)),
+      fetch_scts_(fetch_scts),
+      restart_fetch_(false) {
+}
+
+
+void ContinuousFetcherImpl::AddPeer(const string& node_id,
+                                    const shared_ptr<Peer>& peer) {
+  unique_lock<mutex> lock(lock_);
+
+  // TODO(pphaneuf): Allow updating the peer, as this is currently
+  // simplest, for the case where a peer might change host:port.
+  const auto it(peers_.find(node_id));
+  if (it != peers_.end()) {
+    it->second = peer;
+  } else {
+    CHECK(peers_.emplace(node_id, peer).second);
+  }
+
+  if (fetch_task_) {
+    restart_fetch_ = true;
+    fetch_task_->Cancel();
+  } else {
+    StartFetch(lock);
+  }
+}
+
+
+void ContinuousFetcherImpl::RemovePeer(const string& node_id) {
+  lock_guard<mutex> lock(lock_);
+
+  // TODO(pphaneuf): In tests, we rig more than cluster state
+  // controllers to the same continuous fetcher instance, so additions
+  // and removals can be duplicated. Tolerate this for now, but only
+  // restart the fetching process if there was an actual removal.
+  if (peers_.erase(node_id) > 0 && fetch_task_) {
+    restart_fetch_ = true;
+    fetch_task_->Cancel();
+  }
+}
+
+
+void ContinuousFetcherImpl::StartFetch(const unique_lock<mutex>& lock) {
+  CHECK(lock.owns_lock());
+  CHECK(!fetch_task_);
+
+  restart_fetch_ = false;
+
+  unique_ptr<PeerGroup> peer_group(new PeerGroup(fetch_scts_));
+  for (const auto& peer : peers_) {
+    peer_group->Add(peer.second);
+  }
+
+  fetch_task_.reset(
+      new Task(bind(&ContinuousFetcherImpl::FetchDone, this, _1), executor_));
+
+  VLOG(1) << "starting fetch with tree size: " << peer_group->TreeSize();
+  FetchLogEntries(db_, move(peer_group), log_verifier_, fetch_task_.get());
+}
+
+
+void ContinuousFetcherImpl::FetchDone(Task* task) {
+  if (!task->status().ok()) {
+    LOG(WARNING) << "error while fetching: " << task->status();
+  }
+
+  lock_guard<mutex> lock(lock_);
+  fetch_task_.reset();
+
+  if (restart_fetch_) {
+    executor_->Add(
+        bind(&ContinuousFetcherImpl::FetchDelayDone, this, nullptr));
+  } else {
+    base_->Delay(seconds(FLAGS_delay_between_fetches_seconds),
+                 new Task(bind(&ContinuousFetcherImpl::FetchDelayDone, this,
+                               _1),
+                          executor_));
+  }
+}
+
+
+void ContinuousFetcherImpl::FetchDelayDone(Task* task) {
+  // "task" can be null, if we're restarting a fetch.
+  if (task) {
+    CHECK_EQ(util::Status::OK, task->status());
+    delete task;
+  }
+
+  unique_lock<mutex> lock(lock_);
+  if (!fetch_task_) {
+    StartFetch(lock);
+  }
+}
+
+
+}  // namespace
+
+
+// static
+unique_ptr<ContinuousFetcher> ContinuousFetcher::New(
+    libevent::Base* base, Executor* executor, Database* db,
+    const LogVerifier* log_verifier, bool fetch_scts) {
+  return unique_ptr<ContinuousFetcher>(
+      new ContinuousFetcherImpl(base, executor, db, log_verifier, fetch_scts));
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/continuous_fetcher.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/continuous_fetcher.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/continuous_fetcher.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/continuous_fetcher.h	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,46 @@
+#ifndef CERT_TRANS_FETCHER_CONTINUOUS_FETCHER_H_
+#define CERT_TRANS_FETCHER_CONTINUOUS_FETCHER_H_
+
+#include <map>
+#include <memory>
+#include <mutex>
+#include <set>
+#include <string>
+
+#include "base/macros.h"
+#include "fetcher/peer.h"
+#include "log/database.h"
+#include "log/logged_entry.h"
+#include "util/executor.h"
+#include "util/libevent_wrapper.h"
+#include "util/task.h"
+
+class LogVerifier;
+
+namespace cert_trans {
+
+
+class ContinuousFetcher {
+ public:
+  static std::unique_ptr<ContinuousFetcher> New(
+      libevent::Base* base, util::Executor* executor, Database* db,
+      const LogVerifier* log_verifier, bool fetch_scts);
+
+  virtual ~ContinuousFetcher() = default;
+
+  virtual void AddPeer(const std::string& node_id,
+                       const std::shared_ptr<Peer>& peer) = 0;
+
+  virtual void RemovePeer(const std::string& node_id) = 0;
+
+ protected:
+  ContinuousFetcher() = default;
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(ContinuousFetcher);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_FETCHER_CONTINUOUS_FETCHER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/fetcher.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/fetcher.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/fetcher.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/fetcher.cc	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,318 @@
+#include "fetcher/fetcher.h"
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <memory>
+#include <mutex>
+
+#include "base/macros.h"
+#include "log/log_verifier.h"
+#include "monitoring/monitoring.h"
+
+using cert_trans::AsyncLogClient;
+using cert_trans::LoggedEntry;
+using cert_trans::PeerGroup;
+using std::bind;
+using std::lock_guard;
+using std::move;
+using std::mutex;
+using std::placeholders::_1;
+using std::string;
+using std::to_string;
+using std::unique_lock;
+using std::unique_ptr;
+using std::vector;
+using util::Status;
+using util::Task;
+using util::TaskHold;
+
+DEFINE_int32(fetcher_concurrent_fetches, 2,
+             "number of concurrent fetch requests");
+DEFINE_int32(fetcher_batch_size, 1000,
+             "maximum number of entries to fetch per request");
+
+namespace cert_trans {
+
+Counter<string>* num_invalid_entries_fetched =
+    Counter<string>::New("num_invalid_entries_fetched", "reason",
+                         "Number of invalid entries fetched from remote peers "
+                         "broken down by reason.");
+
+
+namespace {
+
+
+struct Range {
+  enum State {
+    HAVE,
+    FETCHING,
+    WANT,
+  };
+
+  Range(State state, int64_t size, unique_ptr<Range> next = nullptr)
+      : state_(state), size_(size), next_(move(next)) {
+    CHECK(state_ == HAVE || state_ == FETCHING || state_ == WANT);
+    CHECK_GT(size_, 0);
+  };
+
+  State state_;
+  int64_t size_;
+  unique_ptr<Range> next_;
+};
+
+
+struct FetchState {
+  FetchState(Database* db, unique_ptr<PeerGroup> peer_group,
+             const LogVerifier* log_verifier, Task* task);
+
+  void WalkEntries();
+  void FetchRange(const unique_lock<mutex>& lock, Range* current,
+                  int64_t index, Task* range_task);
+  void WriteToDatabase(int64_t index, Range* range,
+                       const vector<AsyncLogClient::Entry>* retval,
+                       Task* range_task, Task* fetch_task);
+
+  Database* const db_;
+  const unique_ptr<PeerGroup> peer_group_;
+  const LogVerifier* const log_verifier_;
+  Task* const task_;
+
+  mutex lock_;
+  int64_t start_;
+  unique_ptr<Range> entries_;
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(FetchState);
+};
+
+
+FetchState::FetchState(Database* db, unique_ptr<PeerGroup> peer_group,
+                       const LogVerifier* log_verifier, Task* task)
+    : db_(CHECK_NOTNULL(db)),
+      peer_group_(move(peer_group)),
+      log_verifier_(CHECK_NOTNULL(log_verifier)),
+      task_(CHECK_NOTNULL(task)),
+      start_(db_->TreeSize()) {
+  // TODO(pphaneuf): Might be better to get that as a parameter?
+  const int64_t remote_tree_size(peer_group_->TreeSize());
+  CHECK_GE(start_, 0);
+
+  // Nothing to do...
+  if (remote_tree_size <= start_) {
+    VLOG(1) << "nothing to do: we have " << start_ << " entries, remote has "
+            << remote_tree_size;
+    task_->Return();
+    return;
+  }
+
+  entries_.reset(new Range(Range::WANT, remote_tree_size - start_));
+
+  WalkEntries();
+}
+
+
+// This is called either when starting the fetching, or when fetching
+// a range completed. In that both cases, there's a hold on our task,
+// so it shouldn't go away from under us.
+void FetchState::WalkEntries() {
+  if (!task_->IsActive()) {
+    // We've already stopped, for one reason or another, no point
+    // getting anything started.
+    return;
+  }
+
+  if (task_->CancelRequested()) {
+    task_->Return(Status::CANCELLED);
+    return;
+  }
+
+  unique_lock<mutex> lock(lock_);
+
+  // Prune fetched and unavailable sequences at the beginning.
+  const int64_t remote_tree_size(peer_group_->TreeSize());
+  while (entries_ &&
+         (entries_->state_ == Range::HAVE ||
+          (entries_->state_ == Range::WANT && remote_tree_size < start_))) {
+    VLOG(1) << "pruning " << entries_->size_ << " at offset " << start_;
+    start_ += entries_->size_;
+    entries_ = move(entries_->next_);
+  }
+
+  // Are we done?
+  if (!entries_) {
+    task_->Return();
+    return;
+  }
+
+  int64_t index(start_);
+  int num_fetch(0);
+  for (Range *current = entries_.get(); current;
+       index += current->size_, current = current->next_.get()) {
+    // Coalesce with the next Range, if possible.
+    if (current->state_ != Range::FETCHING) {
+      while (current->next_ && current->next_->state_ == current->state_) {
+        current->size_ += current->next_->size_;
+        current->next_ = move(current->next_->next_);
+      }
+    }
+
+    switch (current->state_) {
+      case Range::HAVE:
+        VLOG(2) << "at offset " << index << ", we have " << current->size_
+                << " entries";
+        break;
+
+      case Range::FETCHING:
+        VLOG(2) << "at offset " << index << ", fetching " << current->size_
+                << " entries";
+        ++num_fetch;
+        break;
+
+      case Range::WANT:
+        VLOG(2) << "at offset " << index << ", we want " << current->size_
+                << " entries";
+
+        // Do not start a fetch if we think our peer group does not
+        // have it.
+        if (index >= remote_tree_size) {
+          break;
+        }
+
+        // If the range is bigger than the maximum batch size, split it.
+        if (current->size_ > FLAGS_fetcher_batch_size) {
+          current->next_.reset(
+              new Range(Range::WANT, current->size_ - FLAGS_fetcher_batch_size,
+                        move(current->next_)));
+          current->size_ = FLAGS_fetcher_batch_size;
+        }
+
+        FetchRange(lock, current, index,
+                   task_->AddChild(bind(&FetchState::WalkEntries, this)));
+        ++num_fetch;
+
+        break;
+    }
+
+    if (num_fetch >= FLAGS_fetcher_concurrent_fetches ||
+        index >= remote_tree_size) {
+      break;
+    }
+  }
+}
+
+
+void FetchState::FetchRange(const unique_lock<mutex>& lock, Range* current,
+                            int64_t index, Task* range_task) {
+  CHECK(lock.owns_lock());
+  const int64_t end_index(index + current->size_ - 1);
+  VLOG(1) << "fetching from offset " << index << " to " << end_index;
+
+  vector<AsyncLogClient::Entry>* const retval(
+      new vector<AsyncLogClient::Entry>);
+  range_task->DeleteWhenDone(retval);
+
+  current->state_ = Range::FETCHING;
+
+  peer_group_->FetchEntries(index, end_index, retval,
+                            range_task->AddChild(
+                                bind(&FetchState::WriteToDatabase, this, index,
+                                     current, retval, range_task, _1)));
+}
+
+
+void FetchState::WriteToDatabase(int64_t index, Range* range,
+                                 const vector<AsyncLogClient::Entry>* retval,
+                                 Task* range_task, Task* fetch_task) {
+  if (!fetch_task->status().ok()) {
+    LOG(INFO) << "error fetching entries at index " << index << ": "
+              << fetch_task->status();
+    lock_guard<mutex> lock(lock_);
+    range->state_ = Range::WANT;
+    range_task->Return(fetch_task->status());
+    return;
+  }
+
+  CHECK_GT(retval->size(), static_cast<size_t>(0));
+
+  VLOG(1) << "received " << retval->size() << " entries at offset " << index;
+  int64_t processed(0);
+  for (const auto& entry : *retval) {
+    LoggedEntry cert;
+    if (!cert.CopyFromClientLogEntry(entry)) {
+      LOG(WARNING) << "could not convert entry to a LoggedEntry";
+      num_invalid_entries_fetched->Increment("format");
+      break;
+    }
+    if (entry.sct) {
+      *cert.mutable_sct() = *entry.sct;
+      // If we have the full SCT (because this LogEntry came from another
+      // internal node which supports our private "give me the SCT too"
+      // option), then verify that the signature is good.
+      const LogVerifier::LogVerifyResult verify_result(
+          log_verifier_->VerifySignedCertificateTimestamp(
+              cert.contents().entry(), cert.sct()));
+      VLOG(1) << "SCT verify entry #" << index << ": "
+              << LogVerifier::VerifyResultString(verify_result);
+      if (verify_result != LogVerifier::VERIFY_OK) {
+        num_invalid_entries_fetched->Increment("sct_verify_failed");
+        const string msg("Failed to verify SCT signature for entry# " +
+                         to_string(index) + " : " +
+                         LogVerifier::VerifyResultString(verify_result));
+        LOG(WARNING) << msg;
+        task_->Return(Status(util::error::FAILED_PRECONDITION, msg));
+        return;
+      }
+    }
+    cert.set_sequence_number(index++);
+    if (db_->CreateSequencedEntry(cert) == Database::OK) {
+      ++processed;
+    } else {
+      LOG(WARNING) << "could not insert entry into the database:\n"
+                   << cert.DebugString();
+      break;
+    }
+  }
+
+  {
+    lock_guard<mutex> lock(lock_);
+    // TODO(pphaneuf): If we have problems fetching entries, to what
+    // point should we retry? Or should we just return on the task
+    // with an error?
+    if (processed > 0) {
+      // If we don't receive everything, split up the range.
+      if (range->size_ > processed) {
+        range->next_.reset(new Range(Range::WANT, range->size_ - processed,
+                                     move(range->next_)));
+        range->size_ = processed;
+      }
+
+      range->state_ = Range::HAVE;
+    } else {
+      range->state_ = Range::WANT;
+    }
+  }
+
+  if (static_cast<uint64_t>(processed) < retval->size()) {
+    // We couldn't insert everything that we received into the
+    // database, this is fairly serious, return an error for the
+    // overall operation and let the higher level deal with it.
+    task_->Return(Status(util::error::INTERNAL,
+                         "could not write some entries to the database"));
+  }
+
+  range_task->Return();
+}
+
+
+}  // namespace
+
+
+void FetchLogEntries(Database* db, unique_ptr<PeerGroup> peer_group,
+                     const LogVerifier* log_verifier, Task* task) {
+  TaskHold hold(task);
+  task->DeleteWhenDone(
+      new FetchState(db, move(peer_group), log_verifier, task));
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/fetcher.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/fetcher.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/fetcher.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/fetcher.h	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,21 @@
+#ifndef CERT_TRANS_FETCHER_FETCHER_H_
+#define CERT_TRANS_FETCHER_FETCHER_H_
+
+#include <memory>
+
+#include "fetcher/peer_group.h"
+#include "log/database.h"
+#include "util/task.h"
+
+class LogVerifier;
+
+namespace cert_trans {
+
+
+void FetchLogEntries(Database* db, std::unique_ptr<PeerGroup> peer_group,
+                     const LogVerifier* log_verifier, util::Task* task);
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_FETCHER_FETCHER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/mock_continuous_fetcher.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/mock_continuous_fetcher.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/mock_continuous_fetcher.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/mock_continuous_fetcher.h	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,21 @@
+#ifndef CERT_TRANS_FETCHER_MOCK_CONTINUOUS_FETCHER_H_
+#define CERT_TRANS_FETCHER_MOCK_CONTINUOUS_FETCHER_H_
+
+#include <gmock/gmock.h>
+
+#include "fetcher/continuous_fetcher.h"
+
+namespace cert_trans {
+
+
+class MockContinuousFetcher : public ContinuousFetcher {
+ public:
+  MOCK_METHOD2(AddPeer, void(const std::string& node_id,
+                             const std::shared_ptr<Peer>& peer));
+  MOCK_METHOD1(RemovePeer, void(const std::string& node_id));
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_FETCHER_MOCK_CONTINUOUS_FETCHER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer.cc	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,15 @@
+#include "fetcher/peer.h"
+
+#include <glog/logging.h>
+
+using std::unique_ptr;
+
+namespace cert_trans {
+
+
+Peer::Peer(unique_ptr<AsyncLogClient> client) : client_(move(client)) {
+  CHECK_NOTNULL(client_.get());
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer_group.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer_group.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer_group.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer_group.cc	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,121 @@
+#include "fetcher/peer_group.h"
+
+#include <glog/logging.h>
+
+using std::lock_guard;
+using std::max;
+using std::mutex;
+using std::placeholders::_1;
+using std::shared_ptr;
+using std::vector;
+using util::Status;
+using util::Task;
+
+namespace cert_trans {
+
+namespace {
+
+
+void GetEntriesDone(AsyncLogClient::Status client_status,
+                    const vector<AsyncLogClient::Entry>* entries, Task* task) {
+  Status status;
+
+  switch (client_status) {
+    case AsyncLogClient::OK:
+      break;
+
+    default:
+      // TODO(pphaneuf): Improve this a bit? Or wouldn't it be nice if
+      // AsyncLogClient gave us a util::Status in the first place? ;-)
+      status = util::Status::UNKNOWN;
+  }
+
+  if (status.ok() && entries->empty()) {
+    // This should never happen.
+    status =
+        Status(util::error::INTERNAL, "log server did not return any entries");
+  }
+
+  task->Return(status);
+}
+
+
+}  // namespace
+
+
+PeerGroup::PeerGroup(bool fetch_scts) : fetch_scts_(fetch_scts) {
+}
+
+
+void PeerGroup::Add(const shared_ptr<Peer>& peer) {
+  lock_guard<mutex> lock(lock_);
+
+  CHECK(peers_.emplace(peer, PeerState()).second);
+}
+
+
+int64_t PeerGroup::TreeSize() const {
+  lock_guard<mutex> lock(lock_);
+
+  int64_t tree_size(-1);
+  for (const auto& peer : peers_) {
+    tree_size = max(tree_size, peer.first->TreeSize());
+  }
+
+  return tree_size;
+}
+
+
+void PeerGroup::FetchEntries(int64_t start_index, int64_t end_index,
+                             vector<AsyncLogClient::Entry>* entries,
+                             Task* task) {
+  CHECK_GE(start_index, 0);
+  CHECK_GE(end_index, start_index);
+
+  const shared_ptr<Peer> peer(PickPeer(end_index + 1));
+  if (!peer) {
+    task->Return(Status(util::error::UNAVAILABLE,
+                        "requested entries not available in the peer group"));
+    return;
+  }
+
+  // TODO(pphaneuf): Handle the case where we have no peer more cleanly.
+  if (fetch_scts_) {
+    peer->client().GetEntriesAndSCTs(start_index, end_index,
+                                     CHECK_NOTNULL(entries),
+                                     bind(GetEntriesDone, _1, entries, task));
+  } else {
+    peer->client().GetEntries(start_index, end_index, CHECK_NOTNULL(entries),
+                              bind(GetEntriesDone, _1, entries, task));
+  }
+}
+
+
+shared_ptr<Peer> PeerGroup::PickPeer(const int64_t needed_size) const {
+  lock_guard<mutex> lock(lock_);
+
+  // TODO(pphaneuf): We should pick peers a bit more cleverly, to
+  // spread the load somewhat.
+  int64_t group_tree_size(-1);
+  vector<shared_ptr<Peer>> capable_peers;
+  for (const auto& peer : peers_) {
+    const int64_t tree_size(peer.first->TreeSize());
+    group_tree_size = max(group_tree_size, tree_size);
+    if (tree_size >= needed_size) {
+      capable_peers.push_back(peer.first);
+    }
+  }
+
+  if (!capable_peers.empty()) {
+    return capable_peers[std::rand() % capable_peers.size()];
+  }
+
+  LOG(INFO) << "requested a peer with " << needed_size
+            << " entries but the peer group only has " << group_tree_size
+            << " entries";
+
+  return nullptr;
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer_group.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer_group.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer_group.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer_group.h	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,55 @@
+#ifndef CERT_TRANS_FETCHER_PEER_GROUP_H_
+#define CERT_TRANS_FETCHER_PEER_GROUP_H_
+
+#include <stdint.h>
+#include <memory>
+#include <mutex>
+#include <set>
+#include <vector>
+
+#include "base/macros.h"
+#include "client/async_log_client.h"
+#include "fetcher/peer.h"
+#include "util/task.h"
+
+namespace cert_trans {
+
+
+// A PeerGroup is a set of peers used for a fetch operation, providing
+// a slightly higher level abstraction for fetching entries. Fetch
+// errors will be retried, and unhealthy peers will be dropped (so the
+// available tree size can get smaller).
+// TODO(pphaneuf): Make that last sentence true!
+class PeerGroup {
+ public:
+  explicit PeerGroup(bool fetch_scts_);
+
+  // Adding a peer twice is not allowed.
+  void Add(const std::shared_ptr<Peer>& peer);
+
+  // Returns the highest tree size of the peer group.
+  int64_t TreeSize() const;
+
+  void FetchEntries(int64_t start_offset, int64_t end_offset,
+                    std::vector<AsyncLogClient::Entry>* entries,
+                    util::Task* task);
+
+ private:
+  struct PeerState {
+    // TODO(pphaneuf): Keep a count of errors here, to prune away
+    // unhealthy peers.
+  };
+
+  std::shared_ptr<Peer> PickPeer(const int64_t needed_size) const;
+
+  mutable std::mutex lock_;
+  const bool fetch_scts_;
+  std::map<std::shared_ptr<Peer>, PeerState> peers_;
+
+  DISALLOW_COPY_AND_ASSIGN(PeerGroup);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_FETCHER_PEER_GROUP_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/peer.h	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,36 @@
+#ifndef CERT_TRANS_FETCHER_PEER_H_
+#define CERT_TRANS_FETCHER_PEER_H_
+
+#include <memory>
+
+#include "base/macros.h"
+#include "client/async_log_client.h"
+
+namespace cert_trans {
+
+
+class Peer {
+ public:
+  Peer(std::unique_ptr<AsyncLogClient> client);
+  virtual ~Peer() {
+  }
+
+  AsyncLogClient& client() {
+    return *client_;
+  }
+
+  // Returns -1 if we do not know yet.
+  virtual int64_t TreeSize() const = 0;
+
+ protected:
+  const std::unique_ptr<AsyncLogClient> client_;
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(Peer);
+};
+
+
+}  // namespace cert_trans
+
+
+#endif  // CERT_TRANS_FETCHER_PEER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/remote_peer.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/remote_peer.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/remote_peer.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/remote_peer.cc	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,165 @@
+#include "fetcher/remote_peer.h"
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <chrono>
+
+#include "base/time_support.h"
+#include "monitoring/monitoring.h"
+#include "util/util.h"
+
+using ct::SignedTreeHead;
+using std::bind;
+using std::chrono::seconds;
+using std::lock_guard;
+using std::make_shared;
+using std::move;
+using std::mutex;
+using std::placeholders::_1;
+using std::shared_ptr;
+using std::string;
+using std::unique_ptr;
+using util::HexString;
+using util::TaskHold;
+
+namespace cert_trans {
+
+DEFINE_int32(remote_peer_sth_refresh_interval_seconds, 10,
+             "Number of seconds between checks for updated STHs from the "
+             "remote peer.");
+
+Counter<string>* invalid_sths_received =
+    Counter<string>::New("remote_peer_invalid_sths_received", "reason",
+                         "Number of incorrect/invalid STHs received from "
+                         "target, broken down by reason.");
+
+
+struct RemotePeer::Impl {
+  Impl(unique_ptr<LogVerifier> verifier, AsyncLogClient* client,
+       const std::function<void(const ct::SignedTreeHead&)>& on_new_sth,
+       util::Task* task)
+      : verifier_(move(verifier)),
+        client_(CHECK_NOTNULL(client)),
+        on_new_sth_(on_new_sth),
+        task_(CHECK_NOTNULL(task)) {
+    CHECK(verifier_);
+  }
+
+  const std::unique_ptr<LogVerifier> verifier_;
+  AsyncLogClient* const client_;
+  const std::function<void(const ct::SignedTreeHead&)> on_new_sth_;
+  util::Task* const task_;
+
+  mutex lock_;
+  shared_ptr<SignedTreeHead> sth_;
+
+  void FetchSTH();
+  void DoneGetSTH(const std::shared_ptr<ct::SignedTreeHead>& on_new_sth,
+                  AsyncLogClient::Status status);
+};
+
+
+void RemotePeer::Impl::FetchSTH() {
+  if (CHECK_NOTNULL(task_)->CancelRequested()) {
+    task_->Return(util::Status::CANCELLED);
+    return;
+  }
+  shared_ptr<SignedTreeHead> next_sth(make_shared<SignedTreeHead>());
+  client_->GetSTH(next_sth.get(), bind(&Impl::DoneGetSTH, this, next_sth, _1));
+}
+
+
+void RemotePeer::Impl::DoneGetSTH(
+    const std::shared_ptr<ct::SignedTreeHead>& new_sth,
+    AsyncLogClient::Status status) {
+  if (task_->CancelRequested()) {
+    task_->Return(util::Status::CANCELLED);
+    return;
+  }
+
+  if (status == AsyncLogClient::OK) {
+    bool sth_provisionally_valid(false);
+
+    const LogVerifier::LogVerifyResult result(verifier_->VerifySignedTreeHead(
+        *new_sth, 0, (time(NULL) + 10) * kNumMillisPerSecond));
+
+    // TODO(alcutter): We should probably log these invalid STHs somewhere a
+    // bit more durable.
+    switch (result) {
+      case LogVerifier::VERIFY_OK:
+        // Alright!
+        sth_provisionally_valid = true;
+        break;
+      case LogVerifier::INVALID_TIMESTAMP:
+        LOG(WARNING) << "Invalid timestamp on received STH:\n"
+                     << new_sth->DebugString();
+        invalid_sths_received->Increment("invalid_timestamp");
+        break;
+      case LogVerifier::INVALID_SIGNATURE:
+        LOG(WARNING) << "Invalid signature on received STH:\n"
+                     << new_sth->DebugString();
+        invalid_sths_received->Increment("invalid_signature");
+        break;
+      case LogVerifier::INCONSISTENT_TIMESTAMPS:
+      case LogVerifier::INVALID_MERKLE_PATH:
+      case LogVerifier::INVALID_FORMAT:
+        LOG(FATAL) << "Unexpected verify result for VerifySignedTreeHead(): "
+                   << result;
+    }
+
+    if (sth_provisionally_valid) {
+      lock_guard<mutex> lock(lock_);
+
+      if (new_sth->tree_size() < 0) {
+        LOG(WARNING) << "Unexpected tree size in new_sth:\n"
+                     << new_sth->DebugString();
+      } else if (sth_ && new_sth->tree_size() < sth_->tree_size()) {
+        LOG(WARNING) << "Received old STH:\n" << new_sth->DebugString();
+      } else if (!sth_ || new_sth->timestamp() > sth_->timestamp()) {
+        // This STH is good, we'll take it.
+        sth_ = new_sth;
+        if (on_new_sth_) {
+          on_new_sth_(*sth_);
+        }
+      }
+    }
+  } else {
+    LOG(WARNING) << "Problem fetching STH, got error " << status
+                 << " from AsyncLogClient";
+  }
+
+  // Schedule another STH fetch
+  task_->executor()->Delay(
+      seconds(FLAGS_remote_peer_sth_refresh_interval_seconds),
+      task_->AddChild(bind(&RemotePeer::Impl::FetchSTH, this)));
+}
+
+
+RemotePeer::RemotePeer(
+    unique_ptr<AsyncLogClient> client, unique_ptr<LogVerifier> verifier,
+    const std::function<void(const ct::SignedTreeHead&)>& on_new_sth,
+    util::Task* task)
+    : Peer(move(client)),
+      task_(task),
+      impl_(new Impl(move(verifier), client_.get(), on_new_sth, task_)) {
+  TaskHold hold(task);
+  task_->DeleteWhenDone(impl_);
+
+  impl_->FetchSTH();
+}
+
+
+RemotePeer::~RemotePeer() {
+  task_->Return(util::Status::CANCELLED);
+}
+
+
+int64_t RemotePeer::TreeSize() const {
+  lock_guard<mutex> lock(impl_->lock_);
+  return (impl_->sth_ && impl_->sth_->has_tree_size())
+             ? impl_->sth_->tree_size()
+             : -1;
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/remote_peer.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/remote_peer.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/remote_peer.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/remote_peer.h	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,36 @@
+#ifndef CERT_TRANS_FETCHER_REMOTE_PEER_H_
+#define CERT_TRANS_FETCHER_REMOTE_PEER_H_
+
+#include "fetcher/peer.h"
+#include "log/log_verifier.h"
+#include "util/task.h"
+
+namespace cert_trans {
+
+
+class RemotePeer : public Peer {
+ public:
+  // The "task" will return when the object is fully destroyed
+  // (destroying this object starts the asynchronous destruction).
+  // |on_new_sth| will be called for each new STH that this object sees from
+  // the target log.
+  RemotePeer(std::unique_ptr<AsyncLogClient> client,
+             std::unique_ptr<LogVerifier> verifier,
+             const std::function<void(const ct::SignedTreeHead&)>& on_new_sth,
+             util::Task* task);
+  ~RemotePeer() override;
+
+  int64_t TreeSize() const override;
+
+ private:
+  struct Impl;
+
+  util::Task* const task_;
+  // This gets deleted via the util::Task.
+  Impl* const impl_;
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_FETCHER_REMOTE_PEER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/remote_peer_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/remote_peer_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/fetcher/remote_peer_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/fetcher/remote_peer_test.cc	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,292 @@
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <openssl/err.h>
+#include <openssl/evp.h>
+#include <set>
+#include <string>
+#include "log/etcd_consistent_store.h"
+
+#include "base/notification.h"
+#include "client/async_log_client.h"
+#include "fetcher/remote_peer.h"
+#include "log/log_verifier.h"
+#include "log/test_db.h"
+#include "log/test_signer.h"
+#include "log/tree_signer.h"
+#include "merkletree/merkle_verifier.h"
+#include "merkletree/serial_hasher.h"
+#include "monitoring/monitoring.h"
+#include "net/mock_url_fetcher.h"
+#include "proto/cert_serializer.h"
+#include "util/fake_etcd.h"
+#include "util/json_wrapper.h"
+#include "util/mock_masterelection.h"
+#include "util/sync_task.h"
+#include "util/testing.h"
+#include "util/thread_pool.h"
+
+using ct::SignedTreeHead;
+using std::bind;
+using std::chrono::seconds;
+using std::function;
+using std::placeholders::_1;
+using std::placeholders::_2;
+using std::placeholders::_3;
+using std::make_shared;
+using std::map;
+using std::ostream;
+using std::set;
+using std::shared_ptr;
+using std::string;
+using std::unique_ptr;
+using testing::_;
+using testing::InSequence;
+using testing::Invoke;
+using testing::NiceMock;
+using testing::Return;
+using util::Status;
+using util::SyncTask;
+using util::Task;
+
+namespace ct {
+
+
+ostream& operator<<(ostream& os, const SignedTreeHead& sth) {
+  return os << sth.DebugString();
+}
+
+
+}  // namespace ct
+
+
+namespace cert_trans {
+
+DECLARE_int32(remote_peer_sth_refresh_interval_seconds);
+
+const char kLogUrl[] = "https://example.com";
+const char kInvalidSthReceivedMetric[] = "remote_peer_invalid_sths_received";
+
+
+void HandleFetch(Status status, int status_code,
+                 const UrlFetcher::Headers& headers, const string& body,
+                 const UrlFetcher::Request& req, UrlFetcher::Response* resp,
+                 Task* task) {
+  resp->status_code = status_code;
+  resp->headers = headers;
+  resp->body = body;
+  task->Return(status);
+}
+
+
+string Jsonify(const SignedTreeHead& sth) {
+  JsonObject json_reply;
+  json_reply.Add("tree_size", sth.tree_size());
+  json_reply.Add("timestamp", sth.timestamp());
+  json_reply.AddBase64("sha256_root_hash", sth.sha256_root_hash());
+  json_reply.Add("tree_head_signature", sth.signature());
+  LOG(INFO) << "Returning " << json_reply.ToString();
+  return json_reply.ToString();
+}
+
+
+class RemotePeerTest : public ::testing::Test {
+ public:
+  RemotePeerTest()
+      : base_(make_shared<libevent::Base>()),
+        event_pump_(base_),
+        etcd_client_(base_.get()),
+        store_(base_.get(), &pool_, &etcd_client_, &election_, "/root", "id"),
+        log_signer_(TestSigner::DefaultLogSigner()),
+        tree_signer_(std::chrono::duration<double>(0), test_db_.db(),
+                     unique_ptr<CompactMerkleTree>(new CompactMerkleTree(
+                         unique_ptr<Sha256Hasher>(new Sha256Hasher))),
+                     &store_, log_signer_.get()),
+        task_(&pool_) {
+    FLAGS_remote_peer_sth_refresh_interval_seconds = 1;
+    StoreInitialSthMetricValues();
+  }
+
+  ~RemotePeerTest() {
+    task_.task()->Cancel();
+    task_.Wait();
+  }
+
+  void CreatePeer() {
+    peer_.reset(new RemotePeer(
+        unique_ptr<AsyncLogClient>(
+            new AsyncLogClient(&pool_, &fetcher_, kLogUrl)),
+        unique_ptr<LogVerifier>(new LogVerifier(
+            TestSigner::DefaultLogSigVerifier(),
+            new MerkleVerifier(unique_ptr<Sha256Hasher>(new Sha256Hasher)))),
+        bind(&RemotePeerTest::OnNewSTH, this, _1), task_.task()));
+  }
+
+  void StoreInitialSthMetricValues() {
+    set<const Metric*> metrics(Registry::Instance()->GetMetrics());
+    for (const auto& m : metrics) {
+      if (m->Name() == kInvalidSthReceivedMetric) {
+        for (const auto& v : m->CurrentValues()) {
+          ASSERT_EQ(static_cast<size_t>(1), v.first.size());
+          invalid_sth_metric_values_[v.first[0]] = v.second.second;
+        }
+        return;
+      }
+    }
+    LOG(FATAL) << "Couldn't find metric " << kInvalidSthReceivedMetric;
+  }
+
+
+  double GetInvalidSthMetricValue(const string& label) {
+    set<const Metric*> metrics(Registry::Instance()->GetMetrics());
+    for (const auto& m : metrics) {
+      if (m->Name() == kInvalidSthReceivedMetric) {
+        for (const auto& v : m->CurrentValues()) {
+          if (v.first.size() == 1 && v.first[0] == label) {
+            // Only interested in the delta from the start of the test.
+            return v.second.second - invalid_sth_metric_values_[label];
+          }
+        }
+        // no such label - return a default
+        return 0;
+      }
+    }
+    LOG(FATAL) << "Couldn't find metric " << kInvalidSthReceivedMetric;
+  }
+
+  MOCK_METHOD1(OnNewSTH, void(const SignedTreeHead& sth));
+
+  void ExpectGetSth(const SignedTreeHead& return_sth, bool repeated = false) {
+    if (!repeated) {
+      EXPECT_CALL(fetcher_, Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                                    URL(string(kLogUrl) +
+                                                        "/ct/v1/get-sth"),
+                                                    _, ""),
+                                  _, _))
+          .WillOnce(
+              Invoke(bind(&HandleFetch, Status::OK, 200, UrlFetcher::Headers{},
+                          Jsonify(return_sth), _1, _2, _3)));
+    } else {
+      EXPECT_CALL(fetcher_, Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                                    URL(string(kLogUrl) +
+                                                        "/ct/v1/get-sth"),
+                                                    _, ""),
+                                  _, _))
+          .WillRepeatedly(
+              Invoke(bind(&HandleFetch, Status::OK, 200, UrlFetcher::Headers{},
+                          Jsonify(return_sth), _1, _2, _3)));
+    }
+  }
+
+  void ReturnLatestSTH(const UrlFetcher::Request& req,
+                       UrlFetcher::Response* resp, Task* task) {
+    tree_signer_.UpdateTree();
+    HandleFetch(Status::OK, 200, UrlFetcher::Headers{},
+                Jsonify(tree_signer_.LatestSTH()), req, resp, task);
+  }
+
+ protected:
+  shared_ptr<libevent::Base> base_;
+  libevent::EventPumpThread event_pump_;
+  FakeEtcdClient etcd_client_;
+  TestDB<LevelDB> test_db_;
+  ThreadPool pool_;
+  NiceMock<MockMasterElection> election_;
+  cert_trans::EtcdConsistentStore store_;
+  TestSigner test_signer_;
+  unique_ptr<LogSigner> log_signer_;
+  TreeSigner tree_signer_;
+  SyncTask task_;
+  MockUrlFetcher fetcher_;
+  unique_ptr<RemotePeer> peer_;
+  map<string, double> invalid_sth_metric_values_;
+};
+
+
+MATCHER_P(EqualsSTH, sth, "") {
+  return sth.timestamp() == arg.timestamp() &&
+         sth.signature().DebugString() == arg.signature().DebugString() &&
+         sth.version() == arg.version() &&
+         sth.sha256_root_hash() == arg.sha256_root_hash() &&
+         sth.tree_size() == arg.tree_size();
+}
+
+
+TEST_F(RemotePeerTest, RejectsSTHWithInvalidTimestamp) {
+  tree_signer_.UpdateTree();
+
+  const SignedTreeHead sth(tree_signer_.LatestSTH());
+
+  SignedTreeHead modified_sth(sth);
+  modified_sth.set_timestamp(modified_sth.timestamp() + 10000000);
+
+  tree_signer_.UpdateTree();
+  SignedTreeHead new_sth(tree_signer_.LatestSTH());
+
+  {
+    InSequence s;
+    ExpectGetSth(sth);
+    ExpectGetSth(modified_sth);
+    ExpectGetSth(new_sth, true /* repeatedly */);
+  }
+
+  Notification notify;
+  {
+    InSequence t;
+    EXPECT_CALL(*this, OnNewSTH(EqualsSTH(sth))).Times(1);
+    EXPECT_CALL(*this, OnNewSTH(EqualsSTH(modified_sth))).Times(0);
+    EXPECT_CALL(*this, OnNewSTH(EqualsSTH(new_sth)))
+        .WillOnce(Invoke(bind(&Notification::Notify, &notify)));
+  }
+
+  CreatePeer();
+  notify.WaitForNotificationWithTimeout(seconds(5));
+
+  EXPECT_EQ(1, GetInvalidSthMetricValue("invalid_timestamp"));
+  EXPECT_EQ(0, GetInvalidSthMetricValue("invalid_signature"));
+}
+
+
+TEST_F(RemotePeerTest, RejectsSTHWithInvalidSignature) {
+  tree_signer_.UpdateTree();
+  const SignedTreeHead sth(tree_signer_.LatestSTH());
+
+  SignedTreeHead modified_sth(sth);
+  modified_sth.mutable_signature()->set_signature("Autograph");
+
+  tree_signer_.UpdateTree();
+  SignedTreeHead new_sth(tree_signer_.LatestSTH());
+
+  {
+    InSequence s;
+    ExpectGetSth(sth);
+    ExpectGetSth(modified_sth);
+    ExpectGetSth(new_sth, true /* repeatedly */);
+  }
+
+  Notification notify;
+  {
+    InSequence t;
+    EXPECT_CALL(*this, OnNewSTH(EqualsSTH(sth))).Times(1);
+    EXPECT_CALL(*this, OnNewSTH(EqualsSTH(modified_sth))).Times(0);
+    EXPECT_CALL(*this, OnNewSTH(EqualsSTH(new_sth)))
+        .WillOnce(Invoke(bind(&Notification::Notify, &notify)));
+  }
+
+  CreatePeer();
+  notify.WaitForNotificationWithTimeout(seconds(5));
+
+  EXPECT_EQ(0, GetInvalidSthMetricValue("invalid_timestamp"));
+  EXPECT_EQ(1, GetInvalidSthMetricValue("invalid_signature"));
+}
+
+
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  ConfigureSerializerForV1CT();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert.cc	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,1535 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "log/cert.h"
+#include "log/ct_extensions.h"
+#include "merkletree/serial_hasher.h"
+#include "util/openssl_util.h"  // For LOG_OPENSSL_ERRORS
+#include "util/util.h"
+
+#include <glog/logging.h>
+#include <openssl/asn1.h>
+#include <openssl/bio.h>
+#include <openssl/crypto.h>
+#include <openssl/err.h>
+#include <openssl/evp.h>
+#include <openssl/objects.h>
+#include <openssl/pem.h>
+#include <openssl/x509.h>
+#include <openssl/x509v3.h>
+#include <time.h>
+#include <algorithm>
+#include <memory>
+#include <string>
+#include <vector>
+
+using std::move;
+using std::string;
+using std::to_string;
+using std::unique_ptr;
+using std::vector;
+using util::ClearOpenSSLErrors;
+using util::StatusOr;
+using util::error::Code;
+
+
+#if OPENSSL_VERSION_NUMBER < 0x10002000L || defined(OPENSSL_IS_BORINGSSL)
+// Backport from 1.0.2-beta3.
+static int i2d_re_X509_tbs(X509* x, unsigned char** pp) {
+  x->cert_info->enc.modified = 1;
+  return i2d_X509_CINF(x->cert_info, pp);
+}
+#endif
+
+#if OPENSSL_VERSION_NUMBER < 0x10002000L
+static int X509_get_signature_nid(const X509* x) {
+  return OBJ_obj2nid(x->sig_alg->algorithm);
+}
+#endif
+
+
+namespace {
+#if defined(OPENSSL_IS_BORINGSSL)
+// BoringSSL doesn't have DSA hooked up so to accept these certs we have
+// to do the work ourselves. Can be called with a non DSA issuer key but will
+// always return false in that case.
+//
+// cert is the certificate that is to be checked
+// issuer_key is the public key of the certificate issuer (should be DSA)
+// Returns true if the DSA signature was correctly verified or false if
+// it did not or there was any error along the way.
+StatusOr<bool> check_dsa_signature(const X509* cert,
+                                   EVP_PKEY* issuer_key) {
+  // Before we start rummaging about through pointers ensure everything we need
+  // is present
+  if (!cert || !issuer_key || !X509_get_cert_info(cert)) {
+    return ::util::Status(Code::FAILED_PRECONDITION,
+                          "cert is null or missing cert_info");
+  }
+
+  X509_CINF* cert_info = X509_get_cert_info(cert);
+  const X509_ALGOR* sig = X509_CINF_get_signature(cert_info);
+
+  if (!sig) {
+    return ::util::Status(Code::FAILED_PRECONDITION,
+                          "cert is missing a signature");
+  }
+
+  if (EVP_PKEY_type(issuer_key->type) != EVP_PKEY_DSA) {
+    return ::util::Status(Code::FAILED_PRECONDITION,
+                          "issuer does not have a DSA public key");
+  }
+
+  const int alg_nid = X509_get_signature_nid(cert);
+
+  int digest_nid;
+  // We need the nid of the digest so we can create an EVP_MD for it later.
+  // Should succeed as we already checked we have a DSA key
+  if (!OBJ_find_sigid_algs(alg_nid, &digest_nid, nullptr)) {
+    return ::util::Status(Code::INTERNAL, "lookup sigid for algorithm failed");
+  }
+
+  // Get the DER encoded certificate info from the cert
+  unsigned char* der_buf(nullptr);
+  const int der_length = i2d_X509_CINF(cert_info, &der_buf);
+  if (der_length < 0) {
+    // Failed to decode. Several possible reasons but we will just reject
+    // the input rather than trying to interpret the cause
+    LOG(WARNING) << "Failed to serialize the CINF component";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return ::util::Status(Code::INVALID_ARGUMENT,
+                          "failed to serialize cert info");
+  }
+
+  string der_buf_str;
+  der_buf_str.assign(string(reinterpret_cast<char*>(der_buf), der_length));
+  OPENSSL_free(der_buf);
+
+  // If the key is missing parameters we don't accept it. This is allowed
+  // by RFC 3279 but we have not found any examples in the wild where it's
+  // used.
+  if (EVP_PKEY_missing_parameters(issuer_key)) {
+    LOG(WARNING) << "DSA sig check needs key params but not available";
+    return ::util::Status(Code::INVALID_ARGUMENT,
+                          "DSA key in cert has missing parameters");
+  }
+
+  const DSA* dsa = EVP_PKEY_get0_DSA(issuer_key);
+  const EVP_MD* md = EVP_get_digestbynid(digest_nid);
+
+  if (dsa == nullptr || md == nullptr) {
+    return ::util::Status(Code::INTERNAL,
+                          "failed to create hasher or get DSA sig");
+  }
+
+  unsigned char md_buffer[EVP_MAX_MD_SIZE];
+  unsigned int md_size;
+
+  // Build the digest of the cert info. Can't use higher level APIs for
+  // this unfortunately as DSA is not connected up.
+  if (!EVP_Digest(der_buf_str.c_str(), der_length, md_buffer, &md_size, md,
+                  nullptr)) {
+    return ::util::Status(Code::INTERNAL, "digest failed");
+  }
+
+  int out_valid;
+  if (!DSA_check_signature(&out_valid, md_buffer, md_size,
+                           cert->signature->data, cert->signature->length,
+                           dsa)) {
+    return ::util::Status(Code::INTERNAL, "failed to check DSA signature");
+  }
+
+  return out_valid == 1;
+}
+
+#endif
+}
+
+namespace cert_trans {
+
+
+// Convert string from ASN1 and check it doesn't contain nul characters
+string ASN1ToStringAndCheckForNulls(ASN1_STRING* asn1_string,
+                                    const string& tag, util::Status* status) {
+  const string cpp_string(reinterpret_cast<char*>(
+                              ASN1_STRING_data(asn1_string)),
+                          ASN1_STRING_length(asn1_string));
+
+  // Unfortunately ASN1_STRING_length returns a signed value
+  if (ASN1_STRING_length(asn1_string) < 0) {
+    *status = util::Status(Code::INVALID_ARGUMENT, "ASN1 string is corrupt?");
+  }
+
+  // Make sure there isn't an embedded NUL character in the DNS ID
+  // We now know it's not a negative length so this can't overflow.
+  if (static_cast<size_t>(ASN1_STRING_length(asn1_string)) !=
+      cpp_string.length()) {
+    LOG(ERROR) << "Embedded null in asn1 string: " << tag;
+    *status =
+        util::Status(Code::INVALID_ARGUMENT, "Embedded null in asn1 string");
+  } else {
+    *status = util::Status::OK;
+  }
+
+  return cpp_string;
+}
+
+
+unique_ptr<Cert> Cert::FromX509(ScopedX509 x509) {
+  return x509 ? unique_ptr<Cert>(new Cert(move(x509))) : nullptr;
+}
+
+
+Cert::Cert(ScopedX509 x509) : x509_(move(x509)) {
+  CHECK(x509_);
+}
+
+
+unique_ptr<Cert> Cert::FromPemString(const std::string& pem_string) {
+  // A read-only bio.
+  ScopedBIO bio_in(BIO_new_mem_buf(const_cast<char*>(pem_string.data()),
+                                   pem_string.length()));
+  if (!bio_in) {
+    LOG_OPENSSL_ERRORS(ERROR);
+    return nullptr;
+  }
+
+  ScopedX509 x509(PEM_read_bio_X509(bio_in.get(), nullptr, nullptr, nullptr));
+  if (!x509) {
+    // At this point most likely the input was just corrupt. There are a few
+    // real errors that may have happened (a malloc failure is one) and it is
+    // virtually impossible to fish them out.
+    LOG(WARNING) << "Input is not a valid PEM-encoded certificate";
+    LOG_OPENSSL_ERRORS(WARNING);
+  }
+
+  return FromX509(move(x509));
+}
+
+
+unique_ptr<Cert> Cert::Clone() const {
+  ScopedX509 x509;
+  if (x509_) {
+    x509.reset(X509_dup(x509_.get()));
+    if (!x509) {
+      LOG_OPENSSL_ERRORS(ERROR);
+    }
+  }
+  return FromX509(move(x509));
+}
+
+
+unique_ptr<Cert> Cert::FromDerString(const string& der_string) {
+  const unsigned char* start =
+      reinterpret_cast<const unsigned char*>(der_string.data());
+  ScopedX509 x509(d2i_X509(nullptr, &start, der_string.size()));
+  if (!x509) {
+    LOG(WARNING) << "Input is not a valid DER-encoded certificate";
+    LOG_OPENSSL_ERRORS(WARNING);
+  }
+  return FromX509(move(x509));
+}
+
+
+unique_ptr<Cert> Cert::FromDerBio(BIO* bio_in) {
+  ScopedX509 x509(d2i_X509_bio(CHECK_NOTNULL(bio_in), nullptr));
+  if (!x509) {
+    // At this point most likely the input was just corrupt. There are few
+    // real errors that may have happened (a malloc failure is one) and it is
+    // virtually impossible to fish them out.
+    LOG(WARNING) << "Input is not a valid encoded certificate";
+    LOG_OPENSSL_ERRORS(WARNING);
+  }
+  return FromX509(move(x509));
+}
+
+
+string Cert::PrintVersion() const {
+  const long version(X509_get_version(CHECK_NOTNULL(x509_.get())));
+  return to_string(1 + version);
+}
+
+
+string Cert::PrintSerialNumber() const {
+  ScopedBIGNUM serial_number_BN(
+      ASN1_INTEGER_to_BN(X509_get_serialNumber(CHECK_NOTNULL(x509_.get())),
+                         nullptr));
+
+  ScopedOpenSSLString serial_number_hex(BN_bn2hex(serial_number_BN.get()));
+
+  string serial(serial_number_hex.get());
+  std::transform(serial.begin(), serial.end(), serial.begin(), ::toupper);
+  return serial;
+}
+
+
+string Cert::PrintIssuerName() const {
+  return PrintName(X509_get_issuer_name(CHECK_NOTNULL(x509_.get())));
+}
+
+
+string Cert::PrintSubjectName() const {
+  return PrintName(X509_get_subject_name(CHECK_NOTNULL(x509_.get())));
+}
+
+
+// static
+string Cert::PrintName(X509_NAME* name) {
+  if (!name)
+    return string();
+  ScopedBIO bio(BIO_new(BIO_s_mem()));
+  if (!bio) {
+    LOG_OPENSSL_ERRORS(ERROR);
+    return string();
+  }
+
+  if (X509_NAME_print_ex(bio.get(), name, 0, 0) != 1) {
+    LOG_OPENSSL_ERRORS(ERROR);
+    return string();
+  }
+
+  string ret = util::ReadBIO(bio.get());
+  return ret;
+}
+
+
+string Cert::PrintNotBefore() const {
+  return PrintTime(X509_get_notBefore(CHECK_NOTNULL(x509_.get())));
+}
+
+
+string Cert::PrintNotAfter() const {
+  return PrintTime(X509_get_notAfter(CHECK_NOTNULL(x509_.get())));
+}
+
+
+string Cert::PrintSignatureAlgorithm() const {
+  const char* sigalg = OBJ_nid2ln(X509_get_signature_nid(x509_.get()));
+  if (!sigalg)
+    return "NULL";
+  return string(sigalg);
+}
+
+
+// static
+string Cert::PrintTime(ASN1_TIME* when) {
+  if (!when)
+    return string();
+
+  ScopedBIO bio(BIO_new(BIO_s_mem()));
+  if (!bio) {
+    LOG_OPENSSL_ERRORS(ERROR);
+    return string();
+  }
+
+  if (ASN1_TIME_print(bio.get(), when) != 1) {
+    LOG_OPENSSL_ERRORS(ERROR);
+    return string();
+  }
+
+  string ret = util::ReadBIO(bio.get());
+  return ret;
+}
+
+
+bool Cert::IsIdenticalTo(const Cert& other) const {
+  return X509_cmp(x509_.get(), other.x509_.get()) == 0;
+}
+
+
+util::StatusOr<bool> Cert::HasExtension(int extension_nid) const {
+  CHECK(x509_);
+
+  const StatusOr<int> index(ExtensionIndex(extension_nid));
+  if (index.ok()) {
+    return true;
+  }
+
+  if (index.status().CanonicalCode() == util::error::NOT_FOUND) {
+    return false;
+  }
+
+  return util::Status(Code::INTERNAL, "Failed to get extension");
+}
+
+
+StatusOr<bool> Cert::HasCriticalExtension(int extension_nid) const {
+  CHECK(x509_);
+
+  const StatusOr<X509_EXTENSION*> ext(GetExtension(extension_nid));
+  if (!ext.ok()) {
+    // The extension may be absent, which is not an error
+    if (ext.status().CanonicalCode() == util::error::NOT_FOUND) {
+      return false;
+    } else {
+      return util::Status(Code::INTERNAL, "Failed to get extension");
+    }
+  }
+
+  return X509_EXTENSION_get_critical(ext.ValueOrDie()) > 0;
+}
+
+
+StatusOr<bool> Cert::HasBasicConstraintCATrue() const {
+  CHECK(x509_);
+  const StatusOr<void*> ext_struct(ExtensionStructure(NID_basic_constraints));
+
+  if (ext_struct.status().CanonicalCode() == Code::NOT_FOUND) {
+    // No extension found
+    return false;
+  } else if (!ext_struct.ok()) {
+    // Truly odd.
+    LOG(ERROR) << "Failed to check BasicConstraints extension";
+    return ext_struct.status();
+  }
+
+  // |constraints| is never null upon success.
+  ScopedBASIC_CONSTRAINTS basic_constraints(
+      static_cast<BASIC_CONSTRAINTS*>(ext_struct.ValueOrDie()));
+  bool is_ca = basic_constraints->ca;
+  return is_ca;
+}
+
+
+StatusOr<bool> Cert::HasExtendedKeyUsage(int key_usage_nid) const {
+  CHECK(x509_);
+
+  const ASN1_OBJECT* key_usage_obj = OBJ_nid2obj(key_usage_nid);
+  if (!key_usage_obj) {
+    LOG(ERROR) << "OpenSSL OBJ_nid2obj returned NULL for NID " << key_usage_nid
+               << ". Is the NID not recognised?";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return util::Status(Code::INTERNAL, "NID lookup failed");
+  }
+
+  const StatusOr<void*> ext_key_usage = ExtensionStructure(NID_ext_key_usage);
+
+  if (ext_key_usage.status().CanonicalCode() == Code::NOT_FOUND) {
+    // No extension found
+    return false;
+  } else if (!ext_key_usage.ok()) {
+    // Truly odd.
+    LOG(ERROR) << "Failed to check ExtendedKeyUsage extension";
+    return ext_key_usage.status();
+  }
+
+  // |eku| is never null upon success.
+  ScopedEXTENDED_KEY_USAGE eku(
+      static_cast<EXTENDED_KEY_USAGE*>(ext_key_usage.ValueOrDie()));
+  bool ext_key_usage_found = false;
+  for (int i = 0; i < sk_ASN1_OBJECT_num(eku.get()); ++i) {
+    if (OBJ_cmp(key_usage_obj, sk_ASN1_OBJECT_value(eku.get(), i)) == 0) {
+      ext_key_usage_found = true;
+      break;
+    }
+  }
+
+  return ext_key_usage_found;
+}
+
+
+StatusOr<bool> Cert::IsIssuedBy(const Cert& issuer) const {
+  // Seemingly no negative "real" error codes are returned from openssl api.
+  return X509_check_issued(CHECK_NOTNULL(issuer.x509_.get()),
+                           CHECK_NOTNULL(x509_.get())) == X509_V_OK;
+}
+
+StatusOr<bool> Cert::LogUnsupportedAlgorithm() const {
+  LOG(WARNING) << "Unsupported algorithm: " << PrintSignatureAlgorithm();
+  ClearOpenSSLErrors();
+  return util::Status(Code::UNIMPLEMENTED, "Unsupported algorithm");
+}
+
+StatusOr<bool> Cert::IsSignedBy(const Cert& issuer) const {
+  const ScopedEVP_PKEY issuer_key(
+      X509_get_pubkey(CHECK_NOTNULL(issuer.x509_.get())));
+  if (!issuer_key) {
+    LOG(WARNING) << "NULL issuer key";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return false;
+  }
+
+  const int ret(X509_verify(CHECK_NOTNULL(x509_.get()), issuer_key.get()));
+  if (ret == 1) {
+    return true;
+  }
+
+#if defined(OPENSSL_IS_BORINGSSL)
+  // With BoringSSL we might have a signature algorithm that is not supported
+  // by X509_verify but we still want to accept into a log. This is a weaker
+  // check than x509_verify but sufficient for our needs as we are rejecting
+  // spam rather than intending to trust the certificate.
+  // Let's see if we can verify a DSA signature
+  const StatusOr<bool> is_valid_dsa_sig =
+      check_dsa_signature(x509_.get(), issuer_key.get());
+
+  if (is_valid_dsa_sig.ok()) {
+    if (is_valid_dsa_sig.ValueOrDie()) {
+      ClearOpenSSLErrors();
+      return true;
+    } else {
+      // Ensure we return the same status as we'd have got from calling
+      // IsValidSignatureChain() under OpenSSL when the signature is not valid.
+      return util::Status(Code::INVALID_ARGUMENT, "invalid certificate chain");
+    }
+  }
+#endif
+
+  unsigned long err = ERR_peek_last_error();
+  const int reason = ERR_GET_REASON(err);
+  const int lib = ERR_GET_LIB(err);
+  // OpenSSL and BoringSSL use ERR_R_EVP_LIB when a signature fails to verify.
+  // Clear errors in this case, but log unusual failures.
+  if (err == 0 || ((lib == ERR_LIB_X509 || lib == ERR_LIB_ASN1) &&
+                   reason == ERR_R_EVP_LIB)) {
+    ClearOpenSSLErrors();
+    return false;
+  }
+  if (lib == ERR_LIB_ASN1 &&
+      (reason == ASN1_R_UNKNOWN_MESSAGE_DIGEST_ALGORITHM ||
+       reason == ASN1_R_UNKNOWN_SIGNATURE_ALGORITHM)) {
+    return LogUnsupportedAlgorithm();
+  }
+  LOG(ERROR) << "OpenSSL X509_verify returned " << ret;
+  LOG_OPENSSL_ERRORS(ERROR);
+  return util::Status(Code::INTERNAL, "X509 verify error");
+}
+
+
+util::Status Cert::DerEncoding(string* result) const {
+  unsigned char* der_buf(nullptr);
+  int der_length = i2d_X509(CHECK_NOTNULL(x509_.get()), &der_buf);
+
+  if (der_length < 0) {
+    // Failed to decode. Several possible reasons but we will just reject
+    // the input rather than trying to interpret the cause
+    LOG(WARNING) << "Failed to serialize cert";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return util::Status(Code::INVALID_ARGUMENT, "DER decoding failed");
+  }
+
+  result->assign(reinterpret_cast<char*>(der_buf), der_length);
+  OPENSSL_free(der_buf);
+  return util::Status::OK;
+}
+
+
+util::Status Cert::PemEncoding(string* result) const {
+  ScopedBIO bp(BIO_new(BIO_s_mem()));
+  if (!PEM_write_bio_X509(bp.get(), CHECK_NOTNULL(x509_.get()))) {
+    LOG(WARNING) << "Failed to serialize cert";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return util::Status(Code::INVALID_ARGUMENT, "PEM serialize failed");
+  }
+
+  char* data;
+  const long len(BIO_get_mem_data(bp.get(), &data));
+  CHECK_GT(len, 0);
+  CHECK(data);
+
+  result->assign(data, len);
+
+  return util::Status::OK;
+}
+
+
+util::Status Cert::Sha256Digest(string* result) const {
+  unsigned char digest[EVP_MAX_MD_SIZE];
+  unsigned int len;
+  if (X509_digest(CHECK_NOTNULL(x509_.get()), EVP_sha256(), digest, &len) !=
+      1) {
+    // Failed to digest. Several possible reasons but we will just reject
+    // the input rather than trying to interpret the cause
+    LOG(WARNING) << "Failed to compute cert digest";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return util::Status(Code::INVALID_ARGUMENT, "SHA256 digest failed");
+  }
+
+  result->assign(reinterpret_cast<char*>(digest), len);
+  return util::Status::OK;
+}
+
+
+util::Status Cert::DerEncodedTbsCertificate(string* result) const {
+  unsigned char* der_buf(nullptr);
+  int der_length = i2d_re_X509_tbs(CHECK_NOTNULL(x509_.get()), &der_buf);
+  if (der_length < 0) {
+    // Failed to serialize. Several possible reasons but we will just reject
+    // the input rather than trying to interpret the cause
+    LOG(WARNING) << "Failed to serialize the TBS component";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return util::Status(Code::INVALID_ARGUMENT, "TBS DER serialize failed");
+  }
+  result->assign(reinterpret_cast<char*>(der_buf), der_length);
+  OPENSSL_free(der_buf);
+  return util::Status::OK;
+}
+
+
+util::Status Cert::DerEncodedSubjectName(string* result) const {
+  return DerEncodedName(X509_get_subject_name(CHECK_NOTNULL(x509_.get())),
+                        result);
+}
+
+
+util::Status Cert::DerEncodedIssuerName(string* result) const {
+  return DerEncodedName(X509_get_issuer_name(CHECK_NOTNULL(x509_.get())),
+                        result);
+}
+
+
+// static
+util::Status Cert::DerEncodedName(X509_NAME* name, string* result) {
+  unsigned char* der_buf(nullptr);
+  int der_length = i2d_X509_NAME(name, &der_buf);
+  if (der_length < 0) {
+    // Failed to serialize. Several possible reasons but we will just reject
+    // the input rather than trying to interpret the cause
+    LOG(WARNING) << "Failed to serialize the subject name";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return util::Status(Code::INVALID_ARGUMENT, "name DER serialize failed");
+  }
+  result->assign(reinterpret_cast<char*>(der_buf), der_length);
+  OPENSSL_free(der_buf);
+  return util::Status::OK;
+}
+
+
+util::Status Cert::PublicKeySha256Digest(string* result) const {
+  unsigned char digest[EVP_MAX_MD_SIZE];
+  unsigned int len;
+  if (X509_pubkey_digest(CHECK_NOTNULL(x509_.get()), EVP_sha256(), digest,
+                         &len) != 1) {
+    // Failed to digest. Several possible reasons but we will just reject
+    // the input rather than trying to interpret the cause
+    LOG(WARNING) << "Failed to compute public key digest";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return util::Status(Code::INVALID_ARGUMENT, "SHA256 digest failed");
+  }
+  result->assign(reinterpret_cast<char*>(digest), len);
+  return util::Status::OK;
+}
+
+
+StatusOr<string> Cert::SPKI() const {
+  unsigned char* der_buf(nullptr);
+  const int der_length(
+      i2d_X509_PUBKEY(X509_get_X509_PUBKEY(CHECK_NOTNULL(x509_.get())),
+                      &der_buf));
+  if (der_length < 0) {
+    // What does this return value mean? Let's assume it means the cert
+    // is bad until proven otherwise.
+    LOG(WARNING) << "Failed to serialize the Subject Public Key Info";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return util::Status(Code::INVALID_ARGUMENT, "Cert::SPKI() failed");
+  }
+
+  string result;
+  result.assign(
+      string(reinterpret_cast<char*>(CHECK_NOTNULL(der_buf)), der_length));
+
+  OPENSSL_free(der_buf);
+  return result;
+}
+
+
+util::Status Cert::SPKISha256Digest(string* result) const {
+  const util::StatusOr<string> spki(SPKI());
+  if (spki.ok()) {
+    string sha256_digest = Sha256Hasher::Sha256Digest(spki.ValueOrDie());
+    CHECK_NOTNULL(result)->assign(sha256_digest);
+  }
+  return spki.status();
+}
+
+util::Status Cert::OctetStringExtensionData(int extension_nid,
+                                            string* result) const {
+  CHECK(x509_);
+
+  // Callers don't care whether extension is missing or invalid as they
+  // usually call this method after confirming it to be present.
+  const StatusOr<void*> ext_struct = ExtensionStructure(extension_nid);
+  if (!ext_struct.ok() &&
+      ext_struct.status().CanonicalCode() == Code::NOT_FOUND) {
+    return ext_struct.status();
+  }
+
+  // |octet| is never null upon success. Caller is responsible for the
+  // correctness of this cast.
+  ScopedASN1_OCTET_STRING octet(
+      static_cast<ASN1_OCTET_STRING*>(ext_struct.ValueOrDie()));
+  result->assign(reinterpret_cast<const char*>(octet->data), octet->length);
+  return util::Status::OK;
+}
+
+
+util::StatusOr<int> Cert::ExtensionIndex(int extension_nid) const {
+  const int index(
+      X509_get_ext_by_NID(CHECK_NOTNULL(x509_.get()), extension_nid, -1));
+  if (index < -1) {
+    // The most likely and possibly only cause for a return code
+    // other than -1 is an unrecognized NID.
+    LOG(ERROR) << "OpenSSL X509_get_ext_by_NID returned " << index
+               << " for NID " << extension_nid
+               << ". Is the NID not recognised?";
+    LOG_OPENSSL_ERRORS(ERROR);
+    return util::Status(util::error::INTERNAL, "X509_get_ext_by_NID error");
+  }
+  if (index == -1)
+    return util::Status(util::error::NOT_FOUND, "extension not found");
+  return index;
+}
+
+
+StatusOr<X509_EXTENSION*> Cert::GetExtension(int extension_nid) const {
+  const StatusOr<int> extension_index(ExtensionIndex(extension_nid));
+  if (!extension_index.ok()) {
+    return extension_index.status();
+  }
+
+  X509_EXTENSION* const ext(
+      X509_get_ext(x509_.get(), extension_index.ValueOrDie()));
+  if (!ext) {
+    LOG(ERROR) << "Failed to retrieve extension for NID " << extension_nid
+               << ", at index " << extension_index.ValueOrDie();
+    LOG_OPENSSL_ERRORS(ERROR);
+    return util::Status(util::error::INTERNAL,
+                        "failed to retrieve extension for NID " +
+                            to_string(extension_nid) + ", at index " +
+                            to_string(extension_index.ValueOrDie()));
+  }
+
+  return ext;
+}
+
+
+util::StatusOr<void*> Cert::ExtensionStructure(int extension_nid) const {
+  // Let's first check if the extension is present. This allows us to
+  // distinguish between "NID not recognized" and the more harmless
+  // "extension not found, found more than once or corrupt".
+  const StatusOr<bool> has_ext = HasExtension(extension_nid);
+  if (!has_ext.ok()) {
+    return has_ext.status();
+  }
+
+  if (!has_ext.ValueOrDie()) {
+    return util::Status(Code::NOT_FOUND, "Extension NID " +
+                                             to_string(extension_nid) +
+                                             " not present or invalid");
+  }
+
+  int crit;
+
+  void* ext_struct(
+      X509_get_ext_d2i(x509_.get(), extension_nid, &crit, nullptr));
+
+  if (!ext_struct) {
+    if (crit != -1) {
+      LOG(WARNING) << "Corrupt extension data";
+      LOG_OPENSSL_ERRORS(WARNING);
+    }
+
+    return util::Status(Code::FAILED_PRECONDITION,
+                        "Corrupt extension in cert?");
+  }
+
+  return ext_struct;
+}
+
+
+bool IsRedactedHost(const string& hostname) {
+  // Split the hostname on '.' characters
+  const vector<string> tokens(util::split(hostname, '.'));
+
+  for (const string& str : tokens) {
+    if (str == "?") {
+      return true;
+    }
+  }
+
+  return false;
+}
+
+
+bool IsValidRedactedHost(const string& hostname) {
+  // Split the hostname on '.' characters
+  const vector<string> tokens(util::split(hostname, '.'));
+
+  // Enforces the following rules: '?' must be to left of non redactions
+  // If first label is '*' then treat it as if it was a redaction
+  bool can_redact = true;
+  for (size_t pos = 0; pos < tokens.size(); ++pos) {
+    if (tokens[pos] == "?") {
+      if (!can_redact) {
+        return false;
+      }
+    } else {
+      // Allow a leading '*' for redaction but once we've seen anything else
+      // forbid further redactions
+      if (tokens[pos] != "*") {
+        can_redact = false;
+      } else if (pos > 0) {
+        // '*' is only valid at the left
+        return false;
+      }
+    }
+  }
+
+  return true;
+}
+
+
+namespace {
+
+util::Status ExtractSubjectAltNames(STACK_OF(GENERAL_NAME)* subject_alt_names,
+                                    vector<string>* dns_alt_names) {
+  CHECK_NOTNULL(subject_alt_names);
+  CHECK_NOTNULL(dns_alt_names);
+
+  dns_alt_names->clear();
+  const int subject_alt_name_count = sk_GENERAL_NAME_num(subject_alt_names);
+
+  for (int i = 0; i < subject_alt_name_count; ++i) {
+    GENERAL_NAME* const name(sk_GENERAL_NAME_value(subject_alt_names, i));
+
+    util::Status name_status;
+    if (name->type == GEN_DNS) {
+      const string dns_name =
+          ASN1ToStringAndCheckForNulls(name->d.dNSName, "DNS name",
+                                         &name_status);
+
+      if (!name_status.ok()) {
+        return name_status;
+      }
+
+      dns_alt_names->push_back(dns_name);
+    }
+  }
+  return util::Status::OK;
+}
+
+
+
+bool ValidateRedactionSubjectAltNames(STACK_OF(GENERAL_NAME) *
+                                          subject_alt_names,
+                                      vector<string>* dns_alt_names,
+                                      util::Status* status,
+                                      int* redacted_name_count) {
+  // First. Check all the Subject Alt Name extension records. Any that are of
+  // type DNS must pass validation if they are attempting to redact labels
+  if (subject_alt_names) {
+    *CHECK_NOTNULL(status) = ExtractSubjectAltNames(
+        subject_alt_names, CHECK_NOTNULL(dns_alt_names));
+
+    for (const auto& dns_name : *dns_alt_names) {
+      if (IsRedactedHost(dns_name)) {
+        if (!IsValidRedactedHost(dns_name)) {
+          LOG(WARNING) << "Invalid redacted host: " << dns_name;
+          *status = util::Status(Code::INVALID_ARGUMENT,
+                                 "Invalid redacted hostname");
+          return true;
+        }
+
+        (*redacted_name_count)++;
+      }
+    }
+  }
+
+  // This stage of validation is complete, result is not final yet
+  return false;
+}
+
+
+}  // namespace
+
+
+util::Status Cert::SubjectAltNames(vector<string>* dns_alt_names) const {
+  ScopedGENERAL_NAMEStack subject_alt_names(
+      static_cast<STACK_OF(GENERAL_NAME)*>(X509_get_ext_d2i(
+          x509_.get(), NID_subject_alt_name, nullptr, nullptr)));
+
+  if (subject_alt_names) {
+    return ExtractSubjectAltNames(subject_alt_names.get(),
+                                  CHECK_NOTNULL(dns_alt_names));
+  }
+
+  return util::Status::OK;
+}
+
+
+// Helper method for validating V2 redaction rules. If it returns true
+// then the result in status is final.
+bool Cert::ValidateRedactionSubjectAltNameAndCN(int* dns_alt_name_count,
+                                                util::Status* status) const {
+  string common_name;
+  int redacted_name_count = 0;
+  vector<string> dns_alt_names;
+
+  ScopedGENERAL_NAMEStack subject_alt_names(
+      static_cast<STACK_OF(GENERAL_NAME)*>(
+          X509_get_ext_d2i(CHECK_NOTNULL(x509_.get()), NID_subject_alt_name,
+                           nullptr, nullptr)));
+
+  // Apply validation rules for subject alt names, if this returns true
+  // status is already final.
+  if (subject_alt_names &&
+      ValidateRedactionSubjectAltNames(subject_alt_names.get(), &dns_alt_names,
+                                       status, &redacted_name_count)) {
+    return true;
+  }
+
+  // The next stage of validation is that if the subject name CN exists it
+  // must match the first DNS id and have the same labels redacted
+  // TODO: Confirm it's valid to not have a CN.
+  X509_NAME* const name(X509_get_subject_name(x509_.get()));
+
+  if (!name) {
+    LOG(ERROR) << "Missing X509 subject name";
+    *status =
+        util::Status(Code::INVALID_ARGUMENT, "Missing X509 subject name");
+    return true;
+  }
+
+  const int name_pos(X509_NAME_get_index_by_NID(name, NID_commonName, -1));
+
+  if (name_pos >= 0) {
+    X509_NAME_ENTRY* const name_entry(X509_NAME_get_entry(name, name_pos));
+
+    if (name_entry) {
+      ASN1_STRING* const subject_name_asn1(
+          X509_NAME_ENTRY_get_data(name_entry));
+
+      if (!subject_name_asn1) {
+        LOG(WARNING) << "Missing subject name";
+        // TODO: Check this is correct behaviour. Is it OK to not have
+        // a subject?
+      } else {
+        util::Status cn_status;
+        common_name =
+            ASN1ToStringAndCheckForNulls(subject_name_asn1, "CN", &cn_status);
+
+        if (!cn_status.ok()) {
+          *status = cn_status;
+          return true;
+        }
+      }
+    }
+  }
+
+  // If both a subject CN and DNS ids are present in the cert then the
+  // first DNS id must exactly match the CN
+  if (!dns_alt_names.empty() && !common_name.empty()) {
+    if (dns_alt_names[0] != common_name) {
+      LOG(WARNING) << "CN " << common_name << " does not match DNS.0 "
+                   << dns_alt_names[0];
+      *status =
+          util::Status(Code::INVALID_ARGUMENT, "CN does not match DNS.0");
+      return true;
+    }
+  }
+
+  // The attempted redaction passes host validation. Stage two is checking
+  // that the required extensions are present and specified correctly if
+  // we found any redacted names. First though if nothing is redacted
+  // then the rest of the rules need not be applied
+  if (redacted_name_count == 0 && !IsRedactedHost(common_name)) {
+    *status = util::Status::OK;
+    return true;
+  }
+
+  *dns_alt_name_count = dns_alt_names.size();
+  return false;  // validation has no definite result yet
+}
+
+
+util::Status Cert::IsValidWildcardRedaction() const {
+  util::Status status(Code::UNKNOWN, "Unknown error");
+  int dns_alt_name_count = 0;
+
+  // First we apply all the checks to the subject CN and the list of DNS
+  // names in subject alt names. If these checks have a definite result
+  // then return it immediately.
+  if (ValidateRedactionSubjectAltNameAndCN(&dns_alt_name_count, &status)) {
+    return status;
+  }
+
+  // If we reach here then the RFC says the CT redaction count extension
+  // MUST BE present.
+  const StatusOr<X509_EXTENSION*> exty(
+      GetExtension(NID_ctPrecertificateRedactedLabelCount));
+  if (!exty.ok()) {
+    LOG(WARNING)
+        << "required CT redaction count extension could not be found in cert";
+    return util::Status(Code::INVALID_ARGUMENT,
+                        "No CT redaction count extension");
+  }
+
+  // Ensure the data in the extension is a sequence. DER encoding is same for
+  // SEQUENCE and SEQUENCE OF and we'll check types later.
+  if (exty.ValueOrDie()->value->data[0] !=
+      (V_ASN1_SEQUENCE | V_ASN1_CONSTRUCTED)) {
+    LOG(WARNING) << "CT redaction count extension is not a SEQUENCE OF";
+    return util::Status(Code::INVALID_ARGUMENT,
+                        "CT redaction count extension not a sequence");
+  }
+
+  // Unpack the extension contents, which should be SEQUENCE OF INTEGER.
+  // For compatibility we unpack any sequence and check integer type as we go.
+  // Don't pass the pointer from the extension directly as it gets incremented
+  // during parsing.
+  const unsigned char* sequence_data(
+      const_cast<const unsigned char*>(exty.ValueOrDie()->value->data));
+  ScopedASN1_TYPEStack asn1_types(static_cast<STACK_OF(ASN1_TYPE)*>(
+      d2i_ASN1_SEQUENCE_ANY(nullptr, &sequence_data,
+                            exty.ValueOrDie()->value->length)));
+
+  if (asn1_types) {
+    const int num_integers(sk_ASN1_TYPE_num(asn1_types.get()));
+
+    // RFC text says there MUST NOT be more integers than there are DNS ids
+    if (num_integers > dns_alt_name_count) {
+      LOG(WARNING) << "Too many integers in extension: " << num_integers
+                   << " but only " << dns_alt_name_count << " DNS names";
+      return util::Status(Code::INVALID_ARGUMENT,
+                          "More integers in ext than redacted labels");
+    }
+
+    // All the integers in the sequence must be positive, check the sign
+    // after conversion to BIGNUM
+    for (int i = 0; i < num_integers; ++i) {
+      ASN1_TYPE* const asn1_type(sk_ASN1_TYPE_value(asn1_types.get(), i));
+
+      if (asn1_type->type != V_ASN1_INTEGER) {
+        LOG(WARNING) << "Redaction count has non-integer in sequence"
+                     << asn1_type->type;
+        return util::Status(Code::INVALID_ARGUMENT,
+                            "Non integer found in redaction label count");
+      }
+
+      ASN1_INTEGER* const redacted_labels(asn1_type->value.integer);
+      ScopedBIGNUM value(ASN1_INTEGER_to_BN(redacted_labels, nullptr));
+
+      const bool neg = value->neg;
+      if (neg) {
+        ScopedOpenSSLString bn_hex(BN_bn2hex(value.get()));
+        LOG(WARNING) << "Invalid negative redaction label count: "
+                     << bn_hex.get();
+        return util::Status(Code::INVALID_ARGUMENT, "Invalid -ve label count");
+      }
+    }
+
+  } else {
+    LOG(WARNING) << "Failed to unpack SEQUENCE OF in CT extension";
+    return util::Status(Code::INVALID_ARGUMENT,
+                        "Failed to unpack integer sequence in ext");
+  }
+
+  return util::Status::OK;
+}
+
+
+util::Status Cert::IsValidNameConstrainedIntermediateCa() const {
+  // If it's not a CA cert or there is no name constraint extension then we
+  // don't need to apply the rules any further
+  const StatusOr<bool> has_ca_constraint = HasBasicConstraintCATrue();
+  const StatusOr<bool> has_name_constraints =
+      HasExtension(NID_name_constraints);
+
+  // However, we don't expect either of the above lookups to fail as the
+  // extensions are registered.
+  if (!has_ca_constraint.ok()) {
+    return has_ca_constraint.status();
+  }
+
+  if (!has_name_constraints.ok()) {
+    return has_name_constraints.status();
+  }
+
+  if (!has_ca_constraint.ValueOrDie() || !has_name_constraints.ValueOrDie()) {
+    return util::Status::OK;
+  }
+
+  // So there now must be a CT extension and the name constraint must not be
+  // in error
+  const StatusOr<bool> has_ct_nolog_intermediate =
+      HasExtension(NID_ctNameConstraintNologIntermediateCa);
+
+  CHECK(has_name_constraints.ValueOrDie());
+  if (!has_ct_nolog_intermediate.ok() ||
+      !has_ct_nolog_intermediate.ValueOrDie()) {
+    LOG(WARNING) << "Name constraint extension without CT extension";
+    return util::Status(Code::INVALID_ARGUMENT,
+                        "Name constraint ext present, CT ext missing");
+  }
+
+  int crit;
+  NAME_CONSTRAINTS* const nc(static_cast<NAME_CONSTRAINTS*>(
+      X509_get_ext_d2i(x509_.get(), NID_name_constraints, &crit, nullptr)));
+
+  if (!nc || crit == -1) {
+    LOG(ERROR) << "Couldn't parse the name constraint extension";
+    return util::Status(Code::INTERNAL, "Failed to parse name constraint");
+  }
+
+  // Search all the permitted subtrees, there must be at least one DNS
+  // entry and it must not be empty
+  bool seen_dns = false;
+
+  for (int permitted_subtree = 0;
+       permitted_subtree < sk_GENERAL_SUBTREE_num(nc->permittedSubtrees);
+       ++permitted_subtree) {
+    GENERAL_SUBTREE* const perm_subtree(
+        sk_GENERAL_SUBTREE_value(nc->permittedSubtrees, permitted_subtree));
+
+    if (perm_subtree->base && perm_subtree->base->type == GEN_DNS &&
+        perm_subtree->base->d.dNSName->length > 0) {
+      seen_dns = true;
+    }
+  }
+
+  // There must be an excluded subtree entry that covers the whole IPv4 and
+  // IPv6 range. Or at least one entry for both that covers the whole
+  // range
+  bool seen_ipv4 = false;
+  bool seen_ipv6 = false;
+
+  // TODO: Does not handle more complex cases at the moment and I'm
+  // not sure whether it should. E.g. a combination of multiple entries
+  // that end up covering the whole available range. For the moment
+  // things similar to the example in the RFC work.
+  for (int excluded_subtree = 0;
+       excluded_subtree < sk_GENERAL_SUBTREE_num(nc->excludedSubtrees);
+       ++excluded_subtree) {
+    GENERAL_SUBTREE* const excl_subtree(
+        sk_GENERAL_SUBTREE_value(nc->excludedSubtrees, excluded_subtree));
+
+    // Only consider entries that are of type ipAddress (OCTET_STRING)
+    if (excl_subtree->base && excl_subtree->base->type == GEN_IPADD) {
+      // First check that all the bytes of the string are zero
+      bool all_zero = true;
+      for (int i = 0; i < excl_subtree->base->d.ip->length; ++i) {
+        if (excl_subtree->base->d.ip->data[i] != 0) {
+          all_zero = false;
+        }
+      }
+
+      if (all_zero) {
+        if (excl_subtree->base->d.ip->length == 32) {
+          // IPv6
+          seen_ipv6 = true;
+        } else if (excl_subtree->base->d.ip->length == 8) {
+          // IPv4
+          seen_ipv4 = true;
+        }
+      }
+    }
+  }
+
+  NAME_CONSTRAINTS_free(nc);
+
+  if (!seen_dns) {
+    LOG(WARNING) << "No DNS entry found in permitted subtrees";
+    return util::Status(Code::INVALID_ARGUMENT,
+                        "No DNS entry in permitted subtrees");
+  }
+
+  if (!seen_ipv4 || !seen_ipv6) {
+    LOG(WARNING) << "Excluded subtree does not cover all IPv4 and v6 range";
+    return util::Status(Code::INVALID_ARGUMENT,
+                        "Does not exclude all IPv4 and v6 range");
+  }
+
+  return util::Status::OK;
+}
+
+TbsCertificate::TbsCertificate(const Cert& cert) {
+  x509_.reset(X509_dup(CHECK_NOTNULL(cert.x509_.get())));
+
+  if (!x509_)
+    LOG_OPENSSL_ERRORS(ERROR);
+}
+
+
+util::Status TbsCertificate::DerEncoding(string* result) const {
+  if (!IsLoaded()) {
+    LOG(ERROR) << "TBS not loaded";
+    return util::Status(Code::FAILED_PRECONDITION, "Cert not loaded (TBS)");
+  }
+
+  unsigned char* der_buf(nullptr);
+  int der_length = i2d_re_X509_tbs(x509_.get(), &der_buf);
+  if (der_length < 0) {
+    // Failed to serialize. Several possible reasons but we will just reject
+    // the input rather than trying to interpret the cause
+    LOG(WARNING) << "Failed to serialize the TBS component";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return util::Status(Code::INTERNAL, "Failed to serialize TBS");
+  }
+  result->assign(reinterpret_cast<char*>(der_buf), der_length);
+  OPENSSL_free(der_buf);
+  return util::Status::OK;
+}
+
+
+util::Status TbsCertificate::DeleteExtension(int extension_nid) {
+  if (!IsLoaded()) {
+    LOG(ERROR) << "TBS not loaded";
+    return util::Status(Code::FAILED_PRECONDITION, "Cert not loaded (TBS)");
+  }
+
+  const StatusOr<int> extension_index(ExtensionIndex(extension_nid));
+  // If the extension doesn't exist then there is nothing to do and this
+  // propagates the NOT_FOUND status.
+  if (!extension_index.ok()) {
+    return extension_index.status();
+  }
+
+  ScopedX509_EXTENSION ext(
+      X509_delete_ext(x509_.get(), extension_index.ValueOrDie()));
+
+  if (!ext) {
+    // Truly odd.
+    LOG(ERROR) << "Failed to delete the extension";
+    LOG_OPENSSL_ERRORS(ERROR);
+    return util::Status(Code::INTERNAL, "Failed to delete extension");
+  }
+
+
+  // ExtensionIndex returns the first matching index - if the extension
+  // occurs more than once, just give up.
+  const StatusOr<int> ignored_index(ExtensionIndex(extension_nid));
+  if (ignored_index.ok()) {
+    LOG(WARNING)
+        << "Failed to delete the extension. Does the certificate have "
+        << "duplicate extensions?";
+    return util::Status(Code::ALREADY_EXISTS, "Multiple extensions in cert");
+  }
+
+  // It's not an error if the extension didn't exist the second time
+  // as it should have been deleted.
+  if (!ignored_index.ok() &&
+      ignored_index.status().CanonicalCode() != Code::NOT_FOUND) {
+    return ignored_index.status();
+  }
+
+  return util::Status::OK;
+}
+
+
+util::Status TbsCertificate::CopyIssuerFrom(const Cert& from) {
+  if (!IsLoaded()) {
+    LOG(ERROR) << "TBS not loaded";
+    return util::Status(Code::FAILED_PRECONDITION, "Cert not loaded (TBS)");
+  }
+
+  // This just looks up the relevant pointer so there shouldn't
+  // be any errors to clear.
+  X509_NAME* ca_name = X509_get_issuer_name(from.x509_.get());
+  if (!ca_name) {
+    LOG(WARNING) << "Issuer certificate has NULL name";
+    return util::Status(Code::FAILED_PRECONDITION,
+                        "Issuer cert has NULL name");
+  }
+
+  if (X509_set_issuer_name(x509_.get(), ca_name) != 1) {
+    LOG(WARNING) << "Failed to set issuer name, Cert has NULL issuer?";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return util::Status(Code::FAILED_PRECONDITION,
+                        "Failed to set issuer, possibly null?");
+  }
+
+  // Verify that the Authority KeyID extensions are compatible.
+  StatusOr<int> status = ExtensionIndex(NID_authority_key_identifier);
+  if (status.status().CanonicalCode() == Code::NOT_FOUND) {
+    // No extension found = nothing to copy
+    return util::Status::OK;
+  }
+
+  if (!status.ok() || !status.ValueOrDie()) {
+    LOG(ERROR) << "Failed to check Authority Key Identifier extension";
+    return util::Status(Code::INTERNAL,
+                        "Failed to check Authority KeyID extension (TBS)");
+  }
+
+  const StatusOr<int> from_extension_index(
+      from.ExtensionIndex(NID_authority_key_identifier));
+  if (from_extension_index.status().CanonicalCode() ==
+      util::error::NOT_FOUND) {
+    // No extension found = cannot copy.
+    LOG(WARNING) << "Unable to copy issuer: destination has an Authority "
+                 << "KeyID extension, but the source has none.";
+    return util::Status(Code::FAILED_PRECONDITION,
+                        "Incompatible Authority KeyID extensions");
+  }
+
+  if (!from_extension_index.ok()) {
+    LOG(ERROR) << "Failed to check Authority Key Identifier extension";
+    return util::Status(Code::INTERNAL,
+                        "Failed to check Authority KeyID extension");
+  }
+
+  // Ok, now copy the extension, keeping the critical bit (which should always
+  // be false in a valid cert, mind you).
+  X509_EXTENSION* to_ext = X509_get_ext(x509_.get(), status.ValueOrDie());
+  X509_EXTENSION* from_ext =
+      X509_get_ext(from.x509_.get(), from_extension_index.ValueOrDie());
+
+  if (!to_ext || !from_ext) {
+    // Should not happen.
+    LOG(ERROR) << "Failed to retrieve extension";
+    LOG_OPENSSL_ERRORS(ERROR);
+    return util::Status(Code::INTERNAL,
+                        "Failed to retrieve one or both extensions");
+  }
+
+  if (X509_EXTENSION_set_data(to_ext, X509_EXTENSION_get_data(from_ext)) !=
+      1) {
+    LOG(ERROR) << "Failed to copy extension data.";
+    LOG_OPENSSL_ERRORS(ERROR);
+    return util::Status(Code::INTERNAL, "Failed to copy extension data");
+  }
+
+  return util::Status::OK;
+}
+
+
+StatusOr<int> TbsCertificate::ExtensionIndex(int extension_nid) const {
+  int index = X509_get_ext_by_NID(x509_.get(), extension_nid, -1);
+  if (index < -1) {
+    // The most likely and possibly only cause for a return code
+    // other than -1 is an unrecognized NID. This is different from a
+    // known extension not being present.
+    LOG(ERROR) << "OpenSSL X509_get_ext_by_NID returned " << index
+               << " for NID " << extension_nid
+               << ". Is the NID not recognised?";
+    LOG_OPENSSL_ERRORS(ERROR);
+    return util::Status(Code::INTERNAL,
+                        "Extension lookup failed. Incorrect NID?");
+  }
+  if (index == -1) {
+    return util::Status(Code::NOT_FOUND, "Extension not found.");
+  }
+
+  return index;
+}
+
+
+CertChain::CertChain(const string& pem_string) {
+  // A read-only BIO.
+  ScopedBIO bio_in(BIO_new_mem_buf(const_cast<char*>(pem_string.data()),
+                                   pem_string.length()));
+  if (!bio_in) {
+    LOG_OPENSSL_ERRORS(ERROR);
+    return;
+  }
+
+  ScopedX509 x509;
+  while ((x509 = ScopedX509(
+              PEM_read_bio_X509(bio_in.get(), nullptr, nullptr, nullptr)))) {
+    chain_.push_back(Cert::FromX509(move(x509)));
+  }
+
+  // The last error must be EOF.
+  unsigned long err = ERR_peek_last_error();
+  if (ERR_GET_LIB(err) != ERR_LIB_PEM ||
+      ERR_GET_REASON(err) != PEM_R_NO_START_LINE) {
+    // A real error.
+    LOG(WARNING) << "Input is not a valid PEM-encoded certificate chain";
+    LOG_OPENSSL_ERRORS(WARNING);
+    ClearChain();
+  } else {
+    ClearOpenSSLErrors();
+  }
+}
+
+
+bool CertChain::AddCert(unique_ptr<Cert> cert) {
+  if (!cert) {
+    LOG(ERROR) << "Attempting to add an invalid cert";
+    return false;
+  }
+  chain_.push_back(move(cert));
+  return true;
+}
+
+
+void CertChain::RemoveCert() {
+  if (IsLoaded()) {
+    chain_.pop_back();
+  } else {
+    LOG(ERROR) << "Chain is not loaded";
+  }
+}
+
+
+bool CertChain::RemoveCertsAfterFirstSelfSigned() {
+  if (!IsLoaded()) {
+    LOG(ERROR) << "Chain is not loaded";
+    return false;
+  }
+
+  size_t first_self_signed = chain_.size();
+
+  // Find the first self-signed certificate.
+  for (size_t i = 0; i < chain_.size(); ++i) {
+    StatusOr<bool> status = chain_[i]->IsSelfSigned();
+    if (!status.ok()) {
+      return false;
+    } else if (status.ValueOrDie()) {
+      first_self_signed = i;
+      break;
+    }
+  }
+
+  if (first_self_signed == chain_.size())
+    return true;
+
+  // Remove everything after it.
+  size_t chain_size = chain_.size();
+  for (size_t i = first_self_signed + 1; i < chain_size; ++i) {
+    RemoveCert();
+  }
+  return true;
+}
+
+
+CertChain::~CertChain() {
+  ClearChain();
+}
+
+
+util::Status CertChain::IsValidCaIssuerChainMaybeLegacyRoot() const {
+  if (!IsLoaded()) {
+    LOG(ERROR) << "Chain is not loaded";
+    return util::Status(Code::FAILED_PRECONDITION, "Cert not loaded");
+  }
+
+  for (vector<unique_ptr<Cert>>::const_iterator it = chain_.begin();
+       it + 1 < chain_.end(); ++it) {
+    const unique_ptr<Cert>& subject = *it;
+    const unique_ptr<Cert>& issuer = *(it + 1);
+
+    // The root cert may not have CA:True
+    const StatusOr<bool> status = issuer->IsSelfSigned();
+    if (status.ok() && !status.ValueOrDie()) {
+      const StatusOr<bool> s2(issuer->HasBasicConstraintCATrue());
+      if (!s2.ok() || !s2.ValueOrDie()) {
+        return util::Status(Code::INVALID_ARGUMENT,
+                            "CA constraint check failed");
+      }
+    } else if (!status.ok()) {
+      LOG(ERROR) << "Failed to check self-signed status";
+      return util::Status(Code::INVALID_ARGUMENT,
+                          "Failed to check self signed status");
+    }
+
+    const StatusOr<bool> s3 = subject->IsIssuedBy(*issuer);
+    if (!s3.ok() || !s3.ValueOrDie()) {
+      return util::Status(Code::INVALID_ARGUMENT, "Issuer check failed");
+    }
+  }
+  return util::Status::OK;
+}
+
+
+util::Status CertChain::IsValidSignatureChain() const {
+  if (!IsLoaded()) {
+    LOG(ERROR) << "Chain is not loaded";
+    return util::Status(util::error::FAILED_PRECONDITION,
+                        "certificate chain is not loaded");
+  }
+
+  for (vector<unique_ptr<Cert>>::const_iterator it = chain_.begin();
+       it + 1 < chain_.end(); ++it) {
+    const unique_ptr<Cert>& subject = *it;
+    const unique_ptr<Cert>& issuer = *(it + 1);
+
+    const StatusOr<bool> status = subject->IsSignedBy(*issuer);
+
+    // Propagate any failure status if we get one. This includes
+    // UNIMPLEMENTED for unsupported algorithms. This can happen
+    // when a weak algorithm (such as MD2) is intentionally not
+    // accepted in which case it's correct to say that the chain is invalid.
+    // It can also happen when EVP is not properly initialized, in
+    // which case it's more of an INTERNAL_ERROR. However a bust
+    // setup would manifest itself in many other ways, including
+    // failing tests, so we assume the failure is intentional.
+    if (!status.ok()) {
+      return status.status();
+    }
+
+    // Must have been signed by issuer or it's an invalid chain
+    if (!status.ValueOrDie()) {
+      return util::Status(util::error::INVALID_ARGUMENT,
+                          "invalid certificate chain");
+    }
+  }
+
+  return util::Status::OK;
+}
+
+
+void CertChain::ClearChain() {
+  chain_.clear();
+}
+
+
+util::StatusOr<bool> PreCertChain::UsesPrecertSigningCertificate() const {
+  const Cert* issuer = PrecertIssuingCert();
+  if (!issuer) {
+    // No issuer, so it must be a real root CA from the store.
+    return false;
+  }
+
+  return issuer->HasExtendedKeyUsage(cert_trans::NID_ctPrecertificateSigning);
+}
+
+
+util::StatusOr<bool> PreCertChain::IsWellFormed() const {
+  if (!IsLoaded()) {
+    LOG(ERROR) << "Chain is not loaded";
+    return util::Status(Code::FAILED_PRECONDITION, "Cert not loaded");
+  }
+
+  const Cert* pre = PreCert();
+
+  // (1) Check that the leaf contains the critical poison extension.
+  const StatusOr<bool> has_poison =
+      pre->HasCriticalExtension(cert_trans::NID_ctPoison);
+  if (!has_poison.ok() || !has_poison.ValueOrDie()) {
+    return has_poison;
+  }
+
+  // (2) If signed by a Precertificate Signing Certificate, check that
+  // the AKID extensions are compatible.
+  const StatusOr<bool> uses_precert_signing = UsesPrecertSigningCertificate();
+  if (uses_precert_signing.ok() && !uses_precert_signing.ValueOrDie()) {
+    // If there is no precert signing extendedKeyUsage, no more checks:
+    // the cert was issued by a regular CA.
+    return true;
+  }
+
+  if (!uses_precert_signing.ok()) {
+    return uses_precert_signing.status();
+  }
+
+  CHECK(uses_precert_signing.ValueOrDie());
+
+  const Cert* issuer = PrecertIssuingCert();
+  // If pre has the extension set but the issuer doesn't, error.
+  const StatusOr<bool> has_akid =
+      pre->HasExtension(NID_authority_key_identifier);
+
+  if (has_akid.ok() && !has_akid.ValueOrDie()) {
+    return true;
+  }
+  if (!has_akid.ok()) {
+    return has_akid;
+  }
+
+  CHECK(has_akid.ValueOrDie());
+
+  // Extension present in the leaf: check it's present in the issuer.
+  return issuer->HasExtension(NID_authority_key_identifier);
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert_checker.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert_checker.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert_checker.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert_checker.cc	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,346 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "log/cert_checker.h"
+
+#include <glog/logging.h>
+#include <openssl/asn1.h>
+#include <openssl/bio.h>
+#include <openssl/pem.h>
+#include <openssl/x509.h>
+#include <openssl/x509v3.h>
+#include <string.h>
+#include <memory>
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "log/cert.h"
+#include "log/ct_extensions.h"
+#include "util/openssl_scoped_types.h"
+#include "util/openssl_util.h"  // for LOG_OPENSSL_ERRORS
+#include "util/util.h"
+
+using std::move;
+using std::multimap;
+using std::pair;
+using std::string;
+using std::unique_ptr;
+using std::vector;
+using util::ClearOpenSSLErrors;
+using util::Status;
+using util::StatusOr;
+using util::error::Code;
+
+namespace cert_trans {
+
+bool CertChecker::LoadTrustedCertificates(const string& cert_file) {
+  // A read-only BIO.
+  ScopedBIO bio_in(BIO_new(BIO_s_file()));
+  if (!bio_in) {
+    LOG_OPENSSL_ERRORS(ERROR);
+    return false;
+  }
+
+  if (BIO_read_filename(bio_in.get(), cert_file.c_str()) <= 0) {
+    LOG(ERROR) << "Failed to open file " << cert_file << " for reading";
+    LOG_OPENSSL_ERRORS(ERROR);
+    return false;
+  }
+
+  return LoadTrustedCertificatesFromBIO(bio_in.get());
+}
+
+bool CertChecker::LoadTrustedCertificates(
+    const vector<string>& trusted_certs) {
+  string concat_certs;
+  for (vector<string>::const_iterator it = trusted_certs.begin();
+       it != trusted_certs.end(); ++it) {
+    concat_certs.append(*it);
+  }
+  // A read-only memory BIO.
+  ScopedBIO bio_in(BIO_new_mem_buf(
+      const_cast<void*>(reinterpret_cast<const void*>(concat_certs.c_str())),
+      -1 /* no length, since null-terminated */));
+  if (!bio_in) {
+    LOG_OPENSSL_ERRORS(ERROR);
+    return false;
+  }
+
+  return LoadTrustedCertificatesFromBIO(bio_in.get());
+}
+
+bool CertChecker::LoadTrustedCertificatesFromBIO(BIO* bio_in) {
+  CHECK_NOTNULL(bio_in);
+  vector<pair<string, unique_ptr<const Cert>>> certs_to_add;
+  bool error = false;
+  // certs_to_add may be empty if no new certs were added, so keep track of
+  // successfully parsed cert count separately.
+  size_t cert_count = 0;
+
+  while (!error) {
+    ScopedX509 x509(PEM_read_bio_X509(bio_in, nullptr, nullptr, nullptr));
+    if (x509) {
+      // TODO(ekasper): check that the issuing CA cert is temporally valid
+      // and at least warn if it isn't.
+      unique_ptr<Cert> cert(Cert::FromX509(move(x509)));
+      string subject_name;
+      const StatusOr<bool> is_trusted(IsTrusted(*cert, &subject_name));
+      if (!is_trusted.ok()) {
+        error = true;
+        break;
+      }
+
+      ++cert_count;
+      if (!is_trusted.ValueOrDie()) {
+        certs_to_add.push_back(make_pair(subject_name, move(cert)));
+      }
+    } else {
+      // See if we reached the end of the file.
+      auto err = ERR_peek_last_error();
+      if (ERR_GET_LIB(err) == ERR_LIB_PEM &&
+          ERR_GET_REASON(err) == PEM_R_NO_START_LINE) {
+        ClearOpenSSLErrors();
+        break;
+      } else {
+        // A real error.
+        LOG(ERROR) << "Badly encoded certificate file.";
+        LOG_OPENSSL_ERRORS(WARNING);
+        error = true;
+        break;
+      }
+    }
+  }
+
+  if (error || !cert_count) {
+    return false;
+  }
+
+  size_t new_certs = certs_to_add.size();
+  while (!certs_to_add.empty()) {
+    trusted_.insert(move(certs_to_add.back()));
+    certs_to_add.pop_back();
+  }
+  LOG(INFO) << "Added " << new_certs << " new certificate(s) to trusted store";
+
+  return true;
+}
+
+Status CertChecker::CheckCertChain(CertChain* chain) const {
+  if (!chain || !chain->IsLoaded())
+    return Status(util::error::INVALID_ARGUMENT, "invalid certificate chain");
+
+  // Weed out things that should obviously be precert chains instead.
+  const StatusOr<bool> has_poison =
+      chain->LeafCert()->HasCriticalExtension(cert_trans::NID_ctPoison);
+  if (!has_poison.ok()) {
+    return Status(util::error::INTERNAL, "internal error");
+  }
+  if (has_poison.ValueOrDie()) {
+    return Status(util::error::INVALID_ARGUMENT,
+                  "precert extension in certificate chain");
+  }
+
+  return CheckIssuerChain(chain);
+}
+
+Status CertChecker::CheckIssuerChain(CertChain* chain) const {
+  if (!chain->RemoveCertsAfterFirstSelfSigned()) {
+    LOG(ERROR) << "Failed to trim chain";
+    return Status(util::error::INTERNAL, "failed to trim chain");
+  }
+
+  // Note that it is OK to allow a root cert that is not CA:true
+  // because we will later check that it is trusted.
+  Status status = chain->IsValidCaIssuerChainMaybeLegacyRoot();
+  if (!status.ok()) {
+    LOG(ERROR) << "Failed to check issuer chain";
+    return Status(status.CanonicalCode(), "invalid certificate chain");
+  }
+
+  const Status valid_chain(chain->IsValidSignatureChain());
+  if (!valid_chain.ok()) {
+    return valid_chain;
+  }
+
+  return GetTrustedCa(chain);
+}
+
+Status CertChecker::CheckPreCertChain(PreCertChain* chain,
+                                      string* issuer_key_hash,
+                                      string* tbs_certificate) const {
+  if (!chain || !chain->IsLoaded()) {
+    return Status(util::error::INVALID_ARGUMENT, "invalid certificate chain");
+  }
+
+  const StatusOr<bool> chain_well_formed(chain->IsWellFormed());
+  if (chain_well_formed.ok() && !chain_well_formed.ValueOrDie()) {
+    return Status(util::error::INVALID_ARGUMENT, "prechain not well formed");
+  }
+  if (!chain_well_formed.ok()) {
+    LOG(ERROR) << "Failed to check precert chain format";
+    return Status(util::error::INTERNAL, "internal error");
+  }
+
+  // Check the issuer and signature chain.
+  // We do not, at this point, concern ourselves with whether the CA
+  // certificate that issued the precert is a Precertificate Signing
+  // Certificate (i.e., has restricted Extended Key Usage) or not,
+  // since this does not influence the validity of the chain. The
+  // purpose of the EKU is effectively to allow CAs to create an
+  // intermediate whose scope can be limited to CT precerts only (by
+  // making this extension critical).
+  // TODO(ekasper): determine (i.e., ask CAs) if CA:false
+  // Precertificate Signing Certificates should be tolerated if they
+  // have the necessary EKU set.
+  // Preference is "no".
+
+  // TODO(pphaneuf): Once Cert::IsWellFormed returns a util::Status,
+  // remove the braces and re-use the one above.
+  {
+    Status status(CheckIssuerChain(chain));
+    if (!status.ok())
+      return status;
+  }
+
+  const StatusOr<bool> uses_pre_issuer =
+      chain->UsesPrecertSigningCertificate();
+  if (!uses_pre_issuer.ok()) {
+    return Status(util::error::INTERNAL, "internal error");
+  }
+
+  string key_hash;
+  if (uses_pre_issuer.ValueOrDie()) {
+    if (chain->Length() < 3 ||
+        chain->CertAt(2)->SPKISha256Digest(&key_hash) != util::Status::OK)
+      return Status(util::error::INTERNAL, "internal error");
+  } else if (chain->Length() < 2 ||
+             chain->CertAt(1)->SPKISha256Digest(&key_hash) !=
+                 util::Status::OK) {
+    return Status(util::error::INTERNAL, "internal error");
+  }
+  // A well-formed chain always has a precert.
+  TbsCertificate tbs(*chain->PreCert());
+  if (!tbs.IsLoaded() || !tbs.DeleteExtension(cert_trans::NID_ctPoison).ok()) {
+    return Status(util::error::INTERNAL, "internal error");
+  }
+
+  // If the issuing cert is the special Precert Signing Certificate,
+  // replace the issuer with the one that will sign the final cert.
+  // Should always succeed as we've already verified that the chain
+  // is well-formed.
+  if (uses_pre_issuer.ValueOrDie() &&
+      !tbs.CopyIssuerFrom(*chain->PrecertIssuingCert()).ok()) {
+    return Status(util::error::INTERNAL, "internal error");
+  }
+
+  string der_tbs;
+  if (!tbs.DerEncoding(&der_tbs).ok()) {
+    return Status(util::error::INTERNAL,
+                  "could not DER-encode tbs certificate");
+  }
+
+  issuer_key_hash->assign(key_hash);
+  tbs_certificate->assign(der_tbs);
+  return Status::OK;
+}
+
+Status CertChecker::GetTrustedCa(CertChain* chain) const {
+  const Cert* subject = chain->LastCert();
+  if (!subject) {
+    LOG(ERROR) << "Chain has no valid certs";
+    return Status(util::error::INTERNAL, "chain has no valid certificate");
+  }
+
+  // Look up issuer from the trusted store.
+  if (trusted_.empty()) {
+    LOG(WARNING) << "No trusted certificates loaded";
+    return Status(util::error::FAILED_PRECONDITION,
+                  "no trusted certificates loaded");
+  }
+
+  string subject_name;
+  const StatusOr<bool> is_trusted(IsTrusted(*subject, &subject_name));
+  // Either an error, or true, meaning the last cert is in our trusted
+  // store.  Note the trusted cert need not necessarily be
+  // self-signed.
+  if (!is_trusted.ok() || is_trusted.ValueOrDie())
+    return is_trusted.status();
+
+  string issuer_name;
+  util::Status status = subject->DerEncodedIssuerName(&issuer_name);
+  if (status != util::Status::OK) {
+    // Doesn't matter whether the extension doesn't or exist or is corrupt,
+    // it's still a bad chain
+    return Status(util::error::INVALID_ARGUMENT, "invalid certificate chain");
+  }
+
+  if (subject_name == issuer_name) {
+    // Self-signed: no need to scan again.
+    return Status(util::error::FAILED_PRECONDITION,
+                  "untrusted self-signed certificate");
+  }
+
+  const auto issuer_range(trusted_.equal_range(issuer_name));
+  const Cert* issuer(nullptr);
+  for (multimap<string, unique_ptr<const Cert>>::const_iterator it =
+           issuer_range.first;
+       it != issuer_range.second; ++it) {
+    const unique_ptr<const Cert>& issuer_cand(it->second);
+
+    StatusOr<bool> signed_by_issuer = subject->IsSignedBy(*issuer_cand);
+    if (signed_by_issuer.status().CanonicalCode() == Code::UNIMPLEMENTED) {
+      // If the cert's algorithm is unsupported, then there's no point
+      // continuing: it's unconditionally invalid.
+      return Status(util::error::INVALID_ARGUMENT,
+                    "unsupported algorithm in certificate chain");
+    }
+    if (!signed_by_issuer.ok()) {
+      LOG(ERROR) << "Failed to check signature for trusted root";
+      return Status(util::error::INTERNAL,
+                    "failed to check signature for trusted root");
+    }
+    if (signed_by_issuer.ValueOrDie()) {
+      issuer = issuer_cand.get();
+      break;
+    }
+  }
+
+  if (!issuer) {
+    return Status(util::error::FAILED_PRECONDITION, "unknown root");
+  }
+
+  // Clone creates a new Cert but AddCert takes ownership even if Clone
+  // failed and the cert can't be added, so we don't have to explicitly
+  // check for IsLoaded here.
+  if (!chain->AddCert(issuer->Clone())) {
+    LOG(ERROR) << "Failed to add trusted root to chain";
+    return Status(util::error::INTERNAL,
+                  "failed to add trusted root to chain");
+  }
+
+  return Status::OK;
+}
+
+StatusOr<bool> CertChecker::IsTrusted(const Cert& cert,
+                                      string* subject_name) const {
+  string cert_name;
+  util::Status status = cert.DerEncodedSubjectName(&cert_name);
+  if (status != util::Status::OK) {
+    // Doesn't matter whether it failed to decode or did not exist
+    return Status(util::error::INVALID_ARGUMENT, "invalid certificate chain");
+  }
+
+  *subject_name = cert_name;
+
+  const auto cand_range(trusted_.equal_range(cert_name));
+  for (multimap<string, unique_ptr<const Cert>>::const_iterator it(
+           cand_range.first);
+       it != cand_range.second; ++it) {
+    if (cert.IsIdenticalTo(*it->second)) {
+      return true;
+    }
+  }
+  return false;
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert_checker.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert_checker.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert_checker.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert_checker.h	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,109 @@
+#ifndef CERT_TRANS_LOG_CERT_CHECKER_H_
+#define CERT_TRANS_LOG_CERT_CHECKER_H_
+
+#include <openssl/pem.h>
+#include <openssl/x509.h>
+#include <openssl/x509v3.h>
+
+#include <map>
+#include <memory>
+#include <string>
+#include <vector>
+
+#include "base/macros.h"
+#include "log/cert.h"
+#include "util/status.h"
+#include "util/statusor.h"
+
+namespace cert_trans {
+
+class Cert;
+class CertChain;
+class PreCertChain;
+
+// A class for doing sanity-checks on log submissions before accepting them.
+// We don't necessarily want to do full certificate verification
+// before accepting them. E.g., we may want to accept submissions of
+// invalid (say, expired) certificates directly from clients,
+// to detect attacks after the fact. We primarily only
+// want to check that submissions chain to a whitelisted CA, so that
+// (1) we know where a cert is coming from; and
+// (2) we get some spam protection.
+class CertChecker {
+ public:
+  CertChecker() = default;
+  virtual ~CertChecker() = default;
+
+  // Load a file of concatenated PEM-certs.
+  // Returns true if at least one certificate was successfully loaded, and no
+  // errors were encountered. Returns false otherwise (and will not load any
+  // certificates from this file).
+  virtual bool LoadTrustedCertificates(const std::string& trusted_cert_file);
+
+  // Load directly from |trusted_certs|, a vector of PEM-certs.
+  // Returns true if at least one of the supplied certs was loaded
+  // successfully.
+  virtual bool LoadTrustedCertificates(
+      const std::vector<std::string>& trusted_certs);
+
+  virtual const std::multimap<std::string, std::unique_ptr<const Cert>>&
+  GetTrustedCertificates() const {
+    return trusted_;
+  }
+
+  virtual size_t NumTrustedCertificates() const {
+    return trusted_.size();
+  }
+
+  // Check that:
+  // (1) Each certificate is correctly signed by the next one in the chain; and
+  // (2) The last certificate is issued by a certificate in our trusted store.
+  // We do not check that the certificates are otherwise valid. In particular,
+  // we accept certificates that have expired, are not yet valid, or have
+  // critical extensions we do not recognize.
+  // If verification succeeds, add the last self-signed cert to the chain
+  // (or replace with store version) - the resulting chain is guaranteed to
+  // contain at least one certificate. (Having exactly one certificate implies
+  // someone is trying to log a root cert, which is fine though unexciting.)
+  virtual util::Status CheckCertChain(CertChain* chain) const;
+
+  // Check that:
+  // (1) The PreCertChain is well-formed according to I-D rules.
+  // (2) Each certificate is correctly signed by the next one in the chain; and
+  // (3) The last certificate is issued by a certificate in our trusted store.
+  // If verification succeeds, add the last self-signed cert to the chain
+  // (or replace with store version) - the resulting chain is guaranteed to
+  // contain at least two certificates (three if there is a Precert Signing
+  // Certificate);
+  // If valid, also fills in the |issuer_key_hash| and |tbs_certificate|.
+  virtual util::Status CheckPreCertChain(PreCertChain* chain,
+                                         std::string* issuer_key_hash,
+                                         std::string* tbs_certificate) const;
+
+ private:
+  util::Status CheckIssuerChain(CertChain* chain) const;
+
+  // Look issuer up from the trusted store, and verify signature.
+  util::Status GetTrustedCa(CertChain* chain) const;
+
+  // Returns true if the cert is trusted, false if it's not,
+  // INVALID_ARGUMENT if something is wrong with the cert, and
+  // INTERNAL if something terrible happened.
+  util::StatusOr<bool> IsTrusted(const Cert& cert,
+                                 std::string* subject_name) const;
+
+  // A map by the DER encoding of the subject name.
+  // All code manipulating this container must ensure contained elements are
+  // deallocated appropriately.
+  std::multimap<std::string, std::unique_ptr<const Cert>> trusted_;
+
+  // Helper for LoadTrustedCertificates, whether reading from file or memory.
+  // Takes ownership of bio_in and frees it.
+  bool LoadTrustedCertificatesFromBIO(BIO* bio_in);
+
+  DISALLOW_COPY_AND_ASSIGN(CertChecker);
+};
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_CERT_CHECKER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert_checker_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert_checker_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert_checker_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert_checker_test.cc	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,663 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <openssl/err.h>
+#include <openssl/evp.h>
+#include <memory>
+#include <string>
+
+#include "log/cert.h"
+#include "log/cert_checker.h"
+#include "log/ct_extensions.h"
+#include "util/status_test_util.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+using cert_trans::Cert;
+using cert_trans::CertChain;
+using cert_trans::CertChecker;
+using cert_trans::PreCertChain;
+using std::move;
+using std::string;
+using std::unique_ptr;
+using std::vector;
+using util::testing::StatusIs;
+
+// Valid certificates.
+// Self-signed
+static const char kCaCert[] = "ca-cert.pem";
+// Issued by ca-cert.pem
+static const char kLeafCert[] = "test-cert.pem";
+// Issued by ca-cert.pem
+static const char kCaPreCert[] = "ca-pre-cert.pem";
+// Issued by ca-cert.pem
+static const char kPreCert[] = "test-embedded-pre-cert.pem";
+// Issued by ca-pre-cert.pem
+static const char kPreWithPreCaCert[] =
+    "test-embedded-with-preca-pre-cert.pem";
+// Issued by ca-cert.pem
+static const char kIntermediateCert[] = "intermediate-cert.pem";
+// Issued by intermediate-cert.pem
+static const char kChainLeafCert[] = "test-intermediate-cert.pem";
+// CA with no basic constraints.
+static const char kCaNoBCCert[] = "test-no-bc-ca-cert.pem";
+// Chain terminating in that CA.
+static const char kNoBCChain[] = "test-no-bc-cert-chain.pem";
+// Chain where a leaf cert issues another cert
+static const char kBadNoBCChain[] = "test-no-ca-cert-chain.pem";
+// Chain that has two matching issuers.
+static const char kCollisionChain[] = "test-issuer-collision-chain.pem";
+// Two CA certs that have identical name and no AKI.
+static const char kCollisionRoot1[] = "test-colliding-root1.pem";
+static const char kCollisionRoot2[] = "test-colliding-root2.pem";
+static const char kCollidingRoots[] = "test-colliding-roots.pem";
+// A chain terminating with an MD2 intermediate.
+// Issuer is test-no-bc-ca-cert.pem.
+static const char kMd2Chain[] = "test-md2-chain.pem";
+// A file which doesn't exist.
+static const char kNonexistent[] = "test-nonexistent.pem";
+// A file with corrupted contents (bit flip from ca-cert.pem).
+static const char kCorrupted[] = "test-corrupted.pem";
+
+// Corresponds to kCaCert.
+static const char kCaCertPem[] =
+    "-----BEGIN CERTIFICATE-----\n"
+    "MIIC0DCCAjmgAwIBAgIBADANBgkqhkiG9w0BAQUFADBVMQswCQYDVQQGEwJHQjEk\n"
+    "MCIGA1UEChMbQ2VydGlmaWNhdGUgVHJhbnNwYXJlbmN5IENBMQ4wDAYDVQQIEwVX\n"
+    "YWxlczEQMA4GA1UEBxMHRXJ3IFdlbjAeFw0xMjA2MDEwMDAwMDBaFw0yMjA2MDEw\n"
+    "MDAwMDBaMFUxCzAJBgNVBAYTAkdCMSQwIgYDVQQKExtDZXJ0aWZpY2F0ZSBUcmFu\n"
+    "c3BhcmVuY3kgQ0ExDjAMBgNVBAgTBVdhbGVzMRAwDgYDVQQHEwdFcncgV2VuMIGf\n"
+    "MA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDVimhTYhCicRmTbneDIRgcKkATxtB7\n"
+    "jHbrkVfT0PtLO1FuzsvRyY2RxS90P6tjXVUJnNE6uvMa5UFEJFGnTHgW8iQ8+EjP\n"
+    "KDHM5nugSlojgZ88ujfmJNnDvbKZuDnd/iYx0ss6hPx7srXFL8/BT/9Ab1zURmnL\n"
+    "svfP34b7arnRsQIDAQABo4GvMIGsMB0GA1UdDgQWBBRfnYgNyHPmVNT4DdjmsMEk\n"
+    "tEfDVTB9BgNVHSMEdjB0gBRfnYgNyHPmVNT4DdjmsMEktEfDVaFZpFcwVTELMAkG\n"
+    "A1UEBhMCR0IxJDAiBgNVBAoTG0NlcnRpZmljYXRlIFRyYW5zcGFyZW5jeSBDQTEO\n"
+    "MAwGA1UECBMFV2FsZXMxEDAOBgNVBAcTB0VydyBXZW6CAQAwDAYDVR0TBAUwAwEB\n"
+    "/zANBgkqhkiG9w0BAQUFAAOBgQAGCMxKbWTyIF4UbASydvkrDvqUpdryOvw4BmBt\n"
+    "OZDQoeojPUApV2lGOwRmYef6HReZFSCa6i4Kd1F2QRIn18ADB8dHDmFYT9czQiRy\n"
+    "f1HWkLxHqd81TbD26yWVXeGJPE3VICskovPkQNJ0tU4b03YmnKliibduyqQQkOFP\n"
+    "OwqULg==\n"
+    "-----END CERTIFICATE-----\n";
+// Corresponds to kIntermediateCert.
+static const char kIntermediateCertPem[] =
+    "-----BEGIN CERTIFICATE-----\n"
+    "MIIC3TCCAkagAwIBAgIBCTANBgkqhkiG9w0BAQUFADBVMQswCQYDVQQGEwJHQjEk\n"
+    "MCIGA1UEChMbQ2VydGlmaWNhdGUgVHJhbnNwYXJlbmN5IENBMQ4wDAYDVQQIEwVX\n"
+    "YWxlczEQMA4GA1UEBxMHRXJ3IFdlbjAeFw0xMjA2MDEwMDAwMDBaFw0yMjA2MDEw\n"
+    "MDAwMDBaMGIxCzAJBgNVBAYTAkdCMTEwLwYDVQQKEyhDZXJ0aWZpY2F0ZSBUcmFu\n"
+    "c3BhcmVuY3kgSW50ZXJtZWRpYXRlIENBMQ4wDAYDVQQIEwVXYWxlczEQMA4GA1UE\n"
+    "BxMHRXJ3IFdlbjCBnzANBgkqhkiG9w0BAQEFAAOBjQAwgYkCgYEA12pnjRFvUi5V\n"
+    "/4IckGQlCLcHSxTXcRWQZPeSfv3tuHE1oTZe594Yy9XOhl+GDHj0M7TQ09NAdwLn\n"
+    "o+9UKx3+m7qnzflNxZdfxyn4bxBfOBskNTXPnIAPXKeAwdPIRADuZdFu6c9S24rf\n"
+    "/lD1xJM1CyGQv1DVvDbzysWo2q6SzYsCAwEAAaOBrzCBrDAdBgNVHQ4EFgQUllUI\n"
+    "BQJ4R56Hc3ZBMbwUOkfiKaswfQYDVR0jBHYwdIAUX52IDchz5lTU+A3Y5rDBJLRH\n"
+    "w1WhWaRXMFUxCzAJBgNVBAYTAkdCMSQwIgYDVQQKExtDZXJ0aWZpY2F0ZSBUcmFu\n"
+    "c3BhcmVuY3kgQ0ExDjAMBgNVBAgTBVdhbGVzMRAwDgYDVQQHEwdFcncgV2VuggEA\n"
+    "MAwGA1UdEwQFMAMBAf8wDQYJKoZIhvcNAQEFBQADgYEAIgbascZrcdzglcP2qi73\n"
+    "LPd2G+er1/w5wxpM/hvZbWc0yoLyLd5aDIu73YJde28+dhKtjbMAp+IRaYhgIyYi\n"
+    "hMOqXSGR79oQv5I103s6KjQNWUGblKSFZvP6w82LU9Wk6YJw6tKXsHIQ+c5KITix\n"
+    "iBEUO5P6TnqH3TfhOF8sKQg=\n"
+    "-----END CERTIFICATE-----\n";
+
+static const char kDsaPrecertChain[] =
+"-----BEGIN CERTIFICATE-----\n"
+"MIIGbzCCBhWgAwIBAgIQQyzKVQswSJU51uhTRKJOcjALBglghkgBZQMEAwIwQDEL\n"
+"MAkGA1UEBhMCVVMxFTATBgNVBAoTDHRoYXd0ZSwgSW5jLjEaMBgGA1UEAxMRdGhh\n"
+"d3RlIERTQSBTU0wgQ0EwHhcNMTUxMjI5MDAwMDAwWhcNMTcxMjI3MjM1OTU5WjCB\n"
+"pzETMBEGCysGAQQBgjc8AgEDEwJHRTEdMBsGA1UEDxMUUHJpdmF0ZSBPcmdhbml6\n"
+"YXRpb24xEzARBgNVBAoUClVuaVBBWSBMVEQxEjAQBgNVBAUTCTQwMTk1Mzk5OTEL\n"
+"MAkGA1UEBhMCR0UxEDAOBgNVBAgTB1RiaWxpc2kxEDAOBgNVBAcUB1RiaWxpc2kx\n"
+"FzAVBgNVBAMUDnd3dy51bmlwYXkuY29tMIIDRzCCAjoGByqGSM44BAEwggItAoIB\n"
+"AQClyTxv5WDYR4Dv2+pCaEEFTtEayHGtbMmaHG3RR24DVgxtlS//xmk6z4fO03uj\n"
+"EdxylJ7UDZp1GrYxJXts2bixxH2jsoiuzs/PiCyS1TGsrdkD5Vi/y3wkYRzM3iBt\n"
+"abKu23ZANP6WansDX4jILYxOs2cc4GEQepOsuHqn2LWCBvxGP3KmTo0YwuV+sSO8\n"
+"IFTvHsGb0ZFKzZdFfjqPxXbGXiCGHHhuispi23SKqHEXdRjlyuWRjCDHJsyefKTk\n"
+"HW+1nx7lSZIBBB6tPXxdtk/cNcJESoZmXl9aNsYdo/63mQI5aA6iUXX09/FNTIMh\n"
+"dp3aoQHePhdGRRTOxoADIrVNAiEA45OTlEY+5SayLLZyqvLduEKEzOntK0ssMIUp\n"
+"GIXGMo8CggEBAJlGxvWVGST03IYlimBHX4VNpkuKqXGyMSnjNP0niqxVYmEjDUeN\n"
+"cqyoBoBEJO1wsT2/v4IUQXQoQ5yW95D/sfXEF806MLqkgzOPNhXHZsyjqntHMAKj\n"
+"t4hi9XOfjHUKXDINGpk0AwAk1Aajj4DavWjZ/8gBZWgkNHjNnV9UuBnIeBJmOO7C\n"
+"s57cQ98p3TpGHgk0l8+r3ELnaLf/UhJRr6C7SGIEdddMXGbnR1w968IRVZygL7lx\n"
+"3UF9XJFGcR6TuKt5/PA8oxqU+Phl+EEJm7TJ/+pT5KLEo+o0DghM4GVKC6h9u/gg\n"
+"4gBdsEQ4OtkLZ1pSU+Nvyz22TVWTz3D35XoDggEFAAKCAQA//na/RFHzfeuYBoaY\n"
+"0v4SkKwNwAInGn7pAvaF8AiENwesVnVTu8l7z+hi1CYv4fEGJNKkf44j6TTwjds8\n"
+"QTjJbGrg5RzXp3LGrJbAzW8zW/CxabF0pMo4eod3NjTC4sSgVTMawpw2oag/1T79\n"
+"LmDeGEJPbajmUUee9tfJJQK/UirzcB1n9/O2GK0Uthu8rH77IQPcM5Y8ambgwbIG\n"
+"eFXMSU1AODKj83kqPJmRvDcAIQs5ShA+yghs6qfA1m9V4At2sQtgf7iVkD6HKH9X\n"
+"v8izGABvDBVlk3ZRW2WXMeTyGeCl1T43+mnXMGs9i4r1KDuFdt/0WbXVA+F7AVYy\n"
+"u/cGo4IBljCCAZIwJQYDVR0RBB4wHIIKdW5pcGF5LmNvbYIOd3d3LnVuaXBheS5j\n"
+"b20wCQYDVR0TBAIwADAOBgNVHQ8BAf8EBAMCB4AwKwYDVR0fBCQwIjAgoB6gHIYa\n"
+"aHR0cDovL3RlLnN5bWNiLmNvbS90ZS5jcmwwcwYDVR0gBGwwajBoBgtghkgBhvhF\n"
+"AQcwATBZMCYGCCsGAQUFBwIBFhpodHRwczovL3d3dy50aGF3dGUuY29tL2NwczAv\n"
+"BggrBgEFBQcCAjAjDCFodHRwczovL3d3dy50aGF3dGUuY29tL3JlcG9zaXRvcnkw\n"
+"HQYDVR0lBBYwFAYIKwYBBQUHAwEGCCsGAQUFBwMCMB8GA1UdIwQYMBaAFMoTsU3s\n"
+"mn62fEUeuB3k0shyGrEdMFcGCCsGAQUFBwEBBEswSTAfBggrBgEFBQcwAYYTaHR0\n"
+"cDovL3RlLnN5bWNkLmNvbTAmBggrBgEFBQcwAoYaaHR0cDovL3RlLnN5bWNiLmNv\n"
+"bS90ZS5jcnQwEwYKKwYBBAHWeQIEAwEB/wQCBQAwCwYJYIZIAWUDBAMCA0cAMEQC\n"
+"IGqj1ElLQljLIir0ZWTzmr0wOXG2B8X649SNqOHhzXikAiAE9qn9RiIe/fpphfnx\n"
+"jks8c0MAUgqmpKIZWTpvNhja6Q==\n"
+"-----END CERTIFICATE-----\n"
+"-----BEGIN CERTIFICATE-----\n"
+"MIIGJDCCBcmgAwIBAgIQbT3s+pt4qr0oAI3ZcDdjDjALBglghkgBZQMEAwIwga4x\n"
+"CzAJBgNVBAYTAlVTMRUwEwYDVQQKEwx0aGF3dGUsIEluYy4xKDAmBgNVBAsTH0Nl\n"
+"cnRpZmljYXRpb24gU2VydmljZXMgRGl2aXNpb24xODA2BgNVBAsTLyhjKSAyMDEy\n"
+"IHRoYXd0ZSwgSW5jLiAtIEZvciBhdXRob3JpemVkIHVzZSBvbmx5MSQwIgYDVQQD\n"
+"Ext0aGF3dGUgUHJpbWFyeSBSb290IENBIC0gRzQwHhcNMTIxMjIwMDAwMDAwWhcN\n"
+"MjIxMjE5MjM1OTU5WjBAMQswCQYDVQQGEwJVUzEVMBMGA1UEChMMdGhhd3RlLCBJ\n"
+"bmMuMRowGAYDVQQDExF0aGF3dGUgRFNBIFNTTCBDQTCCA0gwggI6BgcqhkjOOAQB\n"
+"MIICLQKCAQEAsOkfT0p9OXj0/j9H+m2Ejyu6VTLpjydK1/dWyl/AQS5WE5GPgy0i\n"
+"6oJQCSEKLcZtJCcnrx9X2WJq/U9sxSydq0oP1R7BqXiRs3fphkJnBhW/OGJNnw13\n"
+"dnBrt9ffmaZNFFRCUQOsGDsSjBPOUQ4tuenBeF3Zs+DAfkDXzxcrK4OQs6qTYubn\n"
+"8QUphcoMaUURJv9aY8VfVpODN3Z5FeamrY72zAcGvc9ajFl45vVlK/dDbu8kMMdp\n"
+"b1wuNMTWUo/dxdPrtgpJA3ZnN9MDSzs2tcGWxYnpWFZTndTePn7xU0b3r/pN/ys7\n"
+"i5FBr1yqYVWelt5uGLMg+ZQ22GQnga8/eQIhAKdVID3cRKJNm0Rd77SM/GgY430w\n"
+"mefDvxS6pQDGnAzXAoIBAQCLQiKLU8kRBsWIkeuRPKlbqwSMkbNwaOYK6/Lh8x5k\n"
+"20djAqPOurHtzNWnAPAvZPYSjL+PR1ydHq4tRDEgjaVYlb5ZZeD8L6v0J/OWNTpS\n"
+"SmeKzHfD1QRP/2dxqiNweivUR4vw7m6wg8Y5ZxOFKbgAfdM08z2hbjkucrCzkbCr\n"
+"0NQUkUy+N4gvMKOIVDYVUiKUFSJmlRiYlCXJNaoIkKWcb4NjRBHjDKbmm4+Isco4\n"
+"PUQ3E7V+CdS6C8hOPdDwhcYm6FPrgbTPcuuoJgEI6YXjgywGCMja6zwEmU1F9NH6\n"
+"9TmpZiKCFDVhrBd5KgOemiiveAE2AAU1ctYz1pkqt2dXA4IBBgACggEBAJzaudYH\n"
+"djJGC5gPXFS+oWZc4SEicF5teHo2ZkI86j8TDGZWBCXHng3m/JrY3qT11tBU4go/\n"
+"XR5AQ9GYtLAiOXZKIdFSjyjrDGVotWNxpoZi1hXpVEsCAEwyWqKdO+47zUF2/tgc\n"
+"QzAnAwbb2NV9D35rg3wKenUKdQfp98PrlWUh2UOmFkae83eLr/7VxEF4nOF+CI/4\n"
+"Kx9y6Qy3So/OHucSp8206yqJ80EyYox9cnAeS81xBwJqn1LIPRFGJ85cEXRldATI\n"
+"+CvgvfdnpWnJaPPUvJoaPF9DVfi4FTGV7aFfeQfi9QemF8WMPq0JpdrFkfrnGVw9\n"
+"wxGzySeiXj7UDhKjggFCMIIBPjASBgNVHRMBAf8ECDAGAQH/AgEAMA4GA1UdDwEB\n"
+"/wQEAwIBBjAyBggrBgEFBQcBAQQmMCQwIgYIKwYBBQUHMAGGFmh0dHA6Ly9vY3Nw\n"
+"LnRoYXd0ZS5jb20wOwYDVR0gBDQwMjAwBgRVHSAAMCgwJgYIKwYBBQUHAgEWGmh0\n"
+"dHBzOi8vd3d3LnRoYXd0ZS5jb20vY3BzMDcGA1UdHwQwMC4wLKAqoCiGJmh0dHA6\n"
+"Ly9jcmwudGhhd3RlLmNvbS9UaGF3dGVQQ0EtRzQuY3JsMC4GA1UdEQQnMCWkIzAh\n"
+"MR8wHQYDVQQDExZTWU1DLURTQS1DQS0yMDQ4LTI1Ni00MB0GA1UdDgQWBBTKE7FN\n"
+"7Jp+tnxFHrgd5NLIchqxHTAfBgNVHSMEGDAWgBTHZ4lkIvGdsfOLg6bCDpmTUXbr\n"
+"ljALBglghkgBZQMEAwIDSAAwRQIhAKb8sDyC2UehqUcEPUQ65bnmmtiplEplDUZt\n"
+"ULqZQweDAiAr4MAcnfC9otwLcBllGVA4vsOKPsFSq5u2EPn3ovIynw==\n"
+"-----END CERTIFICATE-----\n";
+
+// This was generated from the above by manually flipping a bit
+// in one of the signature bytes of the precert.
+static const char kDsaPrecertChainInvalidSig[] =
+"-----BEGIN CERTIFICATE-----\n"
+"MIIGbzCCBhWgAwIBAgIQQyzKVQswSJU51uhTRKJOcjALBglghkgBZQMEAwIwQDEL\n"
+"MAkGA1UEBhMCVVMxFTATBgNVBAoTDHRoYXd0ZSwgSW5jLjEaMBgGA1UEAxMRdGhh\n"
+"d3RlIERTQSBTU0wgQ0EwHhcNMTUxMjI5MDAwMDAwWhcNMTcxMjI3MjM1OTU5WjCB\n"
+"pzETMBEGCysGAQQBgjc8AgEDEwJHRTEdMBsGA1UEDxMUUHJpdmF0ZSBPcmdhbml6\n"
+"YXRpb24xEzARBgNVBAoUClVuaVBBWSBMVEQxEjAQBgNVBAUTCTQwMTk1Mzk5OTEL\n"
+"MAkGA1UEBhMCR0UxEDAOBgNVBAgTB1RiaWxpc2kxEDAOBgNVBAcUB1RiaWxpc2kx\n"
+"FzAVBgNVBAMUDnd3dy51bmlwYXkuY29tMIIDRzCCAjoGByqGSM44BAEwggItAoIB\n"
+"AQClyTxv5WDYR4Dv2+pCaEEFTtEayHGtbMmaHG3RR24DVgxtlS//xmk6z4fO03uj\n"
+"EdxylJ7UDZp1GrYxJXts2bixxH2jsoiuzs/PiCyS1TGsrdkD5Vi/y3wkYRzM3iBt\n"
+"abKu23ZANP6WansDX4jILYxOs2cc4GEQepOsuHqn2LWCBvxGP3KmTo0YwuV+sSO8\n"
+"IFTvHsGb0ZFKzZdFfjqPxXbGXiCGHHhuispi23SKqHEXdRjlyuWRjCDHJsyefKTk\n"
+"HW+1nx7lSZIBBB6tPXxdtk/cNcJESoZmXl9aNsYdo/63mQI5aA6iUXX09/FNTIMh\n"
+"dp3aoQHePhdGRRTOxoADIrVNAiEA45OTlEY+5SayLLZyqvLduEKEzOntK0ssMIUp\n"
+"GIXGMo8CggEBAJlGxvWVGST03IYlimBHX4VNpkuKqXGyMSnjNP0niqxVYmEjDUeN\n"
+"cqyoBoBEJO1wsT2/v4IUQXQoQ5yW95D/sfXEF806MLqkgzOPNhXHZsyjqntHMAKj\n"
+"t4hi9XOfjHUKXDINGpk0AwAk1Aajj4DavWjZ/8gBZWgkNHjNnV9UuBnIeBJmOO7C\n"
+"s57cQ98p3TpGHgk0l8+r3ELnaLf/UhJRr6C7SGIEdddMXGbnR1w968IRVZygL7lx\n"
+"3UF9XJFGcR6TuKt5/PA8oxqU+Phl+EEJm7TJ/+pT5KLEo+o0DghM4GVKC6h9u/gg\n"
+"4gBdsEQ4OtkLZ1pSU+Nvyz22TVWTz3D35XoDggEFAAKCAQA//na/RFHzfeuYBoaY\n"
+"0v4SkKwNwAInGn7pAvaF8AiENwesVnVTu8l7z+hi1CYv4fEGJNKkf44j6TTwjds8\n"
+"QTjJbGrg5RzXp3LGrJbAzW8zW/CxabF0pMo4eod3NjTC4sSgVTMawpw2oag/1T79\n"
+"LmDeGEJPbajmUUee9tfJJQK/UirzcB1n9/O2GK0Uthu8rH77IQPcM5Y8ambgwbIG\n"
+"eFXMSU1AODKj83kqPJmRvDcAIQs5ShA+yghs6qfA1m9V4At2sQtgf7iVkD6HKH9X\n"
+"v8izGABvDBVlk3ZRW2WXMeTyGeCl1T43+mnXMGs9i4r1KDuFdt/0WbXVA+F7AVYy\n"
+"u/cGo4IBljCCAZIwJQYDVR0RBB4wHIIKdW5pcGF5LmNvbYIOd3d3LnVuaXBheS5j\n"
+"b20wCQYDVR0TBAIwADAOBgNVHQ8BAf8EBAMCB4AwKwYDVR0fBCQwIjAgoB6gHIYa\n"
+"aHR0cDovL3RlLnN5bWNiLmNvbS90ZS5jcmwwcwYDVR0gBGwwajBoBgtghkgBhvhF\n"
+"AQcwATBZMCYGCCsGAQUFBwIBFhpodHRwczovL3d3dy50aGF3dGUuY29tL2NwczAv\n"
+"BggrBgEFBQcCAjAjDCFodHRwczovL3d3dy50aGF3dGUuY29tL3JlcG9zaXRvcnkw\n"
+"HQYDVR0lBBYwFAYIKwYBBQUHAwEGCCsGAQUFBwMCMB8GA1UdIwQYMBaAFMoTsU3s\n"
+"mn62fEUeuB3k0shyGrEdMFcGCCsGAQUFBwEBBEswSTAfBggrBgEFBQcwAYYTaHR0\n"
+"cDovL3RlLnN5bWNkLmNvbTAmBggrBgEFBQcwAoYaaHR0cDovL3RlLnN5bWNiLmNv\n"
+"bS90ZS5jcnQwEwYKKwYBBAHWeQIEAwEB/wQCBQAwCwYJYIZIAWUDBAMCA0cAMEQC\n"
+"IGqj1ElLQljLIir0ZWTzmr0wOXG2B8X649SNqOHhzXikAiAE9qr9RiIe/fpphfnx\n"
+"jks8c0MAUgqmpKIZWTpvNhja6Q==\n"
+"-----END CERTIFICATE-----\n"
+"-----BEGIN CERTIFICATE-----\n"
+"MIIGJDCCBcmgAwIBAgIQbT3s+pt4qr0oAI3ZcDdjDjALBglghkgBZQMEAwIwga4x\n"
+"CzAJBgNVBAYTAlVTMRUwEwYDVQQKEwx0aGF3dGUsIEluYy4xKDAmBgNVBAsTH0Nl\n"
+"cnRpZmljYXRpb24gU2VydmljZXMgRGl2aXNpb24xODA2BgNVBAsTLyhjKSAyMDEy\n"
+"IHRoYXd0ZSwgSW5jLiAtIEZvciBhdXRob3JpemVkIHVzZSBvbmx5MSQwIgYDVQQD\n"
+"Ext0aGF3dGUgUHJpbWFyeSBSb290IENBIC0gRzQwHhcNMTIxMjIwMDAwMDAwWhcN\n"
+"MjIxMjE5MjM1OTU5WjBAMQswCQYDVQQGEwJVUzEVMBMGA1UEChMMdGhhd3RlLCBJ\n"
+"bmMuMRowGAYDVQQDExF0aGF3dGUgRFNBIFNTTCBDQTCCA0gwggI6BgcqhkjOOAQB\n"
+"MIICLQKCAQEAsOkfT0p9OXj0/j9H+m2Ejyu6VTLpjydK1/dWyl/AQS5WE5GPgy0i\n"
+"6oJQCSEKLcZtJCcnrx9X2WJq/U9sxSydq0oP1R7BqXiRs3fphkJnBhW/OGJNnw13\n"
+"dnBrt9ffmaZNFFRCUQOsGDsSjBPOUQ4tuenBeF3Zs+DAfkDXzxcrK4OQs6qTYubn\n"
+"8QUphcoMaUURJv9aY8VfVpODN3Z5FeamrY72zAcGvc9ajFl45vVlK/dDbu8kMMdp\n"
+"b1wuNMTWUo/dxdPrtgpJA3ZnN9MDSzs2tcGWxYnpWFZTndTePn7xU0b3r/pN/ys7\n"
+"i5FBr1yqYVWelt5uGLMg+ZQ22GQnga8/eQIhAKdVID3cRKJNm0Rd77SM/GgY430w\n"
+"mefDvxS6pQDGnAzXAoIBAQCLQiKLU8kRBsWIkeuRPKlbqwSMkbNwaOYK6/Lh8x5k\n"
+"20djAqPOurHtzNWnAPAvZPYSjL+PR1ydHq4tRDEgjaVYlb5ZZeD8L6v0J/OWNTpS\n"
+"SmeKzHfD1QRP/2dxqiNweivUR4vw7m6wg8Y5ZxOFKbgAfdM08z2hbjkucrCzkbCr\n"
+"0NQUkUy+N4gvMKOIVDYVUiKUFSJmlRiYlCXJNaoIkKWcb4NjRBHjDKbmm4+Isco4\n"
+"PUQ3E7V+CdS6C8hOPdDwhcYm6FPrgbTPcuuoJgEI6YXjgywGCMja6zwEmU1F9NH6\n"
+"9TmpZiKCFDVhrBd5KgOemiiveAE2AAU1ctYz1pkqt2dXA4IBBgACggEBAJzaudYH\n"
+"djJGC5gPXFS+oWZc4SEicF5teHo2ZkI86j8TDGZWBCXHng3m/JrY3qT11tBU4go/\n"
+"XR5AQ9GYtLAiOXZKIdFSjyjrDGVotWNxpoZi1hXpVEsCAEwyWqKdO+47zUF2/tgc\n"
+"QzAnAwbb2NV9D35rg3wKenUKdQfp98PrlWUh2UOmFkae83eLr/7VxEF4nOF+CI/4\n"
+"Kx9y6Qy3So/OHucSp8206yqJ80EyYox9cnAeS81xBwJqn1LIPRFGJ85cEXRldATI\n"
+"+CvgvfdnpWnJaPPUvJoaPF9DVfi4FTGV7aFfeQfi9QemF8WMPq0JpdrFkfrnGVw9\n"
+"wxGzySeiXj7UDhKjggFCMIIBPjASBgNVHRMBAf8ECDAGAQH/AgEAMA4GA1UdDwEB\n"
+"/wQEAwIBBjAyBggrBgEFBQcBAQQmMCQwIgYIKwYBBQUHMAGGFmh0dHA6Ly9vY3Nw\n"
+"LnRoYXd0ZS5jb20wOwYDVR0gBDQwMjAwBgRVHSAAMCgwJgYIKwYBBQUHAgEWGmh0\n"
+"dHBzOi8vd3d3LnRoYXd0ZS5jb20vY3BzMDcGA1UdHwQwMC4wLKAqoCiGJmh0dHA6\n"
+"Ly9jcmwudGhhd3RlLmNvbS9UaGF3dGVQQ0EtRzQuY3JsMC4GA1UdEQQnMCWkIzAh\n"
+"MR8wHQYDVQQDExZTWU1DLURTQS1DQS0yMDQ4LTI1Ni00MB0GA1UdDgQWBBTKE7FN\n"
+"7Jp+tnxFHrgd5NLIchqxHTAfBgNVHSMEGDAWgBTHZ4lkIvGdsfOLg6bCDpmTUXbr\n"
+"ljALBglghkgBZQMEAwIDSAAwRQIhAKb8sDyC2UehqUcEPUQ65bnmmtiplEplDUZt\n"
+"ULqZQweDAiAr4MAcnfC9otwLcBllGVA4vsOKPsFSq5u2EPn3ovIynw==\n"
+"-----END CERTIFICATE-----\n";
+
+static const char kDsaPrecertChainRootOnly[] =
+"-----BEGIN CERTIFICATE-----\n"
+"MIIGJDCCBcmgAwIBAgIQbT3s+pt4qr0oAI3ZcDdjDjALBglghkgBZQMEAwIwga4x\n"
+"CzAJBgNVBAYTAlVTMRUwEwYDVQQKEwx0aGF3dGUsIEluYy4xKDAmBgNVBAsTH0Nl\n"
+"cnRpZmljYXRpb24gU2VydmljZXMgRGl2aXNpb24xODA2BgNVBAsTLyhjKSAyMDEy\n"
+"IHRoYXd0ZSwgSW5jLiAtIEZvciBhdXRob3JpemVkIHVzZSBvbmx5MSQwIgYDVQQD\n"
+"Ext0aGF3dGUgUHJpbWFyeSBSb290IENBIC0gRzQwHhcNMTIxMjIwMDAwMDAwWhcN\n"
+"MjIxMjE5MjM1OTU5WjBAMQswCQYDVQQGEwJVUzEVMBMGA1UEChMMdGhhd3RlLCBJ\n"
+"bmMuMRowGAYDVQQDExF0aGF3dGUgRFNBIFNTTCBDQTCCA0gwggI6BgcqhkjOOAQB\n"
+"MIICLQKCAQEAsOkfT0p9OXj0/j9H+m2Ejyu6VTLpjydK1/dWyl/AQS5WE5GPgy0i\n"
+"6oJQCSEKLcZtJCcnrx9X2WJq/U9sxSydq0oP1R7BqXiRs3fphkJnBhW/OGJNnw13\n"
+"dnBrt9ffmaZNFFRCUQOsGDsSjBPOUQ4tuenBeF3Zs+DAfkDXzxcrK4OQs6qTYubn\n"
+"8QUphcoMaUURJv9aY8VfVpODN3Z5FeamrY72zAcGvc9ajFl45vVlK/dDbu8kMMdp\n"
+"b1wuNMTWUo/dxdPrtgpJA3ZnN9MDSzs2tcGWxYnpWFZTndTePn7xU0b3r/pN/ys7\n"
+"i5FBr1yqYVWelt5uGLMg+ZQ22GQnga8/eQIhAKdVID3cRKJNm0Rd77SM/GgY430w\n"
+"mefDvxS6pQDGnAzXAoIBAQCLQiKLU8kRBsWIkeuRPKlbqwSMkbNwaOYK6/Lh8x5k\n"
+"20djAqPOurHtzNWnAPAvZPYSjL+PR1ydHq4tRDEgjaVYlb5ZZeD8L6v0J/OWNTpS\n"
+"SmeKzHfD1QRP/2dxqiNweivUR4vw7m6wg8Y5ZxOFKbgAfdM08z2hbjkucrCzkbCr\n"
+"0NQUkUy+N4gvMKOIVDYVUiKUFSJmlRiYlCXJNaoIkKWcb4NjRBHjDKbmm4+Isco4\n"
+"PUQ3E7V+CdS6C8hOPdDwhcYm6FPrgbTPcuuoJgEI6YXjgywGCMja6zwEmU1F9NH6\n"
+"9TmpZiKCFDVhrBd5KgOemiiveAE2AAU1ctYz1pkqt2dXA4IBBgACggEBAJzaudYH\n"
+"djJGC5gPXFS+oWZc4SEicF5teHo2ZkI86j8TDGZWBCXHng3m/JrY3qT11tBU4go/\n"
+"XR5AQ9GYtLAiOXZKIdFSjyjrDGVotWNxpoZi1hXpVEsCAEwyWqKdO+47zUF2/tgc\n"
+"QzAnAwbb2NV9D35rg3wKenUKdQfp98PrlWUh2UOmFkae83eLr/7VxEF4nOF+CI/4\n"
+"Kx9y6Qy3So/OHucSp8206yqJ80EyYox9cnAeS81xBwJqn1LIPRFGJ85cEXRldATI\n"
+"+CvgvfdnpWnJaPPUvJoaPF9DVfi4FTGV7aFfeQfi9QemF8WMPq0JpdrFkfrnGVw9\n"
+"wxGzySeiXj7UDhKjggFCMIIBPjASBgNVHRMBAf8ECDAGAQH/AgEAMA4GA1UdDwEB\n"
+"/wQEAwIBBjAyBggrBgEFBQcBAQQmMCQwIgYIKwYBBQUHMAGGFmh0dHA6Ly9vY3Nw\n"
+"LnRoYXd0ZS5jb20wOwYDVR0gBDQwMjAwBgRVHSAAMCgwJgYIKwYBBQUHAgEWGmh0\n"
+"dHBzOi8vd3d3LnRoYXd0ZS5jb20vY3BzMDcGA1UdHwQwMC4wLKAqoCiGJmh0dHA6\n"
+"Ly9jcmwudGhhd3RlLmNvbS9UaGF3dGVQQ0EtRzQuY3JsMC4GA1UdEQQnMCWkIzAh\n"
+"MR8wHQYDVQQDExZTWU1DLURTQS1DQS0yMDQ4LTI1Ni00MB0GA1UdDgQWBBTKE7FN\n"
+"7Jp+tnxFHrgd5NLIchqxHTAfBgNVHSMEGDAWgBTHZ4lkIvGdsfOLg6bCDpmTUXbr\n"
+"ljALBglghkgBZQMEAwIDSAAwRQIhAKb8sDyC2UehqUcEPUQ65bnmmtiplEplDUZt\n"
+"ULqZQweDAiAr4MAcnfC9otwLcBllGVA4vsOKPsFSq5u2EPn3ovIynw==\n"
+"-----END CERTIFICATE-----\n";
+
+namespace {
+
+class CertCheckerTest : public ::testing::Test {
+ protected:
+  CertCheckerTest()
+      : cert_dir_(FLAGS_test_srcdir + "/test/testdata"),
+        cert_dir_v2_(FLAGS_test_srcdir + "/test/testdata/v2/") {
+  }
+
+  string leaf_pem_;
+  string ca_precert_pem_;
+  string precert_pem_;
+  string precert_with_preca_pem_;
+  string intermediate_pem_;
+  string chain_leaf_pem_;
+  string ca_pem_;
+  CertChecker checker_;
+  const string cert_dir_;
+  const string cert_dir_v2_;
+
+  void SetUp() {
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kLeafCert, &leaf_pem_))
+        << "Could not read test data from " << cert_dir_
+        << ". Wrong --test_srcdir?";
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kCaPreCert, &ca_precert_pem_));
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kPreCert, &precert_pem_));
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kPreWithPreCaCert,
+                             &precert_with_preca_pem_));
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kIntermediateCert,
+                             &intermediate_pem_));
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kChainLeafCert,
+                             &chain_leaf_pem_));
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kCaCert, &ca_pem_));
+  }
+};
+
+TEST_F(CertCheckerTest, LoadTrustedCertificates) {
+  EXPECT_EQ(0U, checker_.NumTrustedCertificates());
+
+  EXPECT_TRUE(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaCert));
+  EXPECT_EQ(1U, checker_.NumTrustedCertificates());
+
+  EXPECT_TRUE(
+      checker_.LoadTrustedCertificates(cert_dir_ + "/" + kIntermediateCert));
+  EXPECT_EQ(2U, checker_.NumTrustedCertificates());
+}
+
+TEST_F(CertCheckerTest, LoadTrustedCertificatesFromMemory) {
+  vector<string> certs;
+  certs.push_back(string(kCaCertPem));
+
+  EXPECT_TRUE(checker_.LoadTrustedCertificates(certs));
+  EXPECT_EQ(1U, checker_.NumTrustedCertificates());
+}
+
+TEST_F(CertCheckerTest, LoadTrustedCertificatesLoadsAll) {
+  EXPECT_EQ(0U, checker_.NumTrustedCertificates());
+
+  EXPECT_TRUE(
+      checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCollidingRoots));
+  EXPECT_EQ(2U, checker_.NumTrustedCertificates());
+}
+
+TEST_F(CertCheckerTest, LoadTrustedCertificatesFromMemoryLoadsAll) {
+  vector<string> certs;
+  certs.push_back(string(kCaCertPem));
+  certs.push_back(string(kIntermediateCertPem));
+
+  EXPECT_TRUE(checker_.LoadTrustedCertificates(certs));
+  EXPECT_EQ(2U, checker_.NumTrustedCertificates());
+}
+
+TEST_F(CertCheckerTest, LoadTrustedCertificatesIgnoresDuplicates) {
+  EXPECT_EQ(0U, checker_.NumTrustedCertificates());
+
+  EXPECT_TRUE(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaCert));
+  EXPECT_EQ(1U, checker_.NumTrustedCertificates());
+  EXPECT_TRUE(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaCert));
+  EXPECT_EQ(1U, checker_.NumTrustedCertificates());
+}
+
+TEST_F(CertCheckerTest, LoadTrustedCertificatesMissingFile) {
+  EXPECT_EQ(0U, checker_.NumTrustedCertificates());
+
+  EXPECT_FALSE(
+      checker_.LoadTrustedCertificates(cert_dir_ + "/" + kNonexistent));
+  EXPECT_EQ(0U, checker_.NumTrustedCertificates());
+}
+
+TEST_F(CertCheckerTest, LoadTrustedCertificatesCorruptedFile) {
+  EXPECT_EQ(0U, checker_.NumTrustedCertificates());
+
+  EXPECT_FALSE(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCorrupted));
+  EXPECT_EQ(0U, checker_.NumTrustedCertificates());
+}
+
+TEST_F(CertCheckerTest, Certificate) {
+  CertChain chain(leaf_pem_);
+  ASSERT_TRUE(chain.IsLoaded());
+
+  // Fail as we have no CA certs.
+  EXPECT_THAT(checker_.CheckCertChain(&chain),
+              StatusIs(util::error::FAILED_PRECONDITION));
+
+  // Load CA certs and expect success.
+  EXPECT_TRUE(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaCert));
+  EXPECT_OK(checker_.CheckCertChain(&chain));
+  EXPECT_EQ(2U, chain.Length());
+}
+
+TEST_F(CertCheckerTest, CertificateWithRoot) {
+  CertChain chain(leaf_pem_);
+  ASSERT_TRUE(chain.IsLoaded());
+  ASSERT_TRUE(chain.AddCert(Cert::FromPemString(ca_pem_)));
+
+  // Fail as even though we give a CA cert, it's not in the local store.
+  EXPECT_THAT(checker_.CheckCertChain(&chain),
+              StatusIs(util::error::FAILED_PRECONDITION));
+
+  // Load CA certs and expect success.
+  EXPECT_TRUE(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaCert));
+  EXPECT_OK(checker_.CheckCertChain(&chain));
+  EXPECT_EQ(2U, chain.Length());
+}
+
+TEST_F(CertCheckerTest, TrimsRepeatedRoots) {
+  CertChain chain(leaf_pem_);
+  ASSERT_TRUE(chain.IsLoaded());
+  ASSERT_TRUE(chain.AddCert(Cert::FromPemString(ca_pem_)));
+  ASSERT_TRUE(chain.AddCert(Cert::FromPemString(ca_pem_)));
+
+  // Load CA certs and expect success.
+  EXPECT_TRUE(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaCert));
+  EXPECT_OK(checker_.CheckCertChain(&chain));
+  EXPECT_EQ(2U, chain.Length());
+}
+
+TEST_F(CertCheckerTest, Intermediates) {
+  // Load CA certs.
+  EXPECT_TRUE(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaCert));
+  // A chain with an intermediate.
+  CertChain chain(chain_leaf_pem_);
+  ASSERT_TRUE(chain.IsLoaded());
+  // Fail as it doesn't chain to a trusted CA.
+  EXPECT_THAT(checker_.CheckCertChain(&chain),
+              StatusIs(util::error::FAILED_PRECONDITION));
+  // Add the intermediate and expect success.
+  ASSERT_TRUE(chain.AddCert(Cert::FromPemString(intermediate_pem_)));
+  ASSERT_EQ(2U, chain.Length());
+  EXPECT_OK(checker_.CheckCertChain(&chain));
+  EXPECT_EQ(3U, chain.Length());
+
+  // An invalid chain, with two certs in wrong order.
+  CertChain invalid(intermediate_pem_ + chain_leaf_pem_);
+  ASSERT_TRUE(invalid.IsLoaded());
+  EXPECT_THAT(checker_.CheckCertChain(&invalid),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertCheckerTest, PreCert) {
+  const string chain_pem = precert_pem_ + ca_pem_;
+  PreCertChain chain(chain_pem);
+
+  ASSERT_TRUE(chain.IsLoaded());
+  EXPECT_TRUE(chain.IsWellFormed().ValueOrDie());
+
+  // Fail as we have no CA certs.
+  string issuer_key_hash, tbs;
+  EXPECT_THAT(checker_.CheckPreCertChain(&chain, &issuer_key_hash, &tbs),
+              StatusIs(util::error::FAILED_PRECONDITION));
+
+  // Load CA certs and expect success.
+  checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaCert);
+  EXPECT_OK(checker_.CheckPreCertChain(&chain, &issuer_key_hash, &tbs));
+  string expected_key_hash;
+  ASSERT_OK(chain.CertAt(1)->SPKISha256Digest(&expected_key_hash));
+  EXPECT_EQ(expected_key_hash, issuer_key_hash);
+  // TODO(ekasper): proper KAT tests.
+  EXPECT_FALSE(tbs.empty());
+}
+
+TEST_F(CertCheckerTest, PreCertWithPreCa) {
+  const string chain_pem = precert_with_preca_pem_ + ca_precert_pem_;
+  PreCertChain chain(chain_pem);
+
+  ASSERT_TRUE(chain.IsLoaded());
+  EXPECT_TRUE(chain.IsWellFormed().ValueOrDie());
+
+  string issuer_key_hash, tbs;
+  // Fail as we have no CA certs.
+  EXPECT_THAT(checker_.CheckPreCertChain(&chain, &issuer_key_hash, &tbs),
+              StatusIs(util::error::FAILED_PRECONDITION));
+
+  // Load CA certs and expect success.
+  checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaCert);
+  EXPECT_OK(checker_.CheckPreCertChain(&chain, &issuer_key_hash, &tbs));
+  string expected_key_hash;
+  ASSERT_OK(chain.CertAt(2)->SPKISha256Digest(&expected_key_hash));
+  EXPECT_EQ(expected_key_hash, issuer_key_hash);
+  // TODO(ekasper): proper KAT tests.
+  EXPECT_FALSE(tbs.empty());
+
+  // A second, invalid chain, with no CA precert.
+  PreCertChain chain2(precert_with_preca_pem_);
+  ASSERT_TRUE(chain2.IsLoaded());
+  EXPECT_TRUE(chain2.IsWellFormed().ValueOrDie());
+  EXPECT_THAT(checker_.CheckPreCertChain(&chain2, &issuer_key_hash, &tbs),
+              StatusIs(util::error::FAILED_PRECONDITION));
+}
+
+TEST_F(CertCheckerTest, CertAsPreCert) {
+  ASSERT_TRUE(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaCert));
+
+  PreCertChain chain(leaf_pem_);
+  string issuer_key_hash, tbs;
+  EXPECT_THAT(checker_.CheckPreCertChain(&chain, &issuer_key_hash, &tbs),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertCheckerTest, PreCertAsCert) {
+  ASSERT_TRUE(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaCert));
+
+  const string chain_pem = precert_pem_ + ca_pem_;
+  PreCertChain chain(chain_pem);
+  EXPECT_THAT(checker_.CheckCertChain(&chain),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+// Accept if the root cert has no CA:True constraint and is in the trust store.
+// Also accept MD2 in root cert.
+TEST_F(CertCheckerTest, AcceptNoBasicConstraintsAndMd2) {
+  ASSERT_TRUE(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaNoBCCert));
+
+  string ca_pem;
+  ASSERT_TRUE(util::ReadTextFile(cert_dir_ + "/" + kCaNoBCCert, &ca_pem));
+  const unique_ptr<Cert> ca(Cert::FromPemString(ca_pem));
+  ASSERT_TRUE(ca.get());
+  // Verify testdata properties: CA is legacy root.
+  ASSERT_EQ("md2WithRSAEncryption", ca->PrintSignatureAlgorithm());
+  ASSERT_FALSE(ca->HasBasicConstraintCATrue().ValueOrDie());
+
+  string chain_pem;
+  ASSERT_TRUE(util::ReadTextFile(cert_dir_ + "/" + kNoBCChain, &chain_pem));
+
+  CertChain chain(chain_pem);
+  ASSERT_TRUE(chain.IsLoaded());
+
+  EXPECT_OK(checker_.CheckCertChain(&chain));
+}
+
+// Don't accept if some other cert without CA:True tries to issue.
+TEST_F(CertCheckerTest, DontAcceptNoBasicConstraints) {
+  ASSERT_TRUE(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaCert));
+
+  string chain_pem;
+  ASSERT_TRUE(util::ReadTextFile(cert_dir_ + "/" + kBadNoBCChain, &chain_pem));
+
+  CertChain chain(chain_pem);
+  ASSERT_TRUE(chain.IsLoaded());
+  EXPECT_THAT(checker_.CheckCertChain(&chain),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+// Don't accept if anything else but the trusted root is signed with MD2.
+TEST_F(CertCheckerTest, DontAcceptMD2) {
+  ASSERT_TRUE(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaNoBCCert));
+
+  string chain_pem;
+  ASSERT_TRUE(util::ReadTextFile(cert_dir_ + "/" + kMd2Chain, &chain_pem));
+
+  CertChain chain(chain_pem);
+  ASSERT_TRUE(chain.IsLoaded());
+  // Verify testdata properties: chain terminates in an MD2 intermediate.
+  ASSERT_FALSE(chain.LastCert()->IsSelfSigned().ValueOrDie());
+  ASSERT_TRUE(chain.LastCert()->HasBasicConstraintCATrue().ValueOrDie());
+  ASSERT_EQ("md2WithRSAEncryption",
+            chain.LastCert()->PrintSignatureAlgorithm());
+
+#ifdef OPENSSL_NO_MD2
+  EXPECT_THAT(checker_.CheckCertChain(&chain),
+              StatusIs(util::error::INVALID_ARGUMENT));
+#else
+  LOG(WARNING) << "Skipping test: MD2 is enabled! You should configure "
+               << "OpenSSL with -DOPENSSL_NO_MD2 to be safe!";
+#endif
+}
+
+TEST_F(CertCheckerTest, ResolveIssuerCollisions) {
+  string chain_pem, root1_pem, root2_pem;
+  ASSERT_TRUE(
+      util::ReadTextFile(cert_dir_ + "/" + kCollisionChain, &chain_pem));
+
+  ASSERT_TRUE(
+      checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCollisionRoot1));
+  ASSERT_TRUE(
+      checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCollisionRoot2));
+  CertChain chain(chain_pem);
+  ASSERT_TRUE(chain.IsLoaded());
+  EXPECT_OK(checker_.CheckCertChain(&chain));
+
+  // The same, but include the root in the submission.
+  ASSERT_TRUE(
+      util::ReadTextFile(cert_dir_ + "/" + kCollisionRoot1, &root1_pem));
+  ASSERT_TRUE(
+      util::ReadTextFile(cert_dir_ + "/" + kCollisionRoot2, &root2_pem));
+  CertChain chain1(chain_pem);
+  ASSERT_TRUE(chain1.AddCert(Cert::FromPemString(root1_pem)));
+  EXPECT_OK(checker_.CheckCertChain(&chain1));
+
+  CertChain chain2(chain_pem);
+  ASSERT_TRUE(chain2.AddCert(Cert::FromPemString(root2_pem)));
+  EXPECT_OK(checker_.CheckCertChain(&chain2));
+}
+
+TEST_F(CertCheckerTest, TestDsaPrecertFailsRootNotTrusted) {
+  // Load CA certs.
+  EXPECT_TRUE(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaCert));
+  PreCertChain pre_chain(kDsaPrecertChain);
+  string issuer_key_hash, tbs;
+
+  // With our default roots this should not be accepted, but it shouldn't
+  // fail with an algorithm related error
+  const util::Status status(
+      checker_.CheckPreCertChain(&pre_chain, &issuer_key_hash, &tbs));
+
+  EXPECT_THAT(status,
+              StatusIs(util::error::FAILED_PRECONDITION, "unknown root"));
+}
+
+TEST_F(CertCheckerTest, TestDsaPrecertChain) {
+  // Explicitly set the root of this chain as trusted
+  vector<string> roots;
+  roots.push_back(kDsaPrecertChainRootOnly);
+  checker_.LoadTrustedCertificates(roots);
+
+  PreCertChain pre_chain(kDsaPrecertChain);
+  string issuer_key_hash, tbs;
+
+  EXPECT_OK(checker_.CheckPreCertChain(&pre_chain, &issuer_key_hash, &tbs));
+  // Added a root CA.
+  EXPECT_EQ(2U, pre_chain.Length());
+  // And set a SHA256 HASH
+  EXPECT_EQ(32U, issuer_key_hash.size());
+  // And the TBS fields
+  EXPECT_FALSE(tbs.empty());
+}
+
+TEST_F(CertCheckerTest, TestDsaPrecertChainRejectsInvalidDsaSig) {
+  // Explicitly set the root of this chain as trusted
+  vector<string> roots;
+  roots.push_back(kDsaPrecertChainRootOnly);
+  checker_.LoadTrustedCertificates(roots);
+
+  // This has a deliberately corrupt signature
+  PreCertChain pre_chain(kDsaPrecertChainInvalidSig);
+  string issuer_key_hash, tbs;
+
+  const util::Status status(
+        checker_.CheckPreCertChain(&pre_chain, &issuer_key_hash, &tbs));
+
+  EXPECT_THAT(status, StatusIs(util::error::INVALID_ARGUMENT,
+                               "invalid certificate chain"));
+}
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  OpenSSL_add_all_algorithms();
+  ERR_load_crypto_strings();
+  cert_trans::LoadCtExtensions();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert.h	2017-01-15 10:56:31.038591151 +0100
@@ -0,0 +1,384 @@
+#ifndef CERT_TRANS_LOG_CERT_H_
+#define CERT_TRANS_LOG_CERT_H_
+
+#include <gtest/gtest_prod.h>
+#include <openssl/asn1.h>
+#include <openssl/x509.h>
+#include <memory>
+#include <string>
+#include <vector>
+
+#include "base/macros.h"
+#include "util/openssl_scoped_types.h"
+#include "util/statusor.h"
+
+namespace cert_trans {
+
+// Tests if a hostname contains any redactions ('?' elements). If it does
+// not then there is no need to apply the validation below
+bool IsRedactedHost(const std::string& hostname);
+// Tests if a hostname containing any redactions follows the RFC rules
+bool IsValidRedactedHost(const std::string& hostname);
+
+class Cert {
+ public:
+  // The following factory static methods return null if the input is
+  // not valid.
+  static std::unique_ptr<Cert> FromDerString(const std::string& der_string);
+  // Caller still owns the BIO afterwards.
+  static std::unique_ptr<Cert> FromDerBio(BIO* bio_in);
+  static std::unique_ptr<Cert> FromPemString(const std::string& pem_string);
+  // Will return null if |x509| is null.
+  static std::unique_ptr<Cert> FromX509(ScopedX509 x509);
+
+  // Returns null if there was a problem with the underlying copy.
+  std::unique_ptr<Cert> Clone() const;
+
+  // These just return an empty string if an error occurs.
+  std::string PrintVersion() const;
+  std::string PrintSerialNumber() const;
+  std::string PrintIssuerName() const;
+  std::string PrintSubjectName() const;
+  std::string PrintNotBefore() const;
+  std::string PrintNotAfter() const;
+  std::string PrintSignatureAlgorithm() const;
+
+  bool IsIdenticalTo(const Cert& other) const;
+
+  // Returns TRUE if the extension is present.
+  // Returns FALSE if the extension is not present.
+  // Returns ERROR if the cert is not loaded, extension_nid is not recognised
+  // or some other unknown error occurred while parsing the extensions.
+  // NID must be either an OpenSSL built-in NID, or one registered by the user
+  // with OBJ_create. (See log/ct_extensions.h for sample code.)
+  util::StatusOr<bool> HasExtension(int extension_nid) const;
+
+  // Returns TRUE if the extension is present and critical.
+  // Returns FALSE if the extension is not present, or is present but not
+  // critical.
+  // Returns ERROR if the cert is not loaded, extension_nid is not recognised
+  // or some other unknown error occurred while parsing the extensions.
+  // NID must be either an OpenSSL built-in NID, or one registered by the user
+  // with OBJ_create. (See log/ct_extensions.h for sample code.)
+  util::StatusOr<bool> HasCriticalExtension(int extension_nid) const;
+
+  // Returns TRUE if the basicConstraints extension is present and CA=TRUE.
+  // Returns FALSE if the extension is not present, is present but CA=FALSE,
+  // or is present but could not be decoded.
+  // Returns ERROR if the cert is not loaded or some other unknown error
+  // occurred while parsing the extensions.
+  util::StatusOr<bool> HasBasicConstraintCATrue() const;
+
+  // Returns TRUE if extendedKeyUsage extension is present and the specified
+  // key usage is set.
+  // Returns FALSE if the extension is not present, is present but could not
+  // be decoded, or is present but the specified key usage is not set.
+  // Returns ERROR if the cert is not loaded, extension_nid is not recognised
+  // or some other unknown error occurred while parsing the extensions.
+  // NID must be either an OpenSSL built-in NID, or one registered by the user
+  // with OBJ_create. (See log/ct_extensions.h for sample code.)
+  util::StatusOr<bool> HasExtendedKeyUsage(int key_usage_nid) const;
+
+  // Returns TRUE if the Cert's issuer matches |issuer|.
+  // Returns FALSE if there is no match.
+  // Returns ERROR if either cert is not loaded.
+  util::StatusOr<bool> IsIssuedBy(const Cert& issuer) const;
+
+  // Returns TRUE if the cert's signature can be verified by the issuer's
+  // public key.
+  // Returns FALSE if the signature cannot be verified.
+  // Returns ERROR if either cert is not loaded or some other error occurs.
+  // Does not check if issuer has CA capabilities.
+  util::StatusOr<bool> IsSignedBy(const Cert& issuer) const;
+
+  util::StatusOr<bool> IsSelfSigned() const {
+    return IsIssuedBy(*this);
+  }
+
+  // Sets the DER encoding of the cert in |result|.
+  // Returns TRUE if the encoding succeeded.
+  // Returns FALSE if the encoding failed.
+  // Returns ERROR if the cert is not loaded.
+  util::Status DerEncoding(std::string* result) const;
+
+  // Sets the PEM encoding of the cert in |result|.
+  // Returns TRUE if the encoding succeeded.
+  // Returns FALSE if the encoding failed.
+  // Returns ERROR if the cert is not loaded.
+  util::Status PemEncoding(std::string* result) const;
+
+  // Sets the SHA256 digest of the cert in |result|.
+  // Returns TRUE if computing the digest succeeded.
+  // Returns FALSE if computing the digest failed.
+  // Returns ERROR if the cert is not loaded.
+  util::Status Sha256Digest(std::string* result) const;
+
+  // Sets the DER-encoded TBS component of the cert in |result|.
+  // Returns TRUE if the encoding succeeded.
+  // Returns FALSE if the encoding failed.
+  // Returns ERROR if the cert is not loaded.
+  util::Status DerEncodedTbsCertificate(std::string* result) const;
+
+  // Sets the DER-encoded subject Name component of the cert in |result|.
+  // Returns TRUE if the encoding succeeded.
+  // Returns FALSE if the encoding failed.
+  // Returns ERROR if the cert is not loaded.
+  util::Status DerEncodedSubjectName(std::string* result) const;
+
+  // Sets the DER-encoded issuer Name component of the cert in |result|.
+  // Returns TRUE if the encoding succeeded.
+  // Returns FALSE if the encoding failed.
+  // Returns ERROR if the cert is not loaded.
+  util::Status DerEncodedIssuerName(std::string* result) const;
+
+  // Sets the SHA256 digest of the cert's public key in |result|.
+  // Returns TRUE if computing the digest succeeded.
+  // Returns FALSE if computing the digest failed.
+  // Returns ERROR if the cert is not loaded.
+  util::Status PublicKeySha256Digest(std::string* result) const;
+
+  // Sets the Subject Alternative Name dNSNames in |dns_alt_names|.
+  // Returns Status::OK if the SAN dNSNames were extracted.
+  // Returns INVALID_ARGUMENT if the DAN dNSNames could not be extracted.
+  // Returns FAILED_PRECONDITION if the cert is not loaded.
+  util::Status SubjectAltNames(std::vector<std::string>* dns_alt_names) const;
+
+  // Sets the SHA256 digest of the cert's subjectPublicKeyInfo in |result|.
+  // Returns TRUE if computing the digest succeeded.
+  // Returns FALSE if computing the digest failed.
+  // Returns ERROR if the cert is not loaded.
+  util::Status SPKISha256Digest(std::string* result) const;
+
+  // Get the cert's subjectPublicKeyInfo.
+  // Returns error INVALID_ARGUMENT if parsing the cert DER failed.
+  // Returns error FAILED_PRECONDITION if the cert is not loaded.
+  util::StatusOr<std::string> SPKI() const;
+
+  // Fetch data from an extension if encoded as an ASN1_OCTET_STRING.
+  // Useful for handling custom extensions registered with X509V3_EXT_add.
+  // Returns true if the extension is present and the data could be decoded.
+  // Returns false if the extension is not present or the data is not a valid
+  // ASN1_OCTET_STRING.
+  //
+  // Caller MUST ensure that the registered type of the extension
+  // contents is an ASN1_OCTET_STRING. Only use if you know what
+  // you're doing.
+  //
+  // Returns OK if the extension data could be fetched and decoded.
+  // Returns NOT_FOUND if the extension is not present, or is present but is
+  // not a valid ASN1 OCTET STRING.
+  // Returns a suitable status if the cert is not loaded or the extension_nid
+  // is not recognised.
+  // TODO(ekasper): consider registering known custom NIDS explicitly with the
+  // Cert API for safety.
+  util::Status OctetStringExtensionData(int extension_nid,
+                                        std::string* result) const;
+
+  // Tests whether the certificate correctly follows the RFC rules for
+  // using wildcard redaction.
+  util::Status IsValidWildcardRedaction() const;
+  // Tests if a certificate correctly follows the rules for name constrained
+  // intermediate CA
+  util::Status IsValidNameConstrainedIntermediateCa() const;
+
+  // CertChecker needs access to the x509_ structure directly.
+  friend class CertChecker;
+  // CmsVerifier needs access to the x509_ structure directly.
+  friend class CmsVerifier;
+  friend class TbsCertificate;
+  // Allow CtExtensions tests to poke around the private members
+  // for convenience.
+  FRIEND_TEST(CtExtensionsTest, TestSCTExtension);
+  FRIEND_TEST(CtExtensionsTest, TestEmbeddedSCTExtension);
+  FRIEND_TEST(CtExtensionsTest, TestPoisonExtension);
+  FRIEND_TEST(CtExtensionsTest, TestPrecertSigning);
+
+ private:
+  // Will CHECK-fail if |x509| is null.
+  explicit Cert(ScopedX509 x509);
+  Cert() = delete;
+
+  util::StatusOr<int> ExtensionIndex(int extension_nid) const;
+  util::StatusOr<X509_EXTENSION*> GetExtension(int extension_nid) const;
+  util::StatusOr<void*> ExtensionStructure(int extension_nid) const;
+  bool ValidateRedactionSubjectAltNameAndCN(int* dns_alt_name_count,
+                                            util::Status* status) const;
+  util::StatusOr<bool> LogUnsupportedAlgorithm() const;
+  static std::string PrintName(X509_NAME* name);
+  static std::string PrintTime(ASN1_TIME* when);
+  static util::Status DerEncodedName(X509_NAME* name, std::string* result);
+  const ScopedX509 x509_;
+
+  DISALLOW_COPY_AND_ASSIGN(Cert);
+};
+
+// A wrapper around X509_CINF for chopping at the TBS to CT-sign it or verify
+// a CT signature. We construct a TBS for this rather than chopping at the full
+// cert so that the X509 information OpenSSL caches doesn't get out of sync.
+class TbsCertificate {
+ public:
+  // TODO(ekasper): add construction from PEM and DER as needed.
+  explicit TbsCertificate(const Cert& cert);
+
+  bool IsLoaded() const {
+    return x509_ != NULL;
+  }
+
+  // Sets the DER-encoded TBS structure in |result|.
+  // Returns OK if the encoding succeeded.
+  // Returns a suitable eror status if the encoding failed.
+  // Returns FAILED_PRECONDITION if the cert is not loaded.
+  util::Status DerEncoding(std::string* result) const;
+
+  // Delete the matching extension, if present.
+  // Returns OK if the extension was present and was deleted.
+  // Returns NOT_FOUND if the extension was not present.
+  // If multiple extensions with this NID are present, deletes the first
+  // occurrence but returns ALREADY_EXISTS.
+  // Returns a suitable status if the cert is not loaded, the NID is not
+  // recognised or deletion failed internally.
+  util::Status DeleteExtension(int extension_nid);
+
+  // Copy the issuer and Authority KeyID information.
+  // Requires that if Authority KeyID is present in the destination,
+  // it must also be present in the source certificate.
+  // Does not overwrite the critical bit.
+  // Returns OK if the operation succeeded.
+  // Returns a suitable status if the operation could not be completed
+  // successfully.
+  // Returns FAILED_PRECONDITION if either cert is not loaded.
+  // Caller should not assume the dest cert was left unmodified without OK as
+  // fields may have been copied successfully before an error occurred.
+  util::Status CopyIssuerFrom(const Cert& from);
+
+ private:
+  util::StatusOr<int> ExtensionIndex(int extension_nid) const;
+  // OpenSSL does not expose a TBSCertificate API, so we keep the TBS wrapped
+  // in the X509.
+  ScopedX509 x509_;
+
+  DISALLOW_COPY_AND_ASSIGN(TbsCertificate);
+};
+
+
+class CertChain {
+ public:
+  CertChain() = default;
+
+  // Loads a chain of PEM-encoded certificates. If any of the PEM-strings
+  // in the chain are invalid, clears the entire chain.
+  // Caller should check IsLoaded() before doing anything else apart from
+  // AddCert().
+  explicit CertChain(const std::string& pem_string);
+  ~CertChain();
+
+  // If the cert has a valid X509 structure, adds it to the end of the chain
+  // and returns true.
+  // Else returns false.
+  bool AddCert(std::unique_ptr<Cert> cert);
+
+  // Remove a cert from the end of the chain, if there is one.
+  void RemoveCert();
+
+  // Keep the first self-signed, remove the rest. We keep the first one so that
+  // chains consisting only of a self-signed cert don't become invalid.
+  // If successful, returns true.
+  // If the chain is empty, returns false.
+  // If the chain has no self-signed certs, does nothing and also returns true.
+  bool RemoveCertsAfterFirstSelfSigned();
+
+  // True if the chain loaded correctly, and contains at least one valid cert.
+  bool IsLoaded() const {
+    return !chain_.empty();
+  }
+
+  size_t Length() const {
+    return chain_.size();
+  }
+
+  Cert const* LeafCert() const {
+    if (!IsLoaded())
+      return NULL;
+    return chain_.front().get();
+  }
+
+  Cert const* CertAt(size_t position) const {
+    return chain_.size() <= position ? NULL : chain_[position].get();
+  }
+
+  Cert const* LastCert() const {
+    if (!IsLoaded())
+      return NULL;
+    return chain_.back().get();
+  }
+
+  // Returns TRUE if the issuer of each cert is the subject of the
+  // next cert, and each issuer has BasicConstraints CA:true, except
+  // the root cert which may not have CA:true to support old CA
+  // certificates.
+  // Returns FALSE if the above does not hold.
+  // Returns ERROR if the chain is not loaded or some error occurred.
+  util::Status IsValidCaIssuerChainMaybeLegacyRoot() const;
+
+  // Is OK if each certificate is signed by the next certificate in
+  // the chain. Does not check whether issuers have CA capabilities.
+  util::Status IsValidSignatureChain() const;
+
+ private:
+  void ClearChain();
+  std::vector<std::unique_ptr<Cert>> chain_;
+
+  DISALLOW_COPY_AND_ASSIGN(CertChain);
+};
+
+// Note: CT extensions must be loaded to use this class. See
+// log/ct_extensions.h for LoadCtExtensions().
+class PreCertChain : public CertChain {
+ public:
+  PreCertChain() = default;
+
+  explicit PreCertChain(const std::string& pem_string)
+      : CertChain(pem_string) {
+  }
+
+  // Some convenient aliases.
+  // A pointer to the precert.
+  Cert const* PreCert() const {
+    return LeafCert();
+  }
+
+  // A pointer to the issuing cert, which is either the issuing CA cert,
+  // or a special-purpose Precertificate Signing Certificate issued
+  // directly by the CA cert.
+  // Can be NULL if the precert is issued directly by a root CA.
+  Cert const* PrecertIssuingCert() const {
+    return Length() >= 2 ? CertAt(1) : NULL;
+  }
+
+  // Returns TRUE if the chain has length >=2 and
+  // extendedKeyUsage=precertSigning can be detected in the leaf's issuer.
+  // Returns FALSE if the above does not hold.
+  // Returns ERROR if the chain is not loaded, CT extensions could not be
+  // detected or some other unknown error occurred while parsing the
+  // extensions.
+  util::StatusOr<bool> UsesPrecertSigningCertificate() const;
+
+  // Returns TRUE if
+  // (1) the leaf certificate contains the critical poison extension;
+  // (2) if the leaf certificate issuing certificate is present and has the
+  //     CT EKU, and the leaf certificate has an Authority KeyID extension,
+  //     then its issuing certificate also has this extension.
+  // (2) is necessary for the log to be able to "predict" the AKID of the final
+  // TbsCertificate.
+  // Returns FALSE if the above does not hold.
+  // Returns ERROR if the chain is not loaded, CT extensions could not be
+  // detected or some other unknown error occurred while parsing the
+  // extensions.
+  // This method does not verify any signatures, or otherwise check
+  // that the chain is valid.
+  util::StatusOr<bool> IsWellFormed() const;
+};
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_CERT_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert_submission_handler.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert_submission_handler.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert_submission_handler.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert_submission_handler.cc	2017-01-15 10:56:31.039591151 +0100
@@ -0,0 +1,173 @@
+#include "log/cert_submission_handler.h"
+
+#include <glog/logging.h>
+#include <string>
+
+#include "log/cert.h"
+#include "log/cert_checker.h"
+#include "log/ct_extensions.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+
+using cert_trans::Cert;
+using cert_trans::CertChain;
+using cert_trans::CertChecker;
+using cert_trans::PreCertChain;
+using cert_trans::TbsCertificate;
+using ct::LogEntry;
+using ct::PrecertChainEntry;
+using ct::X509ChainEntry;
+using std::string;
+using util::Status;
+using util::StatusOr;
+
+namespace cert_trans {
+namespace {
+
+
+bool SerializedTbs(const Cert& cert, string* result) {
+  const StatusOr<bool> has_embedded_proof = cert.HasExtension(
+      cert_trans::NID_ctEmbeddedSignedCertificateTimestampList);
+  if (!has_embedded_proof.ok()) {
+    return false;
+  }
+
+  // Delete the embedded proof.
+  TbsCertificate tbs(cert);
+  if (!tbs.IsLoaded()) {
+    return false;
+  }
+
+  if (has_embedded_proof.ValueOrDie() &&
+      !tbs.DeleteExtension(
+              cert_trans::NID_ctEmbeddedSignedCertificateTimestampList)
+           .ok()) {
+    return false;
+  }
+
+  string der_tbs;
+  if (!tbs.DerEncoding(&der_tbs).ok()) {
+    return false;
+  }
+
+  result->assign(der_tbs);
+  return true;
+}
+
+
+}  // namespace
+
+
+// TODO(ekasper): handle Cert errors consistently and log some errors here
+// if they fail.
+CertSubmissionHandler::CertSubmissionHandler(const CertChecker* cert_checker)
+    : cert_checker_(CHECK_NOTNULL(cert_checker)) {
+}
+
+
+// static
+bool CertSubmissionHandler::X509ChainToEntry(const CertChain& chain,
+                                             LogEntry* entry) {
+  if (!chain.IsLoaded()) {
+    return false;
+  }
+
+  const StatusOr<bool> has_embedded_proof = chain.LeafCert()->HasExtension(
+      cert_trans::NID_ctEmbeddedSignedCertificateTimestampList);
+  if (!has_embedded_proof.ok()) {
+    LOG(ERROR) << "Failed to check embedded SCT extension.";
+    return false;
+  }
+
+  if (has_embedded_proof.ValueOrDie()) {
+    if (chain.Length() < 2) {
+      // need issuer
+      return false;
+    }
+
+    entry->set_type(ct::PRECERT_ENTRY);
+    string key_hash;
+    if (chain.CertAt(1)->SPKISha256Digest(&key_hash) != Status::OK) {
+      return false;
+    }
+
+    entry->mutable_precert_entry()->mutable_pre_cert()->set_issuer_key_hash(
+        key_hash);
+
+    string tbs;
+    if (!SerializedTbs(*chain.LeafCert(), &tbs))
+      return false;
+
+    entry->mutable_precert_entry()->mutable_pre_cert()->set_tbs_certificate(
+        tbs);
+    return true;
+  } else {
+    entry->set_type(ct::X509_ENTRY);
+    string der_cert;
+    if (chain.LeafCert()->DerEncoding(&der_cert) != Status::OK) {
+      return false;
+    }
+
+    entry->mutable_x509_entry()->set_leaf_certificate(der_cert);
+    return true;
+  }
+}
+
+
+Status CertSubmissionHandler::ProcessX509Submission(CertChain* chain,
+                                                    LogEntry* entry) const {
+  entry->set_type(ct::X509_ENTRY);
+  if (!chain->IsLoaded())
+    return Status(util::error::INVALID_ARGUMENT, "empty submission");
+
+  const Status status(cert_checker_->CheckCertChain(chain));
+  if (!status.ok())
+    return status;
+
+  // We have a valid chain; make the entry.
+  string der_cert;
+  // Nothing should fail anymore as we have validated the chain.
+  if (chain->LeafCert()->DerEncoding(&der_cert) != Status::OK) {
+    return Status(util::error::INTERNAL, "could not DER-encode the chain");
+  }
+
+  X509ChainEntry* x509_entry = entry->mutable_x509_entry();
+  x509_entry->set_leaf_certificate(der_cert);
+  for (size_t i = 1; i < chain->Length(); ++i) {
+    if (chain->CertAt(i)->DerEncoding(&der_cert) != Status::OK) {
+      return Status(util::error::INTERNAL, "could not DER-encode the chain");
+    }
+    x509_entry->add_certificate_chain(der_cert);
+  }
+  return Status::OK;
+}
+
+
+Status CertSubmissionHandler::ProcessPreCertSubmission(PreCertChain* chain,
+                                                       LogEntry* entry) const {
+  entry->set_type(ct::PRECERT_ENTRY);
+  PrecertChainEntry* precert_entry = entry->mutable_precert_entry();
+  const Status status(cert_checker_->CheckPreCertChain(
+      chain, precert_entry->mutable_pre_cert()->mutable_issuer_key_hash(),
+      precert_entry->mutable_pre_cert()->mutable_tbs_certificate()));
+
+  if (!status.ok())
+    return status;
+
+  // We have a valid chain; make the entry.
+  string der_cert;
+  // Nothing should fail anymore as we have validated the chain.
+  if (chain->LeafCert()->DerEncoding(&der_cert) != Status::OK) {
+    return Status(util::error::INTERNAL, "could not DER-encode the chain");
+  }
+  precert_entry->set_pre_certificate(der_cert);
+  for (size_t i = 1; i < chain->Length(); ++i) {
+    if (chain->CertAt(i)->DerEncoding(&der_cert) != Status::OK)
+      return Status(util::error::INTERNAL, "could not DER-encode the chain");
+    precert_entry->add_precertificate_chain(der_cert);
+  }
+  return Status::OK;
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert_submission_handler.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert_submission_handler.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert_submission_handler.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert_submission_handler.h	2017-01-15 10:56:31.039591151 +0100
@@ -0,0 +1,46 @@
+#ifndef CERT_TRANS_LOG_CERT_SUBMISSION_HANDLER_H_
+#define CERT_TRANS_LOG_CERT_SUBMISSION_HANDLER_H_
+
+#include <string>
+
+#include "base/macros.h"
+#include "log/cert_checker.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+#include "util/status.h"
+
+namespace cert_trans {
+
+
+// Parse incoming submissions, do preliminary sanity checks and pass them
+// through cert checker.
+// Prepare for signing by parsing the input into an appropriate
+// log entry structure.
+class CertSubmissionHandler {
+ public:
+  // Does not take ownership of the cert_checker.
+  explicit CertSubmissionHandler(const cert_trans::CertChecker* cert_checker);
+
+  // These may change |chain|.
+  // TODO(pphaneuf): These could return StatusOr<ct::LogEntry>.
+  util::Status ProcessX509Submission(cert_trans::CertChain* chain,
+                                     ct::LogEntry* entry) const;
+  util::Status ProcessPreCertSubmission(cert_trans::PreCertChain* chain,
+                                        ct::LogEntry* entry) const;
+
+  // For clients, to reconstruct the bytestring under the signature
+  // from the observed chain. Does not check whether the entry
+  // has valid format (i.e., does not check length limits).
+  static bool X509ChainToEntry(const cert_trans::CertChain& chain,
+                               ct::LogEntry* entry);
+
+ private:
+  const cert_trans::CertChecker* const cert_checker_;
+
+  DISALLOW_COPY_AND_ASSIGN(CertSubmissionHandler);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_CERT_SUBMISSION_HANDLER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert_submission_handler_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert_submission_handler_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert_submission_handler_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert_submission_handler_test.cc	2017-01-15 10:56:31.039591151 +0100
@@ -0,0 +1,217 @@
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <openssl/err.h>
+#include <openssl/evp.h>
+#include <string>
+
+#include "log/cert_checker.h"
+#include "log/cert_submission_handler.h"
+#include "log/ct_extensions.h"
+#include "proto/ct.pb.h"
+#include "util/status_test_util.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+// Valid certificates.
+// Self-signed
+static const char kCaCert[] = "ca-cert.pem";
+// Issued by ca.pem
+static const char kLeafCert[] = "test-cert.pem";
+// Issued by ca.pem
+static const char kCaPreCert[] = "ca-pre-cert.pem";
+// Issued by ca-cert.pem
+static const char kPreCert[] = "test-embedded-pre-cert.pem";
+// Issued by ca-pre-cert.pem
+static const char kPreWithPreCaCert[] =
+    "test-embedded-with-preca-pre-cert.pem";
+// Issued by ca-cert.pem
+static const char kIntermediateCert[] = "intermediate-cert.pem";
+// Issued by intermediate-cert.pem
+static const char kChainLeafCert[] = "test-intermediate-cert.pem";
+
+namespace {
+
+using cert_trans::Cert;
+using cert_trans::CertChain;
+using cert_trans::CertChecker;
+using cert_trans::CertSubmissionHandler;
+using cert_trans::PreCertChain;
+using ct::LogEntry;
+using std::string;
+using util::testing::StatusIs;
+
+class CertSubmissionHandlerTest : public ::testing::Test {
+ protected:
+  string ca_;
+  string leaf_;
+  string ca_precert_;
+  string precert_;
+  string precert_with_preca_;
+  string intermediate_;
+  string chain_leaf_;
+  const string cert_dir_;
+  CertSubmissionHandler* handler_;
+  CertChecker* checker_;
+
+  CertSubmissionHandlerTest()
+      : cert_dir_(FLAGS_test_srcdir + "/test/testdata"), handler_(NULL) {
+  }
+
+  void SetUp() {
+    checker_ = new CertChecker();
+    checker_->LoadTrustedCertificates(cert_dir_ + "/" + kCaCert);
+    handler_ = new CertSubmissionHandler(checker_);
+    CHECK(util::ReadBinaryFile(cert_dir_ + "/" + kCaCert, &ca_))
+        << "Could not read test data from " << cert_dir_
+        << ". Wrong --test_srcdir?";
+    CHECK(util::ReadBinaryFile(cert_dir_ + "/" + kLeafCert, &leaf_));
+    CHECK(util::ReadBinaryFile(cert_dir_ + "/" + kCaPreCert, &ca_precert_));
+    CHECK(util::ReadBinaryFile(cert_dir_ + "/" + kPreCert, &precert_));
+    CHECK(util::ReadBinaryFile(cert_dir_ + "/" + kPreWithPreCaCert,
+                               &precert_with_preca_));
+    CHECK(util::ReadBinaryFile(cert_dir_ + "/" + kIntermediateCert,
+                               &intermediate_));
+    CHECK(
+        util::ReadBinaryFile(cert_dir_ + "/" + kChainLeafCert, &chain_leaf_));
+  }
+
+  ~CertSubmissionHandlerTest() {
+    delete checker_;
+    delete handler_;
+  }
+};
+
+TEST_F(CertSubmissionHandlerTest, SubmitCert) {
+  CertChain submission(leaf_);
+  EXPECT_TRUE(submission.IsLoaded());
+
+  LogEntry entry;
+  // Submit a leaf cert.
+  EXPECT_OK(handler_->ProcessX509Submission(&submission, &entry));
+  EXPECT_TRUE(entry.has_x509_entry());
+  EXPECT_FALSE(entry.has_precert_entry());
+  EXPECT_TRUE(entry.x509_entry().has_leaf_certificate());
+  // Chain should include the root.
+  EXPECT_EQ(1, entry.x509_entry().certificate_chain_size());
+}
+
+TEST_F(CertSubmissionHandlerTest, SubmitEmptyCert) {
+  CertChain submission("");
+  EXPECT_FALSE(submission.IsLoaded());
+
+  LogEntry entry;
+  EXPECT_THAT(handler_->ProcessX509Submission(&submission, &entry),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertSubmissionHandlerTest, SubmitInvalidCert) {
+  CertChain submission(
+      "-----BEGIN CERTIFICATE-----\n"
+      "invalid\n"
+      "-----END CERTIFICATE-----");
+  EXPECT_FALSE(submission.IsLoaded());
+
+  LogEntry entry;
+  EXPECT_THAT(handler_->ProcessX509Submission(&submission, &entry),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertSubmissionHandlerTest, SubmitChain) {
+  // Submit a chain.
+  CertChain submission(chain_leaf_ + intermediate_);
+  EXPECT_TRUE(submission.IsLoaded());
+
+  LogEntry entry;
+  EXPECT_OK(handler_->ProcessX509Submission(&submission, &entry));
+  EXPECT_TRUE(entry.x509_entry().has_leaf_certificate());
+  EXPECT_EQ(2, entry.x509_entry().certificate_chain_size());
+}
+
+TEST_F(CertSubmissionHandlerTest, SubmitPartialChain) {
+  CertChain submission(chain_leaf_);
+  EXPECT_TRUE(submission.IsLoaded());
+
+  LogEntry entry;
+  // Submit a leaf cert with a missing intermediate.
+  EXPECT_THAT(handler_->ProcessX509Submission(&submission, &entry),
+              StatusIs(util::error::FAILED_PRECONDITION));
+}
+
+TEST_F(CertSubmissionHandlerTest, SubmitInvalidChain) {
+  CertChain submission(leaf_ + leaf_);
+  EXPECT_TRUE(submission.IsLoaded());
+
+  LogEntry entry;
+  // An invalid chain with two certs in wrong order.
+  EXPECT_THAT(handler_->ProcessX509Submission(&submission, &entry),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertSubmissionHandlerTest, SubmitCertAsPreCert) {
+  PreCertChain submission(leaf_);
+  EXPECT_TRUE(submission.IsLoaded());
+
+  LogEntry entry;
+  // Various things are wrong here, so do not expect a specific error.
+  EXPECT_FALSE(handler_->ProcessPreCertSubmission(&submission, &entry).ok());
+}
+
+TEST_F(CertSubmissionHandlerTest, SubmitCertChainAsPreCert) {
+  PreCertChain submission(chain_leaf_ + intermediate_);
+  EXPECT_TRUE(submission.IsLoaded());
+
+  LogEntry entry;
+  EXPECT_FALSE(handler_->ProcessPreCertSubmission(&submission, &entry).ok());
+}
+
+TEST_F(CertSubmissionHandlerTest, SubmitPreCertChain) {
+  PreCertChain submission(precert_ + ca_);
+  EXPECT_TRUE(submission.IsLoaded());
+
+  LogEntry entry;
+  EXPECT_OK(handler_->ProcessPreCertSubmission(&submission, &entry));
+  EXPECT_TRUE(entry.has_precert_entry());
+  EXPECT_FALSE(entry.has_x509_entry());
+  EXPECT_TRUE(entry.precert_entry().has_pre_certificate());
+  EXPECT_TRUE(entry.precert_entry().pre_cert().has_issuer_key_hash());
+  EXPECT_TRUE(entry.precert_entry().pre_cert().has_tbs_certificate());
+
+  // CA cert
+  EXPECT_EQ(1, entry.precert_entry().precertificate_chain_size());
+}
+
+TEST_F(CertSubmissionHandlerTest, SubmitPreCertChainUsingPreCA) {
+  PreCertChain submission(precert_with_preca_ + ca_precert_);
+  EXPECT_TRUE(submission.IsLoaded());
+
+  LogEntry entry;
+  EXPECT_OK(handler_->ProcessPreCertSubmission(&submission, &entry));
+  EXPECT_TRUE(entry.has_precert_entry());
+  EXPECT_FALSE(entry.has_x509_entry());
+  EXPECT_TRUE(entry.precert_entry().has_pre_certificate());
+  EXPECT_TRUE(entry.precert_entry().pre_cert().has_issuer_key_hash());
+  EXPECT_TRUE(entry.precert_entry().pre_cert().has_tbs_certificate());
+
+  // Precert Signing Certificate + CA cert
+  EXPECT_EQ(2, entry.precert_entry().precertificate_chain_size());
+}
+
+TEST_F(CertSubmissionHandlerTest, SubmitInvalidPreCertChain) {
+  // Missing issuer.
+  PreCertChain submission(precert_with_preca_);
+  EXPECT_TRUE(submission.IsLoaded());
+
+  LogEntry entry;
+  EXPECT_FALSE(handler_->ProcessPreCertSubmission(&submission, &entry).ok());
+}
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  OpenSSL_add_all_algorithms();
+  ERR_load_crypto_strings();
+  cert_trans::LoadCtExtensions();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cert_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cert_test.cc	2017-01-15 10:56:31.039591151 +0100
@@ -0,0 +1,841 @@
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <openssl/err.h>
+#include <openssl/evp.h>
+#include <string>
+#include <vector>
+
+#include "log/cert.h"
+#include "log/ct_extensions.h"
+#include "merkletree/serial_hasher.h"
+#include "util/status_test_util.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+using cert_trans::Cert;
+using cert_trans::CertChain;
+using cert_trans::PreCertChain;
+using cert_trans::TbsCertificate;
+using std::string;
+using std::unique_ptr;
+using std::vector;
+using util::error::Code;
+using util::StatusOr;
+using util::testing::StatusIs;
+
+// TODO(ekasper): add test certs with intermediates.
+// Valid certificates.
+static const char kCaCert[] = "ca-cert.pem";
+static const char kGoogleCert[] = "google-cert.pem";
+// Issued by ca-cert.pem
+static const char kLeafCert[] = "test-cert.pem";
+// Issued by ca-cert.pem
+// Issued by intermediate-cert.pem
+static const char kLeafWithIntermediateCert[] = "test-intermediate-cert.pem";
+static const char kCaPreCert[] = "ca-pre-cert.pem";
+// Issued by ca-cert.pem
+static const char kPreCert[] = "test-embedded-pre-cert.pem";
+// CA with no basic constraints and an MD2 signature.
+static const char kLegacyCaCert[] = "test-no-bc-ca-cert.pem";
+
+// Leaf cert with CN redaction no DNS or extension (test case 5)
+static const char kV2WildcardRedactTest5[] = "redact_test5.pem";
+// Leaf cert with CN/DNS wildcard redaction mismatch (test case 6)
+static const char kV2WildcardRedactTest6[] = "redact_test6.pem";
+// Leaf cert with valid V2 wildcard redaction (test case 7)
+static const char kV2WildcardRedactTest7[] = "redact_test7.pem";
+// Leaf cert with valid V2 '*' wildcard redaction (test case 8)
+static const char kV2WildcardRedactTest8[] = "redact_test8.pem";
+// Leaf cert with invalid redaction label (test case 9)
+static const char kV2WildcardRedactTest9[] = "redact_test9.pem";
+// Leaf cert with invalid V2 '*' wildcard redaction (test case 10)
+static const char kV2WildcardRedactTest10[] = "redact_test10.pem";
+// Leaf cert with invalid redaction, too many ext values (test case 11)
+static const char kV2WildcardRedactTest11[] = "redact_test11.pem";
+// Leaf cert with invalid V2 redacted label extension (test case 12)
+static const char kV2WildcardRedactTest12[] = "redact_test12.pem";
+// Leaf cert with not enough entries in extension (test case 13)
+static const char kV2WildcardRedactTest13[] = "redact_test13.pem";
+// Leaf cert with valid extension + multiple DNS entries (test case 14)
+static const char kV2WildcardRedactTest14[] = "redact_test14.pem";
+// Leaf cert with too many labels in extension (test case 15)
+static const char kV2WildcardRedactTest15[] = "redact_test15.pem";
+// Leaf cert with wildcard redaction in both CN and DNS-ID no extension
+static const char kV2WildcardRedactTest22[] = "redact_test22.pem";
+// Leaf cert with extension that is not a sequence (invalid)
+static const char kV2WildcardRedactTest23[] = "redact_test23.pem";
+// Leaf cert with extension sequence containing non integer value (invalid)
+static const char kV2WildcardRedactTest24[] = "redact_test24.pem";
+
+// Leaf cert with non CA constraints
+static const char kV2ConstraintTest2[] = "constraint_test2.pem";
+// Leaf cert with CA but no name constraints
+static const char kV2ConstraintTest3[] = "constraint_test3.pem";
+// Leaf cert with constraint and no CT ext
+static const char kV2ConstraintTest4[] = "constraint_test4.pem";
+// Leaf cert with constraint and CT ext but no DNS in constraint
+static const char kV2ConstraintTest5[] = "constraint_test5.pem";
+// Leaf cert with CA constraint + valid CT extension
+static const char kV2ConstraintTest6[] = "constraint_test6.pem";
+// Leaf cert with CA constraint + valid CT extension with multiple DNS
+static const char kV2ConstraintTest7[] = "constraint_test7.pem";
+// Leaf cert with CA constraint + valid CT extension, no IP exclude
+static const char kV2ConstraintTest8[] = "constraint_test8.pem";
+// Leaf cert with CA constraint + valid CT extension, partial IP exclude
+static const char kV2ConstraintTest9[] = "constraint_test9.pem";
+
+static const char kInvalidCertString[] =
+    "-----BEGIN CERTIFICATE-----\ninvalid"
+    "\n-----END CERTIFICATE-----\n";
+
+// This certificate is the same as |kMatchingSigAlgsCertString| below,
+// but with the unsigned signatureAlgorithm parameter changed so as to
+// not match the one in the signed part of the certificate.
+static const char kMismatchingSigAlgsCertString[] =
+    "-----BEGIN CERTIFICATE-----\n"
+    "MIIFVjCCBD2gAwIBAgIQGERW2P+5Xt15QiwP1NRmtTANBgkqhkiG9w0BAQsFADCB\n"
+    "kDELMAkGA1UEBhMCR0IxGzAZBgNVBAgTEkdyZWF0ZXIgTWFuY2hlc3RlcjEQMA4G\n"
+    "A1UEBxMHU2FsZm9yZDEaMBgGA1UEChMRQ09NT0RPIENBIExpbWl0ZWQxNjA0BgNV\n"
+    "BAMTLUNPTU9ETyBSU0EgRG9tYWluIFZhbGlkYXRpb24gU2VjdXJlIFNlcnZlciBD\n"
+    "QTAeFw0xNDA1MjEwMDAwMDBaFw0xNTA1MjkyMzU5NTlaMFQxITAfBgNVBAsTGERv\n"
+    "bWFpbiBDb250cm9sIFZhbGlkYXRlZDEUMBIGA1UECxMLUG9zaXRpdmVTU0wxGTAX\n"
+    "BgNVBAMTEHZpZGVvbWFnaWNhbC5jb20wggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAw\n"
+    "ggEKAoIBAQDOMDIDA7wjsHNDp+cYa9On4oodRjnAxvgJQ852ahkZul+e816WzUTT\n"
+    "Bs8m0LFiXjRZtsl6AHOTVbSSK3iFrke6pVdwatVP95NsR4qQaU6ITfkD9hT01vOm\n"
+    "FrPv77X7RF6C0Pb8tH9ro8prpqJdTlMnjnPTQQy/ljrUaWyIQm0G1ujCApPQhQ7h\n"
+    "XRZYPAk0B5jSalA1q0tjjWKohlQaQMqXpHtbofvL9hUlWw6shJdd08tUH5o0UcW3\n"
+    "so0zHvVfwi4Gw6DiMc/a8aSmNJPO09Rf+xOYGB+wyMezH900OnuhMg6EZgMiRwfJ\n"
+    "O6+c6QyhLBt2Vq2Wtl8HvgwBSiCelq6FAgMBAAGjggHkMIIB4DAfBgNVHSMEGDAW\n"
+    "gBSQr2o6lFoL2JDqElZz30O0Oija5zAdBgNVHQ4EFgQU95g8ikB6kbC9vYcLhM38\n"
+    "6Qm3MyUwDgYDVR0PAQH/BAQDAgWgMAwGA1UdEwEB/wQCMAAwHQYDVR0lBBYwFAYI\n"
+    "KwYBBQUHAwEGCCsGAQUFBwMCMFAGA1UdIARJMEcwOwYMKwYBBAGyMQECAQMEMCsw\n"
+    "KQYIKwYBBQUHAgEWHWh0dHBzOi8vc2VjdXJlLmNvbW9kby5uZXQvQ1BTMAgGBmeB\n"
+    "DAECATBUBgNVHR8ETTBLMEmgR6BFhkNodHRwOi8vY3JsLmNvbW9kb2NhLmNvbS9D\n"
+    "T01PRE9SU0FEb21haW5WYWxpZGF0aW9uU2VjdXJlU2VydmVyQ0EuY3JsMIGFBggr\n"
+    "BgEFBQcBAQR5MHcwTwYIKwYBBQUHMAKGQ2h0dHA6Ly9jcnQuY29tb2RvY2EuY29t\n"
+    "L0NPTU9ET1JTQURvbWFpblZhbGlkYXRpb25TZWN1cmVTZXJ2ZXJDQS5jcnQwJAYI\n"
+    "KwYBBQUHMAGGGGh0dHA6Ly9vY3NwLmNvbW9kb2NhLmNvbTAxBgNVHREEKjAoghB2\n"
+    "aWRlb21hZ2ljYWwuY29tghR3d3cudmlkZW9tYWdpY2FsLmNvbTAOBgkqhkiG9w0B\n"
+    "AQsfZAADggEBABoB/+9vd+ns+5tCWuUNls5iYI+aq/J/wuoSzQ7F1L4YU4d2f7sq\n"
+    "iCC0L9IElGgjKeSVNI/YSPykn7W+KaqYYIoYmUDsDWRXn4F9lGew7HCoRQKKg3Xa\n"
+    "q5Cn8Xk4NYLoin+TJ1B3QblKEMJ12PKbjctPjevwYVrhNouJ+CAo5LpCYr9UmLN3\n"
+    "zL1pARWRBAmqB07LbiLbo5cXOY7XkbI7FlJ6x3fbLWc180f+h8i+QysQ6gWTFghn\n"
+    "SVpUjdu0SbcJpWexSgTLltleMmkvnw4jj/kdMnD8TKsA5qju3dsPYhRay76ojFEI\n"
+    "lc2MPExv3cqIR+AzMZuaY8I2TNDoCeKc5II=\n"
+    "-----END CERTIFICATE-----\n";
+
+// This certificate is the same as |kMismatchingSigAlgsCertString|, but
+// with an illegal value for the unsigned signatureAlgorithm parameter.
+static const char kIllegalSigAlgParameterCertString[] =
+    "-----BEGIN CERTIFICATE-----\n"
+    "MIIFWjCCBD2gAwIBAgIQGERW2P+5Xt15QiwP1NRmtTANBgkqhkiG9w0BAQsFADCB\n"
+    "kDELMAkGA1UEBhMCR0IxGzAZBgNVBAgTEkdyZWF0ZXIgTWFuY2hlc3RlcjEQMA4G\n"
+    "A1UEBxMHU2FsZm9yZDEaMBgGA1UEChMRQ09NT0RPIENBIExpbWl0ZWQxNjA0BgNV\n"
+    "BAMTLUNPTU9ETyBSU0EgRG9tYWluIFZhbGlkYXRpb24gU2VjdXJlIFNlcnZlciBD\n"
+    "QTAeFw0xNDA1MjEwMDAwMDBaFw0xNTA1MjkyMzU5NTlaMFQxITAfBgNVBAsTGERv\n"
+    "bWFpbiBDb250cm9sIFZhbGlkYXRlZDEUMBIGA1UECxMLUG9zaXRpdmVTU0wxGTAX\n"
+    "BgNVBAMTEHZpZGVvbWFnaWNhbC5jb20wggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAw\n"
+    "ggEKAoIBAQDOMDIDA7wjsHNDp+cYa9On4oodRjnAxvgJQ852ahkZul+e816WzUTT\n"
+    "Bs8m0LFiXjRZtsl6AHOTVbSSK3iFrke6pVdwatVP95NsR4qQaU6ITfkD9hT01vOm\n"
+    "FrPv77X7RF6C0Pb8tH9ro8prpqJdTlMnjnPTQQy/ljrUaWyIQm0G1ujCApPQhQ7h\n"
+    "XRZYPAk0B5jSalA1q0tjjWKohlQaQMqXpHtbofvL9hUlWw6shJdd08tUH5o0UcW3\n"
+    "so0zHvVfwi4Gw6DiMc/a8aSmNJPO09Rf+xOYGB+wyMezH900OnuhMg6EZgMiRwfJ\n"
+    "O6+c6QyhLBt2Vq2Wtl8HvgwBSiCelq6FAgMBAAGjggHkMIIB4DAfBgNVHSMEGDAW\n"
+    "gBSQr2o6lFoL2JDqElZz30O0Oija5zAdBgNVHQ4EFgQU95g8ikB6kbC9vYcLhM38\n"
+    "6Qm3MyUwDgYDVR0PAQH/BAQDAgWgMAwGA1UdEwEB/wQCMAAwHQYDVR0lBBYwFAYI\n"
+    "KwYBBQUHAwEGCCsGAQUFBwMCMFAGA1UdIARJMEcwOwYMKwYBBAGyMQECAQMEMCsw\n"
+    "KQYIKwYBBQUHAgEWHWh0dHBzOi8vc2VjdXJlLmNvbW9kby5uZXQvQ1BTMAgGBmeB\n"
+    "DAECATBUBgNVHR8ETTBLMEmgR6BFhkNodHRwOi8vY3JsLmNvbW9kb2NhLmNvbS9D\n"
+    "T01PRE9SU0FEb21haW5WYWxpZGF0aW9uU2VjdXJlU2VydmVyQ0EuY3JsMIGFBggr\n"
+    "BgEFBQcBAQR5MHcwTwYIKwYBBQUHMAKGQ2h0dHA6Ly9jcnQuY29tb2RvY2EuY29t\n"
+    "L0NPTU9ET1JTQURvbWFpblZhbGlkYXRpb25TZWN1cmVTZXJ2ZXJDQS5jcnQwJAYI\n"
+    "KwYBBQUHMAGGGGh0dHA6Ly9vY3NwLmNvbW9kb2NhLmNvbTAxBgNVHREEKjAoghB2\n"
+    "aWRlb21hZ2ljYWwuY29tghR3d3cudmlkZW9tYWdpY2FsLmNvbTASBgkqhkiG9w0B\n"
+    "AQsfgeCB/FAAA4IBAQAaAf/vb3fp7PubQlrlDZbOYmCPmqvyf8LqEs0OxdS+GFOH\n"
+    "dn+7KoggtC/SBJRoIynklTSP2Ej8pJ+1vimqmGCKGJlA7A1kV5+BfZRnsOxwqEUC\n"
+    "ioN12quQp/F5ODWC6Ip/kydQd0G5ShDCddjym43LT43r8GFa4TaLifggKOS6QmK/\n"
+    "VJizd8y9aQEVkQQJqgdOy24i26OXFzmO15GyOxZSesd32y1nNfNH/ofIvkMrEOoF\n"
+    "kxYIZ0laVI3btEm3CaVnsUoEy5bZXjJpL58OI4/5HTJw/EyrAOao7t3bD2IUWsu+\n"
+    "qIxRCJXNjDxMb93KiEfgMzGbmmPCNkzQ6AninOSC\n"
+    "-----END CERTIFICATE-----\n";
+
+static const char kMatchingSigAlgsCertString[] =
+    "-----BEGIN CERTIFICATE-----\n"
+    "MIIFVTCCBD2gAwIBAgIQGERW2P+5Xt15QiwP1NRmtTANBgkqhkiG9w0BAQsFADCB\n"
+    "kDELMAkGA1UEBhMCR0IxGzAZBgNVBAgTEkdyZWF0ZXIgTWFuY2hlc3RlcjEQMA4G\n"
+    "A1UEBxMHU2FsZm9yZDEaMBgGA1UEChMRQ09NT0RPIENBIExpbWl0ZWQxNjA0BgNV\n"
+    "BAMTLUNPTU9ETyBSU0EgRG9tYWluIFZhbGlkYXRpb24gU2VjdXJlIFNlcnZlciBD\n"
+    "QTAeFw0xNDA1MjEwMDAwMDBaFw0xNTA1MjkyMzU5NTlaMFQxITAfBgNVBAsTGERv\n"
+    "bWFpbiBDb250cm9sIFZhbGlkYXRlZDEUMBIGA1UECxMLUG9zaXRpdmVTU0wxGTAX\n"
+    "BgNVBAMTEHZpZGVvbWFnaWNhbC5jb20wggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAw\n"
+    "ggEKAoIBAQDOMDIDA7wjsHNDp+cYa9On4oodRjnAxvgJQ852ahkZul+e816WzUTT\n"
+    "Bs8m0LFiXjRZtsl6AHOTVbSSK3iFrke6pVdwatVP95NsR4qQaU6ITfkD9hT01vOm\n"
+    "FrPv77X7RF6C0Pb8tH9ro8prpqJdTlMnjnPTQQy/ljrUaWyIQm0G1ujCApPQhQ7h\n"
+    "XRZYPAk0B5jSalA1q0tjjWKohlQaQMqXpHtbofvL9hUlWw6shJdd08tUH5o0UcW3\n"
+    "so0zHvVfwi4Gw6DiMc/a8aSmNJPO09Rf+xOYGB+wyMezH900OnuhMg6EZgMiRwfJ\n"
+    "O6+c6QyhLBt2Vq2Wtl8HvgwBSiCelq6FAgMBAAGjggHkMIIB4DAfBgNVHSMEGDAW\n"
+    "gBSQr2o6lFoL2JDqElZz30O0Oija5zAdBgNVHQ4EFgQU95g8ikB6kbC9vYcLhM38\n"
+    "6Qm3MyUwDgYDVR0PAQH/BAQDAgWgMAwGA1UdEwEB/wQCMAAwHQYDVR0lBBYwFAYI\n"
+    "KwYBBQUHAwEGCCsGAQUFBwMCMFAGA1UdIARJMEcwOwYMKwYBBAGyMQECAQMEMCsw\n"
+    "KQYIKwYBBQUHAgEWHWh0dHBzOi8vc2VjdXJlLmNvbW9kby5uZXQvQ1BTMAgGBmeB\n"
+    "DAECATBUBgNVHR8ETTBLMEmgR6BFhkNodHRwOi8vY3JsLmNvbW9kb2NhLmNvbS9D\n"
+    "T01PRE9SU0FEb21haW5WYWxpZGF0aW9uU2VjdXJlU2VydmVyQ0EuY3JsMIGFBggr\n"
+    "BgEFBQcBAQR5MHcwTwYIKwYBBQUHMAKGQ2h0dHA6Ly9jcnQuY29tb2RvY2EuY29t\n"
+    "L0NPTU9ET1JTQURvbWFpblZhbGlkYXRpb25TZWN1cmVTZXJ2ZXJDQS5jcnQwJAYI\n"
+    "KwYBBQUHMAGGGGh0dHA6Ly9vY3NwLmNvbW9kb2NhLmNvbTAxBgNVHREEKjAoghB2\n"
+    "aWRlb21hZ2ljYWwuY29tghR3d3cudmlkZW9tYWdpY2FsLmNvbTANBgkqhkiG9w0B\n"
+    "AQsFAAOCAQEAGgH/72936ez7m0Ja5Q2WzmJgj5qr8n/C6hLNDsXUvhhTh3Z/uyqI\n"
+    "ILQv0gSUaCMp5JU0j9hI/KSftb4pqphgihiZQOwNZFefgX2UZ7DscKhFAoqDddqr\n"
+    "kKfxeTg1guiKf5MnUHdBuUoQwnXY8puNy0+N6/BhWuE2i4n4ICjkukJiv1SYs3fM\n"
+    "vWkBFZEECaoHTstuItujlxc5jteRsjsWUnrHd9stZzXzR/6HyL5DKxDqBZMWCGdJ\n"
+    "WlSN27RJtwmlZ7FKBMuW2V4yaS+fDiOP+R0ycPxMqwDmqO7d2w9iFFrLvqiMUQiV\n"
+    "zYw8TG/dyohH4DMxm5pjwjZM0OgJ4pzkgg==\n"
+    "-----END CERTIFICATE-----\n";
+
+static const char kMismatchingSigAlgsCertIssuerString[] =
+    "-----BEGIN CERTIFICATE-----\n"
+    "MIIGCDCCA/CgAwIBAgIQKy5u6tl1NmwUim7bo3yMBzANBgkqhkiG9w0BAQwFADCB\n"
+    "hTELMAkGA1UEBhMCR0IxGzAZBgNVBAgTEkdyZWF0ZXIgTWFuY2hlc3RlcjEQMA4G\n"
+    "A1UEBxMHU2FsZm9yZDEaMBgGA1UEChMRQ09NT0RPIENBIExpbWl0ZWQxKzApBgNV\n"
+    "BAMTIkNPTU9ETyBSU0EgQ2VydGlmaWNhdGlvbiBBdXRob3JpdHkwHhcNMTQwMjEy\n"
+    "MDAwMDAwWhcNMjkwMjExMjM1OTU5WjCBkDELMAkGA1UEBhMCR0IxGzAZBgNVBAgT\n"
+    "EkdyZWF0ZXIgTWFuY2hlc3RlcjEQMA4GA1UEBxMHU2FsZm9yZDEaMBgGA1UEChMR\n"
+    "Q09NT0RPIENBIExpbWl0ZWQxNjA0BgNVBAMTLUNPTU9ETyBSU0EgRG9tYWluIFZh\n"
+    "bGlkYXRpb24gU2VjdXJlIFNlcnZlciBDQTCCASIwDQYJKoZIhvcNAQEBBQADggEP\n"
+    "ADCCAQoCggEBAI7CAhnhoFmk6zg1jSz9AdDTScBkxwtiBUUWOqigwAwCfx3M28Sh\n"
+    "bXcDow+G+eMGnD4LgYqbSRutA776S9uMIO3Vzl5ljj4Nr0zCsLdFXlIvNN5IJGS0\n"
+    "Qa4Al/e+Z96e0HqnU4A7fK31llVvl0cKfIWLIpeNs4TgllfQcBhglo/uLQeTnaG6\n"
+    "ytHNe+nEKpooIZFNb5JPJaXyejXdJtxGpdCsWTWM/06RQ1A/WZMebFEh7lgUq/51\n"
+    "UHg+TLAchhP6a5i84DuUHoVS3AOTJBhuyydRReZw3iVDpA3hSqXttn7IzW3uLh0n\n"
+    "c13cRTCAquOyQQuvvUSH2rnlG51/ruWFgqUCAwEAAaOCAWUwggFhMB8GA1UdIwQY\n"
+    "MBaAFLuvfgI9+qbxPISOre44mOzZMjLUMB0GA1UdDgQWBBSQr2o6lFoL2JDqElZz\n"
+    "30O0Oija5zAOBgNVHQ8BAf8EBAMCAYYwEgYDVR0TAQH/BAgwBgEB/wIBADAdBgNV\n"
+    "HSUEFjAUBggrBgEFBQcDAQYIKwYBBQUHAwIwGwYDVR0gBBQwEjAGBgRVHSAAMAgG\n"
+    "BmeBDAECATBMBgNVHR8ERTBDMEGgP6A9hjtodHRwOi8vY3JsLmNvbW9kb2NhLmNv\n"
+    "bS9DT01PRE9SU0FDZXJ0aWZpY2F0aW9uQXV0aG9yaXR5LmNybDBxBggrBgEFBQcB\n"
+    "AQRlMGMwOwYIKwYBBQUHMAKGL2h0dHA6Ly9jcnQuY29tb2RvY2EuY29tL0NPTU9E\n"
+    "T1JTQUFkZFRydXN0Q0EuY3J0MCQGCCsGAQUFBzABhhhodHRwOi8vb2NzcC5jb21v\n"
+    "ZG9jYS5jb20wDQYJKoZIhvcNAQEMBQADggIBAE4rdk+SHGI2ibp3wScF9BzWRJ2p\n"
+    "mj6q1WZmAT7qSeaiNbz69t2Vjpk1mA42GHWx3d1Qcnyu3HeIzg/3kCDKo2cuH1Z/\n"
+    "e+FE6kKVxF0NAVBGFfKBiVlsit2M8RKhjTpCipj4SzR7JzsItG8kO3KdY3RYPBps\n"
+    "P0/HEZrIqPW1N+8QRcZs2eBelSaz662jue5/DJpmNXMyYE7l3YphLG5SEXdoltMY\n"
+    "dVEVABt0iN3hxzgEQyjpFv3ZBdRdRydg1vs4O2xyopT4Qhrf7W8GjEXCBgCq5Ojc\n"
+    "2bXhc3js9iPc0d1sjhqPpepUfJa3w/5Vjo1JXvxku88+vZbrac2/4EjxYoIQ5QxG\n"
+    "V/Iz2tDIY+3GH5QFlkoakdH368+PUq4NCNk+qKBR6cGHdNXJ93SrLlP7u3r7l+L4\n"
+    "HyaPs9Kg4DdbKDsx5Q5XLVq4rXmsXiBmGqW5prU5wfWYQ//u+aen/e7KJD2AFsQX\n"
+    "j4rBYKEMrltDR5FL1ZoXX/nUh8HCjLfn4g8wGTeGrODcQgPmlKidrv0PJFGUzpII\n"
+    "0fxQ8ANAe4hZ7Q7drNJ3gjTcBpUC2JD5Leo31Rpg0Gcg19hCC0Wvgmje3WYkN5Ap\n"
+    "lBlGGSW4gNfL1IYoakRwJiNiqZ+Gb7+6kHDSVneFeO/qJakXzlByjAA6quPbYzSf\n"
+    "+AZxAeKCINT+b72x\n"
+    "-----END CERTIFICATE-----\n";
+
+
+namespace {
+
+unique_ptr<Cert> ReadCertFromFile(const string& filename) {
+  string content;
+  CHECK(util::ReadTextFile(filename, &content))
+      << "Could not read test data from " << filename
+      << ". Wrong --test_srcdir?";
+  unique_ptr<Cert> cert(Cert::FromPemString(content));
+  CHECK(cert.get());
+  return cert;
+}
+
+class CertTest : public ::testing::Test {
+ protected:
+  CertTest()
+      : cert_dir_(FLAGS_test_srcdir + "/test/testdata"),
+        cert_dir_v2_(cert_dir_ + "/v2/"),
+        leaf_cert_(ReadCertFromFile(cert_dir_ + "/" + kLeafCert)),
+        ca_cert_(ReadCertFromFile(cert_dir_ + "/" + kCaCert)),
+        ca_precert_cert_(ReadCertFromFile(cert_dir_ + "/" + kCaPreCert)),
+        precert_cert_(ReadCertFromFile(cert_dir_ + "/" + kPreCert)),
+        google_cert_(ReadCertFromFile(cert_dir_ + "/" + kGoogleCert)),
+        legacy_ca_cert_(ReadCertFromFile(cert_dir_ + "/" + kLegacyCaCert)),
+        leaf_with_intermediate_cert_(
+            ReadCertFromFile(cert_dir_ + "/" + kLeafWithIntermediateCert)),
+        v2_wildcard_test5_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2WildcardRedactTest5)),
+        v2_wildcard_test6_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2WildcardRedactTest6)),
+        v2_wildcard_test7_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2WildcardRedactTest7)),
+        v2_wildcard_test8_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2WildcardRedactTest8)),
+        v2_wildcard_test9_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2WildcardRedactTest9)),
+        v2_wildcard_test10_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2WildcardRedactTest10)),
+        v2_wildcard_test11_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2WildcardRedactTest11)),
+        v2_wildcard_test12_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2WildcardRedactTest12)),
+        v2_wildcard_test13_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2WildcardRedactTest13)),
+        v2_wildcard_test14_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2WildcardRedactTest14)),
+        v2_wildcard_test15_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2WildcardRedactTest15)),
+        v2_wildcard_test22_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2WildcardRedactTest22)),
+        v2_wildcard_test23_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2WildcardRedactTest23)),
+        v2_wildcard_test24_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2WildcardRedactTest24)),
+        v2_constraint_test2_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2ConstraintTest2)),
+        v2_constraint_test3_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2ConstraintTest3)),
+        v2_constraint_test4_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2ConstraintTest4)),
+        v2_constraint_test5_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2ConstraintTest5)),
+        v2_constraint_test6_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2ConstraintTest6)),
+        v2_constraint_test7_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2ConstraintTest7)),
+        v2_constraint_test8_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2ConstraintTest8)),
+        v2_constraint_test9_cert_(
+            ReadCertFromFile(cert_dir_v2_ + kV2ConstraintTest9)) {
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kLeafCert, &leaf_pem_));
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kCaCert, &ca_pem_));
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kPreCert, &precert_pem_));
+  }
+
+  const string cert_dir_;
+  const string cert_dir_v2_;
+  const unique_ptr<Cert> leaf_cert_;
+  const unique_ptr<Cert> ca_cert_;
+  const unique_ptr<Cert> ca_precert_cert_;
+  const unique_ptr<Cert> precert_cert_;
+  const unique_ptr<Cert> google_cert_;
+  const unique_ptr<Cert> legacy_ca_cert_;
+  const unique_ptr<Cert> leaf_with_intermediate_cert_;
+
+  const unique_ptr<Cert> v2_wildcard_test5_cert_;
+  const unique_ptr<Cert> v2_wildcard_test6_cert_;
+  const unique_ptr<Cert> v2_wildcard_test7_cert_;
+  const unique_ptr<Cert> v2_wildcard_test8_cert_;
+  const unique_ptr<Cert> v2_wildcard_test9_cert_;
+  const unique_ptr<Cert> v2_wildcard_test10_cert_;
+  const unique_ptr<Cert> v2_wildcard_test11_cert_;
+  const unique_ptr<Cert> v2_wildcard_test12_cert_;
+  const unique_ptr<Cert> v2_wildcard_test13_cert_;
+  const unique_ptr<Cert> v2_wildcard_test14_cert_;
+  const unique_ptr<Cert> v2_wildcard_test15_cert_;
+  const unique_ptr<Cert> v2_wildcard_test22_cert_;
+  const unique_ptr<Cert> v2_wildcard_test23_cert_;
+  const unique_ptr<Cert> v2_wildcard_test24_cert_;
+
+  const unique_ptr<Cert> v2_constraint_test2_cert_;
+  const unique_ptr<Cert> v2_constraint_test3_cert_;
+  const unique_ptr<Cert> v2_constraint_test4_cert_;
+  const unique_ptr<Cert> v2_constraint_test5_cert_;
+  const unique_ptr<Cert> v2_constraint_test6_cert_;
+  const unique_ptr<Cert> v2_constraint_test7_cert_;
+  const unique_ptr<Cert> v2_constraint_test8_cert_;
+  const unique_ptr<Cert> v2_constraint_test9_cert_;
+
+  string leaf_pem_;
+  string ca_pem_;
+  string precert_pem_;
+};
+
+class TbsCertificateTest : public CertTest {};
+class CertChainTest : public CertTest {};
+
+TEST_F(CertTest, LoadInvalid) {
+  // Bogus certs.
+  const unique_ptr<Cert> invalid(Cert::FromPemString(""));
+  EXPECT_FALSE(invalid.get());
+  const unique_ptr<Cert> invalid2(Cert::FromPemString(kInvalidCertString));
+  EXPECT_FALSE(invalid2.get());
+}
+
+TEST_F(CertTest, LoadValidFromDer) {
+  string der;
+  ASSERT_OK(leaf_cert_->DerEncoding(&der));
+  const unique_ptr<Cert> second(Cert::FromDerString(der));
+  EXPECT_TRUE(second.get());
+}
+
+TEST_F(CertTest, LoadInvalidFromDer) {
+  // Make it look almost good for extra fun.
+  string der;
+  ASSERT_OK(leaf_cert_->DerEncoding(&der));
+  const unique_ptr<Cert> second(Cert::FromDerString(der.substr(2)));
+  EXPECT_FALSE(second.get());
+}
+
+TEST_F(CertTest, PrintVersion) {
+  EXPECT_EQ("3", ca_cert_->PrintVersion());
+  EXPECT_EQ("3", leaf_cert_->PrintVersion());
+  EXPECT_EQ("3", google_cert_->PrintVersion());
+}
+
+TEST_F(CertTest, PrintSerialNumber) {
+  EXPECT_EQ("0", ca_cert_->PrintSerialNumber());
+  EXPECT_EQ("01", ca_precert_cert_->PrintSerialNumber());
+  EXPECT_EQ("06", leaf_cert_->PrintSerialNumber());
+  EXPECT_EQ("605381F50001000088BD", google_cert_->PrintSerialNumber());
+}
+
+TEST_F(CertTest, PrintSubjectName) {
+  EXPECT_EQ("C=GB, O=Certificate Transparency, ST=Wales, L=Erw Wen",
+            leaf_cert_->PrintSubjectName());
+}
+
+TEST_F(CertTest, PrintIssuerName) {
+  EXPECT_EQ("C=GB, O=Certificate Transparency CA, ST=Wales, L=Erw Wen",
+            leaf_cert_->PrintIssuerName());
+}
+
+TEST_F(CertTest, PrintNotBefore) {
+  EXPECT_EQ("Jun  1 00:00:00 2012 GMT", leaf_cert_->PrintNotBefore());
+}
+
+TEST_F(CertTest, PrintNotAfter) {
+  EXPECT_EQ("Jun  1 00:00:00 2022 GMT", leaf_cert_->PrintNotAfter());
+}
+
+TEST_F(CertTest, PrintSignatureAlgorithm) {
+  EXPECT_EQ("sha1WithRSAEncryption", leaf_cert_->PrintSignatureAlgorithm());
+}
+
+TEST_F(CertTest, TestUnsupportedAlgorithm) {
+  ASSERT_EQ("md2WithRSAEncryption",
+            legacy_ca_cert_->PrintSignatureAlgorithm());
+// MD2 is disabled by default on modern OpenSSL and you should be
+// surprised to see anything else. Make the test fail if this is not
+// the case to notify the user that their setup is insecure.
+#ifdef OPENSSL_NO_MD2
+  EXPECT_THAT(legacy_ca_cert_->IsSignedBy(*legacy_ca_cert_).status(),
+              StatusIs(Code::UNIMPLEMENTED));
+#else
+  LOG(WARNING) << "Skipping test: MD2 is enabled! You should configure "
+               << "OpenSSL with -DOPENSSL_NO_MD2 to be safe!";
+#endif
+}
+
+TEST_F(CertTest, Identical) {
+  EXPECT_TRUE(leaf_cert_->IsIdenticalTo(*leaf_cert_));
+  EXPECT_FALSE(leaf_cert_->IsIdenticalTo(*ca_cert_));
+  EXPECT_FALSE(ca_cert_->IsIdenticalTo(*leaf_cert_));
+}
+
+TEST_F(CertTest, Extensions) {
+  // Some facts we know are true about those test certs.
+  EXPECT_TRUE(
+      leaf_cert_->HasExtension(NID_authority_key_identifier).ValueOrDie());
+  EXPECT_FALSE(leaf_cert_->HasCriticalExtension(NID_authority_key_identifier)
+                   .ValueOrDie());
+  EXPECT_TRUE(precert_cert_->HasCriticalExtension(cert_trans::NID_ctPoison)
+                  .ValueOrDie());
+
+  EXPECT_FALSE(leaf_cert_->HasBasicConstraintCATrue().ValueOrDie());
+  EXPECT_TRUE(ca_cert_->HasBasicConstraintCATrue().ValueOrDie());
+  EXPECT_TRUE(
+      ca_precert_cert_
+          ->HasExtendedKeyUsage(cert_trans::NID_ctPrecertificateSigning)
+          .ValueOrDie());
+}
+
+TEST_F(CertTest, Issuers) {
+  EXPECT_TRUE(leaf_cert_->IsIssuedBy(*ca_cert_).ValueOrDie());
+  EXPECT_TRUE(leaf_cert_->IsSignedBy(*ca_cert_).ValueOrDie());
+
+  EXPECT_FALSE(ca_cert_->IsIssuedBy(*leaf_cert_).ValueOrDie());
+  EXPECT_FALSE(ca_cert_->IsSignedBy(*leaf_cert_).ValueOrDie());
+
+  EXPECT_FALSE(leaf_cert_->IsSelfSigned().ValueOrDie());
+  EXPECT_TRUE(ca_cert_->IsSelfSigned().ValueOrDie());
+}
+
+TEST_F(CertTest, DerEncodedNames) {
+  ASSERT_TRUE(leaf_cert_->IsIssuedBy(*ca_cert_).ValueOrDie());
+
+  string leaf_subject, leaf_issuer, ca_subject, ca_issuer;
+  EXPECT_OK(leaf_cert_->DerEncodedSubjectName(&leaf_subject));
+  EXPECT_FALSE(leaf_subject.empty());
+
+  EXPECT_OK(leaf_cert_->DerEncodedIssuerName(&leaf_issuer));
+  EXPECT_FALSE(leaf_issuer.empty());
+
+  EXPECT_OK(ca_cert_->DerEncodedSubjectName(&ca_subject));
+  EXPECT_FALSE(ca_subject.empty());
+
+  EXPECT_OK(ca_cert_->DerEncodedIssuerName(&ca_issuer));
+  EXPECT_FALSE(ca_issuer.empty());
+
+  EXPECT_EQ(leaf_issuer, ca_subject);
+  EXPECT_EQ(ca_subject, ca_issuer);
+  EXPECT_NE(leaf_subject, leaf_issuer);
+}
+
+TEST_F(CertTest, SignatureAlgorithmMatches) {
+  const unique_ptr<Cert> matching_algs(
+      Cert::FromPemString(kMatchingSigAlgsCertString));
+  const unique_ptr<Cert> issuer(
+      Cert::FromPemString(kMismatchingSigAlgsCertIssuerString));
+  ASSERT_TRUE(matching_algs.get());
+  ASSERT_TRUE(issuer.get());
+  EXPECT_TRUE(matching_algs->IsSignedBy(*issuer).ValueOrDie());
+
+  const unique_ptr<Cert> mismatched_algs(
+      Cert::FromPemString(kMismatchingSigAlgsCertString));
+  ASSERT_TRUE(mismatched_algs.get());
+  EXPECT_FALSE(mismatched_algs->IsSignedBy(*issuer).ValueOrDie());
+}
+
+TEST_F(CertTest, IllegalSignatureAlgorithmParameter) {
+  const unique_ptr<Cert> cert(
+      Cert::FromPemString(kIllegalSigAlgParameterCertString));
+#if defined(OPENSSL_IS_BORINGSSL)
+  EXPECT_FALSE(cert.get());
+#else
+  EXPECT_TRUE(cert.get());
+#endif
+}
+
+TEST_F(CertTest, TestSubjectAltNames) {
+  vector<string> sans;
+  EXPECT_OK(google_cert_->SubjectAltNames(&sans));
+  EXPECT_EQ(44U, sans.size());
+  EXPECT_EQ("*.google.com", sans[0]);
+  EXPECT_EQ("*.android.com", sans[1]);
+  EXPECT_EQ("youtubeeducation.com", sans[43]);
+}
+
+TEST_F(CertTest, SPKI) {
+  const StatusOr<string> spki(leaf_cert_->SPKI());
+  EXPECT_OK(spki.status());
+  EXPECT_EQ(162U, spki.ValueOrDie().size());
+  EXPECT_EQ("Ojz4hdfbFTowDio/KDGC4/pN9dy/EBfIAsnO2yDbKiE=",
+            util::ToBase64(Sha256Hasher::Sha256Digest(spki.ValueOrDie())));
+}
+
+TEST_F(CertTest, SPKISha256Digest) {
+  string digest;
+
+  EXPECT_OK(leaf_cert_->SPKISha256Digest(&digest));
+  EXPECT_EQ("Ojz4hdfbFTowDio/KDGC4/pN9dy/EBfIAsnO2yDbKiE=",
+            util::ToBase64(digest));
+
+  EXPECT_OK(google_cert_->SPKISha256Digest(&digest));
+  EXPECT_EQ("VCXa3FxokfQkIcY2SygQMz4BuQHcRANCXdqRCLkoflg=",
+            util::ToBase64(digest));
+}
+
+TEST_F(CertTest, TestIsRedactedHost) {
+  EXPECT_FALSE(cert_trans::IsRedactedHost(""));
+  EXPECT_FALSE(cert_trans::IsRedactedHost("example.com"));
+
+  EXPECT_TRUE(cert_trans::IsRedactedHost("?.example.com"));
+  EXPECT_TRUE(cert_trans::IsRedactedHost("?.?.example.com"));
+  EXPECT_TRUE(cert_trans::IsRedactedHost("top.?.example.com"));
+}
+
+TEST_F(CertTest, TestIsValidRedactedHost) {
+  EXPECT_TRUE(cert_trans::IsValidRedactedHost("?.example.com"));
+  EXPECT_TRUE(cert_trans::IsValidRedactedHost("?.?.example.com"));
+  EXPECT_TRUE(cert_trans::IsValidRedactedHost("*.?.example.com"));
+  EXPECT_TRUE(cert_trans::IsValidRedactedHost("*.?.?.example.com"));
+
+  EXPECT_FALSE(cert_trans::IsValidRedactedHost("top.?.example.com"));
+  EXPECT_FALSE(cert_trans::IsValidRedactedHost("top.secret.example.?"));
+  EXPECT_FALSE(cert_trans::IsValidRedactedHost("top.secret.?.com"));
+  EXPECT_FALSE(cert_trans::IsValidRedactedHost("top.*.secret.?.com"));
+  EXPECT_FALSE(cert_trans::IsValidRedactedHost("?.*.example.com"));
+  EXPECT_FALSE(cert_trans::IsValidRedactedHost("*.secret.?.com"));
+}
+
+TEST_F(CertTest, TestNoWildcardRedactionIsValid) {
+  EXPECT_OK(leaf_cert_->IsValidWildcardRedaction());
+}
+
+TEST_F(CertTest, TestWildcardRedactTestCase5) {
+  // This is invalid because the CN is redacted, no DNS or extension
+  EXPECT_THAT(v2_wildcard_test5_cert_->IsValidWildcardRedaction(),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertTest, TestWildcardRedactTestCase6) {
+  // This is invalid because the CN differs from the first DNS-ID
+  EXPECT_THAT(v2_wildcard_test6_cert_->IsValidWildcardRedaction(),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertTest, TestWildcardRedactTestCase7) {
+  // This should be a valid redaction of 1 label with everything set
+  // correctly in the extension
+  EXPECT_OK(v2_wildcard_test7_cert_->IsValidWildcardRedaction());
+}
+
+TEST_F(CertTest, TestWildcardRedactTestCase8) {
+  // This should be a valid redaction of 1 label with everything set
+  // correctly in the extension and a '*' at left of name.
+  EXPECT_OK(v2_wildcard_test8_cert_->IsValidWildcardRedaction());
+}
+
+TEST_F(CertTest, TestWildcardRedactTestCase9) {
+  // Should be invalid as the redacted label does not follow RFC rules
+  EXPECT_THAT(v2_wildcard_test9_cert_->IsValidWildcardRedaction(),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertTest, TestWildcardRedactTestCase10) {
+  // Should be invalid as redacted label uses '*' incorrectly
+  EXPECT_THAT(v2_wildcard_test10_cert_->IsValidWildcardRedaction(),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertTest, TestWildcardRedactTestCase11) {
+  // Should be invalid as there are too many label count values
+  EXPECT_THAT(v2_wildcard_test11_cert_->IsValidWildcardRedaction(),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertTest, TestWildcardRedactTestCase12) {
+  // This should be invalid because the CT extension contains -ve value
+  EXPECT_THAT(v2_wildcard_test12_cert_->IsValidWildcardRedaction(),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertTest, TestWildcardRedactTestCase13) {
+  EXPECT_OK(v2_wildcard_test13_cert_->IsValidWildcardRedaction());
+}
+
+TEST_F(CertTest, TestWildcardRedactTestCase14) {
+  EXPECT_OK(v2_wildcard_test14_cert_->IsValidWildcardRedaction());
+}
+
+TEST_F(CertTest, TestWildcardRedactTestCase15) {
+  // This should be invalid because the CT extension has too many values
+  EXPECT_THAT(v2_wildcard_test15_cert_->IsValidWildcardRedaction(),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertTest, TestWildcardRedactTestCase22) {
+  // This should be a redaction of 1 label but no extension required by
+  // RFC section 3.2.2
+  EXPECT_THAT(v2_wildcard_test22_cert_->IsValidWildcardRedaction(),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertTest, TestWildcardRedactTestCase23) {
+  // Should not be valid because the CT extension is not a SEQUENCE OF
+  // type
+  EXPECT_THAT(v2_wildcard_test23_cert_->IsValidWildcardRedaction(),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertTest, TestWildcardRedactTestCase24) {
+  // Should not be valid because not all the items in the CT extension sequence
+  // are ASN1_INTEGER type
+  EXPECT_THAT(v2_wildcard_test24_cert_->IsValidWildcardRedaction(),
+              StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertTest, TestConstraintTestCase2) {
+  // This should be valid as the cert is non CA and the checks do not apply
+  EXPECT_OK(v2_constraint_test2_cert_->IsValidNameConstrainedIntermediateCa());
+}
+
+TEST_F(CertTest, TestConstraintTestCase3) {
+  // This should be valid as the cert is CA but has no name constraint
+  EXPECT_OK(v2_constraint_test3_cert_->IsValidNameConstrainedIntermediateCa());
+}
+
+TEST_F(CertTest, TestConstraintTestCase4) {
+  // Not valid as there is a constraint but no CT ext
+  EXPECT_THAT(
+      v2_constraint_test4_cert_->IsValidNameConstrainedIntermediateCa(),
+      StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertTest, TestConstraintTestCase5) {
+  // Not valid as there is no DNS entry in name constraints
+  EXPECT_THAT(
+      v2_constraint_test5_cert_->IsValidNameConstrainedIntermediateCa(),
+      StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertTest, TestConstraintTestCase6) {
+  // This should be valid as the CA cert contains valid name constraints +
+  // CT extension
+  EXPECT_OK(v2_constraint_test6_cert_->IsValidNameConstrainedIntermediateCa());
+}
+
+TEST_F(CertTest, TestConstraintTestCase7) {
+  // This should be valid as the CA cert contains valid name constraints +
+  // CT extension + multiple DNS entries
+  EXPECT_OK(v2_constraint_test7_cert_->IsValidNameConstrainedIntermediateCa());
+}
+
+TEST_F(CertTest, TestConstraintTestCase8) {
+  // This should be invalid as there is no IP exclusion in name constraint
+  EXPECT_THAT(
+      v2_constraint_test8_cert_->IsValidNameConstrainedIntermediateCa(),
+      StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(CertTest, TestConstraintTestCase9) {
+  // This should be invalid as both IPv4 and v6 ranges not excluded
+  EXPECT_THAT(
+      v2_constraint_test9_cert_->IsValidNameConstrainedIntermediateCa(),
+      StatusIs(util::error::INVALID_ARGUMENT));
+}
+
+TEST_F(TbsCertificateTest, DerEncoding) {
+  TbsCertificate tbs(*leaf_cert_);
+
+  string cert_tbs_der, raw_tbs_der;
+  EXPECT_OK(leaf_cert_->DerEncodedTbsCertificate(&cert_tbs_der));
+  EXPECT_OK(tbs.DerEncoding(&raw_tbs_der));
+  EXPECT_EQ(cert_tbs_der, raw_tbs_der);
+}
+
+TEST_F(TbsCertificateTest, DeleteExtension) {
+  ASSERT_TRUE(
+      leaf_cert_->HasExtension(NID_authority_key_identifier).ValueOrDie());
+
+  TbsCertificate tbs(*leaf_cert_);
+  string der_before, der_after;
+  EXPECT_OK(tbs.DerEncoding(&der_before));
+  EXPECT_OK(tbs.DeleteExtension(NID_authority_key_identifier));
+  EXPECT_OK(tbs.DerEncoding(&der_after));
+  EXPECT_NE(der_before, der_after);
+
+  ASSERT_FALSE(
+      leaf_cert_->HasExtension(cert_trans::NID_ctPoison).ValueOrDie());
+  TbsCertificate tbs2(*leaf_cert_);
+  string der_before2, der_after2;
+  EXPECT_OK(tbs2.DerEncoding(&der_before2));
+  EXPECT_THAT(tbs2.DeleteExtension(cert_trans::NID_ctPoison),
+              StatusIs(util::error::NOT_FOUND));
+  EXPECT_OK(tbs2.DerEncoding(&der_after2));
+  EXPECT_EQ(der_before2, der_after2);
+}
+
+TEST_F(TbsCertificateTest, CopyIssuer) {
+  TbsCertificate tbs(*leaf_cert_);
+  string der_before, der_after;
+  EXPECT_OK(tbs.DerEncoding(&der_before));
+  EXPECT_OK(tbs.CopyIssuerFrom(*leaf_with_intermediate_cert_));
+  EXPECT_OK(tbs.DerEncoding(&der_after));
+  EXPECT_NE(der_before, der_after);
+
+  TbsCertificate tbs2(*leaf_cert_);
+  string der_before2, der_after2;
+  EXPECT_OK(tbs2.DerEncoding(&der_before2));
+  EXPECT_OK(tbs2.CopyIssuerFrom(*leaf_cert_));
+  EXPECT_OK(tbs2.DerEncoding(&der_after2));
+  EXPECT_EQ(der_before2, der_after2);
+}
+
+TEST_F(CertChainTest, LoadValid) {
+  // A single certificate.
+  CertChain chain(leaf_pem_);
+  EXPECT_TRUE(chain.IsLoaded());
+  EXPECT_EQ(chain.Length(), 1U);
+
+  CertChain chain2(leaf_pem_ + ca_pem_);
+  EXPECT_TRUE(chain2.IsLoaded());
+  EXPECT_EQ(chain2.Length(), 2U);
+}
+
+TEST_F(CertChainTest, LoadInvalid) {
+  // A single certificate.
+  CertChain chain("bogus");
+  EXPECT_FALSE(chain.IsLoaded());
+  EXPECT_EQ(chain.Length(), 0U);
+
+  CertChain chain2(leaf_pem_ + string(kInvalidCertString));
+  EXPECT_FALSE(chain.IsLoaded());
+  EXPECT_EQ(chain.Length(), 0U);
+}
+
+TEST_F(CertChainTest, AddCert) {
+  CertChain chain(leaf_pem_);
+  EXPECT_EQ(chain.Length(), 1U);
+
+  ASSERT_TRUE(chain.AddCert(Cert::FromPemString(ca_pem_)));
+  EXPECT_EQ(chain.Length(), 2U);
+
+  EXPECT_FALSE(chain.AddCert(nullptr));
+  EXPECT_EQ(chain.Length(), 2U);
+
+  EXPECT_FALSE(chain.AddCert(Cert::FromPemString("bogus")));
+  EXPECT_EQ(chain.Length(), 2U);
+}
+
+TEST_F(CertChainTest, RemoveCert) {
+  CertChain chain(leaf_pem_);
+  EXPECT_EQ(chain.Length(), 1U);
+  chain.RemoveCert();
+  EXPECT_EQ(0U, chain.Length());
+
+  // Does nothing.
+  chain.RemoveCert();
+  EXPECT_EQ(0U, chain.Length());
+}
+
+TEST_F(CertChainTest, IssuerChains) {
+  // A single certificate.
+  CertChain chain(leaf_pem_);
+  EXPECT_OK(chain.IsValidCaIssuerChainMaybeLegacyRoot());
+  EXPECT_OK(chain.IsValidSignatureChain());
+
+  // Two certs.
+  CertChain chain2(leaf_pem_ + ca_pem_);
+  EXPECT_OK(chain.IsValidCaIssuerChainMaybeLegacyRoot());
+  EXPECT_OK(chain.IsValidSignatureChain());
+
+  // In reverse order.
+  CertChain chain3(ca_pem_ + leaf_pem_);
+  EXPECT_THAT(chain3.IsValidCaIssuerChainMaybeLegacyRoot(),
+              StatusIs(util::error::INVALID_ARGUMENT));
+  EXPECT_THAT(chain3.IsValidSignatureChain(),
+              StatusIs(util::error::INVALID_ARGUMENT));
+
+  // Invalid
+  CertChain invalid("");
+  EXPECT_THAT(invalid.IsValidCaIssuerChainMaybeLegacyRoot(),
+              StatusIs(util::error::FAILED_PRECONDITION));
+  EXPECT_THAT(invalid.IsValidSignatureChain(),
+              StatusIs(util::error::FAILED_PRECONDITION));
+}
+
+TEST_F(CertChainTest, PreCertChain) {
+  // A precert chain.
+  string pem_bundle = precert_pem_ + ca_pem_;
+  PreCertChain pre_chain(pem_bundle);
+  ASSERT_TRUE(pre_chain.IsLoaded());
+  EXPECT_EQ(pre_chain.Length(), 2U);
+  EXPECT_OK(pre_chain.IsValidCaIssuerChainMaybeLegacyRoot());
+  EXPECT_OK(pre_chain.IsValidSignatureChain());
+  EXPECT_TRUE(pre_chain.IsWellFormed().ValueOrDie());
+
+  // Try to construct a precert chain from regular certs.
+  // The chain should load, but is not well-formed.
+  pem_bundle = leaf_pem_ + ca_pem_;
+  PreCertChain pre_chain2(pem_bundle);
+  ASSERT_TRUE(pre_chain2.IsLoaded());
+  EXPECT_EQ(pre_chain2.Length(), 2U);
+  EXPECT_OK(pre_chain2.IsValidCaIssuerChainMaybeLegacyRoot());
+  EXPECT_OK(pre_chain2.IsValidSignatureChain());
+  EXPECT_FALSE(pre_chain2.IsWellFormed().ValueOrDie());
+}
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  OpenSSL_add_all_algorithms();
+  ERR_load_crypto_strings();
+  cert_trans::LoadCtExtensions();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cluster_state_controller.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cluster_state_controller.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cluster_state_controller.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cluster_state_controller.cc	2017-01-15 10:56:31.039591151 +0100
@@ -0,0 +1,529 @@
+#include "log/cluster_state_controller.h"
+
+#include <stdint.h>
+#include <functional>
+
+#include "fetcher/peer.h"
+#include "log/database.h"
+#include "log/etcd_consistent_store.h"
+#include "monitoring/monitoring.h"
+#include "proto/ct.pb.h"
+
+using ct::ClusterConfig;
+using ct::ClusterNodeState;
+using ct::SignedTreeHead;
+using std::bind;
+using std::lock_guard;
+using std::make_pair;
+using std::make_shared;
+using std::map;
+using std::mutex;
+using std::pair;
+using std::placeholders::_1;
+using std::shared_ptr;
+using std::string;
+using std::to_string;
+using std::unique_lock;
+using std::unique_ptr;
+using std::vector;
+using util::Executor;
+using util::Status;
+using util::StatusOr;
+
+namespace cert_trans {
+namespace {
+
+
+Gauge<>* serving_tree_size =
+    Gauge<>::New("serving_tree_size", "Size of the current serving STH");
+
+Gauge<>* serving_tree_timestamp =
+    Gauge<>::New("serving_tree_timestamp",
+                 "Timestamp of the current serving STH");
+
+
+unique_ptr<AsyncLogClient> BuildAsyncLogClient(
+    const shared_ptr<libevent::Base>& base, UrlFetcher* fetcher,
+    const ClusterNodeState& state) {
+  CHECK(!state.hostname().empty());
+  CHECK_GT(state.log_port(), 0);
+  CHECK_LE(state.log_port(), UINT16_MAX);
+
+  // TODO(pphaneuf): We'd like to support HTTPS at some point.
+  return unique_ptr<AsyncLogClient>(new AsyncLogClient(
+      base.get(), fetcher,
+      "http://" + state.hostname() + ":" + to_string(state.log_port())));
+}
+
+
+}  // namespace
+
+
+ClusterStateController::ClusterPeer::ClusterPeer(
+    const shared_ptr<libevent::Base>& base, UrlFetcher* fetcher,
+    const ClusterNodeState& state)
+    : Peer(BuildAsyncLogClient(base, fetcher, state)), state_(state) {
+}
+
+
+int64_t ClusterStateController::ClusterPeer::TreeSize() const {
+  lock_guard<mutex> lock(lock_);
+  return state_.newest_sth().tree_size();
+}
+
+
+void ClusterStateController::ClusterPeer::UpdateClusterNodeState(
+    const ClusterNodeState& new_state) {
+  lock_guard<mutex> lock(lock_);
+  // TODO(pphaneuf): We have no way of changing the AsyncLogClient in
+  // our parent, maybe we should?
+  CHECK_EQ(state_.hostname(), new_state.hostname());
+  CHECK_EQ(state_.log_port(), new_state.log_port());
+  state_ = new_state;
+}
+
+
+ClusterNodeState ClusterStateController::ClusterPeer::state() const {
+  lock_guard<mutex> lock(lock_);
+  return state_;
+}
+
+
+pair<string, int> ClusterStateController::ClusterPeer::GetHostPort() const {
+  lock_guard<mutex> lock(lock_);
+  return make_pair(state_.hostname(), state_.log_port());
+}
+
+
+// TODO(alcutter): Need a better system for hanging tasks onto events,
+// Pierre's task-a-palooza idea perhaps?
+ClusterStateController::ClusterStateController(
+    Executor* executor, const shared_ptr<libevent::Base>& base,
+    UrlFetcher* url_fetcher, Database* database, ConsistentStore* store,
+    MasterElection* election, ContinuousFetcher* fetcher)
+    : base_(base),
+      url_fetcher_(CHECK_NOTNULL(url_fetcher)),
+      database_(CHECK_NOTNULL(database)),
+      store_(CHECK_NOTNULL(store)),
+      election_(CHECK_NOTNULL(election)),
+      fetcher_(CHECK_NOTNULL(fetcher)),
+      watch_config_task_(CHECK_NOTNULL(executor)),
+      watch_node_states_task_(CHECK_NOTNULL(executor)),
+      watch_serving_sth_task_(CHECK_NOTNULL(executor)),
+      exiting_(false),
+      update_required_(false),
+      cluster_serving_sth_update_thread_(
+          bind(&ClusterStateController::ClusterServingSTHUpdater, this)) {
+  CHECK_NOTNULL(base_.get());
+  store_->WatchClusterNodeStates(
+      bind(&ClusterStateController::OnClusterStateUpdated, this, _1),
+      watch_node_states_task_.task());
+  store_->WatchClusterConfig(
+      bind(&ClusterStateController::OnClusterConfigUpdated, this, _1),
+      watch_config_task_.task());
+  store_->WatchServingSTH(bind(&ClusterStateController::OnServingSthUpdated,
+                               this, _1),
+                          watch_serving_sth_task_.task());
+}
+
+
+ClusterStateController::~ClusterStateController() {
+  watch_config_task_.Cancel();
+  watch_node_states_task_.Cancel();
+  watch_serving_sth_task_.Cancel();
+  {
+    lock_guard<mutex> lock(mutex_);
+    exiting_ = true;
+  }
+  update_required_cv_.notify_all();
+  cluster_serving_sth_update_thread_.join();
+  watch_config_task_.Wait();
+  watch_node_states_task_.Wait();
+  watch_serving_sth_task_.Wait();
+}
+
+
+void ClusterStateController::NewTreeHead(const SignedTreeHead& sth) {
+  unique_lock<mutex> lock(mutex_);
+  SignedTreeHead db_sth;
+  const Database::LookupResult result(database_->LatestTreeHead(&db_sth));
+
+  const bool serving_sth_newer_than_db_sth(
+      actual_serving_sth_ &&
+      ((result == Database::LOOKUP_OK &&
+        db_sth.tree_size() <= actual_serving_sth_->tree_size() &&
+        db_sth.timestamp() < actual_serving_sth_->timestamp()) ||
+       (result == Database::NOT_FOUND)));
+
+  // Check whether this updated tree head would enable us to start serving the
+  // current cluster serving STH. If so, we'll store it to the local DB below.
+  const bool write_sth(serving_sth_newer_than_db_sth &&
+                       sth.tree_size() >= actual_serving_sth_->tree_size());
+
+  if (local_node_state_.has_newest_sth()) {
+    CHECK_GE(sth.timestamp(), local_node_state_.newest_sth().timestamp());
+  }
+  local_node_state_.mutable_newest_sth()->CopyFrom(sth);
+  PushLocalNodeState(lock);
+
+  SignedTreeHead sth_to_write;
+  if (write_sth) {
+    sth_to_write = *actual_serving_sth_;
+  }
+
+  // Updating the tree below can take a while if the tree delta is large and
+  // the DB is under load (e.g. due to fetcher / external traffic), the tree
+  // itself is locked during this process so we can release our lock here to
+  // not block other operations (e.g. watchdog operations.)
+  lock.unlock();
+
+  if (write_sth) {
+    // TODO(alcutter): Perhaps we need to know about updates to the contiguous
+    // tree size in the DB again, so that we can write this out as soon as
+    // we're able to serve it.
+    CHECK_EQ(Database::OK, database_->WriteTreeHead(sth_to_write));
+  }
+}
+
+
+StatusOr<SignedTreeHead> ClusterStateController::GetCalculatedServingSTH()
+    const {
+  lock_guard<mutex> lock(mutex_);
+  if (!calculated_serving_sth_) {
+    return Status(util::error::NOT_FOUND, "No calculated STH");
+  }
+  return *calculated_serving_sth_;
+}
+
+
+void ClusterStateController::GetLocalNodeState(ClusterNodeState* state) const {
+  CHECK_NOTNULL(state);
+  lock_guard<mutex> lock(mutex_);
+  *state = local_node_state_;
+}
+
+
+void ClusterStateController::SetNodeHostPort(const string& host,
+                                             const uint16_t port) {
+  unique_lock<mutex> lock(mutex_);
+  local_node_state_.set_hostname(host);
+  local_node_state_.set_log_port(port);
+  PushLocalNodeState(lock);
+}
+
+
+void ClusterStateController::RefreshNodeState() {
+  unique_lock<mutex> lock(mutex_);
+  PushLocalNodeState(lock);
+}
+
+
+bool ClusterStateController::NodeIsStale() const {
+  lock_guard<mutex> lock(mutex_);
+  if (!actual_serving_sth_) {
+    return true;
+  }
+  return database_->TreeSize() < actual_serving_sth_->tree_size();
+}
+
+
+vector<ClusterNodeState> ClusterStateController::GetFreshNodes() const {
+  lock_guard<mutex> lock(mutex_);
+  if (!actual_serving_sth_) {
+    LOG(WARNING) << "Cluster has no ServingSTH, all nodes are stale.";
+    return {};
+  }
+  vector<ClusterNodeState> fresh;  // for 1983.
+  // Here we go:
+  for (const auto& node : all_peers_) {
+    const bool is_self(
+        node.second->state().hostname() == local_node_state_.hostname() &&
+        node.second->state().log_port() == local_node_state_.log_port());
+    if (!is_self && node.second->state().has_newest_sth() &&
+        node.second->state().newest_sth().tree_size() >=
+            actual_serving_sth_->tree_size()) {
+      VLOG(1) << "Node is fresh: " << node.second->state().node_id();
+      fresh.push_back(node.second->state());
+    }
+  }
+  return fresh;
+}
+
+
+void ClusterStateController::PushLocalNodeState(
+    const unique_lock<mutex>& lock) {
+  CHECK(lock.owns_lock());
+
+  const Status status(store_->SetClusterNodeState(local_node_state_));
+  LOG_IF(WARNING, !status.ok()) << "Couldn't set ClusterNodeState: " << status;
+}
+
+
+void ClusterStateController::OnClusterStateUpdated(
+    const vector<Update<ClusterNodeState>>& updates) {
+  unique_lock<mutex> lock(mutex_);
+  for (const auto& update : updates) {
+    const string& node_id(update.handle_.Key());
+    if (update.exists_) {
+      auto it(all_peers_.find(node_id));
+      VLOG_IF(1, it == all_peers_.end()) << "Node joined: " << node_id;
+
+      // If the host or port change, remove the ClusterPeer, so that
+      // we re-create it.
+      if (it != all_peers_.end() &&
+          it->second->GetHostPort() !=
+              make_pair(update.handle_.Entry().hostname(),
+                        update.handle_.Entry().log_port())) {
+        all_peers_.erase(it);
+        it = all_peers_.end();
+      }
+
+      if (it != all_peers_.end()) {
+        it->second->UpdateClusterNodeState(update.handle_.Entry());
+      } else {
+        const shared_ptr<ClusterPeer> peer(
+            make_shared<ClusterPeer>(base_, url_fetcher_,
+                                     update.handle_.Entry()));
+        // TODO(pphaneuf): all_peers_ and fetcher_ both maintain a
+        // list of cluster members, this should be split off into its
+        // own class, and share an instance between the interested
+        // parties.
+        all_peers_.emplace(node_id, peer);
+        fetcher_->AddPeer(node_id, peer);
+      }
+    } else {
+      VLOG(1) << "Node left: " << node_id;
+      CHECK_EQ(static_cast<size_t>(1), all_peers_.erase(node_id));
+      fetcher_->RemovePeer(node_id);
+    }
+  }
+
+  CalculateServingSTH(lock);
+}
+
+
+void ClusterStateController::OnClusterConfigUpdated(
+    const Update<ClusterConfig>& update) {
+  unique_lock<mutex> lock(mutex_);
+  if (!update.exists_) {
+    LOG(WARNING) << "No ClusterConfig exists.";
+    return;
+  }
+
+  cluster_config_ = update.handle_.Entry();
+  LOG(INFO) << "Received new ClusterConfig:\n"
+            << cluster_config_.DebugString();
+
+  // May need to re-calculate the servingSTH since the ClusterConfig has
+  // changed:
+  CalculateServingSTH(lock);
+}
+
+
+void ClusterStateController::OnServingSthUpdated(
+    const Update<SignedTreeHead>& update) {
+  unique_lock<mutex> lock(mutex_);
+  bool write_sth(true);
+
+  if (!update.exists_) {
+    LOG(WARNING) << "Cluster has no Serving STH!";
+    actual_serving_sth_.reset();
+    write_sth = false;
+  } else {
+    // TODO(alcutter): Validate STH and verify consistency with whatever we've
+    // already got locally.
+    if (update.handle_.Entry().timestamp() == 0) {
+      LOG(WARNING) << "Ignoring invalid Serving STH update.";
+      return;
+    }
+
+    actual_serving_sth_.reset(new SignedTreeHead(update.handle_.Entry()));
+    LOG(INFO) << "Received new Serving STH: "
+              << actual_serving_sth_->ShortDebugString();
+    serving_tree_size->Set(actual_serving_sth_->tree_size());
+    serving_tree_timestamp->Set(actual_serving_sth_->timestamp());
+
+    // Double check this STH is newer than, or idential to, what we have in
+    // the database. (It definitely should be!)
+    SignedTreeHead db_sth;
+    const Database::LookupResult lookup_result(
+        database_->LatestTreeHead(&db_sth));
+    switch (lookup_result) {
+      case Database::LOOKUP_OK:
+        VLOG(1) << "Local latest STH:\n" << db_sth.DebugString();
+        // Check it's for the same log:
+        CHECK_EQ(actual_serving_sth_->id().key_id(), db_sth.id().key_id());
+        CHECK_EQ(actual_serving_sth_->version(), db_sth.version());
+
+        if (db_sth.timestamp() == actual_serving_sth_->timestamp()) {
+          // Either this STH is *identical* to the latest one we have in the DB
+          CHECK_EQ(actual_serving_sth_->tree_size(), db_sth.tree_size());
+          CHECK_EQ(actual_serving_sth_->sha256_root_hash(),
+                   db_sth.sha256_root_hash());
+          // In which case there's no need to write this to the DB because we
+          // already have it.
+          write_sth = false;
+        } else {
+          // Or it's strictly newer:
+          CHECK_GT(actual_serving_sth_->timestamp(), db_sth.timestamp());
+          CHECK_GE(actual_serving_sth_->tree_size(), db_sth.tree_size());
+        }
+        break;
+      case Database::NOT_FOUND:
+        LOG(WARNING) << "Local DB doesn't have any STH, new node?";
+        break;
+      default:
+        LOG(FATAL) << "Problem looking up local DB's latest STH.";
+    }
+
+    if (database_->TreeSize() < actual_serving_sth_->tree_size()) {
+      LOG(INFO) << "Local node doesn't yet have all entries for "
+                << "serving STH, not writing to DB.";
+      write_sth = false;
+    }
+  }
+
+  SignedTreeHead sth_to_write;
+  if (write_sth) {
+    sth_to_write = *actual_serving_sth_;
+  }
+
+  lock.unlock();
+
+  if (write_sth) {
+    // All good, write this STH to our local DB:
+    CHECK_EQ(Database::OK, database_->WriteTreeHead(sth_to_write));
+  }
+}
+
+
+void ClusterStateController::CalculateServingSTH(
+    const unique_lock<mutex>& lock) {
+  VLOG(1) << "Calculating new ServingSTH...";
+  CHECK(lock.owns_lock());
+
+  // First, create a mapping of tree size to number of nodes at that size, and
+  // a mapping of the newst STH for any given size:
+  map<int64_t, SignedTreeHead> sth_by_size;
+  map<int64_t, int> num_nodes_by_sth_size;
+  for (const auto& node : all_peers_) {
+    const ClusterNodeState node_state(node.second->state());
+    if (node_state.has_newest_sth()) {
+      const int64_t tree_size(node_state.newest_sth().tree_size());
+      CHECK_LE(0, tree_size);
+      const int64_t timestamp(node_state.newest_sth().timestamp());
+      CHECK_LE(0, timestamp);
+
+      num_nodes_by_sth_size[tree_size]++;
+
+      // Default timestamp (first call in here) will be 0
+      if (node_state.newest_sth().timestamp() >
+          sth_by_size[tree_size].timestamp()) {
+        sth_by_size[tree_size] = node_state.newest_sth();
+      }
+    }
+  }
+
+  // Next calculate the newest STH we've seen which satisfies the following
+  // criteria:
+  //   - at least minimum_serving_nodes have an STH at least as large
+  //   - at least minimum_serving_fraction have an STH at least as large
+  //   - not smaller than the current serving STH
+  //   - has a timestamp higher than the current serving STH
+  int num_nodes_seen(0);
+  const int current_tree_size(
+      calculated_serving_sth_ ? calculated_serving_sth_->tree_size() : 0);
+  CHECK_LE(0, current_tree_size);
+
+  bool candidates_include_current(false);
+  // Work backwards (from largest STH size) until we see that there's enough
+  // coverage (according to the criteria above) to serve an STH (or determine
+  // that there are insufficient nodes to serve anything.)
+  for (auto it = num_nodes_by_sth_size.rbegin();
+       it != num_nodes_by_sth_size.rend() && it->first >= current_tree_size;
+       ++it) {
+    // num_nodes_seen keeps track of the number of nodes we've seen so far (and
+    // since we're working from larger to smaller size STH, they should all be
+    // able to serve this [and smaller] STHs.)
+    num_nodes_seen += it->second;
+    const double serving_fraction(static_cast<double>(num_nodes_seen) /
+                                  all_peers_.size());
+    if (serving_fraction >= cluster_config_.minimum_serving_fraction() &&
+        num_nodes_seen >= cluster_config_.minimum_serving_nodes()) {
+      const SignedTreeHead& candidate_sth(sth_by_size[it->first]);
+
+      // This STH isn't a viable candidate unless its timestamp is strictly
+      // newer than any current serving STH:
+      if (actual_serving_sth_ &&
+          candidate_sth.timestamp() <= actual_serving_sth_->timestamp()) {
+        VLOG(1) << "Discarding candidate STH:\n" << candidate_sth.DebugString()
+                << "\nbecause its timestamp is <= current serving STH "
+                << "timestamp (" << actual_serving_sth_->timestamp() << ")";
+        candidates_include_current |= candidate_sth.SerializeAsString() ==
+                                      actual_serving_sth_->SerializeAsString();
+        continue;
+      }
+
+      LOG(INFO) << "Can serve @" << it->first << " with " << num_nodes_seen
+                << " nodes (" << (serving_fraction * 100) << "% of cluster)";
+      calculated_serving_sth_.reset(
+          new SignedTreeHead(sth_by_size[it->first]));
+      // Push this STH out to the cluster if we're master:
+      if (election_->IsMaster()) {
+        VLOG(1) << "Pushing new STH out to cluster";
+        update_required_ = true;
+        update_required_cv_.notify_all();
+      } else {
+        VLOG(1) << "Not pushing new STH to cluster since we're not the master";
+      }
+      return;
+    }
+  }
+  // TODO(alcutter): Add a mechanism to take the cluster off-line until we have
+  // sufficient nodes able to serve.
+  if (!candidates_include_current) {
+    LOG(WARNING) << "Failed to determine suitable serving STH.";
+  } else {
+    VLOG(1) << "Continuing to serve previous STH.";
+  }
+}
+
+
+// Thread entry point for cluster_serving_sth_update_thread_.
+void ClusterStateController::ClusterServingSTHUpdater() {
+  while (true) {
+    VLOG(1) << "ClusterServingSTHUpdater going again.";
+    unique_lock<mutex> lock(mutex_);
+    update_required_cv_.wait(lock, [this]() {
+      return update_required_ || exiting_;
+    });
+    VLOG(1) << "ClusterServingSTHUpdater got ping.";
+    if (exiting_) {
+      VLOG(1) << "ClusterServingSTHUpdater thread returning.";
+      return;
+    }
+    CHECK(update_required_);
+    CHECK_NOTNULL(calculated_serving_sth_.get());
+    const SignedTreeHead local_sth(*calculated_serving_sth_);
+
+    update_required_ = false;
+
+    // And then release it before we send the update.
+    // This allows any other code to get on with modifying
+    // calculated_serving_sth_ in response to cluster state changes
+    lock.unlock();
+
+    if (election_->IsMaster()) {
+      LOG(INFO) << "Setting cluster serving STH @ " << local_sth.timestamp();
+      Status status(store_->SetServingSTH(local_sth));
+      LOG_IF(WARNING, !status.ok()) << "SetServingSTH @ "
+                                    << local_sth.timestamp()
+                                    << " failed: " << status;
+    } else {
+      LOG(INFO) << "Not setting cluster serving STH because no-longer master.";
+    }
+  }
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cluster_state_controller.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cluster_state_controller.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cluster_state_controller.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cluster_state_controller.h	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,148 @@
+#ifndef CERT_TRANS_LOG_CLUSTER_STATE_CONTROLLER_H_
+#define CERT_TRANS_LOG_CLUSTER_STATE_CONTROLLER_H_
+
+#include <condition_variable>
+#include <functional>
+#include <map>
+#include <memory>
+#include <queue>
+#include <string>
+
+#include "fetcher/continuous_fetcher.h"
+#include "log/etcd_consistent_store.h"
+#include "log/logged_entry.h"
+#include "proto/ct.pb.h"
+#include "util/libevent_wrapper.h"
+#include "util/masterelection.h"
+#include "util/statusor.h"
+
+namespace cert_trans {
+
+class Database;
+
+
+// A class which updates & maintains the states of the individual cluster
+// member nodes, and uses this information to determine the overall serving
+// state of the cluster.
+//
+// In particular, this class:
+//  - calculates the optimal STH for the cluster to serve at any given time.
+//  - determines whether this node is eligible to participare in the election,
+//    and leaves/joins the election as appropriate.
+class ClusterStateController {
+ public:
+  ClusterStateController(util::Executor* executor,
+                         const std::shared_ptr<libevent::Base>& base,
+                         UrlFetcher* url_fetcher, Database* database,
+                         ConsistentStore* store, MasterElection* election,
+                         ContinuousFetcher* fetcher);
+
+  ~ClusterStateController();
+
+  // Updates *this* node's ClusterNodeState to reflect the new STH available.
+  void NewTreeHead(const ct::SignedTreeHead& sth);
+
+  // Gets the current (if any) calculated serving STH for the cluster.
+  // If there is such an STH then return true and |sth| is populated, returns
+  // false otherwise.
+  //
+  // Note that this simply returns this node's interpretation of the optimum
+  // serving STH, the current master/contents of the servingSTH file may
+  // differ.
+  //
+  // Really only intended for testing.
+  util::StatusOr<ct::SignedTreeHead> GetCalculatedServingSTH() const;
+
+  void GetLocalNodeState(ct::ClusterNodeState* state) const;
+
+  // Publishes this node's listening address in its ClusterNodeState, so that
+  // other nodes can request entries from its database.
+  void SetNodeHostPort(const std::string& host, const uint16_t port);
+
+  void RefreshNodeState();
+
+  bool NodeIsStale() const;
+
+  // Returns a vector of the other nodes in the cluster which are able to serve
+  // the cluster's current ServingSTH. Does not include this node in the
+  // returned list regardless of its freshness.
+  std::vector<ct::ClusterNodeState> GetFreshNodes() const;
+
+ private:
+  class ClusterPeer : public Peer {
+   public:
+    ClusterPeer(const std::shared_ptr<libevent::Base>& base,
+                UrlFetcher* fetcher, const ct::ClusterNodeState& state);
+
+    int64_t TreeSize() const override;
+    void UpdateClusterNodeState(const ct::ClusterNodeState& new_state);
+    ct::ClusterNodeState state() const;
+    std::pair<std::string, int> GetHostPort() const;
+
+   private:
+    mutable std::mutex lock_;
+    ct::ClusterNodeState state_;
+
+    DISALLOW_COPY_AND_ASSIGN(ClusterPeer);
+  };
+
+  // Updates the representation of *this* node's state in the consistent store.
+  void PushLocalNodeState(const std::unique_lock<std::mutex>& lock);
+
+  // Entry point for the watcher callback.
+  // Called whenever a node changes its node state.
+  void OnClusterStateUpdated(
+      const std::vector<Update<ct::ClusterNodeState>>& updates);
+
+  // Entry point for the config watcher callback.
+  // Called whenever the ClusterConfig is changed.
+  void OnClusterConfigUpdated(const Update<ct::ClusterConfig>& update);
+
+  // Entry point for the config watcher callback.
+  // Called whenever the ClusterConfig is changed.
+  void OnServingSthUpdated(const Update<ct::SignedTreeHead>& update);
+
+  // Calculates the STH which should be served by the cluster, given the
+  // current state of the nodes.
+  // If this node is the cluster master then the calculated serving STH is
+  // pushed out to the consistent store.
+  void CalculateServingSTH(const std::unique_lock<std::mutex>& lock);
+
+  // Determines whether this node should be participating in the election based
+  // on the current node's state.
+  void DetermineElectionParticipation(
+      const std::unique_lock<std::mutex>& lock);
+
+  // Thread entry point for ServingSTH updater thread.
+  void ClusterServingSTHUpdater();
+
+  const std::shared_ptr<libevent::Base> base_;
+  UrlFetcher* const url_fetcher_;     // Not owned by us
+  Database* const database_;          // Not owned by us
+  ConsistentStore* const store_;      // Not owned by us
+  MasterElection* const election_;    // Not owned by us
+  ContinuousFetcher* const fetcher_;  // Not owned by us
+  util::SyncTask watch_config_task_;
+  util::SyncTask watch_node_states_task_;
+  util::SyncTask watch_serving_sth_task_;
+  ct::ClusterConfig cluster_config_;
+
+  mutable std::mutex mutex_;  // covers the members below:
+  ct::ClusterNodeState local_node_state_;
+  std::map<std::string, const std::shared_ptr<ClusterPeer>> all_peers_;
+  std::unique_ptr<ct::SignedTreeHead> calculated_serving_sth_;
+  std::unique_ptr<ct::SignedTreeHead> actual_serving_sth_;
+  bool exiting_;
+  bool update_required_;
+  std::condition_variable update_required_cv_;
+  std::thread cluster_serving_sth_update_thread_;
+
+  friend class ClusterStateControllerTest;
+
+  DISALLOW_COPY_AND_ASSIGN(ClusterStateController);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_CLUSTER_STATE_CONTROLLER_H__
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cluster_state_controller_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cluster_state_controller_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cluster_state_controller_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cluster_state_controller_test.cc	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,672 @@
+#include <gtest/gtest.h>
+#include <map>
+#include <memory>
+#include <string>
+#include <thread>
+
+#include "fetcher/mock_continuous_fetcher.h"
+#include "log/cluster_state_controller.h"
+#include "log/logged_entry.h"
+#include "log/test_db.h"
+#include "net/mock_url_fetcher.h"
+#include "proto/cert_serializer.h"
+#include "proto/ct.pb.h"
+#include "util/fake_etcd.h"
+#include "util/libevent_wrapper.h"
+#include "util/mock_masterelection.h"
+#include "util/testing.h"
+#include "util/thread_pool.h"
+#include "util/util.h"
+
+using ct::ClusterConfig;
+using ct::ClusterNodeState;
+using ct::SignedTreeHead;
+using std::make_shared;
+using std::shared_ptr;
+using std::string;
+using std::vector;
+using testing::AnyNumber;
+using testing::NiceMock;
+using testing::Return;
+using testing::_;
+using util::StatusOr;
+
+namespace cert_trans {
+
+const char kNodeId1[] = "node1";
+const char kNodeId2[] = "node2";
+const char kNodeId3[] = "node3";
+
+
+class ClusterStateControllerTest : public ::testing::Test {
+ public:
+  // TODO: Some of the tests in this class rely on sleep() calls.
+  // Ideally they should be waiting for defined conditions to avoid timing
+  // races.
+
+  // TODO(pphaneuf): The size of the thread pool is a bit of a magic
+  // number... We have some callbacks that block, so it has to be "at
+  // least this" (so we're setting it explicitly, in case your machine
+  // doesn't have enough cores). We should hunt down those blocking
+  // callbacks.
+  ClusterStateControllerTest()
+      : pool_(3),
+        base_(make_shared<libevent::Base>()),
+        pump_(base_),
+        etcd_(base_.get()),
+        store1_(new EtcdConsistentStore(base_.get(), &pool_, &etcd_,
+                                        &election1_, "", kNodeId1)),
+        store2_(new EtcdConsistentStore(base_.get(), &pool_, &etcd_,
+                                        &election2_, "", kNodeId2)),
+        store3_(new EtcdConsistentStore(base_.get(), &pool_, &etcd_,
+                                        &election3_, "", kNodeId3)),
+        controller_(&pool_, base_, &url_fetcher_, test_db_.db(), store1_.get(),
+                    &election1_, &fetcher_) {
+    // There will be many calls to ContinuousFetcher::AddPeer during
+    // this test, but this isn't what we're testing here, so just
+    // ignore them.
+    EXPECT_CALL(fetcher_, AddPeer(_, _)).Times(AnyNumber());
+
+    // Set default cluster config:
+    ct::ClusterConfig default_config;
+    default_config.set_minimum_serving_nodes(1);
+    default_config.set_minimum_serving_fraction(1);
+    store1_->SetClusterConfig(default_config);
+
+    controller_.SetNodeHostPort(kNodeId1, 9001);
+
+    // Set up some handy STHs
+    sth100_.set_tree_size(100);
+    sth100_.set_timestamp(100);
+    sth200_.set_tree_size(200);
+    sth200_.set_timestamp(200);
+    sth300_.set_tree_size(300);
+    sth300_.set_timestamp(300);
+
+    cns100_.set_hostname(kNodeId1);
+    cns100_.set_log_port(9001);
+    cns100_.mutable_newest_sth()->CopyFrom(sth100_);
+
+    cns200_.set_hostname(kNodeId2);
+    cns200_.set_log_port(9001);
+    cns200_.mutable_newest_sth()->CopyFrom(sth200_);
+
+    cns300_.set_hostname(kNodeId3);
+    cns300_.set_log_port(9001);
+    cns300_.mutable_newest_sth()->CopyFrom(sth300_);
+  }
+
+ protected:
+  ct::ClusterNodeState GetLocalState() {
+    return controller_.local_node_state_;
+  }
+
+  // TODO: This should probably return a util::StatusOr<ClusterNodeState>
+  // rather than failing a CHECK if absent.
+  ct::ClusterNodeState GetNodeStateView(const string& node_id) {
+    auto it(controller_.all_peers_.find("/nodes/" + node_id));
+    CHECK(it != controller_.all_peers_.end());
+    return it->second->state();
+  }
+
+  static void SetClusterConfig(ConsistentStore* store, const int min_nodes,
+                               const double min_fraction) {
+    ClusterConfig config;
+    config.set_minimum_serving_nodes(min_nodes);
+    config.set_minimum_serving_fraction(min_fraction);
+    CHECK(store->SetClusterConfig(config).ok());
+  }
+
+
+  SignedTreeHead sth100_, sth200_, sth300_;
+  ClusterNodeState cns100_, cns200_, cns300_;
+
+  ThreadPool pool_;
+  shared_ptr<libevent::Base> base_;
+  MockUrlFetcher url_fetcher_;
+  MockContinuousFetcher fetcher_;
+  libevent::EventPumpThread pump_;
+  FakeEtcdClient etcd_;
+  TestDB<FileDB> test_db_;
+  NiceMock<MockMasterElection> election1_;
+  NiceMock<MockMasterElection> election2_;
+  NiceMock<MockMasterElection> election3_;
+  std::unique_ptr<EtcdConsistentStore> store1_;
+  std::unique_ptr<EtcdConsistentStore> store2_;
+  std::unique_ptr<EtcdConsistentStore> store3_;
+  ClusterStateController controller_;
+};
+
+
+typedef class EtcdConsistentStoreTest EtcdConsistentStoreDeathTest;
+
+
+TEST_F(ClusterStateControllerTest, TestNewTreeHead) {
+  ct::SignedTreeHead sth;
+  sth.set_tree_size(234);
+  controller_.NewTreeHead(sth);
+  EXPECT_EQ(sth.DebugString(), GetLocalState().newest_sth().DebugString());
+}
+
+
+TEST_F(ClusterStateControllerTest, TestCalculateServingSTHAt50Percent) {
+  NiceMock<MockMasterElection> election_is_master;
+  EXPECT_CALL(election_is_master, IsMaster()).WillRepeatedly(Return(true));
+  ClusterStateController controller50(&pool_, base_, &url_fetcher_,
+                                      test_db_.db(), store1_.get(),
+                                      &election_is_master, &fetcher_);
+  SetClusterConfig(store1_.get(), 1 /* nodes */, 0.5 /* fraction */);
+
+  store1_->SetClusterNodeState(cns100_);
+  sleep(1);
+  util::StatusOr<SignedTreeHead> sth(controller50.GetCalculatedServingSTH());
+  // Can serve sth1 because all nodes have it !
+  EXPECT_EQ(sth100_.tree_size(), sth.ValueOrDie().tree_size());
+
+  store2_->SetClusterNodeState(cns200_);
+  sleep(1);
+  // Can serve sth2 because 50% of nodes have it
+  sth = controller50.GetCalculatedServingSTH();
+  EXPECT_EQ(sth200_.tree_size(), sth.ValueOrDie().tree_size());
+
+  store3_->SetClusterNodeState(cns300_);
+  sleep(1);
+  // Can serve sth2 because 66% of nodes have it (or higher)
+  // Can't serve sth3 because only 33% of nodes cover it.
+  sth = controller50.GetCalculatedServingSTH();
+  EXPECT_EQ(sth200_.tree_size(), sth.ValueOrDie().tree_size());
+}
+
+
+TEST_F(ClusterStateControllerTest, TestCalculateServingSTHAt70Percent) {
+  NiceMock<MockMasterElection> election_is_master;
+  EXPECT_CALL(election_is_master, IsMaster()).WillRepeatedly(Return(true));
+  ClusterStateController controller70(&pool_, base_, &url_fetcher_,
+                                      test_db_.db(), store1_.get(),
+                                      &election_is_master, &fetcher_);
+  SetClusterConfig(store1_.get(), 1 /* nodes */, 0.7 /* fraction */);
+  store1_->SetClusterNodeState(cns100_);
+  sleep(1);
+  util::StatusOr<SignedTreeHead> sth(controller70.GetCalculatedServingSTH());
+  // Can serve sth1 because all nodes have it !
+  EXPECT_EQ(sth100_.tree_size(), sth.ValueOrDie().tree_size());
+
+  store2_->SetClusterNodeState(cns200_);
+  sleep(1);
+  // Can still only serve sth1 because only 50% of nodes have sth2
+  sth = controller70.GetCalculatedServingSTH();
+  EXPECT_EQ(sth100_.tree_size(), sth.ValueOrDie().tree_size());
+
+  store3_->SetClusterNodeState(cns300_);
+  sleep(1);
+  // Can still only serve sth1 because only 66% of nodes have sth2
+  sth = controller70.GetCalculatedServingSTH();
+  EXPECT_EQ(sth100_.tree_size(), sth.ValueOrDie().tree_size());
+}
+
+
+TEST_F(ClusterStateControllerTest,
+       TestCalculateServingSTHAt60PercentTwoNodeMin) {
+  NiceMock<MockMasterElection> election_is_master;
+  EXPECT_CALL(election_is_master, IsMaster()).WillRepeatedly(Return(true));
+  ClusterStateController controller60(&pool_, base_, &url_fetcher_,
+                                      test_db_.db(), store1_.get(),
+                                      &election_is_master, &fetcher_);
+  SetClusterConfig(store1_.get(), 2 /* nodes */, 0.6 /* fraction */);
+  store1_->SetClusterNodeState(cns100_);
+  sleep(1);
+  util::StatusOr<SignedTreeHead> sth(controller60.GetCalculatedServingSTH());
+  // Can't serve at all because not enough nodes
+  EXPECT_FALSE(sth.ok());
+
+  store2_->SetClusterNodeState(cns200_);
+  sleep(1);
+  // Can serve sth1 because there are two nodes, but < 60% coverage for sth2
+  sth = controller60.GetCalculatedServingSTH();
+  EXPECT_EQ(sth100_.tree_size(), sth.ValueOrDie().tree_size());
+
+  store3_->SetClusterNodeState(cns300_);
+  sleep(1);
+  sth = controller60.GetCalculatedServingSTH();
+  // Can serve sth2 because there are two out of three nodes with sth2 or above
+  EXPECT_EQ(sth200_.tree_size(), sth.ValueOrDie().tree_size());
+}
+
+
+TEST_F(ClusterStateControllerTest, TestCalculateServingSTHAsClusterMoves) {
+  NiceMock<MockMasterElection> election_is_master;
+  EXPECT_CALL(election_is_master, IsMaster()).WillRepeatedly(Return(true));
+  ClusterStateController controller50(&pool_, base_, &url_fetcher_,
+                                      test_db_.db(), store1_.get(),
+                                      &election_is_master, &fetcher_);
+  SetClusterConfig(store1_.get(), 1 /* nodes */, 0.5 /* fraction */);
+  ct::ClusterNodeState node_state(cns100_);
+  store1_->SetClusterNodeState(node_state);
+  node_state.set_hostname(kNodeId2);
+  store2_->SetClusterNodeState(node_state);
+  node_state.set_hostname(kNodeId3);
+  store3_->SetClusterNodeState(node_state);
+  sleep(1);
+  util::StatusOr<SignedTreeHead> sth(controller50.GetCalculatedServingSTH());
+  EXPECT_EQ(sth100_.tree_size(), sth.ValueOrDie().tree_size());
+
+  node_state = cns200_;
+  node_state.set_hostname(kNodeId1);
+  store1_->SetClusterNodeState(node_state);
+  sleep(1);
+  // Node1@200
+  // Node2 and Node3 @100:
+  // Still have to serve at sth100
+  sth = controller50.GetCalculatedServingSTH();
+  EXPECT_EQ(sth100_.tree_size(), sth.ValueOrDie().tree_size());
+
+  node_state.set_hostname(kNodeId3);
+  store3_->SetClusterNodeState(node_state);
+  sleep(1);
+  // Node1 and Node3 @200
+  // Node2 @100:
+  // Can serve at sth200
+  sth = controller50.GetCalculatedServingSTH();
+  EXPECT_EQ(sth200_.tree_size(), sth.ValueOrDie().tree_size());
+
+  node_state = cns300_;
+  node_state.set_hostname(kNodeId2);
+  store2_->SetClusterNodeState(node_state);
+  sleep(1);
+  // Node1 and Node3 @200
+  // Node2 @300:
+  // Still have to serve at sth200
+  sth = controller50.GetCalculatedServingSTH();
+  EXPECT_EQ(sth200_.tree_size(), sth.ValueOrDie().tree_size());
+}
+
+
+TEST_F(ClusterStateControllerTest, TestKeepsNewerSTH) {
+  store1_->SetClusterNodeState(cns100_);
+
+  // Create a node with an identically sized but newer STH:
+  SignedTreeHead newer_sth(sth100_);
+  newer_sth.set_timestamp(newer_sth.timestamp() + 1);
+  ClusterNodeState newer_cns;
+  newer_cns.set_hostname("somenode.example.net");
+  newer_cns.set_log_port(9001);
+  *newer_cns.mutable_newest_sth() = newer_sth;
+  store2_->SetClusterNodeState(newer_cns);
+  sleep(1);
+
+  util::StatusOr<SignedTreeHead> sth(controller_.GetCalculatedServingSTH());
+  EXPECT_EQ(newer_sth.tree_size(), sth.ValueOrDie().tree_size());
+  EXPECT_EQ(newer_sth.timestamp(), sth.ValueOrDie().timestamp());
+}
+
+
+TEST_F(ClusterStateControllerTest, TestCannotSelectSmallerSTH) {
+  NiceMock<MockMasterElection> election_is_master;
+  EXPECT_CALL(election_is_master, IsMaster()).WillRepeatedly(Return(true));
+  ClusterStateController controller50(&pool_, base_, &url_fetcher_,
+                                      test_db_.db(), store1_.get(),
+                                      &election_is_master, &fetcher_);
+  SetClusterConfig(store1_.get(), 1 /* nodes */, 0.5 /* fraction */);
+
+  ct::ClusterNodeState node_state(cns200_);
+  node_state.set_hostname(kNodeId1);
+  store1_->SetClusterNodeState(node_state);
+  node_state.set_hostname(kNodeId2);
+  store2_->SetClusterNodeState(node_state);
+  node_state.set_hostname(kNodeId3);
+  store3_->SetClusterNodeState(node_state);
+  sleep(1);
+  util::StatusOr<SignedTreeHead> sth(controller50.GetCalculatedServingSTH());
+  EXPECT_EQ(sth200_.tree_size(), sth.ValueOrDie().tree_size());
+
+  node_state = cns100_;
+  node_state.set_hostname(kNodeId1);
+  store1_->SetClusterNodeState(node_state);
+  sleep(1);
+  // Node1@100
+  // Node2 and Node3 @200:
+  // Still have to serve at sth200
+  sth = controller50.GetCalculatedServingSTH();
+  EXPECT_EQ(sth200_.tree_size(), sth.ValueOrDie().tree_size());
+
+  node_state.set_hostname(kNodeId3);
+  store3_->SetClusterNodeState(node_state);
+  sleep(1);
+  // Node1 and Node3 @100
+  // Node2 @200
+  // But cannot select an earlier STH than the one we last served with, so must
+  // stick with sth200:
+  sth = controller50.GetCalculatedServingSTH();
+  EXPECT_EQ(sth200_.tree_size(), sth.ValueOrDie().tree_size());
+
+  node_state.set_hostname(kNodeId2);
+  store2_->SetClusterNodeState(node_state);
+  sleep(1);
+  // Still have to serve at sth200
+  sth = controller50.GetCalculatedServingSTH();
+  EXPECT_EQ(sth200_.tree_size(), sth.ValueOrDie().tree_size());
+}
+
+
+TEST_F(ClusterStateControllerTest, TestUsesLargestSTHWithIdenticalTimestamp) {
+  NiceMock<MockMasterElection> election_is_master;
+  EXPECT_CALL(election_is_master, IsMaster()).WillRepeatedly(Return(true));
+  ClusterStateController controller50(&pool_, base_, &url_fetcher_,
+                                      test_db_.db(), store1_.get(),
+                                      &election_is_master, &fetcher_);
+  SetClusterConfig(store1_.get(), 1 /* nodes */, 0.5 /* fraction */);
+
+  ClusterNodeState cns1;
+  cns1.set_hostname(kNodeId1);
+  cns1.set_log_port(9001);
+  cns1.mutable_newest_sth()->set_timestamp(1000);
+  cns1.mutable_newest_sth()->set_tree_size(1000);
+  store1_->SetClusterNodeState(cns1);
+
+  ClusterNodeState cns2(cns1);
+  cns2.set_hostname(kNodeId2);
+  cns2.set_log_port(9001);
+  cns2.mutable_newest_sth()->set_timestamp(1000);
+  cns2.mutable_newest_sth()->set_tree_size(1001);
+  store2_->SetClusterNodeState(cns2);
+
+  ClusterNodeState cns3;
+  cns3.set_hostname(kNodeId3);
+  cns3.set_log_port(9001);
+  cns3.mutable_newest_sth()->set_timestamp(1004);
+  cns3.mutable_newest_sth()->set_tree_size(999);
+  store3_->SetClusterNodeState(cns3);
+  sleep(2);
+
+  util::StatusOr<SignedTreeHead> sth(controller50.GetCalculatedServingSTH());
+  EXPECT_EQ(cns2.newest_sth().tree_size(), sth.ValueOrDie().tree_size());
+  EXPECT_EQ(cns2.newest_sth().timestamp(), sth.ValueOrDie().timestamp());
+}
+
+
+TEST_F(ClusterStateControllerTest, TestDoesNotReuseSTHTimestamp) {
+  NiceMock<MockMasterElection> election_is_master;
+  EXPECT_CALL(election_is_master, IsMaster()).WillRepeatedly(Return(true));
+  ClusterStateController controller50(&pool_, base_, &url_fetcher_,
+                                      test_db_.db(), store1_.get(),
+                                      &election_is_master, &fetcher_);
+  SetClusterConfig(store1_.get(), 3 /* nodes */, 1 /* fraction */);
+
+  ClusterNodeState cns1;
+  cns1.set_hostname(kNodeId1);
+  cns1.set_log_port(9001);
+  cns1.mutable_newest_sth()->set_timestamp(1002);
+  cns1.mutable_newest_sth()->set_tree_size(10);
+  store1_->SetClusterNodeState(cns1);
+
+  ClusterNodeState cns2(cns1);
+  cns2.set_hostname(kNodeId2);
+  cns2.set_log_port(9001);
+  cns2.mutable_newest_sth()->set_timestamp(1000);
+  cns2.mutable_newest_sth()->set_tree_size(11);
+  store2_->SetClusterNodeState(cns2);
+
+  ClusterNodeState cns3;
+  cns3.set_hostname(kNodeId3);
+  cns3.set_log_port(9001);
+  cns3.mutable_newest_sth()->set_timestamp(1002);
+  cns3.mutable_newest_sth()->set_tree_size(9);
+  store3_->SetClusterNodeState(cns3);
+  sleep(1);
+
+  // Have to choose cns3 (9@1002) here because we need 100% coverage:
+  util::StatusOr<SignedTreeHead> sth1(controller50.GetCalculatedServingSTH());
+  EXPECT_EQ(cns3.newest_sth().tree_size(), sth1.ValueOrDie().tree_size());
+  EXPECT_EQ(cns3.newest_sth().timestamp(), sth1.ValueOrDie().timestamp());
+
+  // Now cns3 moves to 13@1004
+  cns3.mutable_newest_sth()->set_timestamp(1004);
+  cns3.mutable_newest_sth()->set_tree_size(13);
+  store3_->SetClusterNodeState(cns3);
+  sleep(1);
+
+  // Which means that the only STH from the current set that we can serve
+  // must be 10@1002 (because coverage).
+  // However, that timestamp was already used above, so the serving STH can't
+  // have changed:
+  util::StatusOr<SignedTreeHead> sth2(controller50.GetCalculatedServingSTH());
+  EXPECT_EQ(sth1.ValueOrDie().DebugString(), sth2.ValueOrDie().DebugString());
+
+  // Now cns1 moves to 13@1003
+  cns3.mutable_newest_sth()->set_timestamp(1003);
+  cns3.mutable_newest_sth()->set_tree_size(13);
+  store3_->SetClusterNodeState(cns3);
+  sleep(1);
+
+  // Which means that the only STH from the current set that we can serve
+  // must be 11@1000 (because coverage).
+  // But that's in the past compared to Serving STH, so no dice.
+  util::StatusOr<SignedTreeHead> sth3(controller50.GetCalculatedServingSTH());
+  EXPECT_EQ(sth1.ValueOrDie().DebugString(), sth3.ValueOrDie().DebugString());
+
+  // Finally cns2 moves to 13@1006
+  cns2.mutable_newest_sth()->set_timestamp(1006);
+  cns2.mutable_newest_sth()->set_tree_size(13);
+  store2_->SetClusterNodeState(cns2);
+  // And cns1 moves to 16@1003
+  cns1.mutable_newest_sth()->set_timestamp(1006);
+  cns1.mutable_newest_sth()->set_tree_size(13);
+  store1_->SetClusterNodeState(cns1);
+  sleep(1);
+
+  // And we've got: 16@1002, 13@1006, 13@1003
+  // So the cluster can move forward with its Serving STH
+  util::StatusOr<SignedTreeHead> sth4(controller50.GetCalculatedServingSTH());
+  EXPECT_EQ(cns2.newest_sth().tree_size(), sth4.ValueOrDie().tree_size());
+  EXPECT_EQ(cns2.newest_sth().timestamp(), sth4.ValueOrDie().timestamp());
+}
+
+
+TEST_F(ClusterStateControllerTest,
+       TestConfigChangesCauseServingSTHToBeRecalculated) {
+  NiceMock<MockMasterElection> election_is_master;
+  EXPECT_CALL(election_is_master, IsMaster()).WillRepeatedly(Return(true));
+  ClusterStateController controller(&pool_, base_, &url_fetcher_,
+                                    test_db_.db(), store1_.get(),
+                                    &election_is_master, &fetcher_);
+  SetClusterConfig(store1_.get(), 0 /* nodes */, 0.5 /* fraction */);
+  store1_->SetClusterNodeState(cns100_);
+  store2_->SetClusterNodeState(cns200_);
+  store3_->SetClusterNodeState(cns300_);
+  sleep(1);
+  StatusOr<SignedTreeHead> sth(controller.GetCalculatedServingSTH());
+  EXPECT_EQ(sth200_.tree_size(), sth.ValueOrDie().tree_size());
+
+  SetClusterConfig(store1_.get(), 0 /* nodes */, 0.9 /* fraction */);
+  sleep(1);
+  sth = controller.GetCalculatedServingSTH();
+  // You might expect sth100 here, but we shouldn't move to a smaller STH
+  EXPECT_EQ(sth200_.tree_size(), sth.ValueOrDie().tree_size());
+
+  SetClusterConfig(store1_.get(), 0 /* nodes */, 0.3 /* fraction */);
+  sleep(1);
+  sth = controller.GetCalculatedServingSTH();
+  // Should be able to move to sth300 now.
+  EXPECT_EQ(sth300_.tree_size(), sth.ValueOrDie().tree_size());
+}
+
+
+TEST_F(ClusterStateControllerTest, TestGetLocalNodeState) {
+  SignedTreeHead sth;
+  sth.set_timestamp(10000);
+  sth.set_tree_size(2344);
+  controller_.NewTreeHead(sth);
+
+  ClusterNodeState state;
+  controller_.GetLocalNodeState(&state);
+  EXPECT_EQ(sth.DebugString(), state.newest_sth().DebugString());
+}
+
+
+TEST_F(ClusterStateControllerTest, TestNodeHostPort) {
+  // Allow some time for our view of the node state to stabilize and then
+  // check that it has. Ideally we would wait for this to definitely happen
+  // but there seems to be no easy way to arrange this.
+  sleep(1);
+  const ClusterNodeState orig_node_state(GetNodeStateView(kNodeId1));
+  EXPECT_EQ(kNodeId1, orig_node_state.hostname());
+  EXPECT_EQ(9001, orig_node_state.log_port());
+
+  // Now try to change the state and again allow some time for our view
+  // to update
+  const string kHost("myhostname");
+  const int kPort(9999);
+
+  controller_.SetNodeHostPort(kHost, kPort);
+  sleep(1);
+
+  const ClusterNodeState node_state(GetNodeStateView(kNodeId1));
+  EXPECT_EQ(kHost, node_state.hostname());
+  EXPECT_EQ(kPort, node_state.log_port());
+}
+
+
+TEST_F(ClusterStateControllerTest, TestStoresServingSthInDatabase) {
+  SignedTreeHead sth;
+  sth.set_timestamp(10000);
+  sth.set_tree_size(0);
+  store1_->SetServingSTH(sth);
+  sleep(1);
+
+  {
+    SignedTreeHead db_sth;
+    EXPECT_EQ(Database::LOOKUP_OK, test_db_.db()->LatestTreeHead(&db_sth));
+    EXPECT_EQ(sth.DebugString(), db_sth.DebugString());
+  }
+}
+
+
+TEST_F(ClusterStateControllerTest, TestWaitsToStoreSTHInDatabaseWhenStale) {
+  SignedTreeHead sth1;
+  sth1.set_timestamp(10000);
+  sth1.set_tree_size(0);
+  store1_->SetServingSTH(sth1);
+  sleep(1);
+
+  {
+    SignedTreeHead db_sth;
+    EXPECT_EQ(Database::LOOKUP_OK, test_db_.db()->LatestTreeHead(&db_sth));
+    EXPECT_EQ(sth1.DebugString(), db_sth.DebugString());
+  }
+
+  SignedTreeHead sth2;
+  sth2.set_timestamp(10001);
+  sth2.set_tree_size(1);
+  store1_->SetServingSTH(sth2);
+  sleep(1);
+
+  {
+    // Should still show the first STH in sth1, because the local DB
+    // doesn't have the entries under sth2 yet.
+    SignedTreeHead db_sth;
+    EXPECT_EQ(Database::LOOKUP_OK, test_db_.db()->LatestTreeHead(&db_sth));
+    EXPECT_EQ(sth1.DebugString(), db_sth.DebugString());
+  }
+
+  // Now pretend the local fetcher has got lots of new entries from another
+  // node, and the local signer has integrated them into our local tree:
+  SignedTreeHead new_local_sth;
+  new_local_sth.set_timestamp(10005);
+  new_local_sth.set_tree_size(100);
+  controller_.NewTreeHead(new_local_sth);
+
+  {
+    // Should now see the updated serving sth2
+    SignedTreeHead db_sth;
+    EXPECT_EQ(Database::LOOKUP_OK, test_db_.db()->LatestTreeHead(&db_sth));
+    EXPECT_EQ(sth2.DebugString(), db_sth.DebugString());
+  }
+}
+
+
+TEST_F(ClusterStateControllerTest, TestNodeIsStale) {
+  EXPECT_TRUE(controller_.NodeIsStale());  // no STH yet.
+
+  {
+    SignedTreeHead sth;
+    sth.set_timestamp(10000);
+    sth.set_tree_size(0);
+    store1_->SetServingSTH(sth);
+    sleep(1);
+  }
+
+  EXPECT_FALSE(controller_.NodeIsStale());  // Have an STH we can serve.
+
+  {
+    SignedTreeHead sth;
+    sth.set_timestamp(10001);
+    sth.set_tree_size(1);
+    store1_->SetServingSTH(sth);
+    sleep(1);
+  }
+
+  EXPECT_TRUE(controller_.NodeIsStale());  // DB doesn't have the leaf
+
+  {
+    LoggedEntry cert;
+    cert.RandomForTest();
+    cert.set_sequence_number(0);
+    EXPECT_EQ(Database::OK, test_db_.db()->CreateSequencedEntry(cert));
+  }
+
+  EXPECT_FALSE(controller_.NodeIsStale());
+}
+
+
+TEST_F(ClusterStateControllerTest, TestGetFreshNodes) {
+  ClusterStateController c2(&pool_, base_, &url_fetcher_, test_db_.db(),
+                            store2_.get(), &election2_, &fetcher_);
+  ClusterStateController c3(&pool_, base_, &url_fetcher_, test_db_.db(),
+                            store3_.get(), &election3_, &fetcher_);
+  store1_->SetClusterNodeState(cns100_);
+  store2_->SetClusterNodeState(cns200_);
+  store3_->SetClusterNodeState(cns300_);
+
+  {
+    vector<ClusterNodeState> fresh(controller_.GetFreshNodes());
+    EXPECT_EQ(static_cast<size_t>(0),
+              fresh.size());  // no STH yet - everyone is stale.
+  }
+
+  // The 3 nodes have states which claim to have 100, 200, and 300 certs in
+  // their DBs, iterate around setting the ServingSTH higher and higher to see
+  // that they all go stale at the appropriate time.
+  // This should knock out nodes based on store1_, store2_, store3_ in that
+  // same order.
+  const vector<vector<string>> kExpectedFreshNodes{
+      {kNodeId2, kNodeId3},  // not including ourself (kNodeId1)
+      {kNodeId2, kNodeId3},  // kNodeId1 is stale this time, so no change.
+      {kNodeId3},
+      {}};
+  for (int i = 0; i < 4; ++i) {
+    LOG(INFO) << "Iteration " << i;
+    SignedTreeHead sth;
+    sth.set_timestamp(i * 100 + 1);
+    sth.set_tree_size(i * 100 + 1);
+    store1_->SetServingSTH(sth);
+    store2_->SetServingSTH(sth);
+    store3_->SetServingSTH(sth);
+    sleep(1);
+
+    vector<string> ids;
+    for (const auto& n : controller_.GetFreshNodes()) {
+      ids.push_back(n.node_id());
+    }
+    EXPECT_EQ(ids, kExpectedFreshNodes[i]);
+  }
+}
+
+
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  ConfigureSerializerForV1CT();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cms_verifier.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cms_verifier.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cms_verifier.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cms_verifier.cc	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,233 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "log/cms_verifier.h"
+#include "log/ct_extensions.h"
+#include "util/cms_scoped_types.h"
+#include "util/openssl_scoped_types.h"
+
+using std::string;
+using std::unique_ptr;
+using util::Status;
+using util::StatusOr;
+
+namespace cert_trans {
+util::StatusOr<bool> CmsVerifier::IsCmsSignedByCert(BIO* cms_bio_in,
+                                                    const Cert& cert) const {
+  CHECK_NOTNULL(cms_bio_in);
+
+  ScopedCMS_ContentInfo cms_content_info(d2i_CMS_bio(cms_bio_in, nullptr));
+
+  if (!cms_content_info) {
+    LOG(ERROR) << "Could not parse CMS data";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return Status(util::error::INVALID_ARGUMENT,
+                  "CMS data could not be parsed");
+  }
+
+  // This stack must not be freed as it points into the CMS structure
+  STACK_OF(CMS_SignerInfo) *
+      const signers(CMS_get0_SignerInfos(cms_content_info.get()));
+
+  if (signers) {
+    for (int s = 0; s < sk_CMS_SignerInfo_num(signers); ++s) {
+      CMS_SignerInfo* const signer = sk_CMS_SignerInfo_value(signers, s);
+
+      if (CMS_SignerInfo_cert_cmp(signer, cert.x509_.get()) == 0) {
+        return true;
+      }
+    }
+  }
+
+  return false;
+}
+
+StatusOr<bool> CmsVerifier::IsCmsSignedByCert(const string& cms_object,
+                                              const Cert& cert) const {
+  // Load a source bio with the CMS signed data object and parse it
+  ScopedBIO source_bio(BIO_new(BIO_s_mem()));
+  BIO_write(source_bio.get(), cms_object.c_str(), cms_object.length());
+
+  ScopedCMS_ContentInfo cms_content_info(
+      d2i_CMS_bio(source_bio.get(), nullptr));
+
+  if (!cms_content_info) {
+    LOG(ERROR) << "Could not parse CMS data";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return Status(util::error::INVALID_ARGUMENT,
+                  "CMS data could not be parsed");
+  }
+
+  // Now that we've got the CMS unpacked check it has a valid signature using
+  // the same key as the cert. First create a certificate stack from our
+  // expected signing cert that can be used by CMS_verify.
+  ScopedWeakX509Stack validation_chain(sk_X509_new(nullptr));
+
+  sk_X509_push(validation_chain.get(), CHECK_NOTNULL(cert.x509_.get()));
+
+  // Must set CMS_NOINTERN as the RFC says certs SHOULD be omitted from the
+  // message but the client might not have obeyed this. CMS_BINARY is required
+  // to avoid MIME-related translation. CMS_NO_SIGNER_CERT_VERIFY because we
+  // will do our own checks that the chain is valid and the message may not
+  // be signed directly by a trusted cert. We don't check it's a signed data
+  // object CMS type as OpenSSL does this.
+  const int verified =
+      CMS_verify(cms_content_info.get(), validation_chain.get(), nullptr,
+                 nullptr, nullptr,
+                 CMS_NO_SIGNER_CERT_VERIFY | CMS_NOINTERN | CMS_BINARY);
+
+  if (verified != 1) {
+    // Most likely, was not CMS signed by the precert
+    return false;
+  }
+
+  // This stack must not be freed as it points into the CMS structure
+  STACK_OF(CMS_SignerInfo) *
+      const signers(CMS_get0_SignerInfos(cms_content_info.get()));
+
+  if (signers) {
+    for (int s = 0; s < sk_CMS_SignerInfo_num(signers); ++s) {
+      CMS_SignerInfo* const signer = sk_CMS_SignerInfo_value(signers, s);
+
+      if (CMS_SignerInfo_cert_cmp(signer, cert.x509_.get()) == 0) {
+        return true;
+      }
+    }
+  }
+
+  return false;
+}
+
+
+util::Status CmsVerifier::UnpackCmsDerBio(BIO* cms_bio_in, const Cert& cert,
+                                          BIO* cms_bio_out) {
+  CHECK_NOTNULL(cms_bio_in);
+
+  ScopedCMS_ContentInfo cms_content_info(d2i_CMS_bio(cms_bio_in, nullptr));
+
+  if (!cms_content_info) {
+    LOG(ERROR) << "Could not parse CMS data";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return Status(util::error::INVALID_ARGUMENT,
+                  "CMS data could not be parsed");
+  }
+
+  const ASN1_OBJECT* message_content_type(
+      CMS_get0_eContentType(cms_content_info.get()));
+  int content_type_nid = OBJ_obj2nid(message_content_type);
+  // TODO: Enforce content type here. This is not yet defined in the RFC.
+  if (content_type_nid != NID_ctV2CmsPayloadContentType) {
+    LOG(WARNING) << "CMS message content has unexpected type: "
+                 << content_type_nid;
+  }
+
+  // Create a certificate stack from our expected signing cert that can be used
+  // by CMS_verify.
+  ScopedWeakX509Stack validation_chain(sk_X509_new(nullptr));
+
+  sk_X509_push(validation_chain.get(), cert.x509_.get());
+
+  // Must set CMS_NOINTERN as the RFC says certs SHOULD be omitted from the
+  // message but the client might not have obeyed this. CMS_BINARY is required
+  // to avoid MIME-related translation. CMS_NO_SIGNER_CERT_VERIFY because we
+  // will do our own checks that the chain is valid and the message may not
+  // be signed directly by a trusted cert. We don't check it's a signed data
+  // object CMS type as OpenSSL does this.
+  int verified =
+      CMS_verify(cms_content_info.get(), validation_chain.get(), nullptr,
+                 nullptr, cms_bio_out,
+                 CMS_NO_SIGNER_CERT_VERIFY | CMS_NOINTERN | CMS_BINARY);
+
+  return (verified == 1) ? util::Status::OK
+                         : util::Status(util::error::INVALID_ARGUMENT,
+                                        "CMS verification failed");
+}
+
+
+util::Status CmsVerifier::UnpackCmsDerBio(BIO* cms_bio_in, BIO* cms_bio_out) {
+  CHECK_NOTNULL(cms_bio_in);
+  CHECK_NOTNULL(cms_bio_out);
+
+  ScopedCMS_ContentInfo cms_content_info(d2i_CMS_bio(cms_bio_in, nullptr));
+
+  if (!cms_content_info) {
+    LOG(ERROR) << "Could not parse CMS data";
+    LOG_OPENSSL_ERRORS(WARNING);
+    return Status(util::error::INVALID_ARGUMENT,
+                  "CMS data could not be parsed");
+  }
+
+  const ASN1_OBJECT* message_content_type(
+      CMS_get0_eContentType(cms_content_info.get()));
+  const int content_type_nid = OBJ_obj2nid(message_content_type);
+  // TODO: Enforce content type here. This is not yet defined in the RFC.
+  if (content_type_nid != NID_ctV2CmsPayloadContentType) {
+    LOG(WARNING) << "CMS message content has unexpected type: "
+                 << content_type_nid;
+  }
+
+  // Must set CMS_NOINTERN as the RFC says certs SHOULD be omitted from the
+  // message but the client might not have obeyed this. CMS_BINARY is required
+  // to avoid MIME-related translation. CMS_NO_SIGNER_CERT_VERIFY because we
+  // will do our own checks that the chain is valid and the message may not
+  // be signed directly by a trusted cert. CMS_NO_CONTENT_VERIFY because we
+  // can't apply the RFC mandated signature checks until we have the unpacked
+  // cert to examine. We don't check it's a signed data object CMS type as
+  // OpenSSL does this.
+  const int verified =
+      CMS_verify(cms_content_info.get(), nullptr, nullptr, nullptr,
+                 cms_bio_out, CMS_NO_SIGNER_CERT_VERIFY | CMS_NOINTERN |
+                                  CMS_BINARY | CMS_NO_CONTENT_VERIFY);
+
+  return (verified == 1) ? util::Status::OK
+                         : util::Status(util::error::INVALID_ARGUMENT,
+                                        "CMS unpack failed");
+}
+
+
+unique_ptr<Cert> CmsVerifier::UnpackCmsSignedCertificate(
+    BIO* cms_bio_in, const Cert& verify_cert) {
+  CHECK_NOTNULL(cms_bio_in);
+  ScopedBIO unpacked_bio(BIO_new(BIO_s_mem()));
+  unique_ptr<Cert> cert;
+
+  if (UnpackCmsDerBio(cms_bio_in, verify_cert, unpacked_bio.get()).ok()) {
+    // The unpacked data should be a valid DER certificate.
+    // TODO: The RFC does not yet define this as the format so this may
+    // need to change.
+    cert = Cert::FromDerBio(unpacked_bio.get());
+
+    if (!cert) {
+      LOG(WARNING) << "Could not unpack cert from CMS DER encoded data";
+    }
+  } else {
+    LOG_OPENSSL_ERRORS(ERROR);
+  }
+
+  return cert;
+}
+
+unique_ptr<Cert> CmsVerifier::UnpackCmsSignedCertificate(
+    const string& cms_object) {
+  // Load the source bio with the CMS signed data object
+  ScopedBIO source_bio(BIO_new(BIO_s_mem()));
+  BIO_write(source_bio.get(), cms_object.c_str(), cms_object.length());
+
+  ScopedBIO unpacked_bio(BIO_new(BIO_s_mem()));
+  unique_ptr<Cert> cert;
+
+  if (UnpackCmsDerBio(source_bio.get(), unpacked_bio.get()).ok()) {
+    // The unpacked data should be a valid DER certificate.
+    // TODO: The RFC does not yet define this as the format so this may
+    // need to change.
+    cert = Cert::FromDerBio(unpacked_bio.get());
+
+    if (!cert) {
+      LOG(WARNING) << "Could not unpack cert from CMS DER encoded data";
+    }
+  } else {
+    LOG_OPENSSL_ERRORS(ERROR);
+  }
+
+  return cert;
+}
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cms_verifier.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cms_verifier.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cms_verifier.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cms_verifier.h	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,76 @@
+#ifndef CERT_TRANS_LOG_CMS_VERIFIER_H_
+#define CERT_TRANS_LOG_CMS_VERIFIER_H_
+
+#include <openssl/asn1.h>
+#include <openssl/bio.h>
+#include <openssl/cms.h>
+#include <memory>
+
+#include "base/macros.h"
+#include "log/cert.h"
+#include "util/openssl_util.h"  // for LOG_OPENSSL_ERRORS
+#include "util/status.h"
+
+namespace cert_trans {
+
+class CmsVerifier {
+ public:
+  CmsVerifier() = default;
+
+  virtual ~CmsVerifier() = default;
+
+  // NOTE: CMS related API is provisional and may evolve over the near
+  // future. Public API does not refer to OpenSSL CMS data objects to
+  // allow for future use with alternate S/MIME implementations providing
+  // CMS functionality.
+
+  // Checks that a CMS_ContentInfo has a signer that matches a specified
+  // certificate. Does not verify the signature or check the payload.
+  virtual util::StatusOr<bool> IsCmsSignedByCert(BIO* cms_bio_in,
+                                                 const Cert& cert) const;
+  // Checks that a CMS_ContentInfo has a signer that matches a specified
+  // certificate. Does not verify the signature or check the payload.
+  virtual util::StatusOr<bool> IsCmsSignedByCert(const std::string& cms_object,
+                                                 const Cert& cert) const;
+
+  // Unpacks a CMS signed data object that is assumed to contain a certificate
+  // Does not do any checks on signatures or cert validity at this point,
+  // the caller must do these separately. Returns a new Cert object built from
+  // the unpacked data, which will only be valid if we successfully unpacked
+  // the CMS blob.
+  virtual std::unique_ptr<Cert> UnpackCmsSignedCertificate(
+      const std::string& cms_object);
+
+  // Unpacks a CMS signed data object that is assumed to contain a certificate
+  // If the CMS signature verifies as being signed by the supplied Cert
+  // then we return a corresponding new Cert object built from the unpacked
+  // data. If it cannot be loaded as a certificate or fails CMS signing check
+  // then an unloaded empty Cert object is returned.
+  // The caller owns the returned certificate and must free the input bio.
+  // NOTE: Certificate validity checks must be done separately. This
+  // only checks that the CMS signature is validly made by the supplied
+  // certificate.
+  virtual std::unique_ptr<Cert> UnpackCmsSignedCertificate(
+      BIO* cms_bio_in, const Cert& verify_cert);
+
+ private:
+  // Verifies that data from a DER BIO is signed by a given certificate.
+  // and writes the unwrapped content to another BIO. NULL can be passed for
+  // cms_bio_out if the caller just wishes to verify the signature. Does
+  // not free either BIO. Does not do any checks on the content of the
+  // CMS message or validate that the CMS signature is trusted to root.
+  util::Status UnpackCmsDerBio(BIO* cms_bio_in, const Cert& certChain,
+                               BIO* cms_bio_out);
+  // Writes the unwrapped content from a CMS object to another BIO. Does
+  // not free either BIO. Does not do any checks on the content of the
+  // CMS message or validate that the CMS signature is trusted to root.
+  // The unpacked data may not be a valid X.509 cert. The caller must
+  // apply any additional checks necessary.
+  util::Status UnpackCmsDerBio(BIO* cms_bio_in, BIO* cms_bio_out);
+
+  DISALLOW_COPY_AND_ASSIGN(CmsVerifier);
+};
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_CMS_VERIFIER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cms_verifier_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cms_verifier_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/cms_verifier_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/cms_verifier_test.cc	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,196 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <openssl/err.h>
+#include <openssl/evp.h>
+#include <memory>
+#include <string>
+
+#include "log/cert.h"
+#include "log/cms_verifier.h"
+#include "log/ct_extensions.h"
+#include "util/status_test_util.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+using cert_trans::Cert;
+using cert_trans::CmsVerifier;
+using cert_trans::ScopedBIO;
+using std::string;
+using std::unique_ptr;
+using std::vector;
+using util::testing::StatusIs;
+
+// Self-signed
+static const char kCaCert[] = "ca-cert.pem";
+// Issued by ca-cert.pem
+static const char kLeafCert[] = "test-cert.pem";
+// Issued by ca-cert.pem
+static const char kIntermediateCert[] = "intermediate-cert.pem";
+
+// A DER file containing a CMS signed message wrapping data that is not
+// valid DER
+static const char kCmsSignedDataTest2[] = "cms_test2.der";
+// A DER file containing a CMS signed message wrapping a DER encoded
+// certificate for test case 3 (valid signature, same signer as cert)
+static const char kCmsSignedDataTest3[] = "cms_test3.der";
+// A DER file with a CMS signed message but not signed by the same
+// key as the certificate it contains in the payload
+static const char kCmsSignedDataTest4[] = "cms_test4.der";
+// A DER file with a CMS signed message with intermediate as signer and
+// issuer of the embedded cert
+static const char kCmsSignedDataTest5[] = "cms_test5.der";
+
+// Subject name we expect in our embedded certificate CMS tests
+static const char kCmsTestSubject[] =
+    "CN=?.example.com, C=GB, ST=Wales, "
+    "L=Erw Wen, O=Certificate Transparency";
+
+namespace {
+
+unique_ptr<Cert> ReadCertFromFile(const string& filename) {
+  string content;
+  CHECK(util::ReadTextFile(filename, &content))
+      << "Could not read test data from " << filename
+      << ". Wrong --test_srcdir?";
+  unique_ptr<Cert> cert(Cert::FromPemString(content));
+  CHECK(cert.get());
+  return cert;
+}
+
+class CmsVerifierTest : public ::testing::Test {
+ protected:
+  CmsVerifierTest()
+      : cert_dir_(FLAGS_test_srcdir + "/test/testdata"),
+        cert_dir_v2_(FLAGS_test_srcdir + "/test/testdata/v2/"),
+        ca_cert_(ReadCertFromFile(cert_dir_ + "/" + kCaCert)),
+        intermediate_cert_(
+            ReadCertFromFile(cert_dir_ + "/" + kIntermediateCert)),
+        leaf_cert_(ReadCertFromFile(cert_dir_ + "/" + kLeafCert)) {
+  }
+
+  const string cert_dir_;
+  const string cert_dir_v2_;
+  const unique_ptr<Cert> ca_cert_;
+  const unique_ptr<Cert> intermediate_cert_;
+  const unique_ptr<Cert> leaf_cert_;
+  CmsVerifier verifier_;
+};
+
+
+BIO* OpenTestFileBio(const string& filename) {
+  BIO* der_bio = BIO_new_file(filename.c_str(), "r");
+
+  CHECK_NOTNULL(der_bio);
+
+  return der_bio;
+}
+
+
+TEST_F(CmsVerifierTest, CmsSignTestCase2) {
+  // In this test the embedded data is not a certificate in DER format
+  // but it doesn't get unpacked and the signature is valid.
+  ScopedBIO bio(OpenTestFileBio(cert_dir_v2_ + kCmsSignedDataTest2));
+  ASSERT_NE(bio.get(), nullptr);
+  EXPECT_TRUE(verifier_.IsCmsSignedByCert(bio.get(), *ca_cert_).ValueOrDie());
+}
+
+
+TEST_F(CmsVerifierTest, CmsSignTestCase3) {
+  // The CMS should be signed by the CA that signed the cert
+  ScopedBIO bio(OpenTestFileBio(cert_dir_v2_ + kCmsSignedDataTest3));
+  ASSERT_NE(bio.get(), nullptr);
+  EXPECT_TRUE(verifier_.IsCmsSignedByCert(bio.get(), *ca_cert_).ValueOrDie());
+}
+
+
+TEST_F(CmsVerifierTest, CmsSignTestCase4) {
+  // The CMS is not signed by the CA that signed the cert it contains
+  ScopedBIO bio(OpenTestFileBio(cert_dir_v2_ + kCmsSignedDataTest4));
+  ASSERT_NE(bio.get(), nullptr);
+  EXPECT_FALSE(verifier_.IsCmsSignedByCert(bio.get(), *ca_cert_).ValueOrDie());
+}
+
+
+TEST_F(CmsVerifierTest, CmsVerifyTestCase2) {
+  ScopedBIO bio(OpenTestFileBio(cert_dir_v2_ + kCmsSignedDataTest2));
+  unique_ptr<Cert> unpacked_cert(
+      verifier_.UnpackCmsSignedCertificate(bio.get(), *ca_cert_));
+
+  ASSERT_FALSE(unpacked_cert.get());
+}
+
+
+TEST_F(CmsVerifierTest, CmsVerifyTestCase3) {
+  // For this test the embedded cert is signed by the CA
+  ScopedBIO bio(OpenTestFileBio(cert_dir_v2_ + kCmsSignedDataTest3));
+  unique_ptr<Cert> unpacked_cert(
+      verifier_.UnpackCmsSignedCertificate(bio.get(), *ca_cert_));
+
+  ASSERT_FALSE(unpacked_cert->HasBasicConstraintCATrue().ValueOrDie());
+  ASSERT_TRUE(
+      unpacked_cert->HasExtension(NID_authority_key_identifier).ValueOrDie());
+  // We built the embedded cert with redaction so this helps to prove
+  // that it was correctly unpacked
+  ASSERT_OK(unpacked_cert->IsValidWildcardRedaction());
+  ASSERT_EQ(kCmsTestSubject, unpacked_cert->PrintSubjectName());
+}
+
+
+TEST_F(CmsVerifierTest, CmsVerifyTestCase4) {
+  // For this test the embedded cert is signed by the intermediate CA
+  ScopedBIO bio(OpenTestFileBio(cert_dir_v2_ + kCmsSignedDataTest4));
+  unique_ptr<Cert> unpacked_cert(
+      verifier_.UnpackCmsSignedCertificate(bio.get(), *ca_cert_));
+
+  ASSERT_FALSE(unpacked_cert.get());
+}
+
+
+TEST_F(CmsVerifierTest, CmsVerifyTestCase5) {
+  // For this test the embedded cert is signed by the intermediate
+  ScopedBIO bio(OpenTestFileBio(cert_dir_v2_ + kCmsSignedDataTest5));
+  unique_ptr<Cert> unpacked_cert(
+      verifier_.UnpackCmsSignedCertificate(bio.get(), *intermediate_cert_));
+
+  ASSERT_TRUE(unpacked_cert.get());
+  ASSERT_FALSE(unpacked_cert->HasBasicConstraintCATrue().ValueOrDie());
+  ASSERT_TRUE(
+      unpacked_cert->HasExtension(NID_authority_key_identifier).ValueOrDie());
+  // We built the embedded cert with redaction so this helps to prove
+  // that it was correctly unpacked
+  ASSERT_OK(unpacked_cert->IsValidWildcardRedaction());
+  ASSERT_EQ(kCmsTestSubject, unpacked_cert->PrintSubjectName());
+}
+
+
+TEST_F(CmsVerifierTest, CmsVerifyTestCase7) {
+  // For this test the embedded cert is signed by the intermediate
+  ScopedBIO bio(OpenTestFileBio(cert_dir_v2_ + kCmsSignedDataTest5));
+  unique_ptr<Cert> unpacked_cert(
+      verifier_.UnpackCmsSignedCertificate(bio.get(), *leaf_cert_));
+
+  ASSERT_FALSE(unpacked_cert.get());
+}
+
+
+TEST_F(CmsVerifierTest, CmsVerifyTestCase8) {
+  // For this test the embedded cert is signed by the intermediate
+  ScopedBIO bio(OpenTestFileBio(cert_dir_v2_ + kCmsSignedDataTest5));
+  unique_ptr<Cert> unpacked_cert(
+      verifier_.UnpackCmsSignedCertificate(bio.get(), *ca_cert_));
+
+  ASSERT_FALSE(unpacked_cert.get());
+}
+
+}  // namespace
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  OpenSSL_add_all_algorithms();
+  ERR_load_crypto_strings();
+  cert_trans::LoadCtExtensions();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/consistent_store.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/consistent_store.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/consistent_store.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/consistent_store.h	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,189 @@
+#ifndef CERT_TRANS_LOG_CONSISTENT_STORE_H_
+#define CERT_TRANS_LOG_CONSISTENT_STORE_H_
+
+#include <stdint.h>
+#include <mutex>
+#include <vector>
+
+#include "base/macros.h"
+#include "log/logged_entry.h"
+#include "proto/ct.pb.h"
+#include "util/status.h"
+#include "util/statusor.h"
+#include "util/task.h"
+
+namespace cert_trans {
+
+
+class EtcdConsistentStore;
+
+
+class EntryHandleBase {
+ public:
+  EntryHandleBase() : has_handle_(false) {
+  }
+
+  bool HasKey() const {
+    return !key_.empty();
+  }
+
+  const std::string& Key() const {
+    return key_;
+  }
+
+  void SetKey(const std::string& key) {
+    key_ = key;
+  }
+
+  bool HasHandle() const {
+    return has_handle_;
+  }
+
+  int Handle() const {
+    return handle_;
+  }
+
+  void SetHandle(int new_handle) {
+    handle_ = new_handle;
+    has_handle_ = true;
+  }
+
+  virtual bool SerializeToString(std::string* output) const = 0;
+
+ protected:
+  EntryHandleBase(int handle) : has_handle_(true), handle_(handle) {
+  }
+  EntryHandleBase(const std::string& key, int handle)
+      : key_(key), has_handle_(true), handle_(handle) {
+  }
+  EntryHandleBase(const std::string& key) : key_(key), has_handle_(false) {
+  }
+
+  std::string key_;
+  bool has_handle_;
+  int handle_;
+};
+
+
+// Wraps an instance of |T| and associates it with a versioning handle
+// (required for atomic 'compare-and-update' semantics.)
+template <class T>
+class EntryHandle : public EntryHandleBase {
+ public:
+  EntryHandle() : entry_() {
+  }
+
+  const T& Entry() const {
+    return entry_;
+  }
+
+  T* MutableEntry() {
+    return &entry_;
+  }
+
+  bool SerializeToString(std::string* output) const override {
+    return entry_.SerializeToString(output);
+  }
+
+ private:
+  EntryHandle(const T& entry, int handle)
+      : EntryHandleBase(handle), entry_(entry) {
+  }
+
+  EntryHandle(const std::string& key, const T& entry, int handle)
+      : EntryHandleBase(key, handle), entry_(entry) {
+  }
+
+  explicit EntryHandle(const std::string& key, const T& entry)
+      : EntryHandleBase(key), entry_(entry) {
+  }
+
+  void Set(const std::string& key, const T& entry, int handle) {
+    key_ = key;
+    entry_ = entry;
+    handle_ = handle;
+    has_handle_ = true;
+  }
+
+  T entry_;
+
+  friend class EtcdConsistentStore;
+  friend class EtcdConsistentStoreTest;
+};
+
+
+template <class T>
+struct Update {
+  Update(const EntryHandle<T>& handle, bool exists)
+      : handle_(handle), exists_(exists) {
+  }
+
+  Update(const Update& other) = default;
+
+  const EntryHandle<T> handle_;
+  const bool exists_;
+};
+
+
+class ConsistentStore {
+ public:
+  typedef std::function<void(const Update<ct::SignedTreeHead>& update)>
+      ServingSTHCallback;
+  typedef std::function<void(const std::vector<Update<ct::ClusterNodeState>>&
+                                 updates)> ClusterNodeStateCallback;
+  typedef std::function<void(const Update<ct::ClusterConfig>& update)>
+      ClusterConfigCallback;
+
+  ConsistentStore() = default;
+
+  virtual ~ConsistentStore() = default;
+
+  virtual util::StatusOr<int64_t> NextAvailableSequenceNumber() const = 0;
+
+  virtual util::Status SetServingSTH(const ct::SignedTreeHead& new_sth) = 0;
+
+  virtual util::StatusOr<ct::SignedTreeHead> GetServingSTH() const = 0;
+
+  virtual util::Status AddPendingEntry(LoggedEntry* entry) = 0;
+
+  virtual util::Status GetPendingEntryForHash(
+      const std::string& hash, EntryHandle<LoggedEntry>* entry) const = 0;
+
+  virtual util::Status GetPendingEntries(
+      std::vector<EntryHandle<LoggedEntry>>* entries) const = 0;
+
+  virtual util::Status GetSequenceMapping(
+      EntryHandle<ct::SequenceMapping>* entry) const = 0;
+
+  virtual util::Status UpdateSequenceMapping(
+      EntryHandle<ct::SequenceMapping>* entry) = 0;
+
+  virtual util::StatusOr<ct::ClusterNodeState> GetClusterNodeState() const = 0;
+
+  virtual util::Status SetClusterNodeState(
+      const ct::ClusterNodeState& state) = 0;
+
+  virtual void WatchServingSTH(const ServingSTHCallback& cb,
+                               util::Task* task) = 0;
+
+  virtual void WatchClusterNodeStates(const ClusterNodeStateCallback& cb,
+                                      util::Task* task) = 0;
+
+  virtual void WatchClusterConfig(const ClusterConfigCallback& cb,
+                                  util::Task* task) = 0;
+
+  virtual util::Status SetClusterConfig(const ct::ClusterConfig& config) = 0;
+
+  // Cleans up entries in the store according to the implementation's policy.
+  // Returns either the number of entries cleaned up, or a Status describing
+  // the error.
+  virtual util::StatusOr<int64_t> CleanupOldEntries() = 0;
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(ConsistentStore);
+};
+
+
+}  // namespace
+
+#endif  // CERT_TRANS_LOG_CONSISTENT_STORE_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/ct_extensions.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/ct_extensions.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/ct_extensions.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/ct_extensions.cc	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,216 @@
+#include "log/ct_extensions.h"
+
+#include <glog/logging.h>
+#include <openssl/asn1.h>
+#include <openssl/asn1t.h>
+#include <openssl/objects.h>
+#include <openssl/x509v3.h>
+#include <string.h>
+
+namespace cert_trans {
+
+int NID_ctSignedCertificateTimestampList = 0;
+int NID_ctEmbeddedSignedCertificateTimestampList = 0;
+int NID_ctPoison = 0;
+int NID_ctPrecertificateSigning = 0;
+int NID_ctPrecertificateRedactedLabelCount = 0;
+int NID_ctNameConstraintNologIntermediateCa = 0;
+int NID_ctV2CmsPayloadContentType = 0;
+
+// The SCT list in the extension of a superfluous certificate
+const char kSCTListOID[] = "1.3.6.1.4.1.11129.2.4.1";
+// The SCT list embedded in the certificate itself
+const char kEmbeddedSCTListOID[] = "1.3.6.1.4.1.11129.2.4.2";
+// Extension indicating consent that certs from an intermediate CA with name
+// constraints may not be logged (not used in V1)
+const char kNameConstraintNologIntermediateOID[] = "1.3.6.1.4.1.11129.2.4.7";
+// The poison extension
+const char kPoisonOID[] = "1.3.6.1.4.1.11129.2.4.3";
+// Extension for wildcard redacted Precertificate indicating redaction count
+// (not used in V1)
+const char kPrecertificateRedactedLabelOID[] = "1.3.6.1.4.1.11129.2.4.6";
+// Extended Key Usage value for Precertificate signing
+const char kPrecertificateSigningOID[] = "1.3.6.1.4.1.11129.2.4.4";
+// V2 Precert content type
+// TODO: Required content type not defined in draft yet. Placeholder in case
+// we use our own.
+const char kV2PrecertificateCmsContentTypeOID[] = "1.3.6.1.4.1.11129.2.4.8";
+
+static const char kSCTListSN[] = "ctSCT";
+static const char kSCTListLN[] =
+    "X509v3 Certificate Transparency Signed Certificate Timestamp List";
+
+static const char kEmbeddedSCTListSN[] = "ctEmbeddedSCT";
+static const char kEmbeddedSCTListLN[] =
+    "X509v3 Certificate Transparency "
+    "Embedded Signed Certificate Timestamp List";
+static const char kPoisonSN[] = "ctPoison";
+static const char kPoisonLN[] = "X509v3 Certificate Transparency Poison";
+static const char kPrecertificateSigningSN[] = "ctPresign";
+static const char kPrecertificateSigningLN[] =
+    "Certificate Transparency "
+    "Precertificate Signing";
+static const char kPrecertificateRedactedLabelCountSN[] = "ctPreredact";
+static const char kPrecertificateRedactedLabelCountLN[] =
+    "Certificate Transparency "
+    "Precertificate Redacted Label Count";
+static const char kNameConstraintNologIntermediateSN[] =
+    "ctNoLogIntermediateOk";
+static const char kNameConstraintNologIntermediateLN[] =
+    "Certificate Transparency "
+    "Name Constrained Intermediate CA NoLog Allowed";
+static const char kV2PrecertCmsContentTypeSN[] = "ctV2PrecertCmsContentType";
+static const char kV2PrecertCmsContentTypeLN[] =
+    "Certificate Transparency "
+    "V2 Precertificate CMS Message Content Type";
+
+static const char kASN1NullValue[] = "NULL";
+
+// String conversion for an ASN1 NULL
+static char* ASN1NullToString(X509V3_EXT_METHOD*, ASN1_NULL* asn1_null) {
+  if (asn1_null == NULL)
+    return NULL;
+  char* buf = strdup(kASN1NullValue);
+  return buf;
+}
+
+// String conversion from an ASN1:NULL conf.
+static ASN1_NULL* StringToASN1Null(X509V3_EXT_METHOD*, X509V3_CTX*,
+                                   char* str) {
+  if (str == NULL || strcmp(str, kASN1NullValue) != 0) {
+    return NULL;
+  }
+
+  return ASN1_NULL_new();
+}
+
+// clang-format off
+static X509V3_EXT_METHOD ct_sctlist_method = {
+    0,  // ext_nid, NID, will be created by OBJ_create()
+    0,  // flags
+    ASN1_ITEM_ref(ASN1_OCTET_STRING),  // the object is an octet string
+    0, 0, 0, 0,                        // ignored since the field above is set
+    // Create from, and print to, a hex string
+    // Allows to specify the extension configuration like so:
+    // ctSCT = <hexstring_value>
+    // (Unused - we just plumb the bytes in the fake cert directly.)
+    reinterpret_cast<X509V3_EXT_I2S>(i2s_ASN1_OCTET_STRING),
+    reinterpret_cast<X509V3_EXT_S2I>(s2i_ASN1_OCTET_STRING), 0, 0, 0, 0,
+    NULL  // usr_data
+};
+
+static X509V3_EXT_METHOD ct_embeddedsctlist_method = {
+    0,  // ext_nid, NID, will be created by OBJ_create()
+    0,  // flags
+    ASN1_ITEM_ref(ASN1_OCTET_STRING),  // the object is an octet string
+    0, 0, 0, 0,                        // ignored since the field above is set
+    // Create from, and print to, a hex string
+    // Allows to specify the extension configuration like so:
+    // ctEmbeddedSCT = <hexstring_value>
+    // (Unused, as we're not issuing certs.)
+    reinterpret_cast<X509V3_EXT_I2S>(i2s_ASN1_OCTET_STRING),
+    reinterpret_cast<X509V3_EXT_S2I>(s2i_ASN1_OCTET_STRING), 0, 0, 0, 0,
+    NULL  // usr_data
+};
+
+static X509V3_EXT_METHOD ct_poison_method = {
+    0,                         // ext_nid, NID, will be created by OBJ_create()
+    0,                         // flags
+    ASN1_ITEM_ref(ASN1_NULL),  // the object is an ASN1 NULL
+    0, 0, 0, 0,                // ignored since the above is set
+    // Create from, and print to, a hex string
+    // Allows to specify the extension configuration like so:
+    // ctPoison = "NULL"
+    // (Unused, as we're not issuing certs.)
+    reinterpret_cast<X509V3_EXT_I2S>(ASN1NullToString),
+    reinterpret_cast<X509V3_EXT_S2I>(StringToASN1Null), 0, 0, 0, 0,
+    NULL  // usr_data
+};
+
+// Not used in protocol v1. Specifies the count of redacted labels of each
+// DNS id in the cert. See RFC section 3.2.2.
+static X509V3_EXT_METHOD ct_redaction_count_method = {
+    0,                         // ext_nid, NID, will be created by OBJ_create()
+    0,                         // flags
+    ASN1_ITEM_ref(REDACTED_LABEL_COUNT),
+    0, 0, 0, 0,                // ignored since the above is set
+    // Create from, and print to, a hex string
+    // Allows to specify the extension configuration like so:
+    // ctPreredact = "NULL"
+    // (Unused, as we're not issuing certs.)
+    reinterpret_cast<X509V3_EXT_I2S>(i2s_ASN1_OCTET_STRING),
+    reinterpret_cast<X509V3_EXT_S2I>(s2i_ASN1_OCTET_STRING), 0, 0, 0, 0,
+    NULL  // usr_data
+};
+
+// Not used in protocol v1. Specifies consent that name constrained
+// intermediate certs may not be logged. See RFC section 3.2.3.
+static X509V3_EXT_METHOD ct_name_constraint_nolog_intermediate_ca_method = {
+    0,                         // ext_nid, NID, will be created by OBJ_create()
+    0,                         // flags
+    ASN1_ITEM_ref(ASN1_NULL),  // the object is an ASN1 NULL
+    0, 0, 0, 0,                // ignored since the above is set
+    // Create from, and print to, a hex string
+    // Allows to specify the extension configuration like so:
+    // ctPoison = "NULL"
+    // (Unused, as we're not issuing certs.)
+    reinterpret_cast<X509V3_EXT_I2S>(ASN1NullToString),
+    reinterpret_cast<X509V3_EXT_S2I>(StringToASN1Null), 0, 0, 0, 0,
+    NULL  // usr_data
+};
+// clang-format on
+
+void LoadCtExtensions() {
+  // V1 Certificate Extensions
+
+  ct_sctlist_method.ext_nid = OBJ_create(kSCTListOID, kSCTListSN, kSCTListLN);
+  CHECK_NE(ct_sctlist_method.ext_nid, 0);
+  CHECK_EQ(1, X509V3_EXT_add(&ct_sctlist_method));
+  NID_ctSignedCertificateTimestampList = ct_sctlist_method.ext_nid;
+
+  ct_embeddedsctlist_method.ext_nid =
+      OBJ_create(kEmbeddedSCTListOID, kEmbeddedSCTListSN, kEmbeddedSCTListLN);
+  CHECK_NE(ct_embeddedsctlist_method.ext_nid, 0);
+  CHECK_EQ(1, X509V3_EXT_add(&ct_embeddedsctlist_method));
+  NID_ctEmbeddedSignedCertificateTimestampList =
+      ct_embeddedsctlist_method.ext_nid;
+
+  ct_poison_method.ext_nid = OBJ_create(kPoisonOID, kPoisonSN, kPoisonLN);
+  CHECK_NE(ct_poison_method.ext_nid, 0);
+  CHECK_EQ(1, X509V3_EXT_add(&ct_poison_method));
+  NID_ctPoison = ct_poison_method.ext_nid;
+
+  int precert_signing_nid =
+      OBJ_create(kPrecertificateSigningOID, kPrecertificateSigningSN,
+                 kPrecertificateSigningLN);
+  CHECK_NE(precert_signing_nid, 0);
+  NID_ctPrecertificateSigning = precert_signing_nid;
+
+  // V2 Certificate extensions
+
+  ct_redaction_count_method.ext_nid =
+      OBJ_create(kPrecertificateRedactedLabelOID,
+                 kPrecertificateRedactedLabelCountSN,
+                 kPrecertificateRedactedLabelCountLN);
+  CHECK_NE(ct_redaction_count_method.ext_nid, 0);
+  CHECK_EQ(1, X509V3_EXT_add(&ct_redaction_count_method));
+  NID_ctPrecertificateRedactedLabelCount = ct_redaction_count_method.ext_nid;
+
+  ct_name_constraint_nolog_intermediate_ca_method.ext_nid =
+      OBJ_create(kNameConstraintNologIntermediateOID,
+                 kNameConstraintNologIntermediateSN,
+                 kNameConstraintNologIntermediateLN);
+  CHECK_NE(ct_name_constraint_nolog_intermediate_ca_method.ext_nid, 0);
+  CHECK_EQ(1,
+           X509V3_EXT_add(&ct_name_constraint_nolog_intermediate_ca_method));
+  NID_ctNameConstraintNologIntermediateCa =
+      ct_name_constraint_nolog_intermediate_ca_method.ext_nid;
+
+  // V2 Content types
+
+  NID_ctV2CmsPayloadContentType =
+      OBJ_create(kV2PrecertificateCmsContentTypeOID,
+                 kV2PrecertCmsContentTypeSN, kV2PrecertCmsContentTypeLN);
+}
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/ct_extensions.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/ct_extensions.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/ct_extensions.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/ct_extensions.h	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,49 @@
+#ifndef CERT_TRANS_LOG_CT_EXTENSIONS_H_
+#define CERT_TRANS_LOG_CT_EXTENSIONS_H_
+
+#include <openssl/asn1t.h>
+
+namespace cert_trans {
+
+// One-time initializer for loading CT-specific certificate extensions.
+void LoadCtExtensions();
+
+// Defines structure for redacted label count to hold a stack of integers
+typedef struct RedactedLabelCount_st {
+  STACK_OF(ASN1_INTEGER) * redacted_labels;
+} REDACTED_LABEL_COUNT;
+
+// Defines asn.1 for redacted label count as a SEQUENCE OF ASN1_INTEGER
+ASN1_SEQUENCE(REDACTED_LABEL_COUNT) = {
+    ASN1_SEQUENCE_OF(REDACTED_LABEL_COUNT, redacted_labels, ASN1_INTEGER),
+} ASN1_SEQUENCE_END(REDACTED_LABEL_COUNT);
+
+// Numerical identifiers.
+// You must call LoadCtExtensions() for these to work.
+extern int NID_ctSignedCertificateTimestampList;
+extern int NID_ctEmbeddedSignedCertificateTimestampList;
+extern int NID_ctPoison;
+extern int NID_ctPrecertificateSigning;
+// V2 numerical identifiers
+extern int NID_ctPrecertificateRedactedLabelCount;
+extern int NID_ctNameConstraintNologIntermediateCa;
+// V2 payload content type
+extern int NID_ctV2CmsPayloadContentType;
+
+// The official CT OIDs
+// The SCT list in the extension of a superfluous certificate
+extern const char kSCTListOID[];
+// The SCT list embedded in the certificate itself
+extern const char kEmbeddedSCTListOID[];
+// The poison extension
+extern const char kPoisonOID[];
+// Extended Key Usage value for Precertificate signing
+extern const char kPrecertificateSigningOID[];
+// Name constrained intermediate CA may not be logged
+extern const char kNameConstraintNologIntermediateOID[];
+// Content type name for Precert V2
+extern const char kV2PrecertPayloadContentType[];
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_CT_EXTENSIONS_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/ct_extensions_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/ct_extensions_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/ct_extensions_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/ct_extensions_test.cc	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,198 @@
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <openssl/bio.h>
+#include <openssl/x509.h>
+#include <openssl/x509v3.h>
+#include <string>
+
+#include "log/cert.h"
+#include "log/ct_extensions.h"
+#include "util/openssl_scoped_types.h"
+#include "util/status_test_util.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+namespace cert_trans {
+
+using std::string;
+using std::unique_ptr;
+using util::StatusOr;
+
+static const char kSimpleCert[] = "test-cert.pem";
+static const char kSimpleCaCert[] = "ca-cert.pem";
+static const char kFakeCertWithSCT[] = "test-cert-proof.pem";
+static const char kCertWithPrecertSigning[] = "ca-pre-cert.pem";
+static const char kCertWithPoison[] = "test-embedded-pre-cert.pem";
+static const char kCertWithEmbeddedSCT[] = "test-embedded-cert.pem";
+
+class CtExtensionsTest : public ::testing::Test {
+ protected:
+  string simple_cert_;
+  string simple_ca_cert_;
+  string sct_cert_;
+  string pre_signing_cert_;
+  string poison_cert_;
+  string embedded_sct_cert_;
+
+  void SetUp() {
+    const string cert_dir(FLAGS_test_srcdir + "/test/testdata");
+    CHECK(util::ReadTextFile(cert_dir + "/" + kSimpleCert, &simple_cert_))
+        << "Could not read test data from " << cert_dir
+        << ". Wrong --test_srcdir?";
+    CHECK(
+        util::ReadTextFile(cert_dir + "/" + kSimpleCaCert, &simple_ca_cert_));
+    CHECK(util::ReadTextFile(cert_dir + "/" + kFakeCertWithSCT, &sct_cert_));
+    CHECK(util::ReadTextFile(cert_dir + "/" + kCertWithPrecertSigning,
+                             &pre_signing_cert_));
+    CHECK(util::ReadTextFile(cert_dir + "/" + kCertWithPoison, &poison_cert_));
+    CHECK(util::ReadTextFile(cert_dir + "/" + kCertWithEmbeddedSCT,
+                             &embedded_sct_cert_));
+  }
+};
+
+TEST_F(CtExtensionsTest, TestSCTExtension) {
+  // Sanity check
+  const unique_ptr<Cert> simple_cert(Cert::FromPemString(simple_cert_));
+  ASSERT_TRUE(simple_cert.get());
+  EXPECT_FALSE(
+      simple_cert
+          ->HasExtension(cert_trans::NID_ctSignedCertificateTimestampList)
+          .ValueOrDie());
+
+  const unique_ptr<Cert> sct_cert(Cert::FromPemString(sct_cert_));
+  ASSERT_TRUE(sct_cert.get());
+  // Check we can find the extension by its advertised NID.
+  // We should really be checking that the OID matches the expected OID but
+  // what other extension could this cert be having that the other one doesn't?
+  ASSERT_TRUE(
+      sct_cert->HasExtension(cert_trans::NID_ctSignedCertificateTimestampList)
+          .ValueOrDie());
+
+  string ext_data;
+  EXPECT_OK(sct_cert->OctetStringExtensionData(
+      cert_trans::NID_ctSignedCertificateTimestampList, &ext_data));
+  EXPECT_FALSE(ext_data.empty());
+
+  // Now fish the extension data out using the print methods and check they
+  // operate as expected.
+  // TODO(ekasper):
+  const StatusOr<X509_EXTENSION*> ext(sct_cert->GetExtension(
+      cert_trans::NID_ctSignedCertificateTimestampList));
+  ASSERT_OK(ext);
+  ScopedBIO buf(BIO_new(BIO_s_mem()));
+  ASSERT_NE(buf.get(), static_cast<BIO*>(NULL));
+
+  EXPECT_EQ(1, X509V3_EXT_print(buf.get(), ext.ValueOrDie(), 0, 0));
+  CHECK_EQ(1, BIO_write(buf.get(), "", 1));  // NULL-terminate
+  char* result;
+  BIO_get_mem_data(buf.get(), &result);
+
+  // Should be printing the octet string contents in hex.
+  EXPECT_STRCASEEQ(util::HexString(ext_data, ':').c_str(), result);
+}
+
+TEST_F(CtExtensionsTest, TestEmbeddedSCTExtension) {
+  // Sanity check
+  const unique_ptr<Cert> simple_cert(Cert::FromPemString(simple_cert_));
+  ASSERT_TRUE(simple_cert.get());
+  EXPECT_FALSE(
+      simple_cert
+          ->HasExtension(
+              cert_trans::NID_ctEmbeddedSignedCertificateTimestampList)
+          .ValueOrDie());
+
+  const unique_ptr<Cert> embedded_sct_cert(
+      Cert::FromPemString(embedded_sct_cert_));
+  ASSERT_TRUE(embedded_sct_cert.get());
+  // Check we can find the extension by its advertised NID.
+  // We should really be checking that the OID matches the expected OID but
+  // what other extension could this cert be having that the other one doesn't?
+  ASSERT_TRUE(embedded_sct_cert
+                  ->HasExtension(
+                      cert_trans::NID_ctEmbeddedSignedCertificateTimestampList)
+                  .ValueOrDie());
+  string ext_data;
+  EXPECT_OK(embedded_sct_cert->OctetStringExtensionData(
+      cert_trans::NID_ctEmbeddedSignedCertificateTimestampList, &ext_data));
+  EXPECT_FALSE(ext_data.empty());
+
+  // Now fish the extension data out using the print methods and check they
+  // operate as expected.
+  const StatusOr<X509_EXTENSION*> ext(embedded_sct_cert->GetExtension(
+      cert_trans::NID_ctEmbeddedSignedCertificateTimestampList));
+  ASSERT_OK(ext);
+  ScopedBIO buf(BIO_new(BIO_s_mem()));
+  ASSERT_NE(buf.get(), static_cast<BIO*>(NULL));
+
+  EXPECT_EQ(1, X509V3_EXT_print(buf.get(), ext.ValueOrDie(), 0, 0));
+  CHECK_EQ(1, BIO_write(buf.get(), "", 1));  // NULL-terminate
+  char* result;
+  BIO_get_mem_data(buf.get(), &result);
+
+  // Should be printing the octet string contents in hex.
+  EXPECT_STRCASEEQ(util::HexString(ext_data, ':').c_str(), result);
+}
+
+TEST_F(CtExtensionsTest, TestPoisonExtension) {
+  // Sanity check
+  const unique_ptr<Cert> simple_cert(Cert::FromPemString(simple_cert_));
+  ASSERT_TRUE(simple_cert.get());
+  EXPECT_FALSE(
+      simple_cert->HasExtension(cert_trans::NID_ctPoison).ValueOrDie());
+
+  const unique_ptr<Cert> poison_cert(Cert::FromPemString(poison_cert_));
+  ASSERT_TRUE(poison_cert.get());
+  // Check we can find the extension by its advertised NID.
+  // We should really be checking that the OID matches the expected OID but
+  // what other extension could this cert be having that the other one doesn't?
+  ASSERT_TRUE(
+      poison_cert->HasExtension(cert_trans::NID_ctPoison).ValueOrDie());
+
+  // Now fish the extension data out using the print methods and check they
+  // operate as expected.
+  const StatusOr<X509_EXTENSION*> ext(
+      poison_cert->GetExtension(cert_trans::NID_ctPoison));
+  ASSERT_OK(ext);
+
+  ScopedBIO buf(BIO_new(BIO_s_mem()));
+  ASSERT_NE(buf.get(), static_cast<BIO*>(NULL));
+
+  EXPECT_EQ(1, X509V3_EXT_print(buf.get(), ext.ValueOrDie(), 0, 0));
+  CHECK_EQ(1, BIO_write(buf.get(), "", 1));  // NULL-terminate
+  char* result;
+  BIO_get_mem_data(buf.get(), &result);
+
+  // Should be printing "NULL".
+  EXPECT_STREQ("NULL", result);
+}
+
+TEST_F(CtExtensionsTest, TestPrecertSigning) {
+  // Sanity check
+  const unique_ptr<Cert> simple_ca_cert(Cert::FromPemString(simple_ca_cert_));
+  ASSERT_TRUE(simple_ca_cert.get());
+  EXPECT_FALSE(
+      simple_ca_cert
+          ->HasExtendedKeyUsage(cert_trans::NID_ctPrecertificateSigning)
+          .ValueOrDie());
+
+  const unique_ptr<Cert> pre_signing_cert(
+      Cert::FromPemString(pre_signing_cert_));
+  ASSERT_TRUE(pre_signing_cert.get());
+  // Check we can find the key usage by its advertised NID.
+  // We should really be checking that the OID matches the expected OID but
+  // what other key usage could this cert be having that the other one doesn't?
+  ASSERT_TRUE(
+      pre_signing_cert
+          ->HasExtendedKeyUsage(cert_trans::NID_ctPrecertificateSigning)
+          .ValueOrDie());
+}
+
+}  // namespace cert_trans
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  OpenSSL_add_all_algorithms();
+  cert_trans::LoadCtExtensions();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/database.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/database.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/database.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/database.cc	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,32 @@
+#include "log/database.h"
+
+namespace cert_trans {
+
+
+DatabaseNotifierHelper::~DatabaseNotifierHelper() {
+  CHECK(callbacks_.empty());
+}
+
+
+void DatabaseNotifierHelper::Add(const NotifySTHCallback* callback) {
+  CHECK(callbacks_.insert(callback).second);
+}
+
+
+void DatabaseNotifierHelper::Remove(const NotifySTHCallback* callback) {
+  Map::iterator it(callbacks_.find(callback));
+  CHECK(it != callbacks_.end());
+
+  callbacks_.erase(it);
+}
+
+
+void DatabaseNotifierHelper::Call(const ct::SignedTreeHead& sth) const {
+  for (Map::const_iterator it = callbacks_.begin(); it != callbacks_.end();
+       ++it) {
+    (**it)(sth);
+  }
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/database.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/database.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/database.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/database.h	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,167 @@
+#ifndef CERT_TRANS_LOG_DATABASE_H_
+#define CERT_TRANS_LOG_DATABASE_H_
+
+#include <glog/logging.h>
+#include <stdint.h>
+#include <functional>
+#include <memory>
+#include <set>
+
+#include "base/macros.h"
+#include "log/logged_entry.h"
+#include "proto/ct.pb.h"
+
+namespace cert_trans {
+
+// This is a database interface for the log server.
+//
+// Implementations of this interface MUST provide for the same
+// certificate being sequenced multiple times in the tree.
+//
+// Although the log server implementation which uses this database
+// interface should not allow duplicate entries to be created, this
+// code base will also support running in a log mirroring mode, and
+// since the RFC does not forbid the same certificate appearing
+// multiple times in a log 3rd party logs may exhibit this behavour
+// the mirror must permit it too.
+
+
+class ReadOnlyDatabase {
+ public:
+  typedef std::function<void(const ct::SignedTreeHead&)> NotifySTHCallback;
+
+  enum LookupResult {
+    LOOKUP_OK,
+    NOT_FOUND,
+  };
+
+  class Iterator {
+   public:
+    Iterator() = default;
+    virtual ~Iterator() = default;
+
+    // If there is an entry available, fill *entry and return true,
+    // otherwise return false.
+    virtual bool GetNextEntry(LoggedEntry* entry) = 0;
+
+   private:
+    DISALLOW_COPY_AND_ASSIGN(Iterator);
+  };
+
+  virtual ~ReadOnlyDatabase() = default;
+
+  // Look up by hash. If the entry exists write the result. If the
+  // entry is not logged return NOT_FOUND.
+  virtual LookupResult LookupByHash(const std::string& hash,
+                                    LoggedEntry* result) const = 0;
+
+  // Look up by sequence number.
+  virtual LookupResult LookupByIndex(int64_t sequence_number,
+                                     LoggedEntry* result) const = 0;
+
+  // Return the tree head with the freshest timestamp.
+  virtual LookupResult LatestTreeHead(ct::SignedTreeHead* result) const = 0;
+
+  // Scan the entries, starting with the given index.
+  virtual std::unique_ptr<Iterator> ScanEntries(int64_t start_index) const = 0;
+
+  // Return the number of entries of contiguous entries (what could be
+  // put in a signed tree head). This can be greater than the tree
+  // size returned by LatestTreeHead.
+  virtual int64_t TreeSize() const = 0;
+
+  // Add/remove a callback to be called when a new tree head is
+  // available. The pointer is used as a key, so it should be the same
+  // in matching add/remove calls.
+  //
+  // When adding a callback, if we have a current tree head, it will
+  // be called right away with that tree head.
+  //
+  // As a sanity check, all callbacks must be removed before the
+  // database instance is destroyed.
+  virtual void AddNotifySTHCallback(const NotifySTHCallback* callback) = 0;
+  virtual void RemoveNotifySTHCallback(const NotifySTHCallback* callback) = 0;
+
+  virtual void InitializeNode(const std::string& node_id) = 0;
+  virtual LookupResult NodeId(std::string* node_id) = 0;
+
+ protected:
+  ReadOnlyDatabase() = default;
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(ReadOnlyDatabase);
+};
+
+
+class Database : public ReadOnlyDatabase {
+ public:
+  enum WriteResult {
+    OK,
+    // Create failed, certificate hash is primary key and must exist.
+    MISSING_CERTIFICATE_HASH,
+    // Create failed, an entry with this hash already exists.
+    DUPLICATE_CERTIFICATE_HASH,
+    // Update failed, entry does not exist.
+    ENTRY_NOT_FOUND,
+    // Another entry has this sequence number already.
+    SEQUENCE_NUMBER_ALREADY_IN_USE,
+    // Timestamp is primary key, it must exist and be unique,
+    DUPLICATE_TREE_HEAD_TIMESTAMP,
+    MISSING_TREE_HEAD_TIMESTAMP,
+  };
+
+  virtual ~Database() = default;
+
+  // Attempt to create a new entry with the status LOGGED.
+  // Fail if an entry with this hash already exists.
+  WriteResult CreateSequencedEntry(const LoggedEntry& logged) {
+    CHECK(logged.has_sequence_number());
+    CHECK_GE(logged.sequence_number(), 0);
+    return CreateSequencedEntry_(logged);
+  }
+
+  // Attempt to write a tree head. Fails only if a tree head with this
+  // timestamp already exists (i.e., |timestamp| is primary key). Does
+  // not check that the timestamp is newer than previous entries.
+  WriteResult WriteTreeHead(const ct::SignedTreeHead& sth) {
+    if (!sth.has_timestamp())
+      return MISSING_TREE_HEAD_TIMESTAMP;
+    return WriteTreeHead_(sth);
+  }
+
+ protected:
+  Database() = default;
+
+  // See the inline methods with similar names defined above for more
+  // documentation.
+  virtual WriteResult CreateSequencedEntry_(const LoggedEntry& logged) = 0;
+  virtual WriteResult WriteTreeHead_(const ct::SignedTreeHead& sth) = 0;
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(Database);
+};
+
+
+class DatabaseNotifierHelper {
+ public:
+  typedef std::function<void(const ct::SignedTreeHead&)> NotifySTHCallback;
+
+  DatabaseNotifierHelper() = default;
+  ~DatabaseNotifierHelper();
+
+  void Add(const NotifySTHCallback* callback);
+  void Remove(const NotifySTHCallback* callback);
+  void Call(const ct::SignedTreeHead& sth) const;
+
+ private:
+  typedef std::set<const NotifySTHCallback*> Map;
+
+  Map callbacks_;
+
+  DISALLOW_COPY_AND_ASSIGN(DatabaseNotifierHelper);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_DATABASE_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/database_large_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/database_large_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/database_large_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/database_large_test.cc	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,123 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <stdlib.h>
+#include <sys/resource.h>
+#include <set>
+#include <string>
+
+#include "log/database.h"
+#include "log/file_db.h"
+#include "log/file_storage.h"
+#include "log/leveldb_db.h"
+#include "log/logged_entry.h"
+#include "log/sqlite_db.h"
+#include "log/test_db.h"
+#include "log/test_signer.h"
+#include "proto/cert_serializer.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+DEFINE_int32(database_size, 100,
+             "Number of entries to put in the test database. Be careful "
+             "choosing this, as the database will fill up your disk (entries "
+             "are a few kB each). Maximum is limited to 1 000 000. Also note "
+             "that SQLite may be very slow with small batch sizes.");
+
+namespace {
+
+using cert_trans::Database;
+using cert_trans::FileDB;
+using cert_trans::LevelDB;
+using cert_trans::LoggedEntry;
+using cert_trans::SQLiteDB;
+using std::string;
+
+
+template <class T>
+class LargeDBTest : public ::testing::Test {
+ protected:
+  LargeDBTest() : test_db_(), test_signer_() {
+  }
+
+  ~LargeDBTest() {
+  }
+
+  void FillDatabase(int entries) {
+    LoggedEntry logged_cert;
+    for (int i = 0; i < entries; ++i) {
+      test_signer_.CreateUniqueFakeSignature(&logged_cert);
+      logged_cert.set_sequence_number(i);
+      EXPECT_EQ(Database::OK, db()->CreateSequencedEntry(logged_cert));
+    }
+  }
+
+  int ReadAllSequencedEntries(int num) {
+    std::set<string>::const_iterator it;
+    LoggedEntry lookup_cert;
+    for (int i = 0; i < num; ++i) {
+      EXPECT_EQ(Database::LOOKUP_OK,
+                this->db()->LookupByIndex(i, &lookup_cert));
+    }
+    return num;
+  }
+
+  T* db() const {
+    return test_db_.db();
+  }
+
+  TestDB<T> test_db_;
+  TestSigner test_signer_;
+};
+
+typedef testing::Types<FileDB, SQLiteDB, LevelDB> Databases;
+
+TYPED_TEST_CASE(LargeDBTest, Databases);
+
+TYPED_TEST(LargeDBTest, Benchmark) {
+  int entries = FLAGS_database_size;
+  CHECK_GE(entries, 0);
+  int original_log_level = FLAGS_minloglevel;
+
+  struct rusage ru_before, ru_after;
+  getrusage(RUSAGE_SELF, &ru_before);
+  uint64_t realtime_before, realtime_after;
+  realtime_before = util::TimeInMilliseconds();
+  this->FillDatabase(entries);
+  realtime_after = util::TimeInMilliseconds();
+  getrusage(RUSAGE_SELF, &ru_after);
+
+  FLAGS_minloglevel = 0;
+  LOG(INFO) << "Real time spent creating " << FLAGS_database_size
+            << " entries: " << realtime_after - realtime_before << " ms";
+  LOG(INFO) << "Peak RSS delta (as reported by getrusage()) was "
+            << ru_after.ru_maxrss - ru_before.ru_maxrss << " kB";
+  FLAGS_minloglevel = original_log_level;
+
+  getrusage(RUSAGE_SELF, &ru_before);
+  realtime_before = util::TimeInMilliseconds();
+  CHECK_EQ(FLAGS_database_size,
+           this->ReadAllSequencedEntries(FLAGS_database_size));
+  realtime_after = util::TimeInMilliseconds();
+  getrusage(RUSAGE_SELF, &ru_after);
+
+  FLAGS_minloglevel = 0;
+  LOG(INFO) << "Real time spent reading " << FLAGS_database_size
+            << " entries, sorted by key: " << realtime_after - realtime_before
+            << " ms";
+  LOG(INFO) << "Peak RSS delta (as reported by getrusage()) was "
+            << ru_after.ru_maxrss - ru_before.ru_maxrss << " kB";
+  FLAGS_minloglevel = original_log_level;
+}
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  CHECK_GT(FLAGS_database_size, 0) << "Please specify the test database size";
+  CHECK_LE(FLAGS_database_size, 1000000)
+      << "Database size exceeds allowed maximum";
+  ConfigureSerializerForV1CT();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/database_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/database_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/database_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/database_test.cc	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,439 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include <gtest/gtest.h>
+#include <set>
+#include <string>
+
+#include "log/database.h"
+#include "log/file_db.h"
+#include "log/file_storage.h"
+#include "log/leveldb_db.h"
+#include "log/logged_entry.h"
+#include "log/sqlite_db.h"
+#include "log/test_db.h"
+#include "log/test_signer.h"
+#include "proto/cert_serializer.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+// TODO(benl): Introduce a test |Logged| type.
+
+namespace {
+
+using cert_trans::Database;
+using cert_trans::FileDB;
+using cert_trans::LevelDB;
+using cert_trans::LoggedEntry;
+using cert_trans::SQLiteDB;
+using ct::SignedTreeHead;
+using std::string;
+using std::unique_ptr;
+
+
+template <class T>
+class DBTest : public ::testing::Test {
+ protected:
+  DBTest() : test_db_(), test_signer_() {
+  }
+
+  ~DBTest() {
+  }
+
+  T* db() const {
+    return test_db_.db();
+  }
+
+  TestDB<T> test_db_;
+  TestSigner test_signer_;
+};
+
+typedef testing::Types<FileDB, SQLiteDB, LevelDB> Databases;
+
+
+template <class T>
+class DBTestDeathTest : public DBTest<T> {};
+
+TYPED_TEST_CASE(DBTest, Databases);
+TYPED_TEST_CASE(DBTestDeathTest, Databases);
+
+
+TYPED_TEST(DBTest, CreateSequenced) {
+  LoggedEntry logged_cert, lookup_cert;
+  this->test_signer_.CreateUnique(&logged_cert);
+
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert));
+
+  EXPECT_EQ(Database::LOOKUP_OK,
+            this->db()->LookupByHash(logged_cert.Hash(), &lookup_cert));
+  TestSigner::TestEqualLoggedCerts(logged_cert, lookup_cert);
+
+  lookup_cert.Clear();
+  EXPECT_EQ(Database::LOOKUP_OK,
+            this->db()->LookupByIndex(logged_cert.sequence_number(),
+                                      &lookup_cert));
+  TestSigner::TestEqualLoggedCerts(logged_cert, lookup_cert);
+
+  string similar_hash = logged_cert.Hash();
+  similar_hash[similar_hash.size() - 1] ^= 1;
+
+  EXPECT_EQ(Database::NOT_FOUND,
+            this->db()->LookupByHash(similar_hash, &lookup_cert));
+  EXPECT_EQ(Database::NOT_FOUND,
+            this->db()->LookupByHash(this->test_signer_.UniqueHash(),
+                                     &lookup_cert));
+}
+
+
+TYPED_TEST(DBTest, CreateSequencedDuplicateEntry) {
+  LoggedEntry logged_cert;
+  this->test_signer_.CreateUnique(&logged_cert);
+
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert));
+
+  LoggedEntry duplicate_cert;
+  duplicate_cert.CopyFrom(logged_cert);
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(duplicate_cert));
+
+  LoggedEntry lookup_cert;
+  EXPECT_EQ(Database::LOOKUP_OK,
+            this->db()->LookupByHash(logged_cert.Hash(), &lookup_cert));
+  // Check that we get the original entry back.
+  TestSigner::TestEqualLoggedCerts(logged_cert, lookup_cert);
+
+  lookup_cert.Clear();
+  EXPECT_EQ(Database::LOOKUP_OK,
+            this->db()->LookupByIndex(logged_cert.sequence_number(),
+                                      &lookup_cert));
+  TestSigner::TestEqualLoggedCerts(logged_cert, lookup_cert);
+}
+
+
+TYPED_TEST(DBTest, CreateSequencedDuplicateEntryNewSequenceNumber) {
+  LoggedEntry logged_cert, duplicate_cert, lookup_cert;
+  this->test_signer_.CreateUnique(&logged_cert);
+
+  duplicate_cert.CopyFrom(logged_cert);
+  // Change the timestamp so that we can check that we get the right thing
+  // back.
+  duplicate_cert.mutable_sct()->set_timestamp(logged_cert.sct().timestamp() +
+                                              1000);
+  logged_cert.set_sequence_number(1);
+
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert));
+
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(duplicate_cert));
+
+  EXPECT_EQ(Database::LOOKUP_OK,
+            this->db()->LookupByHash(logged_cert.Hash(), &lookup_cert));
+  // Check that we get the original entry back.
+  TestSigner::TestEqualLoggedCerts(logged_cert, lookup_cert);
+
+  // Check that we can find it by sequence number too:
+  lookup_cert.Clear();
+  EXPECT_EQ(Database::LOOKUP_OK,
+            this->db()->LookupByIndex(logged_cert.sequence_number(),
+                                      &lookup_cert));
+
+  // And that we can find the duplicate ok as well:
+  lookup_cert.Clear();
+  EXPECT_EQ(Database::LOOKUP_OK,
+            this->db()->LookupByIndex(duplicate_cert.sequence_number(),
+                                      &lookup_cert));
+  TestSigner::TestEqualLoggedCerts(duplicate_cert, lookup_cert);
+}
+
+
+TYPED_TEST(DBTest, CreateSequencedDuplicateSequenceNumber) {
+  LoggedEntry logged_cert, duplicate_seq, lookup_cert;
+  this->test_signer_.CreateUnique(&logged_cert);
+  this->test_signer_.CreateUnique(&duplicate_seq);
+  duplicate_seq.set_sequence_number(logged_cert.sequence_number());
+
+  // Change the timestamp so that we can check that we get the right thing
+  // back.
+  duplicate_seq.mutable_sct()->set_timestamp(logged_cert.sct().timestamp() +
+                                             1000);
+
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert));
+
+  EXPECT_EQ(Database::SEQUENCE_NUMBER_ALREADY_IN_USE,
+            this->db()->CreateSequencedEntry(duplicate_seq));
+
+  EXPECT_EQ(Database::LOOKUP_OK,
+            this->db()->LookupByIndex(logged_cert.sequence_number(),
+                                      &lookup_cert));
+  // Check that we get the original entry back.
+  TestSigner::TestEqualLoggedCerts(logged_cert, lookup_cert);
+
+  lookup_cert.Clear();
+  EXPECT_EQ(Database::LOOKUP_OK,
+            this->db()->LookupByIndex(logged_cert.sequence_number(),
+                                      &lookup_cert));
+  TestSigner::TestEqualLoggedCerts(logged_cert, lookup_cert);
+}
+
+
+TYPED_TEST(DBTest, TreeSize) {
+  LoggedEntry logged_cert;
+
+  this->test_signer_.CreateUnique(&logged_cert);
+  logged_cert.set_sequence_number(0);
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert));
+  EXPECT_EQ(1, this->db()->TreeSize());
+
+  this->test_signer_.CreateUnique(&logged_cert);
+  logged_cert.set_sequence_number(1);
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert));
+  EXPECT_EQ(2, this->db()->TreeSize());
+
+  // Create a gap, this will not increase the tree size.
+  this->test_signer_.CreateUnique(&logged_cert);
+  logged_cert.set_sequence_number(4);
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert));
+  EXPECT_EQ(2, this->db()->TreeSize());
+
+  // Contiguous with the previous one, but still after the gap, so no
+  // change in tree size.
+  this->test_signer_.CreateUnique(&logged_cert);
+  logged_cert.set_sequence_number(3);
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert));
+  EXPECT_EQ(2, this->db()->TreeSize());
+
+  // Another gap.
+  this->test_signer_.CreateUnique(&logged_cert);
+  logged_cert.set_sequence_number(6);
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert));
+  EXPECT_EQ(2, this->db()->TreeSize());
+
+  // This fills the first gap, but not the second.
+  this->test_signer_.CreateUnique(&logged_cert);
+  logged_cert.set_sequence_number(2);
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert));
+  EXPECT_EQ(5, this->db()->TreeSize());
+
+  // Now all the gaps are filled.
+  this->test_signer_.CreateUnique(&logged_cert);
+  logged_cert.set_sequence_number(5);
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert));
+  EXPECT_EQ(7, this->db()->TreeSize());
+}
+
+
+TYPED_TEST(DBTest, LookupBySequenceNumber) {
+  LoggedEntry logged_cert, logged_cert2, lookup_cert, lookup_cert2;
+  this->test_signer_.CreateUnique(&logged_cert);
+  logged_cert.set_sequence_number(42);
+  this->test_signer_.CreateUnique(&logged_cert2);
+  logged_cert2.set_sequence_number(22);
+
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert));
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert2));
+
+  EXPECT_EQ(Database::NOT_FOUND, this->db()->LookupByIndex(23, &lookup_cert));
+
+  EXPECT_EQ(Database::LOOKUP_OK, this->db()->LookupByIndex(42, &lookup_cert));
+  EXPECT_EQ(42U, lookup_cert.sequence_number());
+
+  TestSigner::TestEqualLoggedCerts(logged_cert, lookup_cert);
+
+  EXPECT_EQ(Database::LOOKUP_OK, this->db()->LookupByIndex(22, &lookup_cert2));
+  EXPECT_EQ(22U, lookup_cert2.sequence_number());
+
+  TestSigner::TestEqualLoggedCerts(logged_cert2, lookup_cert2);
+}
+
+
+TYPED_TEST(DBTest, WriteTreeHead) {
+  SignedTreeHead sth, lookup_sth;
+  this->test_signer_.CreateUnique(&sth);
+
+  EXPECT_EQ(Database::NOT_FOUND, this->db()->LatestTreeHead(&lookup_sth));
+  EXPECT_EQ(Database::OK, this->db()->WriteTreeHead(sth));
+  EXPECT_EQ(Database::LOOKUP_OK, this->db()->LatestTreeHead(&lookup_sth));
+  TestSigner::TestEqualTreeHeads(sth, lookup_sth);
+}
+
+
+TYPED_TEST(DBTest, WriteTreeHeadDuplicateTimestamp) {
+  SignedTreeHead sth, sth2, lookup_sth;
+  this->test_signer_.CreateUnique(&sth);
+
+  EXPECT_EQ(Database::OK, this->db()->WriteTreeHead(sth));
+
+  sth2.CopyFrom(sth);
+  sth2.set_tree_size(sth.tree_size() + 1);
+  EXPECT_EQ(Database::DUPLICATE_TREE_HEAD_TIMESTAMP,
+            this->db()->WriteTreeHead(sth2));
+
+  EXPECT_EQ(Database::LOOKUP_OK, this->db()->LatestTreeHead(&lookup_sth));
+  TestSigner::TestEqualTreeHeads(sth, lookup_sth);
+}
+
+
+TYPED_TEST(DBTest, WriteTreeHeadNewerTimestamp) {
+  SignedTreeHead sth, sth2, lookup_sth;
+  this->test_signer_.CreateUnique(&sth);
+  this->test_signer_.CreateUnique(&sth2);
+  // Should be newer already but don't rely on this.
+  sth2.set_timestamp(sth.timestamp() + 1000);
+
+  EXPECT_EQ(Database::OK, this->db()->WriteTreeHead(sth));
+  EXPECT_EQ(Database::OK, this->db()->WriteTreeHead(sth2));
+
+  EXPECT_EQ(Database::LOOKUP_OK, this->db()->LatestTreeHead(&lookup_sth));
+  TestSigner::TestEqualTreeHeads(sth2, lookup_sth);
+}
+
+
+TYPED_TEST(DBTest, WriteTreeHeadOlderTimestamp) {
+  SignedTreeHead sth, sth2, lookup_sth;
+  this->test_signer_.CreateUnique(&sth);
+  this->test_signer_.CreateUnique(&sth2);
+  // Should be newer already but don't rely on this.
+  sth2.set_timestamp(sth.timestamp() - 1000);
+
+  EXPECT_EQ(Database::OK, this->db()->WriteTreeHead(sth));
+  EXPECT_EQ(Database::OK, this->db()->WriteTreeHead(sth2));
+
+  EXPECT_EQ(Database::LOOKUP_OK, this->db()->LatestTreeHead(&lookup_sth));
+  TestSigner::TestEqualTreeHeads(sth, lookup_sth);
+}
+
+
+TYPED_TEST(DBTest, Resume) {
+  LoggedEntry logged_cert, logged_cert2, lookup_cert, lookup_cert2;
+  const int64_t kSeq1(129);
+  const int64_t kSeq2(22);
+
+  this->test_signer_.CreateUnique(&logged_cert);
+  logged_cert.set_sequence_number(kSeq1);
+  this->test_signer_.CreateUnique(&logged_cert2);
+  logged_cert2.set_sequence_number(kSeq2);
+
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert));
+  EXPECT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert2));
+
+  SignedTreeHead sth, sth2, lookup_sth;
+  this->test_signer_.CreateUnique(&sth);
+  this->test_signer_.CreateUnique(&sth2);
+  sth2.set_timestamp(sth.timestamp() - 1000);
+  EXPECT_EQ(Database::OK, this->db()->WriteTreeHead(sth));
+  EXPECT_EQ(Database::OK, this->db()->WriteTreeHead(sth2));
+
+  Database* db2 = this->test_db_.SecondDB();
+
+  EXPECT_EQ(Database::LOOKUP_OK,
+            db2->LookupByHash(logged_cert.Hash(), &lookup_cert));
+  EXPECT_EQ(kSeq1, lookup_cert.sequence_number());
+
+  TestSigner::TestEqualLoggedCerts(logged_cert, lookup_cert);
+
+  EXPECT_EQ(Database::LOOKUP_OK,
+            db2->LookupByHash(logged_cert2.Hash(), &lookup_cert2));
+  EXPECT_EQ(kSeq2, lookup_cert2.sequence_number());
+
+  TestSigner::TestEqualLoggedCerts(logged_cert2, lookup_cert2);
+
+  EXPECT_EQ(Database::LOOKUP_OK, db2->LatestTreeHead(&lookup_sth));
+  TestSigner::TestEqualTreeHeads(sth, lookup_sth);
+
+  delete db2;
+}
+
+
+TYPED_TEST(DBTest, ResumeEmpty) {
+  Database* db2 = this->test_db_.SecondDB();
+
+  LoggedEntry lookup_cert;
+  EXPECT_EQ(Database::NOT_FOUND, db2->LookupByIndex(0, &lookup_cert));
+
+  SignedTreeHead lookup_sth;
+  EXPECT_EQ(Database::NOT_FOUND, db2->LatestTreeHead(&lookup_sth));
+
+  delete db2;
+}
+
+
+TYPED_TEST(DBTest, NodeId) {
+  const string kNodeId("node_id");
+  this->db()->InitializeNode(kNodeId);
+  std::string id_from_db;
+  EXPECT_EQ(Database::LOOKUP_OK, this->db()->NodeId(&id_from_db));
+  EXPECT_EQ(kNodeId, id_from_db);
+}
+
+
+TYPED_TEST(DBTest, NoNodeIdSet) {
+  std::string id_from_db;
+  EXPECT_EQ(Database::NOT_FOUND, this->db()->NodeId(&id_from_db));
+}
+
+
+TYPED_TEST(DBTestDeathTest, CannotOverwriteNodeId) {
+  const string kNodeId("some_node_id");
+  this->db()->InitializeNode(kNodeId);
+  EXPECT_DEATH(this->db()->InitializeNode("something_else"), kNodeId);
+}
+
+
+TYPED_TEST(DBTestDeathTest, CannotHaveEmptyNodeId) {
+  EXPECT_DEATH(this->db()->InitializeNode(""), "empty");
+}
+
+
+TYPED_TEST(DBTest, Iterator) {
+  LoggedEntry logged_cert1, logged_cert2, logged_cert3;
+  const int64_t kSeq1(129);
+  const int64_t kSeq2(22);
+  const int64_t kSeq3(42);
+  // Make sure the entries are not in order.
+  CHECK_GT(kSeq1, kSeq2);
+  CHECK_GT(kSeq3, kSeq2);
+
+  this->test_signer_.CreateUnique(&logged_cert1);
+  logged_cert1.set_sequence_number(kSeq1);
+  ASSERT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert1));
+
+  this->test_signer_.CreateUnique(&logged_cert2);
+  logged_cert2.set_sequence_number(kSeq2);
+  ASSERT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert2));
+
+  this->test_signer_.CreateUnique(&logged_cert3);
+  logged_cert3.set_sequence_number(kSeq3);
+  ASSERT_EQ(Database::OK, this->db()->CreateSequencedEntry(logged_cert3));
+
+  unique_ptr<Database::Iterator> it(this->db()->ScanEntries(0));
+  LoggedEntry it_cert;
+  ASSERT_TRUE(it->GetNextEntry(&it_cert));
+  TestSigner::TestEqualLoggedCerts(logged_cert2, it_cert);
+
+  ASSERT_TRUE(it->GetNextEntry(&it_cert));
+  TestSigner::TestEqualLoggedCerts(logged_cert3, it_cert);
+
+  ASSERT_TRUE(it->GetNextEntry(&it_cert));
+  TestSigner::TestEqualLoggedCerts(logged_cert1, it_cert);
+
+  EXPECT_FALSE(it->GetNextEntry(&it_cert));
+
+  it = this->db()->ScanEntries(kSeq3);
+  ASSERT_TRUE(it->GetNextEntry(&it_cert));
+  TestSigner::TestEqualLoggedCerts(logged_cert3, it_cert);
+
+  ASSERT_TRUE(it->GetNextEntry(&it_cert));
+  TestSigner::TestEqualLoggedCerts(logged_cert1, it_cert);
+
+  EXPECT_FALSE(it->GetNextEntry(&it_cert));
+
+  it = this->db()->ScanEntries(kSeq1 + 1);
+  EXPECT_FALSE(it->GetNextEntry(&it_cert));
+}
+
+
+}  // namespace
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  ::testing::FLAGS_gtest_death_test_style = "threadsafe";
+  ConfigureSerializerForV1CT();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/etcd_consistent_store.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/etcd_consistent_store.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/etcd_consistent_store.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/etcd_consistent_store.cc	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,888 @@
+#include "log/etcd_consistent_store.h"
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <chrono>
+#include <unordered_map>
+#include <vector>
+
+#include "base/notification.h"
+#include "monitoring/event_metric.h"
+#include "monitoring/latency.h"
+#include "monitoring/monitoring.h"
+#include "util/etcd_delete.h"
+#include "util/executor.h"
+#include "util/masterelection.h"
+#include "util/util.h"
+
+using ct::ClusterConfig;
+using ct::ClusterNodeState;
+using ct::SequenceMapping;
+using ct::SignedTreeHead;
+using std::bind;
+using std::chrono::seconds;
+using std::lock_guard;
+using std::map;
+using std::move;
+using std::mutex;
+using std::placeholders::_1;
+using std::string;
+using std::unique_lock;
+using std::unique_ptr;
+using std::vector;
+using util::FromBase64;
+using util::Status;
+using util::StatusOr;
+using util::SyncTask;
+using util::Task;
+using util::ToBase64;
+
+// This needs to be quite frequent since the number of entries which can be
+// added every second can be pretty high.
+DEFINE_int32(etcd_stats_collection_interval_seconds, 2,
+             "Number of seconds between fetches of etcd stats.");
+DEFINE_int32(node_state_ttl_seconds, 60,
+             "TTL in seconds on the node state files.");
+
+namespace cert_trans {
+namespace {
+
+// etcd path constants.
+const char kClusterConfigFile[] = "/cluster_config";
+const char kEntriesDir[] = "/entries/";
+const char kSequenceFile[] = "/sequence_mapping";
+const char kServingSthFile[] = "/serving_sth";
+const char kNodesDir[] = "/nodes/";
+
+
+static Gauge<string>* etcd_total_entries =
+    Gauge<string>::New("etcd_total_entries", "type",
+                       "Total number of entries in etcd by type.");
+
+static Gauge<string>* etcd_store_stats =
+    Gauge<string>::New("etcd_store_stats", "name",
+                       "Re-export of etcd's store stats.");
+
+static EventMetric<string> etcd_throttle_delay_ms("etcd_throttle_delay_ms",
+                                                  "type",
+                                                  "Count and total thottle "
+                                                  "delay applied to requests, "
+                                                  "broken down by request "
+                                                  "type");
+
+static Counter<string>* etcd_rejected_requests =
+    Counter<string>::New("etcd_rejected_requests", "type",
+                         "Total number of requests rejected due to overload, "
+                         "broken down by request type.");
+
+static Latency<std::chrono::milliseconds, string> etcd_latency_by_op_ms(
+    "etcd_latency_by_op_ms", "operation",
+    "Etcd latency in ms broken down by operation.");
+
+
+// TODO(pphaneuf): Hmm, I think this should check that it's not just
+// ordered, but contiguous?
+void CheckMappingIsOrdered(const SequenceMapping& mapping) {
+  if (mapping.mapping_size() < 2) {
+    return;
+  }
+  for (int64_t i = 0; i < mapping.mapping_size() - 1; ++i) {
+    CHECK_LT(mapping.mapping(i).sequence_number(),
+             mapping.mapping(i + 1).sequence_number());
+  }
+}
+
+
+StatusOr<int64_t> GetStat(const map<string, int64_t>& stats,
+                          const string& name) {
+  const auto& it(stats.find(name));
+  if (it == stats.end()) {
+    return Status(util::error::FAILED_PRECONDITION, name + " missing.");
+  }
+  return it->second;
+}
+
+
+StatusOr<int64_t> CalculateNumEtcdEntries(const map<string, int64_t>& stats) {
+  StatusOr<int64_t> created(GetStat(stats, "createSuccess"));
+  if (!created.ok()) {
+    return created;
+  }
+
+  StatusOr<int64_t> deleted(GetStat(stats, "deleteSuccess"));
+  if (!deleted.ok()) {
+    return deleted;
+  }
+
+  StatusOr<int64_t> compareDeleted(GetStat(stats, "compareAndDeleteSuccess"));
+  if (!compareDeleted.ok()) {
+    return compareDeleted;
+  }
+  StatusOr<int64_t> expired(GetStat(stats, "expireCount"));
+  if (!expired.ok()) {
+    return expired;
+  }
+
+  const int64_t num_removed(deleted.ValueOrDie() +
+                            compareDeleted.ValueOrDie() +
+                            expired.ValueOrDie());
+  return created.ValueOrDie() - num_removed;
+}
+
+}  // namespace
+
+
+EtcdConsistentStore::EtcdConsistentStore(
+    libevent::Base* base, util::Executor* executor, EtcdClient* client,
+    const MasterElection* election, const string& root, const string& node_id)
+    : client_(CHECK_NOTNULL(client)),
+      base_(CHECK_NOTNULL(base)),
+      executor_(CHECK_NOTNULL(executor)),
+      election_(CHECK_NOTNULL(election)),
+      root_(root),
+      node_id_(node_id),
+      serving_sth_watch_task_(CHECK_NOTNULL(executor)),
+      cluster_config_watch_task_(CHECK_NOTNULL(executor)),
+      etcd_stats_task_(executor_),
+      received_initial_sth_(false),
+      exiting_(false),
+      num_etcd_entries_(0) {
+  // Set up watches on things we're interested in...
+  WatchServingSTH(bind(&EtcdConsistentStore::OnEtcdServingSTHUpdated, this,
+                       _1),
+                  serving_sth_watch_task_.task());
+  WatchClusterConfig(bind(&EtcdConsistentStore::OnClusterConfigUpdated, this,
+                          _1),
+                     cluster_config_watch_task_.task());
+
+  StartEtcdStatsFetch();
+
+  // And wait for the initial updates to come back so that we've got a
+  // view on the current state before proceding...
+  {
+    unique_lock<mutex> lock(mutex_);
+    serving_sth_cv_.wait(lock, [this]() { return received_initial_sth_; });
+  }
+}
+
+
+EtcdConsistentStore::~EtcdConsistentStore() {
+  VLOG(1) << "Cancelling watch tasks.";
+  serving_sth_watch_task_.Cancel();
+  cluster_config_watch_task_.Cancel();
+  VLOG(1) << "Waiting for watch tasks to return.";
+  serving_sth_watch_task_.Wait();
+  cluster_config_watch_task_.Wait();
+  VLOG(1) << "Cancelling stats task.";
+  etcd_stats_task_.Cancel();
+  etcd_stats_task_.Wait();
+  VLOG(1) << "Joining cleanup thread";
+  {
+    lock_guard<mutex> lock(mutex_);
+    exiting_ = true;
+  }
+  serving_sth_cv_.notify_all();
+}
+
+
+StatusOr<int64_t> EtcdConsistentStore::NextAvailableSequenceNumber() const {
+  ScopedLatency scoped_latency(etcd_latency_by_op_ms.GetScopedLatency(
+      "next_available_sequence_number"));
+
+  EntryHandle<SequenceMapping> sequence_mapping;
+  Status status(GetSequenceMapping(&sequence_mapping));
+  if (!status.ok()) {
+    return status;
+  }
+  etcd_total_entries->Set("sequenced",
+                          sequence_mapping.Entry().mapping_size());
+  if (sequence_mapping.Entry().mapping_size() > 0) {
+    return sequence_mapping.Entry()
+               .mapping(sequence_mapping.Entry().mapping_size() - 1)
+               .sequence_number() +
+           1;
+  }
+
+  if (!serving_sth_) {
+    LOG(WARNING) << "Log has no Serving STH [new log?], returning 0";
+    return 0;
+  }
+
+  return serving_sth_->Entry().tree_size();
+}
+
+
+void EtcdConsistentStore::WaitForServingSTHVersion(unique_lock<mutex>* lock,
+                                                   const int version) {
+  VLOG(1) << "Waiting for ServingSTH version " << version;
+  serving_sth_cv_.wait(*lock, [this, version]() {
+    VLOG(1) << "Want version " << version << ", have: "
+            << (serving_sth_ ? std::to_string(serving_sth_->Handle())
+                             : "none");
+    return serving_sth_ && serving_sth_->Handle() >= version;
+  });
+}
+
+
+Status EtcdConsistentStore::SetServingSTH(const SignedTreeHead& new_sth) {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("set_serving_sth"));
+
+  const string full_path(GetFullPath(kServingSthFile));
+  unique_lock<mutex> lock(mutex_);
+
+  // The watcher should have already populated serving_sth_ if etcd had one.
+  if (!serving_sth_) {
+    // Looks like we're creating the first ever serving_sth!
+    LOG(WARNING) << "Creating new " << full_path;
+    // There's no current serving STH, so we can try to create one.
+    EntryHandle<SignedTreeHead> sth_handle(full_path, new_sth);
+    Status status(CreateEntry(&sth_handle));
+    if (!status.ok()) {
+      return status;
+    }
+    WaitForServingSTHVersion(&lock, sth_handle.Handle());
+    return Status::OK;
+  }
+
+  // Looks like we're updating an existing serving_sth.
+  // First check that we're not trying to overwrite it with itself or an older
+  // one:
+  if (serving_sth_->Entry().timestamp() >= new_sth.timestamp()) {
+    return Status(util::error::OUT_OF_RANGE,
+                  "Tree head is not newer than existing head");
+  }
+
+  // Ensure that nothing weird is going on with the tree size:
+  CHECK_LE(serving_sth_->Entry().tree_size(), new_sth.tree_size());
+
+  VLOG(1) << "Updating existing " << full_path;
+  EntryHandle<SignedTreeHead> sth_to_etcd(full_path, new_sth,
+                                          serving_sth_->Handle());
+  Status status(UpdateEntry(&sth_to_etcd));
+  if (!status.ok()) {
+    return status;
+  }
+  WaitForServingSTHVersion(&lock, sth_to_etcd.Handle());
+  return Status::OK;
+}
+
+
+StatusOr<SignedTreeHead> EtcdConsistentStore::GetServingSTH() const {
+  lock_guard<mutex> lock(mutex_);
+  if (serving_sth_) {
+    return serving_sth_->Entry();
+  } else {
+    return Status(util::error::NOT_FOUND, "No current Serving STH.");
+  }
+}
+
+
+bool LeafEntriesMatch(const LoggedEntry& a, const LoggedEntry& b) {
+  CHECK_EQ(a.entry().type(), b.entry().type());
+  switch (a.entry().type()) {
+    case ct::X509_ENTRY:
+      return a.entry().x509_entry().leaf_certificate() ==
+             b.entry().x509_entry().leaf_certificate();
+    case ct::PRECERT_ENTRY:
+      return a.entry().precert_entry().pre_certificate() ==
+             b.entry().precert_entry().pre_certificate();
+    case ct::PRECERT_ENTRY_V2:
+      // TODO(mhs): V2 implementation required here
+      LOG(FATAL) << "CT V2 not yet implemented";
+      break;
+    case ct::X_JSON_ENTRY:
+      return a.entry().x_json_entry().json() ==
+             b.entry().x_json_entry().json();
+    case ct::UNKNOWN_ENTRY_TYPE:
+      // Handle it below.
+      break;
+  }
+  LOG(FATAL) << "Encountered UNKNOWN_ENTRY_TYPE:\n" << a.entry().DebugString();
+}
+
+
+Status EtcdConsistentStore::AddPendingEntry(LoggedEntry* entry) {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("add_pending_entry"));
+
+  CHECK_NOTNULL(entry);
+  CHECK(!entry->has_sequence_number());
+
+  Status status(MaybeReject("add_pending_entry"));
+  if (!status.ok()) {
+    return status;
+  }
+
+  const string full_path(GetEntryPath(*entry));
+  EntryHandle<LoggedEntry> handle(full_path, *entry);
+  status = CreateEntry(&handle);
+  if (status.CanonicalCode() == util::error::FAILED_PRECONDITION) {
+    // Entry with that hash already exists.
+    EntryHandle<LoggedEntry> preexisting_entry;
+    status = GetEntry(full_path, &preexisting_entry);
+    if (!status.ok()) {
+      LOG(ERROR) << "Couldn't create or fetch " << full_path << " : "
+                 << status;
+      return status;
+    }
+
+    // Check the leaf certs are the same (we might be seeing the same cert
+    // submitted with a different chain.)
+    CHECK(LeafEntriesMatch(preexisting_entry.Entry(), *entry));
+    *entry->mutable_sct() = preexisting_entry.Entry().sct();
+    return Status(util::error::ALREADY_EXISTS,
+                  "Pending entry already exists.");
+  }
+  return status;
+}
+
+
+Status EtcdConsistentStore::GetPendingEntryForHash(
+    const string& hash, EntryHandle<LoggedEntry>* entry) const {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("get_pending_entry_for_hash"));
+
+  Status status(GetEntry(GetEntryPath(hash), entry));
+  if (status.ok()) {
+    CHECK(!entry->Entry().has_sequence_number());
+  }
+
+  return status;
+}
+
+
+Status EtcdConsistentStore::GetPendingEntries(
+    vector<EntryHandle<LoggedEntry>>* entries) const {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("get_pending_entries"));
+
+  Status status(GetAllEntriesInDir(GetFullPath(kEntriesDir), entries));
+  if (status.ok()) {
+    for (const auto& entry : *entries) {
+      CHECK(!entry.Entry().has_sequence_number());
+    }
+  }
+  etcd_total_entries->Set("entries", entries->size());
+  return status;
+}
+
+
+Status EtcdConsistentStore::GetSequenceMapping(
+    EntryHandle<SequenceMapping>* sequence_mapping) const {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("get_sequence_mapping"));
+
+  Status status(GetEntry(GetFullPath(kSequenceFile), sequence_mapping));
+  if (!status.ok()) {
+    return status;
+  }
+  CheckMappingIsOrdered(sequence_mapping->Entry());
+  CheckMappingIsContiguousWithServingTree(sequence_mapping->Entry());
+  etcd_total_entries->Set("sequenced",
+                          sequence_mapping->Entry().mapping_size());
+  return Status::OK;
+}
+
+
+Status EtcdConsistentStore::UpdateSequenceMapping(
+    EntryHandle<SequenceMapping>* entry) {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("update_sequence_mapping"));
+
+  CHECK(entry->HasHandle());
+  CheckMappingIsOrdered(entry->Entry());
+  CheckMappingIsContiguousWithServingTree(entry->Entry());
+  return UpdateEntry(entry);
+}
+
+
+StatusOr<ClusterNodeState> EtcdConsistentStore::GetClusterNodeState() const {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("get_cluster_node_state"));
+
+  EntryHandle<ClusterNodeState> handle;
+  Status status(GetEntry(GetNodePath(node_id_), &handle));
+  if (!status.ok()) {
+    return status;
+  }
+  return handle.Entry();
+}
+
+
+Status EtcdConsistentStore::SetClusterNodeState(
+    const ClusterNodeState& state) {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("set_cluster_node_state"));
+
+  // TODO(alcutter): consider keeping the handle for this around to check that
+  // nobody else is updating our cluster state.
+  ClusterNodeState local_state(state);
+  local_state.set_node_id(node_id_);
+  EntryHandle<ClusterNodeState> entry(GetNodePath(node_id_), local_state);
+  const seconds ttl(FLAGS_node_state_ttl_seconds);
+  return ForceSetEntryWithTTL(ttl, &entry);
+}
+
+
+// static
+template <class T, class CB>
+void EtcdConsistentStore::ConvertSingleUpdate(
+    const string& full_path, const CB& callback,
+    const vector<EtcdClient::Node>& updates) {
+  CHECK_LE(static_cast<size_t>(0), updates.size());
+  if (updates.empty()) {
+    EntryHandle<T> handle;
+    handle.SetKey(full_path);
+    callback(Update<T>(handle, false /* exists */));
+  } else {
+    callback(TypedUpdateFromNode<T>(updates[0]));
+  }
+}
+
+
+// static
+template <class T, class CB>
+void EtcdConsistentStore::ConvertMultipleUpdate(
+    const CB& callback, const vector<EtcdClient::Node>& watch_updates) {
+  vector<Update<T>> updates;
+  for (auto& w : watch_updates) {
+    updates.emplace_back(TypedUpdateFromNode<T>(w));
+  }
+  callback(updates);
+}
+
+
+void EtcdConsistentStore::WatchServingSTH(
+    const ConsistentStore::ServingSTHCallback& cb, Task* task) {
+  const string full_path(GetFullPath(kServingSthFile));
+  client_->Watch(full_path,
+                 bind(&ConvertSingleUpdate<
+                          SignedTreeHead, ConsistentStore::ServingSTHCallback>,
+                      full_path, cb, _1),
+                 task);
+}
+
+
+void EtcdConsistentStore::WatchClusterNodeStates(
+    const ConsistentStore::ClusterNodeStateCallback& cb, Task* task) {
+  client_->Watch(
+      GetFullPath(kNodesDir),
+      bind(&ConvertMultipleUpdate<ClusterNodeState,
+                                  ConsistentStore::ClusterNodeStateCallback>,
+           cb, _1),
+      task);
+}
+
+
+void EtcdConsistentStore::WatchClusterConfig(
+    const ConsistentStore::ClusterConfigCallback& cb, Task* task) {
+  const string full_path(GetFullPath(kClusterConfigFile));
+  client_->Watch(
+      full_path,
+      bind(&ConvertSingleUpdate<ClusterConfig,
+                                ConsistentStore::ClusterConfigCallback>,
+           full_path, cb, _1),
+      task);
+}
+
+
+Status EtcdConsistentStore::SetClusterConfig(const ClusterConfig& config) {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("set_cluster_config"));
+
+  EntryHandle<ClusterConfig> entry(GetFullPath(kClusterConfigFile), config);
+  return ForceSetEntry(&entry);
+}
+
+
+template <class T>
+Status EtcdConsistentStore::GetEntry(const string& path,
+                                     EntryHandle<T>* entry) const {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("get_entry"));
+
+  CHECK_NOTNULL(entry);
+  SyncTask task(executor_);
+  EtcdClient::GetResponse resp;
+  client_->Get(path, &resp, task.task());
+  task.Wait();
+  if (!task.status().ok()) {
+    return task.status();
+  }
+  T t;
+  CHECK(t.ParseFromString(FromBase64(resp.node.value_.c_str())));
+  entry->Set(path, t, resp.node.modified_index_);
+  return Status::OK;
+}
+
+
+Status EtcdConsistentStore::GetAllEntriesInDir(
+    const string& dir, vector<EntryHandle<LoggedEntry>>* entries) const {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("get_all_entries_in_dir"));
+
+  CHECK_NOTNULL(entries);
+  CHECK_EQ(static_cast<size_t>(0), entries->size());
+  SyncTask task(executor_);
+  EtcdClient::GetResponse resp;
+  client_->Get(dir, &resp, task.task());
+  task.Wait();
+  if (!task.status().ok()) {
+    return task.status();
+  }
+  if (!resp.node.is_dir_) {
+    return Status(util::error::FAILED_PRECONDITION,
+                  "node is not a directory: " + dir);
+  }
+  for (const auto& node : resp.node.nodes_) {
+    LoggedEntry entry;
+    CHECK(entry.ParseFromString(FromBase64(node.value_.c_str())));
+    entries->emplace_back(
+        EntryHandle<LoggedEntry>(node.key_, entry, node.modified_index_));
+  }
+  return Status::OK;
+}
+
+
+Status EtcdConsistentStore::UpdateEntry(EntryHandleBase* t) {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("update_entry"));
+
+  CHECK_NOTNULL(t);
+  CHECK(t->HasHandle());
+  CHECK(t->HasKey());
+  string flat_entry;
+  CHECK(t->SerializeToString(&flat_entry));
+  SyncTask task(executor_);
+  EtcdClient::Response resp;
+  client_->Update(t->Key(), ToBase64(flat_entry), t->Handle(), &resp,
+                  task.task());
+  task.Wait();
+  if (task.status().ok()) {
+    t->SetHandle(resp.etcd_index);
+  }
+  return task.status();
+}
+
+
+Status EtcdConsistentStore::CreateEntry(EntryHandleBase* t) {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("create_entry"));
+
+  CHECK_NOTNULL(t);
+  CHECK(!t->HasHandle());
+  CHECK(t->HasKey());
+  string flat_entry;
+  CHECK(t->SerializeToString(&flat_entry));
+  SyncTask task(executor_);
+  EtcdClient::Response resp;
+  client_->Create(t->Key(), ToBase64(flat_entry), &resp, task.task());
+  task.Wait();
+  if (task.status().ok()) {
+    t->SetHandle(resp.etcd_index);
+  }
+  return task.status();
+}
+
+
+Status EtcdConsistentStore::ForceSetEntry(EntryHandleBase* t) {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("force_set_entry"));
+
+  CHECK_NOTNULL(t);
+  CHECK(t->HasKey());
+  // For now we check that |t| wasn't fetched from the etcd store (i.e. it's a
+  // new EntryHandle.  The reason is that if it had been fetched, then the
+  // calling code should be doing an UpdateEntry() here since they have the
+  // handle.
+  CHECK(!t->HasHandle());
+  string flat_entry;
+  CHECK(t->SerializeToString(&flat_entry));
+  SyncTask task(executor_);
+  EtcdClient::Response resp;
+  client_->ForceSet(t->Key(), ToBase64(flat_entry), &resp, task.task());
+  task.Wait();
+  if (task.status().ok()) {
+    t->SetHandle(resp.etcd_index);
+  }
+  return task.status();
+}
+
+
+Status EtcdConsistentStore::ForceSetEntryWithTTL(const seconds& ttl,
+                                                 EntryHandleBase* t) {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("force_set_entry_with_ttl"));
+
+  CHECK_NOTNULL(t);
+  CHECK(t->HasKey());
+  // For now we check that |t| wasn't fetched from the etcd store (i.e. it's a
+  // new EntryHandle.  The reason is that if it had been fetched, then the
+  // calling code should be doing an UpdateEntryWithTTL() here since they have
+  // the handle.
+  CHECK(!t->HasHandle());
+  CHECK_LE(0, ttl.count());
+  string flat_entry;
+  CHECK(t->SerializeToString(&flat_entry));
+  SyncTask task(executor_);
+  EtcdClient::Response resp;
+  client_->ForceSetWithTTL(t->Key(), ToBase64(flat_entry), ttl, &resp,
+                           task.task());
+  task.Wait();
+  if (task.status().ok()) {
+    t->SetHandle(resp.etcd_index);
+  }
+  return task.status();
+}
+
+
+Status EtcdConsistentStore::DeleteEntry(const EntryHandleBase& entry) {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("delete_entry"));
+
+  CHECK(entry.HasHandle());
+  CHECK(entry.HasKey());
+  SyncTask task(executor_);
+  client_->Delete(entry.Key(), entry.Handle(), task.task());
+  task.Wait();
+  return task.status();
+}
+
+
+string EtcdConsistentStore::GetEntryPath(const LoggedEntry& entry) const {
+  return GetEntryPath(entry.Hash());
+}
+
+
+string EtcdConsistentStore::GetEntryPath(const string& hash) const {
+  return GetFullPath(string(kEntriesDir) + util::HexString(hash));
+}
+
+
+string EtcdConsistentStore::GetNodePath(const string& id) const {
+  return GetFullPath(string(kNodesDir) + id);
+}
+
+
+string EtcdConsistentStore::GetFullPath(const string& key) const {
+  CHECK(key.size() > 0);
+  CHECK_EQ('/', key[0]);
+  return root_ + key;
+}
+
+
+void EtcdConsistentStore::CheckMappingIsContiguousWithServingTree(
+    const SequenceMapping& mapping) const {
+  lock_guard<mutex> lock(mutex_);
+  if (serving_sth_ && mapping.mapping_size() > 0) {
+    // The sequence numbers are signed. However the tree size must fit in
+    // memory so the unsigned -> signed conversion below should not overflow.
+    CHECK_LE(serving_sth_->Entry().tree_size(), INT64_MAX);
+
+    const int64_t tree_size(serving_sth_->Entry().tree_size());
+    // The mapping must not have a gap between its lowest mapping and the
+    // serving tree
+    const int64_t lowest_sequence_number(mapping.mapping(0).sequence_number());
+    CHECK_LE(lowest_sequence_number, tree_size);
+    // It must also be contiguous for all entries not yet included in the
+    // serving tree. (Note that entries below that may not be contiguous
+    // because the clean-up operation may not remove them in order.)
+    bool above_sth(false);
+    for (int i(0); i < mapping.mapping_size() - 1; ++i) {
+      const int64_t mapped_seq(mapping.mapping(i).sequence_number());
+      if (mapped_seq >= tree_size) {
+        CHECK_EQ(mapped_seq + 1, mapping.mapping(i + 1).sequence_number());
+        above_sth = true;
+      } else {
+        CHECK(!above_sth);
+      }
+    }
+  }
+}
+
+
+// static
+template <class T>
+Update<T> EtcdConsistentStore::TypedUpdateFromNode(
+    const EtcdClient::Node& node) {
+  const string raw_value(FromBase64(node.value_.c_str()));
+  T thing;
+  CHECK(thing.ParseFromString(raw_value)) << raw_value;
+  EntryHandle<T> handle(node.key_, thing);
+  if (!node.deleted_) {
+    handle.SetHandle(node.modified_index_);
+  }
+  return Update<T>(handle, !node.deleted_);
+}
+
+
+void EtcdConsistentStore::UpdateLocalServingSTH(
+    const unique_lock<mutex>& lock,
+    const EntryHandle<SignedTreeHead>& handle) {
+  CHECK(lock.owns_lock());
+  CHECK(!serving_sth_ ||
+        serving_sth_->Entry().timestamp() < handle.Entry().timestamp());
+
+  VLOG(1) << "Updating serving_sth_ to: " << handle.Entry().DebugString();
+  serving_sth_.reset(new EntryHandle<SignedTreeHead>(handle));
+}
+
+
+void EtcdConsistentStore::OnEtcdServingSTHUpdated(
+    const Update<SignedTreeHead>& update) {
+  unique_lock<mutex> lock(mutex_);
+
+  if (update.exists_) {
+    VLOG(1) << "Got ServingSTH version " << update.handle_.Handle() << ": "
+            << update.handle_.Entry().DebugString();
+    UpdateLocalServingSTH(lock, update.handle_);
+  } else {
+    LOG(WARNING) << "ServingSTH non-existent/deleted.";
+    // TODO(alcutter): What to do here?
+    serving_sth_.reset();
+  }
+  received_initial_sth_ = true;
+  lock.unlock();
+  serving_sth_cv_.notify_all();
+}
+
+
+void EtcdConsistentStore::OnClusterConfigUpdated(
+    const Update<ClusterConfig>& update) {
+  if (update.exists_) {
+    VLOG(1) << "Got ClusterConfig version " << update.handle_.Handle() << ": "
+            << update.handle_.Entry().DebugString();
+    lock_guard<mutex> lock(mutex_);
+    cluster_config_.reset(new ClusterConfig(update.handle_.Entry()));
+  } else {
+    LOG(WARNING) << "ClusterConfig non-existent/deleted.";
+    // TODO(alcutter): What to do here?
+  }
+}
+
+
+StatusOr<int64_t> EtcdConsistentStore::CleanupOldEntries() {
+  ScopedLatency scoped_latency(
+      etcd_latency_by_op_ms.GetScopedLatency("cleanup_old_entries"));
+
+  if (!election_->IsMaster()) {
+    return Status(util::error::PERMISSION_DENIED,
+                  "Non-master node cannot run cleanups.");
+  }
+
+  // Figure out where we're cleaning up to...
+  unique_lock<mutex> lock(mutex_);
+  if (!serving_sth_) {
+    LOG(INFO) << "No current serving_sth, nothing to do.";
+    return 0;
+  }
+  const int64_t clean_up_to_sequence_number(serving_sth_->Entry().tree_size() -
+                                            1);
+  lock.unlock();
+
+  LOG(INFO) << "Cleaning old entries up to and including sequence number: "
+            << clean_up_to_sequence_number;
+
+  EntryHandle<SequenceMapping> sequence_mapping;
+  Status status(GetSequenceMapping(&sequence_mapping));
+  if (!status.ok()) {
+    LOG(WARNING) << "Couldn't get sequence mapping: " << status;
+    return status;
+  }
+
+  vector<string> keys_to_delete;
+  for (int mapping_index = 0;
+       mapping_index < sequence_mapping.Entry().mapping_size() &&
+       sequence_mapping.Entry().mapping(mapping_index).sequence_number() <=
+           clean_up_to_sequence_number;
+       ++mapping_index) {
+    // Delete the entry from /entries.
+    keys_to_delete.emplace_back(GetEntryPath(
+        sequence_mapping.Entry().mapping(mapping_index).entry_hash()));
+  }
+
+
+  const int64_t num_entries_cleaned(keys_to_delete.size());
+  SyncTask task(executor_);
+  EtcdForceDeleteKeys(client_, move(keys_to_delete), task.task());
+  task.Wait();
+  status = task.status();
+  if (!status.ok()) {
+    LOG(WARNING) << "EtcdDeleteKeys failed: " << task.status();
+  }
+  return num_entries_cleaned;
+}
+
+
+void EtcdConsistentStore::StartEtcdStatsFetch() {
+  if (etcd_stats_task_.task()->CancelRequested()) {
+    etcd_stats_task_.task()->Return(Status::CANCELLED);
+    return;
+  }
+  EtcdClient::StatsResponse* response(new EtcdClient::StatsResponse);
+  Task* stats_task(etcd_stats_task_.task()->AddChild(
+      bind(&EtcdConsistentStore::EtcdStatsFetchDone, this, response, _1)));
+  client_->GetStoreStats(response, stats_task);
+}
+
+
+void EtcdConsistentStore::EtcdStatsFetchDone(
+    EtcdClient::StatsResponse* response, Task* task) {
+  CHECK_NOTNULL(response);
+  CHECK_NOTNULL(task);
+  unique_ptr<EtcdClient::StatsResponse> response_deleter(response);
+  if (task->status().ok()) {
+    for (const auto& stat : response->stats) {
+      VLOG(2) << "etcd stat: " << stat.first << " = " << stat.second;
+      etcd_store_stats->Set(stat.first, stat.second);
+    }
+    const StatusOr<int64_t> num_entries(
+        CalculateNumEtcdEntries(response->stats));
+    if (num_entries.ok()) {
+      {
+        lock_guard<mutex> lock(mutex_);
+        num_etcd_entries_ = num_entries.ValueOrDie();
+      }
+      etcd_total_entries->Set("all", num_etcd_entries_);
+    } else {
+      VLOG(1) << "Failed to calculate num_entries: " << num_entries.status();
+    }
+  } else {
+    LOG(WARNING) << "Etcd stats fetch failed: " << task->status();
+  }
+
+  base_->Delay(seconds(FLAGS_etcd_stats_collection_interval_seconds),
+               etcd_stats_task_.task()->AddChild(
+                   bind(&EtcdConsistentStore::StartEtcdStatsFetch, this)));
+}
+
+// This method attempts to modulate the incoming traffic in response to the
+// number of entries currently in etcd.
+//
+// Once the number of entries is above reject_threshold, we will start
+// returning a RESOURCE_EXHAUSTED status, which should result in a 503 being
+// sent to the client.
+Status EtcdConsistentStore::MaybeReject(const string& type) const {
+  unique_lock<mutex> lock(mutex_);
+
+  if (!cluster_config_) {
+    // No config, whatever.
+    return Status::OK;
+  }
+
+  const int64_t etcd_size(num_etcd_entries_);
+  const int64_t reject_threshold(
+      cluster_config_->etcd_reject_add_pending_threshold());
+  lock.unlock();
+
+  if (etcd_size >= reject_threshold) {
+    etcd_rejected_requests->Increment(type);
+    return Status(util::error::RESOURCE_EXHAUSTED,
+                  "Rejected due to high number of pending entries.");
+  }
+  return Status::OK;
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/etcd_consistent_store.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/etcd_consistent_store.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/etcd_consistent_store.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/etcd_consistent_store.h	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,169 @@
+#ifndef CERT_TRANS_LOG_ETCD_CONSISTENT_STORE_H_
+#define CERT_TRANS_LOG_ETCD_CONSISTENT_STORE_H_
+
+#include <stdint.h>
+#include <memory>
+#include <mutex>
+#include <vector>
+
+#include "base/macros.h"
+#include "log/consistent_store.h"
+#include "log/logged_entry.h"
+#include "proto/ct.pb.h"
+#include "util/etcd.h"
+#include "util/libevent_wrapper.h"
+#include "util/status.h"
+#include "util/sync_task.h"
+
+namespace cert_trans {
+
+class MasterElection;
+
+
+class EtcdConsistentStore : public ConsistentStore {
+ public:
+  // No change of ownership for |client|, |executor| must continue to be valid
+  // at least as long as this object is, and should not be the libevent::Base
+  // used by |client|.
+  EtcdConsistentStore(libevent::Base* base, util::Executor* executor,
+                      EtcdClient* client, const MasterElection* election,
+                      const std::string& root, const std::string& node_id);
+
+  virtual ~EtcdConsistentStore();
+
+  util::StatusOr<int64_t> NextAvailableSequenceNumber() const override;
+
+  util::Status SetServingSTH(const ct::SignedTreeHead& new_sth) override;
+
+  util::StatusOr<ct::SignedTreeHead> GetServingSTH() const override;
+
+  util::Status AddPendingEntry(LoggedEntry* entry) override;
+
+  util::Status GetPendingEntryForHash(
+      const std::string& hash, EntryHandle<LoggedEntry>* entry) const override;
+
+  util::Status GetPendingEntries(
+      std::vector<EntryHandle<LoggedEntry>>* entries) const override;
+
+  util::Status GetSequenceMapping(
+      EntryHandle<ct::SequenceMapping>* entry) const override;
+
+  util::Status UpdateSequenceMapping(
+      EntryHandle<ct::SequenceMapping>* entry) override;
+
+  util::StatusOr<ct::ClusterNodeState> GetClusterNodeState() const override;
+
+  util::Status SetClusterNodeState(const ct::ClusterNodeState& state) override;
+
+  void WatchServingSTH(const ConsistentStore::ServingSTHCallback& cb,
+                       util::Task* task) override;
+
+  void WatchClusterNodeStates(
+      const ConsistentStore::ClusterNodeStateCallback& cb,
+      util::Task* task) override;
+
+  void WatchClusterConfig(const ConsistentStore::ClusterConfigCallback& cb,
+                          util::Task* task) override;
+
+  util::Status SetClusterConfig(const ct::ClusterConfig& config) override;
+
+  // Removes sequenced entries with sequence numbers covered by the current
+  // serving STH.
+  util::StatusOr<int64_t> CleanupOldEntries() override;
+
+ private:
+  void WaitForServingSTHVersion(std::unique_lock<std::mutex>* lock,
+                                const int version);
+
+  template <class T>
+  util::Status GetEntry(const std::string& path, EntryHandle<T>* entry) const;
+
+  util::Status GetAllEntriesInDir(
+      const std::string& dir,
+      std::vector<EntryHandle<LoggedEntry>>* entries) const;
+
+  util::Status UpdateEntry(EntryHandleBase* entry);
+
+  util::Status CreateEntry(EntryHandleBase* entry);
+
+  util::Status ForceSetEntry(EntryHandleBase* entry);
+
+  util::Status ForceSetEntryWithTTL(const std::chrono::seconds& ttl,
+                                    EntryHandleBase* entry);
+
+  util::Status DeleteEntry(const EntryHandleBase& entry);
+
+  std::string GetEntryPath(const LoggedEntry& entry) const;
+
+  std::string GetEntryPath(const std::string& hash) const;
+
+  std::string GetNodePath(const std::string& node_id) const;
+
+  std::string GetFullPath(const std::string& key) const;
+
+  void CheckMappingIsContiguousWithServingTree(
+      const ct::SequenceMapping& mapping) const;
+
+  // The following 3 methods are static just so that they have friend access to
+  // the private c'tor/setters of Update<>
+
+  // Converts a single Node to an Update<T> (using
+  // TypedUpdateFromNode() below), and calls |callback| with it.
+  template <class T, class CB>
+  static void ConvertSingleUpdate(
+      const std::string& full_path, const CB& callback,
+      const std::vector<EtcdClient::Node>& updates);
+
+  // Converts a vector of Nodes to a vector<Update<T>> (using
+  // TypedUpdateFromNode() below), and calls |callback| with it.
+  template <class T, class CB>
+  static void ConvertMultipleUpdate(
+      const CB& callback, const std::vector<EtcdClient::Node>& updates);
+
+  // Converts a generic Node to an Update<T>.
+  // T must implement ParseFromString().
+  template <class T>
+  static Update<T> TypedUpdateFromNode(const EtcdClient::Node& node);
+
+  void UpdateLocalServingSTH(const std::unique_lock<std::mutex>& lock,
+                             const EntryHandle<ct::SignedTreeHead>& handle);
+
+  void OnEtcdServingSTHUpdated(const Update<ct::SignedTreeHead>& update);
+
+  void OnClusterConfigUpdated(const Update<ct::ClusterConfig>& update);
+
+  void StartEtcdStatsFetch();
+  void EtcdStatsFetchDone(EtcdClient::StatsResponse* response,
+                          util::Task* task);
+
+  util::Status MaybeReject(const std::string& type) const;
+
+  EtcdClient* const client_;              // We don't own this.
+  libevent::Base* base_;                  // We don't own this.
+  util::Executor* const executor_;        // We don't own this.
+  const MasterElection* const election_;  // We don't own this.
+  const std::string root_;
+  const std::string node_id_;
+  std::condition_variable serving_sth_cv_;
+  util::SyncTask serving_sth_watch_task_;
+  util::SyncTask cluster_config_watch_task_;
+  util::SyncTask etcd_stats_task_;
+
+  mutable std::mutex mutex_;
+  bool received_initial_sth_;
+  std::unique_ptr<EntryHandle<ct::SignedTreeHead>> serving_sth_;
+  std::unique_ptr<ct::ClusterConfig> cluster_config_;
+  bool exiting_;
+  int64_t num_etcd_entries_;
+
+  friend class EtcdConsistentStoreTest;
+  template <class T>
+  friend class TreeSignerTest;
+
+  DISALLOW_COPY_AND_ASSIGN(EtcdConsistentStore);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_ETCD_CONSISTENT_STORE_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/etcd_consistent_store_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/etcd_consistent_store_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/etcd_consistent_store_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/etcd_consistent_store_test.cc	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,801 @@
+#include "log/etcd_consistent_store.h"
+
+#include <gflags/gflags.h>
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <atomic>
+#include <functional>
+#include <map>
+#include <memory>
+#include <string>
+#include <thread>
+#include <unordered_map>
+#include <unordered_set>
+
+#include "log/logged_entry.h"
+#include "monitoring/registry.h"
+#include "proto/cert_serializer.h"
+#include "proto/ct.pb.h"
+#include "util/fake_etcd.h"
+#include "util/libevent_wrapper.h"
+#include "util/mock_masterelection.h"
+#include "util/status_test_util.h"
+#include "util/testing.h"
+#include "util/thread_pool.h"
+#include "util/util.h"
+
+DECLARE_int32(node_state_ttl_seconds);
+DECLARE_int32(etcd_stats_collection_interval_seconds);
+
+namespace cert_trans {
+
+
+using ct::SequenceMapping;
+using ct::SignedTreeHead;
+using std::atomic;
+using std::bind;
+using std::chrono::milliseconds;
+using std::lock_guard;
+using std::make_pair;
+using std::make_shared;
+using std::mutex;
+using std::ostringstream;
+using std::pair;
+using std::placeholders::_1;
+using std::shared_ptr;
+using std::string;
+using std::thread;
+using std::unique_ptr;
+using std::unordered_map;
+using std::unordered_set;
+using std::vector;
+using testing::_;
+using testing::AllOf;
+using testing::ContainerEq;
+using testing::Contains;
+using testing::Pair;
+using testing::Return;
+using testing::SetArgumentPointee;
+using util::Status;
+using util::StatusOr;
+using util::SyncTask;
+using util::testing::StatusIs;
+
+
+const char kRoot[] = "/root";
+const char kNodeId[] = "node_id";
+const int kTimestamp = 9000;
+
+
+class EtcdConsistentStoreTest : public ::testing::Test {
+ public:
+  EtcdConsistentStoreTest()
+      : base_(make_shared<libevent::Base>()),
+        executor_(2),
+        event_pump_(base_),
+        client_(base_.get()) {
+  }
+
+ protected:
+  void SetUp() override {
+    Registry::Instance()->ResetForTestingOnly();
+    FLAGS_etcd_stats_collection_interval_seconds = 1;
+    store_.reset(new EtcdConsistentStore(base_.get(), &executor_, &client_,
+                                         &election_, kRoot, kNodeId));
+    InsertEntry("/root/sequence_mapping", SequenceMapping());
+  }
+
+  LoggedEntry DefaultCert() {
+    return MakeCert(kTimestamp, "leaf");
+  }
+
+  LoggedEntry MakeCert(int timestamp, const string& body) {
+    LoggedEntry cert;
+    cert.mutable_sct()->set_timestamp(timestamp);
+    cert.mutable_entry()->set_type(ct::X509_ENTRY);
+    cert.mutable_entry()->mutable_x509_entry()->set_leaf_certificate(body);
+    return cert;
+  }
+
+  LoggedEntry MakeSequencedCert(int timestamp, const string& body, int seq) {
+    LoggedEntry cert(MakeCert(timestamp, body));
+    cert.set_sequence_number(seq);
+    return cert;
+  }
+
+  string CertPath(const LoggedEntry& cert) const {
+    return string(kRoot) + "/entries/ " + util::HexString(cert.Hash());
+  }
+
+  EntryHandle<LoggedEntry> HandleForCert(const LoggedEntry& cert) {
+    return EntryHandle<LoggedEntry>(CertPath(cert), cert);
+  }
+
+  EntryHandle<LoggedEntry> HandleForCert(const LoggedEntry& cert, int handle) {
+    return EntryHandle<LoggedEntry>(CertPath(cert), cert, handle);
+  }
+
+  void PopulateForCleanupTests(int num_seq, int num_pending,
+                               int starting_seq) {
+    int timestamp(345345);
+    int seq(starting_seq);
+    EntryHandle<SequenceMapping> mapping;
+    Status status(store_->GetSequenceMapping(&mapping));
+    CHECK_EQ(Status::OK, status);
+    for (int i = 0; i < num_seq; ++i) {
+      std::ostringstream ss;
+      ss << "sequenced body " << i;
+      LoggedEntry lc(MakeCert(timestamp++, ss.str()));
+      CHECK(store_->AddPendingEntry(&lc).ok());
+      SequenceMapping::Mapping* m(mapping.MutableEntry()->add_mapping());
+      m->set_entry_hash(lc.Hash());
+      m->set_sequence_number(seq++);
+    }
+    CHECK_EQ(Status::OK, store_->UpdateSequenceMapping(&mapping));
+    for (int i = 0; i < num_pending; ++i) {
+      std::ostringstream ss;
+      ss << "pending body " << i;
+      LoggedEntry lc(MakeCert(timestamp++, ss.str()));
+      CHECK(store_->AddPendingEntry(&lc).ok());
+    }
+  }
+
+  util::StatusOr<int64_t> CleanupOldEntries() {
+    return store_->CleanupOldEntries();
+  }
+
+  void AddSequenceMapping(int64_t seq, const string& hash) {
+    EntryHandle<SequenceMapping> mapping;
+    Status status(store_->GetSequenceMapping(&mapping));
+    CHECK_EQ(Status::OK, status);
+    SequenceMapping::Mapping* m(mapping.MutableEntry()->add_mapping());
+    m->set_sequence_number(seq);
+    m->set_entry_hash(hash);
+    CHECK_EQ(Status::OK, store_->UpdateSequenceMapping(&mapping));
+  }
+
+
+  template <class T>
+  void ForceSetEntry(const string& key, const T& thing) {
+    // Set up scenario:
+    SyncTask task(base_.get());
+    EtcdClient::Response resp;
+    client_.ForceSet(key, Serialize(thing), &resp, task.task());
+    task.Wait();
+    ASSERT_EQ(Status::OK, task.status());
+  }
+
+
+  template <class T>
+  void InsertEntry(const string& key, const T& thing) {
+    // Set up scenario:
+    SyncTask task(base_.get());
+    EtcdClient::Response resp;
+    client_.Create(key, Serialize(thing), &resp, task.task());
+    task.Wait();
+    ASSERT_EQ(Status::OK, task.status());
+  }
+
+  template <class T>
+  void PeekEntry(const string& key, T* thing) {
+    EtcdClient::GetResponse resp;
+    SyncTask task(base_.get());
+    client_.Get(key, &resp, task.task());
+    task.Wait();
+    ASSERT_EQ(Status::OK, task.status());
+    Deserialize(resp.node.value_, thing);
+  }
+
+  template <class T>
+  string Serialize(const T& t) {
+    string flat;
+    t.SerializeToString(&flat);
+    return util::ToBase64(flat);
+  }
+
+  template <class T>
+  void Deserialize(const string& flat, T* t) {
+    ASSERT_TRUE(t->ParseFromString(util::FromBase64(flat.c_str())));
+  }
+
+  template <class T>
+  EtcdClient::Node NodeFor(const int index, const std::string& key,
+                           const T& t) {
+    return EtcdClient::Node(index, index, key, Serialize(t));
+  }
+
+  ct::SignedTreeHead ServingSTH() {
+    return store_->serving_sth_->Entry();
+  }
+
+  int64_t GetNumEtcdEntries() const {
+    return store_->num_etcd_entries_;
+  }
+
+
+  shared_ptr<libevent::Base> base_;
+  ThreadPool executor_;
+  libevent::EventPumpThread event_pump_;
+  FakeEtcdClient client_;
+  MockMasterElection election_;
+  unique_ptr<EtcdConsistentStore> store_;
+};
+
+
+typedef class EtcdConsistentStoreTest EtcdConsistentStoreDeathTest;
+
+
+TEST_F(
+    EtcdConsistentStoreDeathTest,
+    TestNextAvailableSequenceNumberWhenNoSequencedEntriesOrServingSTHExist) {
+  util::StatusOr<int64_t> sequence_number(
+      store_->NextAvailableSequenceNumber());
+  ASSERT_EQ(Status::OK, sequence_number.status());
+  EXPECT_EQ(0, sequence_number.ValueOrDie());
+}
+
+
+TEST_F(EtcdConsistentStoreTest,
+       TestNextAvailableSequenceNumberWhenSequencedEntriesExist) {
+  AddSequenceMapping(0, "zero");
+  AddSequenceMapping(1, "one");
+  util::StatusOr<int64_t> sequence_number(
+      store_->NextAvailableSequenceNumber());
+  ASSERT_EQ(Status::OK, sequence_number.status());
+  EXPECT_EQ(2, sequence_number.ValueOrDie());
+}
+
+
+TEST_F(EtcdConsistentStoreTest,
+       TestNextAvailableSequenceNumberWhenNoSequencedEntriesExistButHaveSTH) {
+  ct::SignedTreeHead serving_sth;
+  serving_sth.set_timestamp(123);
+  serving_sth.set_tree_size(600);
+  EXPECT_TRUE(store_->SetServingSTH(serving_sth).ok());
+
+  util::StatusOr<int64_t> sequence_number(
+      store_->NextAvailableSequenceNumber());
+  ASSERT_EQ(Status::OK, sequence_number.status());
+  EXPECT_EQ(serving_sth.tree_size(), sequence_number.ValueOrDie());
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestSetServingSTH) {
+  ct::SignedTreeHead sth;
+  util::Status status(store_->SetServingSTH(sth));
+  EXPECT_TRUE(status.ok()) << status;
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestSetServingSTHOverwrites) {
+  ct::SignedTreeHead sth;
+  sth.set_timestamp(234);
+  util::Status status(store_->SetServingSTH(sth));
+  EXPECT_TRUE(status.ok()) << status;
+
+  ct::SignedTreeHead sth2;
+  sth2.set_timestamp(sth.timestamp() + 1);
+  status = store_->SetServingSTH(sth2);
+  EXPECT_TRUE(status.ok()) << status;
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestSetServingSTHWontOverwriteWithOlder) {
+  ct::SignedTreeHead sth;
+  sth.set_timestamp(234);
+  EXPECT_OK(store_->SetServingSTH(sth));
+
+  ct::SignedTreeHead sth2;
+  sth2.set_timestamp(sth.timestamp() - 1);
+  EXPECT_THAT(store_->SetServingSTH(sth2),
+              StatusIs(util::error::OUT_OF_RANGE));
+}
+
+TEST_F(EtcdConsistentStoreDeathTest, TestSetServingSTHChecksInconsistentSize) {
+  ct::SignedTreeHead sth;
+  sth.set_timestamp(234);
+  sth.set_tree_size(10);
+  util::Status status(store_->SetServingSTH(sth));
+  EXPECT_TRUE(status.ok()) << status;
+
+  ct::SignedTreeHead sth2;
+  // newer STH...
+  sth2.set_timestamp(sth.timestamp() + 1);
+  // but. curiously, a smaller tree...
+  sth2.set_tree_size(sth.tree_size() - 1);
+  EXPECT_DEATH(store_->SetServingSTH(sth2), "tree_size");
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestAddPendingEntryWorks) {
+  LoggedEntry cert(DefaultCert());
+  util::Status status(store_->AddPendingEntry(&cert));
+  ASSERT_EQ(Status::OK, status);
+  EtcdClient::GetResponse resp;
+  SyncTask task(base_.get());
+  client_.Get(string(kRoot) + "/entries/" + util::HexString(cert.Hash()),
+              &resp, task.task());
+  task.Wait();
+  EXPECT_EQ(Status::OK, task.status());
+  EXPECT_EQ(Serialize(cert), resp.node.value_);
+}
+
+
+TEST_F(EtcdConsistentStoreTest,
+       TestAddPendingEntryForExistingEntryReturnsSct) {
+  LoggedEntry cert(DefaultCert());
+  LoggedEntry other_cert(DefaultCert());
+  other_cert.mutable_sct()->set_timestamp(55555);
+
+  const string kKey(util::HexString(cert.Hash()));
+  const string kPath(string(kRoot) + "/entries/" + kKey);
+  // Set up scenario:
+  InsertEntry(kPath, other_cert);
+
+  EXPECT_THAT(store_->AddPendingEntry(&cert),
+              StatusIs(util::error::ALREADY_EXISTS));
+  EXPECT_EQ(other_cert.timestamp(), cert.timestamp());
+}
+
+
+TEST_F(EtcdConsistentStoreDeathTest,
+       TestAddPendingEntryForExistingNonIdenticalEntry) {
+  LoggedEntry cert(DefaultCert());
+  LoggedEntry other_cert(MakeCert(2342, "something else"));
+
+  const string kKey(util::HexString(cert.Hash()));
+  const string kPath(string(kRoot) + "/entries/" + kKey);
+  // Set up scenario:
+  InsertEntry(kPath, other_cert);
+
+  EXPECT_DEATH(store_->AddPendingEntry(&cert),
+               "Check failed: LeafEntriesMatch");
+}
+
+
+TEST_F(EtcdConsistentStoreDeathTest,
+       TestAddPendingEntryDoesNotAcceptSequencedEntry) {
+  LoggedEntry cert(DefaultCert());
+  cert.set_sequence_number(76);
+  EXPECT_DEATH(store_->AddPendingEntry(&cert),
+               "!entry\\->has_sequence_number");
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestGetPendingEntryForHash) {
+  const LoggedEntry one(MakeCert(123, "one"));
+  const string kPath(string(kRoot) + "/entries/" +
+                     util::HexString(one.Hash()));
+  InsertEntry(kPath, one);
+
+  EntryHandle<LoggedEntry> handle;
+  util::Status status(store_->GetPendingEntryForHash(one.Hash(), &handle));
+  EXPECT_TRUE(status.ok()) << status;
+  EXPECT_EQ(one, handle.Entry());
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestGetPendingEntryForNonExistantHash) {
+  const string kPath(string(kRoot) + "/entries/" + util::HexString("Nah"));
+  EntryHandle<LoggedEntry> handle;
+  EXPECT_THAT(store_->GetPendingEntryForHash("Nah", &handle),
+              StatusIs(util::error::NOT_FOUND));
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestGetPendingEntries) {
+  const string kPath(string(kRoot) + "/entries/");
+  const LoggedEntry one(MakeCert(123, "one"));
+  const LoggedEntry two(MakeCert(456, "two"));
+  InsertEntry(kPath + "one", one);
+  InsertEntry(kPath + "two", two);
+
+  vector<EntryHandle<LoggedEntry>> entries;
+  util::Status status(store_->GetPendingEntries(&entries));
+  EXPECT_TRUE(status.ok()) << status;
+  EXPECT_EQ(static_cast<size_t>(2), entries.size());
+  vector<LoggedEntry> certs;
+  for (const auto& e : entries) {
+    certs.push_back(e.Entry());
+  }
+  EXPECT_THAT(certs, AllOf(Contains(one), Contains(two)));
+}
+
+
+TEST_F(EtcdConsistentStoreDeathTest,
+       TestGetPendingEntriesBarfsWithSequencedEntry) {
+  const string kPath(string(kRoot) + "/entries/");
+  LoggedEntry one(MakeSequencedCert(123, "one", 666));
+  InsertEntry(kPath + "one", one);
+  vector<EntryHandle<LoggedEntry>> entries;
+  EXPECT_DEATH(store_->GetPendingEntries(&entries), "has_sequence_number");
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestGetSequenceMapping) {
+  AddSequenceMapping(0, "zero");
+  AddSequenceMapping(1, "one");
+  EntryHandle<SequenceMapping> mapping;
+  util::Status status(store_->GetSequenceMapping(&mapping));
+  CHECK_EQ(util::Status::OK, status);
+
+  EXPECT_EQ(2, mapping.Entry().mapping_size());
+  EXPECT_EQ(0, mapping.Entry().mapping(0).sequence_number());
+  EXPECT_EQ("zero", mapping.Entry().mapping(0).entry_hash());
+  EXPECT_EQ(1, mapping.Entry().mapping(1).sequence_number());
+  EXPECT_EQ("one", mapping.Entry().mapping(1).entry_hash());
+}
+
+
+TEST_F(EtcdConsistentStoreTest,
+       TestGetSequenceMappingAllowsGapsBelowTreeSize) {
+  SignedTreeHead sth;
+  sth.set_tree_size(3);
+  store_->SetServingSTH(sth);
+
+  SequenceMapping mapping;
+  mapping.add_mapping()->set_sequence_number(0);
+  mapping.add_mapping()->set_sequence_number(2);
+  ForceSetEntry("/root/sequence_mapping", mapping);
+  EntryHandle<SequenceMapping> entry;
+  EXPECT_OK(store_->GetSequenceMapping(&entry));
+}
+
+
+TEST_F(EtcdConsistentStoreDeathTest,
+       TestGetSequenceMappingBarfsOnGapsAboveTreeSize) {
+  SignedTreeHead sth;
+  sth.set_tree_size(0);
+  store_->SetServingSTH(sth);
+
+  SequenceMapping mapping;
+  mapping.add_mapping()->set_sequence_number(0);
+  mapping.add_mapping()->set_sequence_number(2);
+  ForceSetEntry("/root/sequence_mapping", mapping);
+  EntryHandle<SequenceMapping> entry;
+  EXPECT_DEATH(store_->GetSequenceMapping(&entry), "mapped_seq \\+ 1");
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestUpdateSequenceMapping) {
+  EntryHandle<SequenceMapping> mapping;
+  Status status(store_->GetSequenceMapping(&mapping));
+  EXPECT_EQ(Status::OK, status);
+
+  const SequenceMapping original(mapping.Entry());
+
+  SequenceMapping::Mapping* m(mapping.MutableEntry()->add_mapping());
+  m->set_sequence_number(0);
+  m->set_entry_hash("zero");
+  EXPECT_EQ(Status::OK, store_->UpdateSequenceMapping(&mapping));
+
+  status = store_->GetSequenceMapping(&mapping);
+  EXPECT_EQ(Status::OK, status);
+
+  EXPECT_EQ(mapping.Entry().mapping_size(), original.mapping_size() + 1);
+  EXPECT_EQ(0, mapping.Entry()
+                   .mapping(mapping.Entry().mapping_size() - 1)
+                   .sequence_number());
+  EXPECT_EQ("zero", mapping.Entry()
+                        .mapping(mapping.Entry().mapping_size() - 1)
+                        .entry_hash());
+}
+
+
+TEST_F(EtcdConsistentStoreDeathTest,
+       TestUpdateSequenceMappingBarfsWithOutOfOrderSequenceNumber) {
+  EntryHandle<SequenceMapping> mapping;
+  Status status(store_->GetSequenceMapping(&mapping));
+  EXPECT_EQ(Status::OK, status);
+
+  SequenceMapping::Mapping* m1(mapping.MutableEntry()->add_mapping());
+  m1->set_sequence_number(2);
+  m1->set_entry_hash("two");
+  SequenceMapping::Mapping* m2(mapping.MutableEntry()->add_mapping());
+  m2->set_sequence_number(0);
+  m2->set_entry_hash("zero");
+  EXPECT_DEATH(store_->UpdateSequenceMapping(&mapping),
+               "sequence_number\\(\\) < mapping");
+}
+
+TEST_F(EtcdConsistentStoreDeathTest,
+       TestUpdateSequenceMappingBarfsMappingNonContiguousToServingTree) {
+  SignedTreeHead sth;
+  sth.set_timestamp(123);
+  sth.set_tree_size(1000);
+  CHECK_EQ(Status::OK, store_->SetServingSTH(sth));
+
+  EntryHandle<SequenceMapping> mapping;
+  Status status(store_->GetSequenceMapping(&mapping));
+  EXPECT_EQ(Status::OK, status);
+
+  SequenceMapping::Mapping* m1(mapping.MutableEntry()->add_mapping());
+  m1->set_sequence_number(sth.tree_size() + 1);
+  m1->set_entry_hash("zero");
+  EXPECT_DEATH(store_->UpdateSequenceMapping(&mapping),
+               "lowest_sequence_number <= tree_size");
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestSetClusterNodeState) {
+  const string kPath(string(kRoot) + "/nodes/" + kNodeId);
+
+  ct::ClusterNodeState state;
+  state.set_node_id(kNodeId);
+
+  util::Status status(store_->SetClusterNodeState(state));
+  EXPECT_TRUE(status.ok()) << status;
+
+  ct::ClusterNodeState set_state;
+  PeekEntry(kPath, &set_state);
+  EXPECT_EQ(state.node_id(), set_state.node_id());
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestSetClusterNodeStateHasTTL) {
+  FLAGS_node_state_ttl_seconds = 1;
+  const string kPath(string(kRoot) + "/nodes/" + kNodeId);
+
+  ct::ClusterNodeState state;
+  state.set_node_id(kNodeId);
+
+  util::Status status(store_->SetClusterNodeState(state));
+  EXPECT_TRUE(status.ok()) << status;
+
+  ct::ClusterNodeState set_state;
+  PeekEntry(kPath, &set_state);
+  EXPECT_EQ(state.node_id(), set_state.node_id());
+
+  sleep(2);
+
+  EtcdClient::GetResponse resp;
+  SyncTask task(base_.get());
+  client_.Get(kPath, &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::NOT_FOUND));
+}
+
+
+TEST_F(EtcdConsistentStoreTest, WatchServingSTH) {
+  Notification notify;
+
+  const string kPath(string(kRoot) + "/serving_sth");
+
+  ct::SignedTreeHead sth;
+  sth.set_timestamp(234234);
+
+  SyncTask task(&executor_);
+  mutex mutex;
+  int call_count(0);
+  store_->WatchServingSTH(
+      [&sth, &notify, &call_count,
+       &mutex](const Update<ct::SignedTreeHead>& update) {
+        lock_guard<std::mutex> lock(mutex);
+        ASSERT_LE(call_count, 2)
+            << "Extra update: key:" << update.handle_.Key() << "@"
+            << update.handle_.Handle() << " exists:" << update.exists_
+            << " entry: " << update.handle_.Entry().DebugString();
+        switch (call_count) {
+          case 0:
+            // initial empty state
+            EXPECT_FALSE(update.exists_);
+            break;
+          case 1:
+            // notification of update
+            EXPECT_TRUE(update.exists_);
+            EXPECT_EQ(sth.DebugString(), update.handle_.Entry().DebugString());
+            notify.Notify();
+            break;
+        }
+        ++call_count;
+      },
+      task.task());
+
+  util::Status status(store_->SetServingSTH(sth));
+  EXPECT_TRUE(status.ok()) << status;
+  notify.WaitForNotification();
+  EXPECT_EQ(ServingSTH().DebugString(), sth.DebugString());
+  task.Cancel();
+  task.Wait();
+}
+
+
+TEST_F(EtcdConsistentStoreTest, WatchClusterNodeStates) {
+  const string kPath(string(kRoot) + "/nodes/" + kNodeId);
+
+  ct::ClusterNodeState state;
+  state.set_node_id(kNodeId);
+
+  SyncTask task(&executor_);
+  store_->WatchClusterNodeStates(
+      [&state](const vector<Update<ct::ClusterNodeState>>& updates) {
+        if (updates.empty()) {
+          VLOG(1) << "Ignoring initial empty update.";
+          return;
+        }
+        EXPECT_TRUE(updates[0].exists_);
+        EXPECT_EQ(updates[0].handle_.Entry().DebugString(),
+                  state.DebugString());
+      },
+      task.task());
+  util::Status status(store_->SetClusterNodeState(state));
+  EXPECT_TRUE(status.ok()) << status;
+  task.Cancel();
+  task.Wait();
+}
+
+
+TEST_F(EtcdConsistentStoreTest, WatchClusterConfig) {
+  const string kPath(string(kRoot) + "/cluster_config");
+
+  ct::ClusterConfig config;
+  config.set_minimum_serving_nodes(1);
+  config.set_minimum_serving_fraction(0.6);
+  Notification notification;
+
+  SyncTask task(&executor_);
+  store_->WatchClusterConfig(
+      [&config, &notification](const Update<ct::ClusterConfig>& update) {
+        if (!update.exists_) {
+          VLOG(1) << "Ignoring initial empty update.";
+          return;
+        }
+        EXPECT_TRUE(update.exists_);
+        EXPECT_EQ(update.handle_.Entry().DebugString(), config.DebugString());
+        notification.Notify();
+      },
+      task.task());
+  util::Status status(store_->SetClusterConfig(config));
+  EXPECT_TRUE(status.ok()) << status;
+  // Make sure we got called from the watcher:
+  EXPECT_TRUE(notification.WaitForNotificationWithTimeout(milliseconds(5000)));
+  task.Cancel();
+  task.Wait();
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestDoesNotCleanUpIfNotMaster) {
+  EXPECT_CALL(election_, IsMaster()).WillRepeatedly(Return(false));
+  EXPECT_THAT(CleanupOldEntries().status(),
+              StatusIs(util::error::PERMISSION_DENIED));
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestEmptyClean) {
+  EXPECT_CALL(election_, IsMaster()).WillRepeatedly(Return(true));
+  const StatusOr<int64_t> num_cleaned(CleanupOldEntries());
+  ASSERT_OK(num_cleaned.status());
+  EXPECT_EQ(0, num_cleaned.ValueOrDie());
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestCleansUpToNewSTH) {
+  PopulateForCleanupTests(5, 4, 100);
+
+  // Be sure about our starting state of sequenced entries so we can compare
+  // later on
+  EntryHandle<SequenceMapping> orig_seq_mapping;
+  ASSERT_EQ(Status::OK, store_->GetSequenceMapping(&orig_seq_mapping));
+  EXPECT_EQ(5, orig_seq_mapping.Entry().mapping_size());
+
+  // Do the same for the pending entries
+  vector<EntryHandle<LoggedEntry>> pending_entries_pre;
+  CHECK(store_->GetPendingEntries(&pending_entries_pre).ok());
+  // Prune out any "pending" entries which have counterparts in the
+  // "sequenced" set:
+  unordered_map<int64_t, string> seq_to_hash;
+  {
+    unordered_set<string> seq_hashes;
+    for (auto& m : orig_seq_mapping.Entry().mapping()) {
+      seq_hashes.insert(m.entry_hash());
+      seq_to_hash.insert(make_pair(m.sequence_number(), m.entry_hash()));
+    }
+    auto it(pending_entries_pre.begin());
+    while (it != pending_entries_pre.end()) {
+      if (seq_hashes.find(it->Entry().Hash()) != seq_hashes.end()) {
+        it = pending_entries_pre.erase(it);
+      } else {
+        ++it;
+      }
+    }
+  }
+  EXPECT_EQ(static_cast<size_t>(4), pending_entries_pre.size());
+
+  EXPECT_CALL(election_, IsMaster()).WillRepeatedly(Return(true));
+
+  // Set ServingSTH to something which will cause entries 100, 101, and 102 to
+  // be cleaned up:
+  SignedTreeHead sth;
+  sth.set_timestamp(345345);
+  sth.set_tree_size(103);
+  CHECK(store_->SetServingSTH(sth).ok());
+  {
+    const StatusOr<int64_t> num_cleaned(CleanupOldEntries());
+    ASSERT_OK(num_cleaned.status());
+    EXPECT_EQ(3, num_cleaned.ValueOrDie());
+  }
+
+  EntryHandle<LoggedEntry> unused;
+  EXPECT_THAT(store_->GetPendingEntryForHash(seq_to_hash[100], &unused),
+              StatusIs(util::error::NOT_FOUND));
+  EXPECT_THAT(store_->GetPendingEntryForHash(seq_to_hash[101], &unused),
+              StatusIs(util::error::NOT_FOUND));
+  EXPECT_THAT(store_->GetPendingEntryForHash(seq_to_hash[102], &unused),
+              StatusIs(util::error::NOT_FOUND));
+  EXPECT_OK(store_->GetPendingEntryForHash(seq_to_hash[103], &unused));
+
+  // Check that we didn't modify the sequence mapping:
+  EntryHandle<SequenceMapping> seq_mapping;
+  CHECK(store_->GetSequenceMapping(&seq_mapping).ok());
+  EXPECT_EQ(orig_seq_mapping.Entry().DebugString(),
+            seq_mapping.Entry().DebugString());
+
+  // Now update ServingSTH so that all sequenced entries should be cleaned up:
+  sth.set_timestamp(sth.timestamp() + 1);
+  sth.set_tree_size(105);
+  CHECK(store_->SetServingSTH(sth).ok());
+  {
+    const StatusOr<int64_t> num_cleaned(CleanupOldEntries());
+    ASSERT_OK(num_cleaned.status());
+    EXPECT_EQ(5, num_cleaned.ValueOrDie());
+  }
+
+
+  // Ensure they were:
+  EXPECT_THAT(store_->GetPendingEntryForHash(seq_to_hash[103], &unused),
+              StatusIs(util::error::NOT_FOUND));
+  EXPECT_THAT(store_->GetPendingEntryForHash(seq_to_hash[104], &unused),
+              StatusIs(util::error::NOT_FOUND));
+
+  // Check that we didn't modify the sequence mapping:
+  CHECK(store_->GetSequenceMapping(&seq_mapping).ok());
+  EXPECT_EQ(orig_seq_mapping.Entry().DebugString(),
+            seq_mapping.Entry().DebugString());
+
+  // Check we've not touched the pending entries:
+  vector<EntryHandle<LoggedEntry>> pending_entries_post;
+  CHECK(store_->GetPendingEntries(&pending_entries_post).ok());
+  EXPECT_EQ(pending_entries_pre.size(), pending_entries_post.size());
+  for (int i = 0; i < static_cast<int>(pending_entries_pre.size()); ++i) {
+    EXPECT_EQ(pending_entries_pre[i].Handle(),
+              pending_entries_post[i].Handle());
+    EXPECT_EQ(pending_entries_pre[i].Entry(), pending_entries_post[i].Entry());
+  }
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestStoreStatsFetcher) {
+  EXPECT_EQ(0, GetNumEtcdEntries());
+  PopulateForCleanupTests(100, 100, 100);
+  sleep(2 * FLAGS_etcd_stats_collection_interval_seconds);
+  EXPECT_LE(200, GetNumEtcdEntries());
+}
+
+
+TEST_F(EtcdConsistentStoreTest, TestRejectsAddsWhenOverCapacity) {
+  ct::ClusterConfig config;
+  config.set_etcd_reject_add_pending_threshold(2);
+  util::Status status(store_->SetClusterConfig(config));
+  ASSERT_OK(status);
+
+  EXPECT_EQ(0, GetNumEtcdEntries());
+
+  PopulateForCleanupTests(3, 0, 1);
+  sleep(2 * FLAGS_etcd_stats_collection_interval_seconds);
+
+  EXPECT_LT(2, GetNumEtcdEntries());
+
+  LoggedEntry cert(MakeCert(1000, "cert1000"));
+  EXPECT_THAT(store_->AddPendingEntry(&cert),
+              StatusIs(util::error::RESOURCE_EXHAUSTED));
+}
+
+
+}  // namespace cert_trans
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  ::testing::FLAGS_gtest_death_test_style = "threadsafe";
+  ConfigureSerializerForV1CT();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/file_db.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/file_db.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/file_db.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/file_db.cc	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,371 @@
+#include "log/file_db.h"
+
+#include <glog/logging.h>
+#include <stdint.h>
+#include <map>
+#include <set>
+#include <string>
+#include <vector>
+
+#include "log/file_storage.h"
+#include "monitoring/latency.h"
+#include "monitoring/monitoring.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+#include "util/util.h"
+
+using cert_trans::serialization::DeserializeResult;
+using std::chrono::milliseconds;
+using std::lock_guard;
+using std::make_pair;
+using std::min;
+using std::mutex;
+using std::set;
+using std::stoll;
+using std::string;
+using std::to_string;
+using std::unique_lock;
+using std::unique_ptr;
+
+namespace cert_trans {
+namespace {
+
+
+static Latency<milliseconds, string> latency_by_op_ms(
+    "filedb_latency_by_operation_ms", "operation",
+    "Database latency in ms broken out by operation.");
+
+
+const char kMetaNodeIdKey[] = "node_id";
+
+
+string FormatSequenceNumber(const int64_t seq) {
+  return to_string(seq);
+}
+
+
+int64_t ParseSequenceNumber(const string& seq) {
+  return stoll(seq);
+}
+
+
+}  // namespace
+
+
+const size_t FileDB::kTimestampBytesIndexed = 6;
+
+
+class FileDB::Iterator : public Database::Iterator {
+ public:
+  Iterator(const FileDB* db, int64_t start_index)
+      : db_(CHECK_NOTNULL(db)), next_index_(start_index) {
+    CHECK_GE(next_index_, 0);
+  }
+
+  bool GetNextEntry(LoggedEntry* entry) override {
+    CHECK_NOTNULL(entry);
+    {
+      lock_guard<mutex> lock(db_->lock_);
+      if (next_index_ >= db_->contiguous_size_) {
+        set<int64_t>::const_iterator it(
+            db_->sparse_entries_.lower_bound(next_index_));
+        if (it == db_->sparse_entries_.end()) {
+          return false;
+        }
+
+        next_index_ = *it;
+      }
+    }
+
+    CHECK_EQ(db_->LookupByIndex(next_index_, entry), Database::LOOKUP_OK);
+    ++next_index_;
+    return true;
+  }
+
+ private:
+  const FileDB* const db_;
+  int64_t next_index_;
+};
+
+
+FileDB::FileDB(FileStorage* cert_storage, FileStorage* tree_storage,
+               FileStorage* meta_storage)
+    : cert_storage_(CHECK_NOTNULL(cert_storage)),
+      tree_storage_(CHECK_NOTNULL(tree_storage)),
+      meta_storage_(CHECK_NOTNULL(meta_storage)),
+      contiguous_size_(0),
+      latest_tree_timestamp_(0) {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("open"));
+  BuildIndex();
+}
+
+
+FileDB::~FileDB() {
+}
+
+
+Database::WriteResult FileDB::CreateSequencedEntry_(
+    const LoggedEntry& logged) {
+  CHECK(logged.has_sequence_number());
+  CHECK_GE(logged.sequence_number(), 0);
+  ScopedLatency latency(
+      latency_by_op_ms.GetScopedLatency("create_sequenced_entry"));
+
+  string data;
+  CHECK(logged.SerializeToString(&data));
+
+  const string seq_str(FormatSequenceNumber(logged.sequence_number()));
+
+  unique_lock<mutex> lock(lock_);
+
+  // Try to create.
+  util::Status status(cert_storage_->CreateEntry(seq_str, data));
+  if (status.CanonicalCode() == util::error::ALREADY_EXISTS) {
+    string existing_data;
+    status = cert_storage_->LookupEntry(seq_str, &existing_data);
+    CHECK_EQ(status, util::Status::OK);
+    if (existing_data == data) {
+      return this->OK;
+    }
+    return this->SEQUENCE_NUMBER_ALREADY_IN_USE;
+  }
+  CHECK_EQ(status, util::Status::OK);
+
+  InsertEntryMapping(logged.sequence_number(), logged.Hash());
+
+  return this->OK;
+}
+
+
+Database::LookupResult FileDB::LookupByHash(const string& hash,
+                                            LoggedEntry* result) const {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("lookup_by_hash"));
+
+  unique_lock<mutex> lock(lock_);
+
+  auto i(id_by_hash_.find(hash));
+  if (i == id_by_hash_.end()) {
+    return this->NOT_FOUND;
+  }
+  const string seq_str(FormatSequenceNumber(i->second));
+
+  lock.unlock();
+
+  string cert_data;
+  const util::Status status(cert_storage_->LookupEntry(seq_str, &cert_data));
+  // Gotta be there, or we're in trouble...
+  CHECK_EQ(status, util::Status::OK);
+
+  if (result) {
+    CHECK(result->ParseFromString(cert_data));
+    CHECK_EQ(result->Hash(), hash);
+  }
+
+  return this->LOOKUP_OK;
+}
+
+
+Database::LookupResult FileDB::LookupByIndex(int64_t sequence_number,
+                                             LoggedEntry* result) const {
+  CHECK_GE(sequence_number, 0);
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("lookup_by_index"));
+
+  const string seq_str(FormatSequenceNumber(sequence_number));
+  string cert_data;
+  if (cert_storage_->LookupEntry(seq_str, &cert_data).CanonicalCode() ==
+      util::error::NOT_FOUND) {
+    return this->NOT_FOUND;
+  }
+  if (result) {
+    CHECK(result->ParseFromString(cert_data));
+    CHECK_EQ(result->sequence_number(), sequence_number);
+  }
+  return this->LOOKUP_OK;
+}
+
+
+unique_ptr<Database::Iterator> FileDB::ScanEntries(int64_t start_index) const {
+  return unique_ptr<Iterator>(new Iterator(this, start_index));
+}
+
+
+Database::WriteResult FileDB::WriteTreeHead_(const ct::SignedTreeHead& sth) {
+  CHECK_GE(sth.tree_size(), 0);
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("write_tree_head"));
+
+  // 6 bytes are good enough for some 9000 years.
+  string timestamp_key =
+      Serializer::SerializeUint(sth.timestamp(),
+                                FileDB::kTimestampBytesIndexed);
+  string data;
+  CHECK(sth.SerializeToString(&data));
+
+  unique_lock<mutex> lock(lock_);
+  util::Status status(tree_storage_->CreateEntry(timestamp_key, data));
+  if (status.CanonicalCode() == util::error::ALREADY_EXISTS) {
+    string existing_sth_data;
+    status = tree_storage_->LookupEntry(timestamp_key, &existing_sth_data);
+    CHECK_EQ(status, util::Status::OK);
+    if (existing_sth_data == data) {
+      LOG(WARNING) << "Attempted to store identical STH in DB.";
+      return this->OK;
+    }
+    return this->DUPLICATE_TREE_HEAD_TIMESTAMP;
+  }
+  CHECK_EQ(status, util::Status::OK);
+
+  if (sth.timestamp() > latest_tree_timestamp_) {
+    latest_tree_timestamp_ = sth.timestamp();
+    latest_timestamp_key_ = timestamp_key;
+  }
+
+  lock.unlock();
+  callbacks_.Call(sth);
+
+  return this->OK;
+}
+
+
+Database::LookupResult FileDB::LatestTreeHead(
+    ct::SignedTreeHead* result) const {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("latest_tree_head"));
+  lock_guard<mutex> lock(lock_);
+
+  return LatestTreeHeadNoLock(result);
+}
+
+
+int64_t FileDB::TreeSize() const {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("tree_size"));
+  lock_guard<mutex> lock(lock_);
+
+  return contiguous_size_;
+}
+
+
+void FileDB::AddNotifySTHCallback(
+    const Database::NotifySTHCallback* callback) {
+  unique_lock<mutex> lock(lock_);
+
+  callbacks_.Add(callback);
+
+  ct::SignedTreeHead sth;
+  if (LatestTreeHeadNoLock(&sth) == this->LOOKUP_OK) {
+    lock.unlock();
+    (*callback)(sth);
+  }
+}
+
+
+void FileDB::RemoveNotifySTHCallback(
+    const Database::NotifySTHCallback* callback) {
+  lock_guard<mutex> lock(lock_);
+
+  callbacks_.Remove(callback);
+}
+
+
+void FileDB::InitializeNode(const string& node_id) {
+  CHECK(!node_id.empty());
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("initialize_node"));
+  unique_lock<mutex> lock(lock_);
+  string existing_id;
+  if (NodeId(&existing_id) != this->NOT_FOUND) {
+    LOG(FATAL) << "Attempting to initialze DB belonging to node with node_id: "
+               << existing_id;
+  }
+  CHECK(meta_storage_->CreateEntry(kMetaNodeIdKey, node_id).ok());
+}
+
+
+Database::LookupResult FileDB::NodeId(string* node_id) {
+  CHECK_NOTNULL(node_id);
+  if (!meta_storage_->LookupEntry(kMetaNodeIdKey, node_id).ok()) {
+    return this->NOT_FOUND;
+  }
+  return this->LOOKUP_OK;
+}
+
+
+void FileDB::BuildIndex() {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("build_index"));
+  // Technically, this should only be called from the constructor, so
+  // this should not be necessarily, but just to be sure...
+  lock_guard<mutex> lock(lock_);
+
+  const set<string> sequence_numbers(cert_storage_->Scan());
+  id_by_hash_.reserve(sequence_numbers.size());
+
+  for (const auto& seq_path : sequence_numbers) {
+    const int64_t seq(ParseSequenceNumber(seq_path));
+    string cert_data;
+    // Read the data; tolerate no errors.
+    CHECK_EQ(cert_storage_->LookupEntry(seq_path, &cert_data),
+             util::Status::OK)
+        << "Failed to read entry with sequence number " << seq;
+
+    LoggedEntry logged;
+    CHECK(logged.ParseFromString(cert_data))
+        << "Failed to parse entry with sequence number " << seq;
+    CHECK(logged.has_sequence_number())
+        << "sequence_number() is unset for for entry with sequence number "
+        << seq;
+    CHECK_EQ(logged.sequence_number(), seq)
+        << "Entry has a negative sequence_number(): " << seq;
+
+    InsertEntryMapping(logged.sequence_number(), logged.Hash());
+  }
+
+  // Now read the STH entries.
+  set<string> sth_timestamps = tree_storage_->Scan();
+  if (!sth_timestamps.empty()) {
+    latest_timestamp_key_ = *sth_timestamps.rbegin();
+    CHECK_EQ(DeserializeResult::OK,
+             Deserializer::DeserializeUint<uint64_t>(
+                 latest_timestamp_key_, FileDB::kTimestampBytesIndexed,
+                 &latest_tree_timestamp_));
+  }
+}
+
+
+Database::LookupResult FileDB::LatestTreeHeadNoLock(
+    ct::SignedTreeHead* result) const {
+  if (latest_tree_timestamp_ == 0) {
+    return this->NOT_FOUND;
+  }
+
+  string tree_data;
+  CHECK_EQ(tree_storage_->LookupEntry(latest_timestamp_key_, &tree_data),
+           util::Status::OK);
+
+  CHECK(result->ParseFromString(tree_data));
+  CHECK_EQ(result->timestamp(), latest_tree_timestamp_);
+
+  return this->LOOKUP_OK;
+}
+
+
+// This must be called with "lock_" held.
+void FileDB::InsertEntryMapping(int64_t sequence_number, const string& hash) {
+  if (!id_by_hash_.insert(make_pair(hash, sequence_number)).second) {
+    // This is a duplicate hash under a new sequence number.
+    // Make sure we track the entry with the lowest sequence number:
+    id_by_hash_[hash] = min(id_by_hash_[hash], sequence_number);
+  }
+
+  if (sequence_number == contiguous_size_) {
+    ++contiguous_size_;
+    for (auto i = sparse_entries_.find(contiguous_size_);
+         i != sparse_entries_.end() && *i == contiguous_size_;) {
+      ++contiguous_size_;
+      i = sparse_entries_.erase(i);
+    }
+  } else {
+    // It's not contiguous, put it with the other sparse entries.
+    CHECK(sparse_entries_.insert(sequence_number).second)
+        << "sequence number " << sequence_number << " already assigned.";
+  }
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/file_db.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/file_db.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/file_db.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/file_db.h	2017-01-15 10:56:31.041591151 +0100
@@ -0,0 +1,110 @@
+#ifndef CERT_TRANS_LOG_FILE_DB_H_
+#define CERT_TRANS_LOG_FILE_DB_H_
+
+#include <stdint.h>
+#include <map>
+#include <memory>
+#include <mutex>
+#include <set>
+#include <unordered_map>
+#include <vector>
+
+#include "base/macros.h"
+#include "log/database.h"
+#include "proto/ct.pb.h"
+#include "util/statusor.h"
+
+namespace cert_trans {
+
+class FileStorage;
+
+
+// Database interface that stores certificates and tree head
+// signatures in the filesystem.
+class FileDB : public Database {
+ public:
+  // Reference implementation: reads the entire database on boot
+  // and builds an in-memory index.
+  // Writes to the underlying FileStorage are atomic (assuming underlying
+  // file system operations such as 'rename' are atomic) which should
+  // guarantee full recoverability from crashes/power failures.
+  // The tree head database uses 6-byte primary keys corresponding to the
+  // 6 lower bytes of the (unique) timestamp, so the storage depth of
+  // the FileDB should be set up accordingly. For example, a storage depth
+  // of 8 buckets tree head updates within about 1 minute
+  // (timestamps xxxxxxxx0000 - xxxxxxxxFFFF) to the same directory.
+  // Takes ownership of |cert_storage|, |tree_storage|, and |meta_storage|.
+  FileDB(FileStorage* cert_storage, FileStorage* tree_storage,
+         FileStorage* meta_storage);
+  ~FileDB();
+
+  static const size_t kTimestampBytesIndexed;
+
+  // Implement abstract functions, see database.h for comments.
+  Database::WriteResult CreateSequencedEntry_(
+      const LoggedEntry& logged) override;
+
+  Database::LookupResult LookupByHash(const std::string& hash,
+                                      LoggedEntry* result) const override;
+
+  Database::LookupResult LookupByIndex(int64_t sequence_number,
+                                       LoggedEntry* result) const override;
+
+  std::unique_ptr<Database::Iterator> ScanEntries(
+      int64_t start_index) const override;
+
+  Database::WriteResult WriteTreeHead_(const ct::SignedTreeHead& sth) override;
+
+  Database::LookupResult LatestTreeHead(
+      ct::SignedTreeHead* result) const override;
+
+  int64_t TreeSize() const override;
+
+  void AddNotifySTHCallback(
+      const Database::NotifySTHCallback* callback) override;
+
+  void RemoveNotifySTHCallback(
+      const Database::NotifySTHCallback* callback) override;
+
+  void InitializeNode(const std::string& node_id) override;
+
+  Database::LookupResult NodeId(std::string* node_id) override;
+
+ private:
+  class Iterator;
+
+  void BuildIndex();
+  Database::LookupResult LatestTreeHeadNoLock(
+      ct::SignedTreeHead* result) const;
+  void InsertEntryMapping(int64_t sequence_number, const std::string& hash);
+
+  const std::unique_ptr<FileStorage> cert_storage_;
+  // Store all tree heads, but currently only support looking up the latest
+  // one.
+  // Other necessary lookup indices (by tree size, by timestamp range?) TBD.
+  const std::unique_ptr<FileStorage> tree_storage_;
+
+  const std::unique_ptr<FileStorage> meta_storage_;
+
+  mutable std::mutex lock_;
+
+  int64_t contiguous_size_;
+  std::unordered_map<std::string, int64_t> id_by_hash_;
+
+  // This is a mapping of the non-contiguous entries of the log (which
+  // can happen while it is being fetched). When entries here become
+  // contiguous with the head of the tree they'll be removed.
+  std::set<int64_t> sparse_entries_;
+
+  uint64_t latest_tree_timestamp_;
+  // The same as a string;
+  std::string latest_timestamp_key_;
+  DatabaseNotifierHelper callbacks_;
+
+  DISALLOW_COPY_AND_ASSIGN(FileDB);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_FILE_DB_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/file_storage.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/file_storage.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/file_storage.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/file_storage.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,213 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "log/file_storage.h"
+
+#include <dirent.h>
+#include <errno.h>
+#include <glog/logging.h>
+#include <sys/stat.h>
+#include <unistd.h>
+#include <cstdlib>
+#include <set>
+#include <string>
+
+#include "log/filesystem_ops.h"
+#include "util/util.h"
+
+using cert_trans::BasicFilesystemOps;
+using cert_trans::FilesystemOps;
+using std::string;
+
+namespace cert_trans {
+
+
+FileStorage::FileStorage(const string& file_base, int storage_depth)
+    : storage_dir_(file_base + "/storage"),
+      tmp_dir_(file_base + "/tmp"),
+      tmp_file_template_(tmp_dir_ + "/tmpXXXXXX"),
+      storage_depth_(storage_depth),
+      file_op_(new BasicFilesystemOps()) {
+  CHECK_GE(storage_depth_, 0);
+  CreateMissingDirectory(storage_dir_);
+  CreateMissingDirectory(tmp_dir_);
+}
+
+
+FileStorage::FileStorage(const string& file_base, int storage_depth,
+                         FilesystemOps* file_op)
+    : storage_dir_(file_base + "/storage"),
+      tmp_dir_(file_base + "/tmp"),
+      tmp_file_template_(tmp_dir_ + "/tmpXXXXXX"),
+      storage_depth_(storage_depth),
+      file_op_(CHECK_NOTNULL(file_op)) {
+  CHECK_GE(storage_depth_, 0);
+  CreateMissingDirectory(storage_dir_);
+  CreateMissingDirectory(tmp_dir_);
+}
+
+
+FileStorage::~FileStorage() {
+  // Needs to be where FilesystemOps is visible.
+}
+
+
+std::set<string> FileStorage::Scan() const {
+  std::set<string> storage_keys;
+  ScanDir(storage_dir_, storage_depth_, &storage_keys);
+  return storage_keys;
+}
+
+
+util::Status FileStorage::CreateEntry(const string& key, const string& data) {
+  if (LookupEntry(key, NULL).ok()) {
+    return util::Status(util::error::ALREADY_EXISTS,
+                        "entry already exists: " + key);
+  }
+  WriteStorageEntry(key, data);
+  return util::Status::OK;
+}
+
+
+util::Status FileStorage::UpdateEntry(const string& key, const string& data) {
+  if (!LookupEntry(key, NULL).ok()) {
+    return util::Status(util::error::NOT_FOUND,
+                        "tried to update non-existent entry: " + key);
+  }
+  WriteStorageEntry(key, data);
+  return util::Status::OK;
+}
+
+
+util::Status FileStorage::LookupEntry(const string& key,
+                                      string* result) const {
+  string data_file = StoragePath(key);
+  if (!FileExists(data_file)) {
+    return util::Status(util::error::NOT_FOUND, "entry not found: " + key);
+  }
+  if (result) {
+    CHECK(util::ReadBinaryFile(data_file, result));
+  }
+  return util::Status::OK;
+}
+
+
+string FileStorage::StoragePathBasename(const string& hex) const {
+  if (hex.length() <= static_cast<uint>(storage_depth_))
+    return "-";
+  return hex.substr(storage_depth_);
+}
+
+
+string FileStorage::StoragePathComponent(const string& hex, int n) const {
+  CHECK_GE(n, 0);
+  CHECK_LT(n, storage_depth_);
+  if (static_cast<uint>(n) >= hex.length())
+    return "-";
+  return string(1, hex[n]);
+}
+
+
+string FileStorage::StoragePath(const string& key) const {
+  string hex = util::HexString(key);
+  string dirname = storage_dir_ + "/";
+  for (int n = 0; n < storage_depth_; ++n)
+    dirname += StoragePathComponent(hex, n) + "/";
+  return dirname + StoragePathBasename(hex);
+}
+
+
+string FileStorage::StorageKey(const string& storage_path) const {
+  CHECK_EQ(storage_path.substr(0, storage_dir_.size()), storage_dir_);
+  string key_path = storage_path.substr(storage_dir_.size() + 1);
+  string hex_key;
+  for (int n = 0; n < storage_depth_; ++n) {
+    char hex_char = key_path[2 * n];
+    if (hex_char == '-')
+      return util::BinaryString(hex_key);
+    hex_key.push_back(hex_char);
+  }
+  string basename = key_path.substr(2 * storage_depth_);
+  if (basename != "-")
+    hex_key.append(basename);
+  return util::BinaryString(hex_key);
+}
+
+
+void FileStorage::WriteStorageEntry(const string& key, const string& data) {
+  string hex = util::HexString(key);
+
+  // Make the intermediate directories, if needed.
+  // TODO(ekasper): we can skip this if we know we're updating.
+  string dir = storage_dir_;
+  for (int n = 0; n < storage_depth_; ++n) {
+    dir += "/" + StoragePathComponent(hex, n);
+    CreateMissingDirectory(dir);
+  }
+
+  // == StoragePath(key)
+  string filename = dir + "/" + StoragePathBasename(hex);
+  AtomicWriteBinaryFile(filename, data);
+}
+
+
+void FileStorage::ScanFiles(const string& dir_path,
+                            std::set<string>* keys) const {
+  DIR* dir = CHECK_NOTNULL(opendir(dir_path.c_str()));
+  struct dirent* entry;
+  while ((entry = readdir(dir)) != NULL) {
+    if (entry->d_name[0] == '.')
+      continue;
+    keys->insert(StorageKey(dir_path + "/" + entry->d_name));
+  }
+  closedir(dir);
+}
+
+
+void FileStorage::ScanDir(const string& dir_path, int depth,
+                          std::set<string>* keys) const {
+  CHECK_GE(depth, 0);
+  if (depth > 0) {
+    // Parse subdirectories. (TODO: make opendir part of filesystemop).
+    DIR* dir = CHECK_NOTNULL(opendir(dir_path.c_str()));
+    struct dirent* entry;
+    std::set<string> result;
+    while ((entry = readdir(dir)) != NULL) {
+      if (entry->d_name[0] == '.')
+        continue;
+      ScanDir(dir_path + "/" + entry->d_name, depth - 1, keys);
+    }
+    closedir(dir);
+  } else {
+    // depth == 0; parse files.
+    ScanFiles(dir_path, keys);
+  }
+}
+
+
+bool FileStorage::FileExists(const string& file_path) const {
+  if (file_op_->access(file_path, F_OK) == 0)
+    return true;
+
+  CHECK_EQ(errno, ENOENT);
+
+  return false;
+}
+
+
+void FileStorage::AtomicWriteBinaryFile(const string& file_path,
+                                        const string& data) {
+  const string tmp_file(
+      util::WriteTemporaryBinaryFile(tmp_file_template_, data));
+
+  CHECK(!tmp_file.empty());
+  CHECK_EQ(file_op_->rename(tmp_file, file_path), 0);
+}
+
+
+void FileStorage::CreateMissingDirectory(const string& dir_path) {
+  if (file_op_->mkdir(dir_path, 0700) != 0) {
+    CHECK_EQ(errno, EEXIST);
+  }
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/file_storage.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/file_storage.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/file_storage.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/file_storage.h	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,97 @@
+#ifndef CERT_TRANS_LOG_FILE_STORAGE_H_
+#define CERT_TRANS_LOG_FILE_STORAGE_H_
+
+#include <stdint.h>
+#include <memory>
+#include <set>
+#include <string>
+
+#include "base/macros.h"
+#include "util/status.h"
+
+namespace cert_trans {
+
+class FilesystemOps;
+
+// A simple filesystem-based database for (key, data) entries,
+// structured as follows:
+//
+// <root>/storage - Storage for the data, filenames are derived from
+//                  the hex key like so: "89abcd" becomes "8/9/a/bcd"
+//                  (for storage depth 3). This is because filesystems
+//                  tend to perform badly with very large
+//                  directories. For this to work, we assume keys are
+//                  hashes, i.e., random, and of reasonable
+//                  length. However, numerical monotonically
+//                  increasing keys can be made to work too: for
+//                  example, 4-byte keys could be set up with max 256
+//                  entries/directory by setting storage_depth=6:
+//
+//                  "00000000" -> "0/0/0/0/0/0/00"
+//                  "00000001" -> "0/0/0/0/0/0/01"
+//                  ...
+//                  "00000100" -> "0/0/0/0/0/1/00"
+//                  ...
+//
+//                  Each key corresponds to a file with the
+//                  data. Writes to these files are atomic
+//                  (i.e. create a new file and move into place).
+//
+// <root>/tmp     - Temporary storage for atomicity. Must be on the
+//                  same filesystem as <root>/storage.
+//
+// FileStorage aborts upon any FilesystemOps error. This class is
+// threadsafe.
+class FileStorage {
+ public:
+  // Default constructor, uses BasicFilesystemOps.
+  FileStorage(const std::string& file_base, int storage_depth);
+  // Takes ownership of the FilesystemOps.
+  FileStorage(const std::string& file_base, int storage_depth,
+              cert_trans::FilesystemOps* file_op);
+  ~FileStorage();
+
+  // Scan the entire database and return the list of keys.
+  std::set<std::string> Scan() const;
+
+  // Write (key, data) unless an entry matching |key| already exists.
+  util::Status CreateEntry(const std::string& key, const std::string& data);
+
+  // Update an existing entry; fail if it doesn't already exist.
+  util::Status UpdateEntry(const std::string& key, const std::string& data);
+
+  // Lookup entry based on key.
+  util::Status LookupEntry(const std::string& key, std::string* result) const;
+
+ private:
+  std::string StoragePathBasename(const std::string& hex) const;
+  std::string StoragePathComponent(const std::string& hex, int n) const;
+  std::string StoragePath(const std::string& key) const;
+  std::string StorageKey(const std::string& storage_path) const;
+  // Write or overwrite.
+  void WriteStorageEntry(const std::string& key, const std::string& data);
+  void ScanFiles(const std::string& dir_path,
+                 std::set<std::string>* keys) const;
+  void ScanDir(const std::string& dir_path, int depth,
+               std::set<std::string>* keys) const;
+
+  // The following methods abort upon any error.
+  bool FileExists(const std::string& file_path) const;
+  void AtomicWriteBinaryFile(const std::string& file_path,
+                             const std::string& data);
+  // Create directory, unless it already exists.
+  void CreateMissingDirectory(const std::string& dir_path);
+
+  const std::string storage_dir_;
+  const std::string tmp_dir_;
+  const std::string tmp_file_template_;
+  const int storage_depth_;
+  const std::unique_ptr<cert_trans::FilesystemOps> file_op_;
+
+  DISALLOW_COPY_AND_ASSIGN(FileStorage);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_FILE_STORAGE_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/file_storage_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/file_storage_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/file_storage_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/file_storage_test.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,366 @@
+#include <errno.h>
+#include <gtest/gtest.h>
+#include <stdio.h>
+#include <sys/stat.h>
+#include <unistd.h>
+#include <iostream>
+#include <set>
+#include <string>
+
+#include "log/file_storage.h"
+#include "log/filesystem_ops.h"
+#include "log/test_db.h"
+#include "util/status_test_util.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+using cert_trans::FailingFilesystemOps;
+using cert_trans::FileStorage;
+using std::string;
+using util::testing::StatusIs;
+
+namespace {
+
+const unsigned kStorageDepth = 3;
+
+class BasicFileStorageTest : public ::testing::Test {
+ protected:
+  BasicFileStorageTest() : test_db_() {
+  }
+
+  FileStorage* fs() const {
+    return test_db_.db();
+  }
+
+  TestDB<FileStorage> test_db_;
+};
+
+TEST_F(BasicFileStorageTest, Create) {
+  string key0("1234xyzw", 8);
+  string value0("unicorn", 7);
+
+  string key1("1245abcd", 8);
+  string value1("Alice", 5);
+
+  EXPECT_THAT(fs()->LookupEntry(key0, NULL), StatusIs(util::error::NOT_FOUND));
+  EXPECT_THAT(fs()->LookupEntry(key1, NULL), StatusIs(util::error::NOT_FOUND));
+
+  EXPECT_OK(fs()->CreateEntry(key0, value0));
+  string lookup_result;
+  EXPECT_OK(fs()->LookupEntry(key0, &lookup_result));
+  EXPECT_EQ(value0, lookup_result);
+
+  EXPECT_OK(fs()->CreateEntry(key1, value1));
+  EXPECT_OK(fs()->LookupEntry(key1, &lookup_result));
+  EXPECT_EQ(value1, lookup_result);
+}
+
+TEST_F(BasicFileStorageTest, Scan) {
+  string key0("1234xyzw", 8);
+  string value0("unicorn", 7);
+
+  string key1("1245abcd", 8);
+  string value1("Alice", 5);
+
+  EXPECT_OK(fs()->CreateEntry(key0, value0));
+  EXPECT_OK(fs()->CreateEntry(key1, value1));
+
+  std::set<string> keys;
+  keys.insert(key0);
+  keys.insert(key1);
+
+  std::set<string> scan_keys = fs()->Scan();
+  EXPECT_EQ(keys, scan_keys);
+}
+
+TEST_F(BasicFileStorageTest, CreateDuplicate) {
+  string key("1234xyzw", 8);
+  string value("unicorn", 7);
+
+  EXPECT_THAT(fs()->LookupEntry(key, NULL), StatusIs(util::error::NOT_FOUND));
+  EXPECT_OK(fs()->CreateEntry(key, value));
+  string lookup_result;
+  EXPECT_OK(fs()->LookupEntry(key, &lookup_result));
+  EXPECT_EQ(value, lookup_result);
+
+  // Try to log another entry with the same key.
+  string new_value("alice", 5);
+  EXPECT_THAT(fs()->CreateEntry(key, new_value),
+              StatusIs(util::error::ALREADY_EXISTS));
+  lookup_result.clear();
+  EXPECT_OK(fs()->LookupEntry(key, &lookup_result));
+
+  // Expect to receive the original entry on lookup.
+  EXPECT_EQ(value, lookup_result);
+}
+
+TEST_F(BasicFileStorageTest, Update) {
+  string key("1234xyzw", 8);
+  string value("unicorn", 7);
+
+  EXPECT_THAT(fs()->LookupEntry(key, NULL), StatusIs(util::error::NOT_FOUND));
+  EXPECT_OK(fs()->CreateEntry(key, value));
+  string lookup_result;
+  EXPECT_OK(fs()->LookupEntry(key, &lookup_result));
+  EXPECT_EQ(value, lookup_result);
+
+  // Update.
+  string new_value("alice", 5);
+  EXPECT_OK(fs()->UpdateEntry(key, new_value));
+  EXPECT_OK(fs()->LookupEntry(key, &lookup_result));
+
+  // Expect to receive the new entry on lookup.
+  EXPECT_EQ(new_value, lookup_result);
+}
+
+// Test for non-existing keys that are similar to  existing ones.
+TEST_F(BasicFileStorageTest, LookupInvalidKey) {
+  string key("1234xyzw", 8);
+  string value("unicorn", 7);
+
+  string similar_key0("1234xyz", 7);
+  string similar_key1("1234xyzv", 8);
+  string similar_key2("123", 3);
+  string empty_key;
+
+  EXPECT_OK(fs()->CreateEntry(key, value));
+  EXPECT_OK(fs()->LookupEntry(key, NULL));
+  EXPECT_THAT(fs()->LookupEntry(similar_key0, NULL),
+              StatusIs(util::error::NOT_FOUND));
+  EXPECT_THAT(fs()->LookupEntry(similar_key1, NULL),
+              StatusIs(util::error::NOT_FOUND));
+  EXPECT_THAT(fs()->LookupEntry(similar_key2, NULL),
+              StatusIs(util::error::NOT_FOUND));
+  EXPECT_THAT(fs()->LookupEntry(empty_key, NULL),
+              StatusIs(util::error::NOT_FOUND));
+}
+
+TEST_F(BasicFileStorageTest, Resume) {
+  string key0("1234xyzw", 8);
+  string value0("unicorn", 7);
+
+  string key1("1245abcd", 8);
+  string value1("Alice", 5);
+
+  EXPECT_OK(fs()->CreateEntry(key0, value0));
+  EXPECT_OK(fs()->CreateEntry(key1, value1));
+
+  // A second database.
+  FileStorage* db2 = test_db_.SecondDB();
+
+  // Look up and expect to find the entries.
+  string lookup_result;
+  EXPECT_OK(db2->LookupEntry(key0, &lookup_result));
+  EXPECT_EQ(value0, lookup_result);
+
+  EXPECT_OK(db2->LookupEntry(key1, &lookup_result));
+  EXPECT_EQ(value1, lookup_result);
+
+  delete db2;
+};
+
+TEST_F(BasicFileStorageTest, ScanOnResume) {
+  string key0("1234xyzw", 8);
+  string value0("unicorn", 7);
+
+  string key1("1245abcd", 8);
+  string value1("Alice", 5);
+
+  EXPECT_OK(fs()->CreateEntry(key0, value0));
+  EXPECT_OK(fs()->CreateEntry(key1, value1));
+
+  // A second database.
+  FileStorage* db2 = test_db_.SecondDB();
+
+  std::set<string> keys;
+  keys.insert(key0);
+  keys.insert(key1);
+
+  std::set<string> scan_keys = db2->Scan();
+  EXPECT_EQ(keys, scan_keys);
+  delete db2;
+}
+
+class FailingFileStorageDeathTest : public ::testing::Test {
+ protected:
+  string GetTemporaryDirectory() {
+    return util::CreateTemporaryDirectory(tmp_.TmpStorageDir() +
+                                          "/ctlogXXXXXX");
+  }
+  TmpStorage tmp_;
+};
+
+TEST(DeathTest, SupportDeath) {
+#ifndef EXPECT_DEATH
+  FAIL() << "Death tests not supported on this platform.";
+#endif
+};
+
+// TODO(ekasper): death tests throw the following warning
+// (at least on some platforms):
+//
+// [WARNING] ../src/gtest-death-test.cc:789:: Death tests use fork(),
+// which is unsafe particularly in a threaded context.
+// For this test, Google Test couldn't detect the number of threads.
+//
+// Find out why.
+
+TEST_F(FailingFileStorageDeathTest, DieOnFailedCreate) {
+  // Profiling run: count file operations.
+  FailingFilesystemOps* failing_file_op = new FailingFilesystemOps(-1);
+  FileStorage db(GetTemporaryDirectory(), kStorageDepth, failing_file_op);
+
+  // Count ops for constructor.
+  int op_count_init = failing_file_op->OpCount();
+  ASSERT_GE(op_count_init, 0);
+
+  string key0("1234xyzw", 8);
+  string value0("unicorn", 7);
+
+  EXPECT_OK(db.CreateEntry(key0, value0));
+  int op_count0 = failing_file_op->OpCount();
+  ASSERT_GT(op_count0, op_count_init);
+
+  string key1("1245abcd", 8);
+  string value1("Alice", 5);
+
+  EXPECT_OK(db.CreateEntry(key1, value1));
+  int op_count1 = failing_file_op->OpCount();
+  ASSERT_GT(op_count1, op_count0);
+
+  // Real run. Repeat for each file op individually.
+  for (int i = op_count_init; i < op_count0; ++i) {
+    FileStorage db(GetTemporaryDirectory(), kStorageDepth,
+                   new FailingFilesystemOps(i));
+    EXPECT_DEATH_IF_SUPPORTED(db.CreateEntry(key0, value0), "");
+  }
+
+  for (int i = op_count0; i < op_count1; ++i) {
+    FileStorage db(GetTemporaryDirectory(), kStorageDepth,
+                   new FailingFilesystemOps(i));
+    EXPECT_OK(db.CreateEntry(key0, value0));
+    EXPECT_DEATH_IF_SUPPORTED(db.CreateEntry(key1, value1), "");
+  }
+};
+
+TEST_F(FailingFileStorageDeathTest, DieOnFailedUpdate) {
+  // Profiling run: count file operations.
+  FailingFilesystemOps* failing_file_op = new FailingFilesystemOps(-1);
+  FileStorage db(GetTemporaryDirectory(), kStorageDepth, failing_file_op);
+
+  string key("1234xyzw", 8);
+  string value("unicorn", 7);
+
+  EXPECT_OK(db.CreateEntry(key, value));
+  int op_count0 = failing_file_op->OpCount();
+  ASSERT_GT(op_count0, 0);
+
+  string new_value("Alice", 5);
+
+  EXPECT_OK(db.UpdateEntry(key, new_value));
+  int op_count1 = failing_file_op->OpCount();
+  ASSERT_GT(op_count1, op_count0);
+
+  // Real run. Repeat for each file op individually.
+  for (int i = op_count0; i < op_count1; ++i) {
+    FileStorage db(GetTemporaryDirectory(), kStorageDepth,
+                   new FailingFilesystemOps(i));
+    EXPECT_OK(db.CreateEntry(key, value));
+    EXPECT_DEATH_IF_SUPPORTED(db.UpdateEntry(key, new_value), "");
+  }
+};
+
+TEST_F(FailingFileStorageDeathTest, ResumeOnFailedCreate) {
+  // Profiling run: count file operations.
+  FailingFilesystemOps* failing_file_op = new FailingFilesystemOps(-1);
+  FileStorage db(GetTemporaryDirectory(), kStorageDepth, failing_file_op);
+
+  string key0("1234xyzw", 8);
+  string value0("unicorn", 7);
+
+  int op_count_init = failing_file_op->OpCount();
+  EXPECT_OK(db.CreateEntry(key0, value0));
+  int op_count0 = failing_file_op->OpCount();
+  ASSERT_GT(op_count0, 0);
+
+  string key1("1245abcd", 8);
+  string value1("Alice", 5);
+
+  EXPECT_OK(db.CreateEntry(key1, value1));
+  int op_count1 = failing_file_op->OpCount();
+  ASSERT_GT(op_count1, op_count0);
+
+  // Real run. Repeat for each file op individually.
+  for (int i = op_count_init; i < op_count0; ++i) {
+    string db_dir = GetTemporaryDirectory();
+    FileStorage db(db_dir, kStorageDepth, new FailingFilesystemOps(i));
+    EXPECT_DEATH_IF_SUPPORTED(db.CreateEntry(key0, value0), "");
+    FileStorage db2(db_dir, kStorageDepth);
+    // Entry should not be there, and we should be able to insert it.
+    EXPECT_THAT(db2.LookupEntry(key0, NULL), StatusIs(util::error::NOT_FOUND));
+    EXPECT_OK(db2.CreateEntry(key0, value0));
+    // Look it up to double-check that everything works.
+    string lookup_result;
+    EXPECT_OK(db2.LookupEntry(key0, &lookup_result));
+    EXPECT_EQ(value0, lookup_result);
+  }
+
+  for (int i = op_count0; i < op_count1; ++i) {
+    string db_dir = GetTemporaryDirectory();
+    FileStorage db(db_dir, kStorageDepth, new FailingFilesystemOps(i));
+    EXPECT_OK(db.CreateEntry(key0, value0));
+    EXPECT_DEATH_IF_SUPPORTED(db.CreateEntry(key1, value1), "");
+    FileStorage db2(db_dir, kStorageDepth);
+    // First entry should be there just fine.
+    string lookup_result;
+    EXPECT_OK(db2.LookupEntry(key0, &lookup_result));
+    EXPECT_EQ(value0, lookup_result);
+
+    // Second entry should not be there, and we should be able to insert it.
+    EXPECT_THAT(db2.LookupEntry(key1, NULL), StatusIs(util::error::NOT_FOUND));
+    EXPECT_OK(db2.CreateEntry(key1, value1));
+    // Look it up to double-check that everything works.
+    EXPECT_OK(db2.LookupEntry(key1, &lookup_result));
+    EXPECT_EQ(value1, lookup_result);
+  }
+}
+
+TEST_F(FailingFileStorageDeathTest, ResumeOnFailedUpdate) {
+  // Profiling run: count file operations.
+  FailingFilesystemOps* failing_file_op = new FailingFilesystemOps(-1);
+  FileStorage db(GetTemporaryDirectory(), kStorageDepth, failing_file_op);
+
+  string key("1234xyzw", 8);
+  string value("unicorn", 7);
+
+  EXPECT_OK(db.CreateEntry(key, value));
+  int op_count0 = failing_file_op->OpCount();
+  ASSERT_GT(op_count0, 0);
+
+  string new_value("Alice", 5);
+
+  EXPECT_OK(db.UpdateEntry(key, new_value));
+  int op_count1 = failing_file_op->OpCount();
+  ASSERT_GT(op_count1, op_count0);
+
+  // Real run. Repeat for each file op individually.
+  for (int i = op_count0; i < op_count1; ++i) {
+    string db_dir = GetTemporaryDirectory();
+    FileStorage db(db_dir, kStorageDepth, new FailingFilesystemOps(i));
+    EXPECT_OK(db.CreateEntry(key, value));
+    EXPECT_DEATH_IF_SUPPORTED(db.UpdateEntry(key, new_value), "");
+    FileStorage db2(db_dir, kStorageDepth);
+    // The entry should be there just fine...
+    string lookup_result;
+    EXPECT_OK(db2.LookupEntry(key, &lookup_result));
+    // ... but it should still have its old value.
+    EXPECT_EQ(value, lookup_result);
+  }
+}
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/filesystem_ops.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/filesystem_ops.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/filesystem_ops.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/filesystem_ops.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,74 @@
+#include "log/filesystem_ops.h"
+
+#include <errno.h>
+#include <stdio.h>
+#include <sys/stat.h>
+#include <unistd.h>
+
+namespace cert_trans {
+
+
+int BasicFilesystemOps::mkdir(const std::string& path, mode_t mode) {
+  return ::mkdir(path.c_str(), mode);
+}
+
+
+int BasicFilesystemOps::remove(const std::string& path) {
+  return ::remove(path.c_str());
+}
+
+
+int BasicFilesystemOps::rename(const std::string& old_name,
+                               const std::string& new_name) {
+  return ::rename(old_name.c_str(), new_name.c_str());
+}
+
+
+int BasicFilesystemOps::access(const std::string& path, int amode) {
+  return ::access(path.c_str(), amode);
+}
+
+
+FailingFilesystemOps::FailingFilesystemOps(int fail_point)
+    : op_count_(0), fail_point_(fail_point) {
+}
+
+
+int FailingFilesystemOps::mkdir(const std::string& path, mode_t mode) {
+  if (fail_point_ == op_count_++) {
+    errno = EIO;
+    return -1;
+  }
+  return BasicFilesystemOps::mkdir(path, mode);
+}
+
+
+int FailingFilesystemOps::remove(const std::string& path) {
+  if (fail_point_ == op_count_++) {
+    errno = EIO;
+    return -1;
+  }
+  return BasicFilesystemOps::remove(path);
+}
+
+
+int FailingFilesystemOps::rename(const std::string& old_name,
+                                 const std::string& new_name) {
+  if (fail_point_ == op_count_++) {
+    errno = EIO;
+    return -1;
+  }
+  return BasicFilesystemOps::rename(old_name, new_name);
+}
+
+
+int FailingFilesystemOps::access(const std::string& path, int amode) {
+  if (fail_point_ == op_count_++) {
+    errno = EACCES;
+    return -1;
+  }
+  return BasicFilesystemOps::access(path, amode);
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/filesystem_ops.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/filesystem_ops.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/filesystem_ops.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/filesystem_ops.h	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,67 @@
+#ifndef CERT_TRANS_LOG_FILESYSTEM_OPS_H_
+#define CERT_TRANS_LOG_FILESYSTEM_OPS_H_
+
+#include <sys/types.h>
+#include <string>
+
+#include "base/macros.h"
+
+namespace cert_trans {
+
+
+// Make filesystem operations virtual so that we can override
+// to simulate filesystem errors.
+class FilesystemOps {
+ public:
+  virtual ~FilesystemOps() = default;
+
+  virtual int mkdir(const std::string& path, mode_t mode) = 0;
+  virtual int remove(const std::string& path) = 0;
+  virtual int rename(const std::string& old_name,
+                     const std::string& new_name) = 0;
+  virtual int access(const std::string& path, int amode) = 0;
+
+ protected:
+  FilesystemOps() = default;
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(FilesystemOps);
+};
+
+
+class BasicFilesystemOps : public FilesystemOps {
+ public:
+  BasicFilesystemOps() = default;
+
+  int mkdir(const std::string& path, mode_t mode) override;
+  int remove(const std::string& path) override;
+  int rename(const std::string& old_name,
+             const std::string& new_name) override;
+  int access(const std::string& path, int amode) override;
+};
+
+
+// Fail at an operation with a given op count.
+class FailingFilesystemOps : public BasicFilesystemOps {
+ public:
+  explicit FailingFilesystemOps(int fail_point);
+
+  int OpCount() const {
+    return op_count_;
+  }
+
+  int mkdir(const std::string& path, mode_t mode) override;
+  int remove(const std::string& path) override;
+  int rename(const std::string& old_name,
+             const std::string& new_name) override;
+  int access(const std::string& path, int amode) override;
+
+ private:
+  int op_count_;
+  int fail_point_;
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_FILESYSTEM_OPS_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/frontend.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/frontend.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/frontend.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/frontend.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,57 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "log/frontend.h"
+
+#include <glog/logging.h>
+
+#include "log/cert.h"
+#include "log/cert_submission_handler.h"
+#include "log/frontend_signer.h"
+#include "monitoring/event_metric.h"
+#include "proto/ct.pb.h"
+#include "util/status.h"
+
+using cert_trans::CertChain;
+using cert_trans::PreCertChain;
+using ct::LogEntry;
+using ct::SignedCertificateTimestamp;
+using std::string;
+using std::lock_guard;
+using std::mutex;
+using util::Status;
+
+namespace {
+
+static cert_trans::EventMetric<std::string, std::string>
+    submission_status_metric(
+        "submission_status", "entry_type", "status",
+        "Submission status totals broken down by entry type and status code.");
+
+Status UpdateStats(ct::LogEntryType type, const Status& status) {
+  if (type == ct::X509_ENTRY) {
+    submission_status_metric.RecordEvent(
+        "x509", util::ErrorCodeString(status.CanonicalCode()), 1);
+  } else {
+    submission_status_metric.RecordEvent(
+        "precert", util::ErrorCodeString(status.CanonicalCode()), 1);
+  }
+  return status;
+}
+
+}  // namespace
+
+Frontend::Frontend(FrontendSigner* signer) : signer_(CHECK_NOTNULL(signer)) {
+}
+
+Frontend::~Frontend() {
+}
+
+Status Frontend::QueueProcessedEntry(Status pre_status, const LogEntry& entry,
+                                     SignedCertificateTimestamp* sct) {
+  CHECK(entry.has_type());
+  if (!pre_status.ok()) {
+    return UpdateStats(entry.type(), pre_status);
+  }
+
+  // Step 2. Submit to database.
+  return UpdateStats(entry.type(), signer_->QueueEntry(entry, sct));
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/frontend.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/frontend.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/frontend.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/frontend.h	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,34 @@
+#ifndef CERT_TRANS_LOG_FRONTEND_H_
+#define CERT_TRANS_LOG_FRONTEND_H_
+
+#include <memory>
+#include <mutex>
+
+#include "base/macros.h"
+#include "log/cert.h"
+#include "proto/ct.pb.h"
+
+class FrontendSigner;
+
+namespace util {
+class Status;
+}  // namespace util
+
+// Frontend for accepting new submissions.
+class Frontend {
+ public:
+  // Takes ownership of the signer.
+  Frontend(FrontendSigner* signer);
+  ~Frontend();
+
+  util::Status QueueProcessedEntry(util::Status pre_status,
+                                   const ct::LogEntry& entry,
+                                   ct::SignedCertificateTimestamp* sct);
+
+ private:
+  const std::unique_ptr<FrontendSigner> signer_;
+
+  DISALLOW_COPY_AND_ASSIGN(Frontend);
+};
+
+#endif  // CERT_TRANS_LOG_FRONTEND_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/frontend_signer.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/frontend_signer.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/frontend_signer.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/frontend_signer.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,86 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "log/frontend_signer.h"
+
+#include <glog/logging.h>
+
+#include "log/database.h"
+#include "log/log_signer.h"
+#include "merkletree/serial_hasher.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+#include "util/status.h"
+#include "util/util.h"
+
+using cert_trans::ConsistentStore;
+using cert_trans::Database;
+using cert_trans::LoggedEntry;
+using ct::LogEntry;
+using ct::SignedCertificateTimestamp;
+using std::string;
+using util::Status;
+
+
+FrontendSigner::FrontendSigner(Database* db, ConsistentStore* store,
+                               LogSigner* signer)
+    : db_(CHECK_NOTNULL(db)),
+      store_(CHECK_NOTNULL(store)),
+      signer_(CHECK_NOTNULL(signer)) {
+}
+
+Status FrontendSigner::QueueEntry(const LogEntry& entry,
+                                  SignedCertificateTimestamp* sct) {
+  const string sha256_hash(
+      Sha256Hasher::Sha256Digest(Serializer::LeafData(entry)));
+  CHECK(!sha256_hash.empty());
+
+  // Check if the entry already exists in the local DB (i.e. it's been
+  // integrated into the tree.)
+  // This isn't foolproof; it could be that the local node doesn't yet have
+  // a copy of this if the cert was added recently, but it's not fatal if the
+  // same cert gets added twice.
+  // TODO(ekasper): switch to using SignedEntryWithType as the DB key.
+  cert_trans::LoggedEntry logged;
+  Database::LookupResult db_result = db_->LookupByHash(sha256_hash, &logged);
+
+  if (db_result == Database::LOOKUP_OK) {
+    // If we did find a local copy, return the previously issued SCT.
+    if (sct != nullptr) {
+      *sct = logged.sct();
+    }
+    return Status(util::error::ALREADY_EXISTS,
+                  "entry already exists in Database");
+  }
+  CHECK_EQ(Database::NOT_FOUND, db_result);
+
+  // Dont have the cert locally, so create an SCT and store it and the cert.
+  SignedCertificateTimestamp local_sct;
+  TimestampAndSign(entry, &local_sct);
+
+  cert_trans::LoggedEntry new_logged;
+  new_logged.mutable_sct()->CopyFrom(local_sct);
+  new_logged.mutable_entry()->CopyFrom(entry);
+  CHECK_EQ(new_logged.Hash(), sha256_hash);
+
+  // If this cert has already been added (but not yet integrated into the
+  // tree), then this call will update new_logged.sct with the previously
+  // issued one.
+  util::Status status(store_->AddPendingEntry(&new_logged));
+  CHECK_EQ(new_logged.Hash(), sha256_hash);
+
+  if (sct != nullptr) {
+    *sct = new_logged.sct();
+  }
+
+  return status;
+}
+
+
+void FrontendSigner::TimestampAndSign(const LogEntry& entry,
+                                      SignedCertificateTimestamp* sct) const {
+  sct->set_version(ct::V1);
+  sct->set_timestamp(util::TimeInMilliseconds());
+  sct->clear_extensions();
+  // The submission handler has already verified the format of this entry,
+  // so this should never fail.
+  CHECK_EQ(LogSigner::OK, signer_->SignCertificateTimestamp(entry, sct));
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/frontend_signer.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/frontend_signer.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/frontend_signer.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/frontend_signer.h	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,46 @@
+#ifndef CERT_TRANS_LOG_FRONTEND_SIGNER_H_
+#define CERT_TRANS_LOG_FRONTEND_SIGNER_H_
+
+#include <stdint.h>
+#include <string>
+
+#include "base/macros.h"
+#include "log/consistent_store.h"
+#include "log/logged_entry.h"
+
+class LogSigner;
+
+namespace util {
+class Status;
+}  // namespace util
+
+namespace cert_trans {
+class Database;
+}  // namespace cert_trans
+
+
+class FrontendSigner {
+ public:
+  // Does not take ownership of |db|, |store| or |signer|.
+  FrontendSigner(cert_trans::Database* db, cert_trans::ConsistentStore* store,
+                 LogSigner* signer);
+
+  // Log the entry if it's not already in the database,
+  // and return either a new timestamp-signature pair,
+  // or a previously existing one. (Currently also copies the
+  // entry to the sct but you shouldn't rely on this.)
+  util::Status QueueEntry(const ct::LogEntry& entry,
+                          ct::SignedCertificateTimestamp* sct);
+
+ private:
+  void TimestampAndSign(const ct::LogEntry& entry,
+                        ct::SignedCertificateTimestamp* sct) const;
+
+  cert_trans::Database* const db_;
+  cert_trans::ConsistentStore* const store_;
+  LogSigner* const signer_;
+
+  DISALLOW_COPY_AND_ASSIGN(FrontendSigner);
+};
+
+#endif  // CERT_TRANS_LOG_FRONTEND_SIGNER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/frontend_signer_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/frontend_signer_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/frontend_signer_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/frontend_signer_test.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,262 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include <glog/logging.h>
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <memory>
+#include <string>
+
+#include "log/etcd_consistent_store.h"
+#include "log/file_db.h"
+#include "log/frontend_signer.h"
+#include "log/log_verifier.h"
+#include "log/logged_entry.h"
+#include "log/sqlite_db.h"
+#include "log/test_db.h"
+#include "log/test_signer.h"
+#include "merkletree/merkle_verifier.h"
+#include "merkletree/serial_hasher.h"
+#include "proto/cert_serializer.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+#include "util/fake_etcd.h"
+#include "util/libevent_wrapper.h"
+#include "util/mock_masterelection.h"
+#include "util/status.h"
+#include "util/status_test_util.h"
+#include "util/testing.h"
+#include "util/thread_pool.h"
+#include "util/util.h"
+
+namespace {
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::ConsistentStore;
+using cert_trans::Database;
+using cert_trans::EntryHandle;
+using cert_trans::EtcdConsistentStore;
+using cert_trans::FakeEtcdClient;
+using cert_trans::FileDB;
+using cert_trans::LoggedEntry;
+using cert_trans::MockMasterElection;
+using cert_trans::SQLiteDB;
+using cert_trans::ThreadPool;
+using ct::LogEntry;
+using ct::SignedCertificateTimestamp;
+using std::make_shared;
+using std::shared_ptr;
+using std::string;
+using std::unique_ptr;
+using std::vector;
+using testing::NiceMock;
+using testing::_;
+using util::testing::StatusIs;
+
+typedef FrontendSigner FS;
+
+template <class T>
+class FrontendSignerTest : public ::testing::Test {
+ protected:
+  FrontendSignerTest()
+      : test_db_(),
+        test_signer_(),
+        verifier_(TestSigner::DefaultLogSigVerifier(),
+                  new MerkleVerifier(
+                      unique_ptr<Sha256Hasher>(new Sha256Hasher))),
+        base_(make_shared<libevent::Base>()),
+        event_pump_(base_),
+        etcd_client_(base_.get()),
+        pool_(2),
+        store_(base_.get(), &pool_, &etcd_client_, &election_, "/root", "id"),
+        log_signer_(TestSigner::DefaultLogSigner()),
+        frontend_(db(), &store_, log_signer_.get()) {
+  }
+
+  T* db() const {
+    return test_db_.db();
+  }
+
+  TestDB<T> test_db_;
+  TestSigner test_signer_;
+  LogVerifier verifier_;
+
+  shared_ptr<libevent::Base> base_;
+  libevent::EventPumpThread event_pump_;
+  FakeEtcdClient etcd_client_;
+  ThreadPool pool_;
+  NiceMock<MockMasterElection> election_;
+  EtcdConsistentStore store_;
+  unique_ptr<LogSigner> log_signer_;
+  FS frontend_;
+};
+
+typedef testing::Types<FileDB, SQLiteDB> Databases;
+
+TYPED_TEST_CASE(FrontendSignerTest, Databases);
+
+TYPED_TEST(FrontendSignerTest, LogKatTest) {
+  LogEntry default_entry;
+  this->test_signer_.SetDefaults(&default_entry);
+
+  // Log and expect success.
+  EXPECT_OK(this->frontend_.QueueEntry(default_entry, NULL));
+
+  // Look it up and expect to get the right thing back.
+  string hash =
+      Sha256Hasher::Sha256Digest(Serializer::LeafData(default_entry));
+  EntryHandle<LoggedEntry> entry_handle;
+  EXPECT_TRUE(this->store_.GetPendingEntryForHash(hash, &entry_handle).ok());
+  const LoggedEntry& logged_cert(entry_handle.Entry());
+
+  TestSigner::TestEqualEntries(default_entry, logged_cert.entry());
+}
+
+TYPED_TEST(FrontendSignerTest, Log) {
+  LogEntry entry0, entry1;
+  this->test_signer_.CreateUnique(&entry0);
+  this->test_signer_.CreateUnique(&entry1);
+
+  // Log and expect success.
+  EXPECT_OK(this->frontend_.QueueEntry(entry0, NULL));
+  EXPECT_OK(this->frontend_.QueueEntry(entry1, NULL));
+
+  // Look it up and expect to get the right thing back.
+  string hash0 = Sha256Hasher::Sha256Digest(Serializer::LeafData(entry0));
+  string hash1 = Sha256Hasher::Sha256Digest(Serializer::LeafData(entry1));
+
+  EntryHandle<LoggedEntry> entry_handle0;
+  EntryHandle<LoggedEntry> entry_handle1;
+  EXPECT_TRUE(this->store_.GetPendingEntryForHash(hash0, &entry_handle0).ok());
+  EXPECT_TRUE(this->store_.GetPendingEntryForHash(hash1, &entry_handle1).ok());
+  const LoggedEntry& logged_cert0(entry_handle0.Entry());
+  const LoggedEntry& logged_cert1(entry_handle1.Entry());
+
+  TestSigner::TestEqualEntries(entry0, logged_cert0.entry());
+  TestSigner::TestEqualEntries(entry1, logged_cert1.entry());
+}
+
+TYPED_TEST(FrontendSignerTest, Time) {
+  LogEntry entry0, entry1;
+  this->test_signer_.CreateUnique(&entry0);
+  this->test_signer_.CreateUnique(&entry1);
+
+  // Log and expect success.
+  SignedCertificateTimestamp sct0, sct1;
+  EXPECT_OK(this->frontend_.QueueEntry(entry0, &sct0));
+  EXPECT_LE(sct0.timestamp(), util::TimeInMilliseconds());
+  EXPECT_GT(sct0.timestamp(), 0U);
+
+  EXPECT_OK(this->frontend_.QueueEntry(entry1, &sct1));
+  EXPECT_LE(sct0.timestamp(), sct1.timestamp());
+  EXPECT_LE(sct1.timestamp(), util::TimeInMilliseconds());
+}
+
+TYPED_TEST(FrontendSignerTest, LogDuplicates) {
+  LogEntry entry;
+  this->test_signer_.CreateUnique(&entry);
+
+  SignedCertificateTimestamp sct0, sct1;
+  // Log and expect success.
+  EXPECT_OK(this->frontend_.QueueEntry(entry, &sct0));
+  // Wait for time to change.
+  usleep(2000);
+  // Try to log again.
+  EXPECT_THAT(this->frontend_.QueueEntry(entry, &sct1),
+              StatusIs(util::error::ALREADY_EXISTS, _));
+
+  // Expect to get the original timestamp.
+  EXPECT_EQ(sct0.timestamp(), sct1.timestamp());
+}
+
+TYPED_TEST(FrontendSignerTest, LogDuplicatesDifferentChain) {
+  LogEntry entry0, entry1;
+  this->test_signer_.CreateUnique(&entry0);
+  entry1.CopyFrom(entry0);
+  if (entry1.type() == ct::X509_ENTRY) {
+    entry1.mutable_x509_entry()->add_certificate_chain(
+        this->test_signer_.UniqueFakeCertBytestring());
+  } else {
+    CHECK_EQ(ct::PRECERT_ENTRY, entry1.type());
+    entry1.mutable_precert_entry()->add_precertificate_chain(
+        this->test_signer_.UniqueFakeCertBytestring());
+  }
+
+  SignedCertificateTimestamp sct0, sct1;
+  // Log and expect success.
+  EXPECT_OK(this->frontend_.QueueEntry(entry0, &sct0));
+  // Wait for time to change.
+  usleep(2000);
+  // Try to log again.
+  EXPECT_THAT(this->frontend_.QueueEntry(entry1, &sct1),
+              StatusIs(util::error::ALREADY_EXISTS, _));
+
+  // Expect to get the original timestamp.
+  EXPECT_EQ(sct0.timestamp(), sct1.timestamp());
+}
+
+TYPED_TEST(FrontendSignerTest, Verify) {
+  LogEntry entry0, entry1;
+  this->test_signer_.CreateUnique(&entry0);
+  this->test_signer_.CreateUnique(&entry1);
+
+  // Log and expect success.
+  SignedCertificateTimestamp sct0, sct1;
+  EXPECT_OK(this->frontend_.QueueEntry(entry0, &sct0));
+  EXPECT_OK(this->frontend_.QueueEntry(entry1, &sct1));
+
+  // Verify results.
+
+  EXPECT_EQ(this->verifier_.VerifySignedCertificateTimestamp(entry0, sct0),
+            LogVerifier::VERIFY_OK);
+  EXPECT_EQ(this->verifier_.VerifySignedCertificateTimestamp(entry1, sct1),
+            LogVerifier::VERIFY_OK);
+
+  // Swap the data and expect failure.
+  EXPECT_EQ(this->verifier_.VerifySignedCertificateTimestamp(entry0, sct1),
+            LogVerifier::INVALID_SIGNATURE);
+}
+
+TYPED_TEST(FrontendSignerTest, TimedVerify) {
+  LogEntry entry0, entry1;
+  this->test_signer_.CreateUnique(&entry0);
+  this->test_signer_.CreateUnique(&entry1);
+
+  uint64_t past_time = util::TimeInMilliseconds();
+  usleep(2000);
+
+  // Log and expect success.
+  SignedCertificateTimestamp sct0, sct1;
+  EXPECT_OK(this->frontend_.QueueEntry(entry0, &sct0));
+  // Make sure we get different timestamps.
+  usleep(2000);
+  EXPECT_OK(this->frontend_.QueueEntry(entry1, &sct1));
+
+  EXPECT_GT(sct1.timestamp(), sct0.timestamp());
+
+  // Verify.
+  EXPECT_EQ(this->verifier_.VerifySignedCertificateTimestamp(entry0, sct0),
+            LogVerifier::VERIFY_OK);
+  EXPECT_EQ(this->verifier_.VerifySignedCertificateTimestamp(entry1, sct1),
+            LogVerifier::VERIFY_OK);
+
+  // Go back to the past and expect verification to fail (since the sct is
+  // from the future).
+  EXPECT_EQ(this->verifier_.VerifySignedCertificateTimestamp(entry0, sct0, 0,
+                                                             past_time),
+            LogVerifier::INVALID_TIMESTAMP);
+
+  // Swap timestamps and expect failure.
+  SignedCertificateTimestamp wrong_sct(sct0);
+  wrong_sct.set_timestamp(sct1.timestamp());
+  EXPECT_EQ(this->verifier_.VerifySignedCertificateTimestamp(entry0,
+                                                             wrong_sct),
+            LogVerifier::INVALID_SIGNATURE);
+}
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  ConfigureSerializerForV1CT();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/frontend_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/frontend_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/frontend_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/frontend_test.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,422 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include <glog/logging.h>
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <openssl/err.h>
+#include <openssl/evp.h>
+#include <memory>
+#include <string>
+
+#include "log/cert_submission_handler.h"
+#include "log/ct_extensions.h"
+#include "log/etcd_consistent_store.h"
+#include "log/file_db.h"
+#include "log/frontend.h"
+#include "log/frontend_signer.h"
+#include "log/log_verifier.h"
+#include "log/logged_entry.h"
+#include "log/sqlite_db.h"
+#include "log/test_db.h"
+#include "log/test_signer.h"
+#include "merkletree/merkle_verifier.h"
+#include "merkletree/serial_hasher.h"
+#include "proto/cert_serializer.h"
+#include "proto/ct.pb.h"
+#include "util/fake_etcd.h"
+#include "util/libevent_wrapper.h"
+#include "util/mock_masterelection.h"
+#include "util/status_test_util.h"
+#include "util/testing.h"
+#include "util/thread_pool.h"
+#include "util/util.h"
+
+//  Valid certificates.
+// Self-signed
+static const char kCaCert[] = "ca-cert.pem";
+// Issued by ca-cert.pem
+static const char kLeafCert[] = "test-cert.pem";
+// Issued by ca.pem
+static const char kCaPreCert[] = "ca-pre-cert.pem";
+// Issued by ca-cert.pem
+static const char kPreCert[] = "test-embedded-pre-cert.pem";
+// Issued by ca-pre-cert.pem
+static const char kPreWithPreCaCert[] =
+    "test-embedded-with-preca-pre-cert.pem";
+// The resulting embedded certs, issued by ca-cert.pem
+static const char kEmbeddedCert[] = "test-embedded-cert.pem";
+static const char kEmbeddedWithPreCaCert[] =
+    "test-embedded-with-preca-cert.pem";
+// Issued by ca-cert.pem
+static const char kIntermediateCert[] = "intermediate-cert.pem";
+// Issued by intermediate-cert.pem
+static const char kChainLeafCert[] = "test-intermediate-cert.pem";
+
+namespace {
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::Cert;
+using cert_trans::CertChain;
+using cert_trans::CertChecker;
+using cert_trans::CertSubmissionHandler;
+using cert_trans::Database;
+using cert_trans::EntryHandle;
+using cert_trans::EtcdConsistentStore;
+using cert_trans::FakeEtcdClient;
+using cert_trans::FileDB;
+using cert_trans::LoggedEntry;
+using cert_trans::MockMasterElection;
+using cert_trans::PreCertChain;
+using cert_trans::SQLiteDB;
+using cert_trans::ThreadPool;
+using ct::LogEntry;
+using ct::SignedCertificateTimestamp;
+using std::make_shared;
+using std::shared_ptr;
+using std::string;
+using std::unique_ptr;
+using std::vector;
+using testing::NiceMock;
+using testing::_;
+using util::testing::StatusIs;
+
+typedef Frontend FE;
+
+// A slightly shorter notation for constructing hex strings from binary blobs.
+string H(const string& byte_string) {
+  return util::HexString(byte_string);
+}
+
+template <class T>
+class FrontendTest : public ::testing::Test {
+ protected:
+  FrontendTest()
+      : test_db_(),
+        test_signer_(),
+        verifier_(TestSigner::DefaultLogSigVerifier(),
+                  new MerkleVerifier(
+                      unique_ptr<Sha256Hasher>(new Sha256Hasher))),
+        checker_(),
+        base_(make_shared<libevent::Base>()),
+        event_pump_(base_),
+        etcd_client_(base_.get()),
+        pool_(2),
+        store_(base_.get(), &pool_, &etcd_client_, &election_, "/root", "id"),
+        log_signer_(TestSigner::DefaultLogSigner()),
+        submission_handler_(&checker_),
+        frontend_(new FrontendSigner(db(), &store_, log_signer_.get())),
+        cert_dir_(FLAGS_test_srcdir + "/test/testdata") {
+  }
+
+  void SetUp() {
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kLeafCert, &leaf_pem_))
+        << "Could not read test data from " << cert_dir_
+        << ". Wrong --test_srcdir?";
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kCaPreCert, &ca_precert_pem_));
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kPreCert, &precert_pem_));
+    CHECK(util::ReadBinaryFile(cert_dir_ + "/" + kPreWithPreCaCert,
+                               &precert_with_preca_pem_));
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kIntermediateCert,
+                             &intermediate_pem_));
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kChainLeafCert,
+                             &chain_leaf_pem_));
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kCaCert, &ca_pem_));
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kEmbeddedCert, &embedded_pem_));
+    CHECK(util::ReadTextFile(cert_dir_ + "/" + kEmbeddedWithPreCaCert,
+                             &embedded_with_preca_pem_));
+    CHECK(checker_.LoadTrustedCertificates(cert_dir_ + "/" + kCaCert));
+  }
+
+
+  T* db() const {
+    return test_db_.db();
+  }
+
+  TestDB<T> test_db_;
+  TestSigner test_signer_;
+  LogVerifier verifier_;
+  CertChecker checker_;
+  shared_ptr<libevent::Base> base_;
+  libevent::EventPumpThread event_pump_;
+  FakeEtcdClient etcd_client_;
+  ThreadPool pool_;
+  NiceMock<MockMasterElection> election_;
+  EtcdConsistentStore store_;
+  unique_ptr<LogSigner> log_signer_;
+  CertSubmissionHandler submission_handler_;
+  FE frontend_;
+  const string cert_dir_;
+  string leaf_pem_;
+  string ca_precert_pem_;
+  string precert_pem_;
+  string precert_with_preca_pem_;
+  string intermediate_pem_;
+  string chain_leaf_pem_;
+  string embedded_pem_;
+  string embedded_with_preca_pem_;
+  string ca_pem_;
+};
+
+typedef testing::Types<FileDB, SQLiteDB> Databases;
+
+TYPED_TEST_CASE(FrontendTest, Databases);
+
+TYPED_TEST(FrontendTest, TestSubmitValid) {
+  CertChain chain(this->leaf_pem_);
+  EXPECT_TRUE(chain.IsLoaded());
+
+  LogEntry entry;
+  SignedCertificateTimestamp sct;
+  EXPECT_OK(this->frontend_.QueueProcessedEntry(
+      this->submission_handler_.ProcessX509Submission(&chain, &entry), entry,
+      &sct));
+
+  // Look it up and expect to get the right thing back.
+  EntryHandle<LoggedEntry> entry_handle;
+  const unique_ptr<Cert> cert(Cert::FromPemString(this->leaf_pem_));
+  ASSERT_TRUE(cert.get());
+
+  string sha256_digest;
+  ASSERT_OK(cert->Sha256Digest(&sha256_digest));
+  EXPECT_TRUE(
+      this->store_.GetPendingEntryForHash(sha256_digest, &entry_handle).ok());
+  const LoggedEntry& logged_cert(entry_handle.Entry());
+
+  EXPECT_EQ(ct::X509_ENTRY, logged_cert.entry().type());
+  // Compare the leaf cert.
+  string der_string;
+  ASSERT_OK(cert->DerEncoding(&der_string));
+  EXPECT_EQ(H(der_string),
+            H(logged_cert.entry().x509_entry().leaf_certificate()));
+
+  // And verify the signature.
+  EXPECT_EQ(LogVerifier::VERIFY_OK,
+            this->verifier_.VerifySignedCertificateTimestamp(
+                logged_cert.entry(), sct));
+}
+
+TYPED_TEST(FrontendTest, TestSubmitValidWithIntermediate) {
+  CertChain chain(this->chain_leaf_pem_ + this->intermediate_pem_);
+  EXPECT_TRUE(chain.IsLoaded());
+
+  LogEntry entry;
+  SignedCertificateTimestamp sct;
+  EXPECT_OK(this->frontend_.QueueProcessedEntry(
+      this->submission_handler_.ProcessX509Submission(&chain, &entry), entry,
+      &sct));
+
+  // Look it up and expect to get the right thing back.
+  const unique_ptr<Cert> cert(Cert::FromPemString(this->chain_leaf_pem_));
+  ASSERT_TRUE(cert.get());
+
+  string sha256_digest;
+  ASSERT_OK(cert->Sha256Digest(&sha256_digest));
+  EntryHandle<LoggedEntry> entry_handle;
+  EXPECT_TRUE(
+      this->store_.GetPendingEntryForHash(sha256_digest, &entry_handle).ok());
+  const LoggedEntry& logged_cert(entry_handle.Entry());
+
+  EXPECT_EQ(ct::X509_ENTRY, logged_cert.entry().type());
+  // Compare the leaf cert.
+  string der_string;
+  ASSERT_OK(cert->DerEncoding(&der_string));
+  EXPECT_EQ(H(der_string),
+            H(logged_cert.entry().x509_entry().leaf_certificate()));
+
+  // And verify the signature.
+  EXPECT_EQ(LogVerifier::VERIFY_OK,
+            this->verifier_.VerifySignedCertificateTimestamp(
+                logged_cert.entry(), sct));
+
+  // Compare the first intermediate.
+  ASSERT_GE(logged_cert.entry().x509_entry().certificate_chain_size(), 1);
+  const unique_ptr<Cert> cert2(Cert::FromPemString(this->intermediate_pem_));
+  ASSERT_TRUE(cert2.get());
+
+  ASSERT_OK(cert2->DerEncoding(&der_string));
+  EXPECT_EQ(H(der_string),
+            H(logged_cert.entry().x509_entry().certificate_chain(0)));
+}
+
+TYPED_TEST(FrontendTest, TestSubmitDuplicate) {
+  CertChain chain1(this->leaf_pem_);
+  CertChain chain2(this->leaf_pem_);
+  EXPECT_TRUE(chain1.IsLoaded());
+  EXPECT_TRUE(chain2.IsLoaded());
+
+  SignedCertificateTimestamp sct;
+  LogEntry entry1, entry2;
+  EXPECT_OK(this->frontend_.QueueProcessedEntry(
+      this->submission_handler_.ProcessX509Submission(&chain1, &entry1),
+      entry1, nullptr));
+  EXPECT_THAT(this->frontend_.QueueProcessedEntry(
+                  this->submission_handler_.ProcessX509Submission(&chain2,
+                                                                  &entry2),
+                  entry2, &sct),
+              StatusIs(util::error::ALREADY_EXISTS, _));
+
+  // Look it up and expect to get the right thing back.
+  const unique_ptr<Cert> cert(Cert::FromPemString(this->leaf_pem_));
+  ASSERT_TRUE(cert.get());
+
+  string sha256_digest;
+  ASSERT_OK(cert->Sha256Digest(&sha256_digest));
+  EntryHandle<LoggedEntry> entry_handle;
+  EXPECT_TRUE(
+      this->store_.GetPendingEntryForHash(sha256_digest, &entry_handle).ok());
+  const LoggedEntry& logged_cert(entry_handle.Entry());
+
+  EXPECT_EQ(ct::X509_ENTRY, logged_cert.entry().type());
+  // Compare the leaf cert.
+  string der_string;
+  ASSERT_OK(cert->DerEncoding(&der_string));
+  EXPECT_EQ(H(der_string),
+            H(logged_cert.entry().x509_entry().leaf_certificate()));
+
+  // And verify the signature.
+  EXPECT_EQ(LogVerifier::VERIFY_OK,
+            this->verifier_.VerifySignedCertificateTimestamp(
+                logged_cert.entry(), sct));
+}
+
+TYPED_TEST(FrontendTest, TestSubmitInvalidChain) {
+  CertChain chain(this->chain_leaf_pem_);
+  EXPECT_TRUE(chain.IsLoaded());
+
+  LogEntry entry;
+  SignedCertificateTimestamp sct;
+  // Missing intermediate.
+  EXPECT_THAT(this->frontend_.QueueProcessedEntry(
+                  this->submission_handler_.ProcessX509Submission(&chain,
+                                                                  &entry),
+                  entry, &sct),
+              StatusIs(util::error::FAILED_PRECONDITION, "unknown root"));
+  EXPECT_FALSE(sct.has_signature());
+}
+
+TYPED_TEST(FrontendTest, TestSubmitInvalidPem) {
+  CertChain chain(
+      "-----BEGIN CERTIFICATE-----\n"
+      "Iamnotavalidcert\n"
+      "-----END CERTIFICATE-----\n");
+  EXPECT_FALSE(chain.IsLoaded());
+
+  LogEntry entry;
+  SignedCertificateTimestamp sct;
+  EXPECT_THAT(this->frontend_.QueueProcessedEntry(
+                  this->submission_handler_.ProcessX509Submission(&chain,
+                                                                  &entry),
+                  entry, &sct),
+              StatusIs(util::error::INVALID_ARGUMENT, "empty submission"));
+  EXPECT_FALSE(sct.has_signature());
+}
+
+TYPED_TEST(FrontendTest, TestSubmitPrecert) {
+  PreCertChain submission(this->precert_pem_);
+  EXPECT_TRUE(submission.IsLoaded());
+
+  LogEntry log_entry;
+  SignedCertificateTimestamp sct;
+  EXPECT_OK(this->frontend_.QueueProcessedEntry(
+      this->submission_handler_.ProcessPreCertSubmission(&submission,
+                                                         &log_entry),
+      log_entry, &sct));
+
+  CertChain chain(this->embedded_pem_ + this->ca_pem_);
+  LogEntry entry;
+  CertSubmissionHandler::X509ChainToEntry(chain, &entry);
+
+  // Look it up.
+  string hash = Sha256Hasher::Sha256Digest(
+      entry.precert_entry().pre_cert().tbs_certificate());
+  EntryHandle<LoggedEntry> entry_handle;
+  EXPECT_TRUE(this->store_.GetPendingEntryForHash(hash, &entry_handle).ok());
+  const LoggedEntry& logged_cert(entry_handle.Entry());
+  const unique_ptr<Cert> pre(Cert::FromPemString(this->precert_pem_));
+  const unique_ptr<Cert> ca(Cert::FromPemString(this->ca_pem_));
+  ASSERT_TRUE(pre.get());
+  ASSERT_TRUE(ca.get());
+
+  EXPECT_EQ(ct::PRECERT_ENTRY, logged_cert.entry().type());
+  // Verify the signature.
+  EXPECT_EQ(LogVerifier::VERIFY_OK,
+            this->verifier_.VerifySignedCertificateTimestamp(
+                logged_cert.entry(), sct));
+
+  // Expect to have the original certs logged in the chain.
+  ASSERT_EQ(logged_cert.entry().precert_entry().precertificate_chain_size(),
+            1);
+
+  string pre_der, ca_der;
+  ASSERT_OK(pre->DerEncoding(&pre_der));
+  ASSERT_OK(ca->DerEncoding(&ca_der));
+
+  EXPECT_EQ(H(pre_der),
+            H(logged_cert.entry().precert_entry().pre_certificate()));
+  EXPECT_EQ(H(ca_der),
+            H(logged_cert.entry().precert_entry().precertificate_chain(0)));
+}
+
+TYPED_TEST(FrontendTest, TestSubmitPrecertUsingPreCA) {
+  PreCertChain submission(this->precert_with_preca_pem_ +
+                          this->ca_precert_pem_);
+  EXPECT_TRUE(submission.IsLoaded());
+
+  LogEntry log_entry;
+  SignedCertificateTimestamp sct;
+  EXPECT_OK(this->frontend_.QueueProcessedEntry(
+      this->submission_handler_.ProcessPreCertSubmission(&submission,
+                                                         &log_entry),
+      log_entry, &sct));
+
+  CertChain chain(this->embedded_with_preca_pem_ + this->ca_pem_);
+  LogEntry entry;
+  CertSubmissionHandler::X509ChainToEntry(chain, &entry);
+
+  // Look it up.
+  string hash = Sha256Hasher::Sha256Digest(
+      entry.precert_entry().pre_cert().tbs_certificate());
+  EntryHandle<LoggedEntry> entry_handle;
+  EXPECT_TRUE(this->store_.GetPendingEntryForHash(hash, &entry_handle).ok());
+  const LoggedEntry& logged_cert(entry_handle.Entry());
+  const unique_ptr<Cert> pre(
+      Cert::FromPemString(this->precert_with_preca_pem_));
+  const unique_ptr<Cert> ca_pre(Cert::FromPemString(this->ca_precert_pem_));
+  const unique_ptr<Cert> ca(Cert::FromPemString(this->ca_pem_));
+  ASSERT_TRUE(pre.get());
+  ASSERT_TRUE(ca_pre.get());
+  ASSERT_TRUE(ca.get());
+
+  EXPECT_EQ(ct::PRECERT_ENTRY, logged_cert.entry().type());
+  // Verify the signature.
+  EXPECT_EQ(LogVerifier::VERIFY_OK,
+            this->verifier_.VerifySignedCertificateTimestamp(
+                logged_cert.entry(), sct));
+
+  // Expect to have the original certs logged in the chain.
+  ASSERT_GE(logged_cert.entry().precert_entry().precertificate_chain_size(),
+            2);
+
+  string pre_der, ca_der, ca_pre_der;
+  ASSERT_OK(pre->DerEncoding(&pre_der));
+  ASSERT_OK(ca->DerEncoding(&ca_der));
+  ASSERT_OK(ca_pre->DerEncoding(&ca_pre_der));
+
+  EXPECT_EQ(H(pre_der),
+            H(logged_cert.entry().precert_entry().pre_certificate()));
+  EXPECT_EQ(H(ca_pre_der),
+            H(logged_cert.entry().precert_entry().precertificate_chain(0)));
+  EXPECT_EQ(H(ca_der),
+            H(logged_cert.entry().precert_entry().precertificate_chain(1)));
+}
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  OpenSSL_add_all_algorithms();
+  ERR_load_crypto_strings();
+  cert_trans::LoadCtExtensions();
+  ConfigureSerializerForV1CT();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/leveldb_db.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/leveldb_db.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/leveldb_db.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/leveldb_db.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,441 @@
+#include "log/leveldb_db.h"
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <stdint.h>
+#include <map>
+#include <string>
+
+#include "monitoring/latency.h"
+#include "monitoring/monitoring.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+#include "util/util.h"
+
+using cert_trans::serialization::DeserializeResult;
+using std::chrono::milliseconds;
+using std::lock_guard;
+using std::make_pair;
+using std::min;
+using std::mutex;
+using std::string;
+using std::unique_lock;
+using std::unique_ptr;
+
+DEFINE_int32(leveldb_max_open_files, 0,
+             "number of open files that can be used by leveldb");
+DEFINE_int32(leveldb_bloom_filter_bits_per_key, 0,
+             "number of open files that can be used by leveldb");
+
+namespace cert_trans {
+namespace {
+
+
+static Latency<milliseconds, string> latency_by_op_ms(
+    "leveldb_latency_by_operation_ms", "operation",
+    "Database latency in ms broken out by operation.");
+
+
+const char kMetaNodeIdKey[] = "metadata";
+const char kEntryPrefix[] = "entry-";
+const char kTreeHeadPrefix[] = "sth-";
+const char kMetaPrefix[] = "meta-";
+
+
+#ifdef HAVE_LEVELDB_FILTER_POLICY_H
+unique_ptr<const leveldb::FilterPolicy> BuildFilterPolicy() {
+  unique_ptr<const leveldb::FilterPolicy> retval;
+
+  if (FLAGS_leveldb_bloom_filter_bits_per_key > 0) {
+    retval.reset(CHECK_NOTNULL(leveldb::NewBloomFilterPolicy(
+        FLAGS_leveldb_bloom_filter_bits_per_key)));
+  }
+
+  return retval;
+}
+#endif
+
+
+// WARNING: Do NOT change the type of "index" from int64_t, or you'll
+// break existing databases!
+string IndexToKey(int64_t index) {
+  const char nibble[] = "0123456789abcdef";
+  string index_str(sizeof(index) * 2, nibble[0]);
+  for (int i = sizeof(index) * 2; i > 0 && index > 0; --i) {
+    index_str[i - 1] = nibble[index & 0xf];
+    index = index >> 4;
+  }
+
+  return kEntryPrefix + index_str;
+}
+
+
+int64_t KeyToIndex(leveldb::Slice key) {
+  CHECK(key.starts_with(kEntryPrefix));
+  key.remove_prefix(strlen(kEntryPrefix));
+  const string index_str(util::BinaryString(key.ToString()));
+
+  int64_t index(0);
+  CHECK_EQ(index_str.size(), sizeof(index));
+  for (size_t i = 0; i < sizeof(index); ++i) {
+    index = (index << 8) | static_cast<unsigned char>(index_str[i]);
+  }
+
+  return index;
+}
+
+
+}  // namespace
+
+
+class LevelDB::Iterator : public Database::Iterator {
+ public:
+  Iterator(const LevelDB* db, int64_t start_index)
+      : it_(CHECK_NOTNULL(db)->db_->NewIterator(leveldb::ReadOptions())) {
+    CHECK(it_);
+    it_->Seek(IndexToKey(start_index));
+  }
+
+  bool GetNextEntry(LoggedEntry* entry) override {
+    if (!it_->Valid() || !it_->key().starts_with(kEntryPrefix)) {
+      return false;
+    }
+
+    const int64_t seq(KeyToIndex(it_->key()));
+    CHECK(entry->ParseFromArray(it_->value().data(), it_->value().size()))
+        << "failed to parse entry for key " << it_->key().ToString();
+    CHECK(entry->has_sequence_number())
+        << "no sequence number for entry with expected sequence number "
+        << seq;
+    CHECK_EQ(entry->sequence_number(), seq) << "unexpected sequence_number";
+
+    it_->Next();
+
+    return true;
+  }
+
+ private:
+  const unique_ptr<leveldb::Iterator> it_;
+};
+
+
+const size_t LevelDB::kTimestampBytesIndexed = 6;
+
+
+LevelDB::LevelDB(const string& dbfile)
+    :
+#ifdef HAVE_LEVELDB_FILTER_POLICY_H
+      filter_policy_(BuildFilterPolicy()),
+#endif
+      contiguous_size_(0),
+      latest_tree_timestamp_(0) {
+  LOG(INFO) << "Opening " << dbfile;
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("open"));
+  leveldb::Options options;
+  options.create_if_missing = true;
+  if (FLAGS_leveldb_max_open_files > 0) {
+    options.max_open_files = FLAGS_leveldb_max_open_files;
+  }
+#ifdef HAVE_LEVELDB_FILTER_POLICY_H
+  options.filter_policy = filter_policy_.get();
+#else
+  CHECK_EQ(FLAGS_leveldb_bloom_filter_bits_per_key, 0)
+      << "this version of leveldb does not have bloom filter support";
+#endif
+  leveldb::DB* db;
+  leveldb::Status status(leveldb::DB::Open(options, dbfile, &db));
+  CHECK(status.ok()) << status.ToString();
+  db_.reset(db);
+
+  BuildIndex();
+}
+
+
+Database::WriteResult LevelDB::CreateSequencedEntry_(
+    const LoggedEntry& logged) {
+  CHECK(logged.has_sequence_number());
+  CHECK_GE(logged.sequence_number(), 0);
+  ScopedLatency latency(
+      latency_by_op_ms.GetScopedLatency("create_sequenced_entry"));
+
+  unique_lock<mutex> lock(lock_);
+
+  string data;
+  CHECK(logged.SerializeToString(&data));
+
+  const string key(IndexToKey(logged.sequence_number()));
+
+  string existing_data;
+  leveldb::Status status(
+      db_->Get(leveldb::ReadOptions(), key, &existing_data));
+  if (status.IsNotFound()) {
+    status = db_->Put(leveldb::WriteOptions(), key, data);
+    CHECK(status.ok()) << "Failed to write sequenced entry (seq: "
+                       << logged.sequence_number()
+                       << "): " << status.ToString();
+  } else {
+    if (existing_data == data) {
+      return this->OK;
+    }
+    return this->SEQUENCE_NUMBER_ALREADY_IN_USE;
+  }
+
+  InsertEntryMapping(logged.sequence_number(), logged.Hash());
+
+  return this->OK;
+}
+
+
+Database::LookupResult LevelDB::LookupByHash(const string& hash,
+                                             LoggedEntry* result) const {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("lookup_by_hash"));
+
+  unique_lock<mutex> lock(lock_);
+
+  auto i(id_by_hash_.find(hash));
+  if (i == id_by_hash_.end()) {
+    return this->NOT_FOUND;
+  }
+
+  string cert_data;
+  const leveldb::Status status(
+      db_->Get(leveldb::ReadOptions(), IndexToKey(i->second), &cert_data));
+  if (status.IsNotFound()) {
+    return this->NOT_FOUND;
+  }
+  CHECK(status.ok()) << "Failed to get entry by hash(" << util::HexString(hash)
+                     << "): " << status.ToString();
+
+  if (result) {
+    CHECK(result->ParseFromString(cert_data));
+    CHECK_EQ(result->Hash(), hash);
+  }
+
+  return this->LOOKUP_OK;
+}
+
+
+Database::LookupResult LevelDB::LookupByIndex(int64_t sequence_number,
+                                              LoggedEntry* result) const {
+  CHECK_GE(sequence_number, 0);
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("lookup_by_index"));
+
+  string cert_data;
+  leveldb::Status status(db_->Get(leveldb::ReadOptions(),
+                                  IndexToKey(sequence_number), &cert_data));
+  if (status.IsNotFound()) {
+    return this->NOT_FOUND;
+  }
+  CHECK(status.ok()) << "Failed to get entry for sequence number "
+                     << sequence_number;
+
+  if (result) {
+    CHECK(result->ParseFromString(cert_data));
+    CHECK_EQ(result->sequence_number(), sequence_number);
+  }
+
+  return this->LOOKUP_OK;
+}
+
+
+unique_ptr<Database::Iterator> LevelDB::ScanEntries(
+    int64_t start_index) const {
+  return unique_ptr<Iterator>(new Iterator(this, start_index));
+}
+
+
+Database::WriteResult LevelDB::WriteTreeHead_(const ct::SignedTreeHead& sth) {
+  CHECK_GE(sth.tree_size(), 0);
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("write_tree_head"));
+
+  // 6 bytes are good enough for some 9000 years.
+  string timestamp_key =
+      Serializer::SerializeUint(sth.timestamp(),
+                                LevelDB::kTimestampBytesIndexed);
+  string data;
+  CHECK(sth.SerializeToString(&data));
+
+  unique_lock<mutex> lock(lock_);
+  string existing_data;
+  leveldb::Status status(db_->Get(leveldb::ReadOptions(),
+                                  kTreeHeadPrefix + timestamp_key,
+                                  &existing_data));
+  if (status.ok()) {
+    if (existing_data == data) {
+      return this->OK;
+    }
+    return this->DUPLICATE_TREE_HEAD_TIMESTAMP;
+  }
+
+  leveldb::WriteOptions opts;
+  opts.sync = true;
+  status = db_->Put(opts, kTreeHeadPrefix + timestamp_key, data);
+  CHECK(status.ok()) << "Failed to write tree head (" << timestamp_key
+                     << "): " << status.ToString();
+
+  if (sth.timestamp() > latest_tree_timestamp_) {
+    latest_tree_timestamp_ = sth.timestamp();
+    latest_timestamp_key_ = timestamp_key;
+  }
+
+  lock.unlock();
+  callbacks_.Call(sth);
+
+  return this->OK;
+}
+
+
+Database::LookupResult LevelDB::LatestTreeHead(
+    ct::SignedTreeHead* result) const {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("latest_tree_head"));
+  lock_guard<mutex> lock(lock_);
+
+  return LatestTreeHeadNoLock(result);
+}
+
+
+int64_t LevelDB::TreeSize() const {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("tree_size"));
+  lock_guard<mutex> lock(lock_);
+
+  return contiguous_size_;
+}
+
+
+void LevelDB::AddNotifySTHCallback(
+    const Database::NotifySTHCallback* callback) {
+  unique_lock<mutex> lock(lock_);
+
+  callbacks_.Add(callback);
+
+  ct::SignedTreeHead sth;
+  if (LatestTreeHeadNoLock(&sth) == this->LOOKUP_OK) {
+    lock.unlock();
+    (*callback)(sth);
+  }
+}
+
+
+void LevelDB::RemoveNotifySTHCallback(
+    const Database::NotifySTHCallback* callback) {
+  lock_guard<mutex> lock(lock_);
+
+  callbacks_.Remove(callback);
+}
+
+
+void LevelDB::InitializeNode(const string& node_id) {
+  CHECK(!node_id.empty());
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("initialize_node"));
+  unique_lock<mutex> lock(lock_);
+  string existing_id;
+  if (NodeId(&existing_id) != this->NOT_FOUND) {
+    LOG(FATAL)
+        << "Attempting to initialize DB belonging to node with node_id: "
+        << existing_id;
+  }
+  leveldb::Status status =
+      db_->Put(leveldb::WriteOptions(), string(kMetaPrefix) + kMetaNodeIdKey,
+               node_id);
+  CHECK(status.ok()) << "Failed to store NodeId: " << status.ToString();
+}
+
+
+Database::LookupResult LevelDB::NodeId(string* node_id) {
+  CHECK_NOTNULL(node_id);
+  leveldb::Status status =
+      db_->Get(leveldb::ReadOptions(), string(kMetaPrefix) + kMetaNodeIdKey,
+               node_id);
+
+  if (status.ok()) {
+    return this->LOOKUP_OK;
+  }
+  if (status.IsNotFound()) {
+    return this->NOT_FOUND;
+  }
+  LOG(FATAL) << "Node ID lookup failed: " << status.ToString();
+}
+
+
+void LevelDB::BuildIndex() {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("build_index"));
+  // Technically, this should only be called from the constructor, so
+  // this should not be necessarily, but just to be sure...
+  lock_guard<mutex> lock(lock_);
+
+  leveldb::ReadOptions options;
+  options.fill_cache = false;
+  unique_ptr<leveldb::Iterator> it(db_->NewIterator(options));
+  CHECK(it);
+  it->Seek(kEntryPrefix);
+
+  for (; it->Valid() && it->key().starts_with(kEntryPrefix); it->Next()) {
+    const int64_t seq(KeyToIndex(it->key()));
+    LoggedEntry logged;
+    CHECK(logged.ParseFromString(it->value().ToString()))
+        << "Failed to parse entry with sequence number " << seq;
+    CHECK(logged.has_sequence_number())
+        << "No sequence number for entry with sequence number " << seq;
+    CHECK_EQ(logged.sequence_number(), seq)
+        << "Entry has unexpected sequence_number: " << seq;
+
+    InsertEntryMapping(logged.sequence_number(), logged.Hash());
+  }
+
+  // Now read the STH entries.
+  it->Seek(kTreeHeadPrefix);
+  for (; it->Valid() && it->key().starts_with(kTreeHeadPrefix); it->Next()) {
+    leveldb::Slice key_slice(it->key());
+    key_slice.remove_prefix(strlen(kTreeHeadPrefix));
+    latest_timestamp_key_ = key_slice.ToString();
+    CHECK_EQ(DeserializeResult::OK,
+             Deserializer::DeserializeUint<uint64_t>(
+                 latest_timestamp_key_, LevelDB::kTimestampBytesIndexed,
+                 &latest_tree_timestamp_));
+  }
+}
+
+
+Database::LookupResult LevelDB::LatestTreeHeadNoLock(
+    ct::SignedTreeHead* result) const {
+  if (latest_tree_timestamp_ == 0) {
+    return this->NOT_FOUND;
+  }
+
+  string tree_data;
+  leveldb::Status status(db_->Get(leveldb::ReadOptions(),
+                                  kTreeHeadPrefix + latest_timestamp_key_,
+                                  &tree_data));
+  CHECK(status.ok()) << "Failed to read latest tree head: "
+                     << status.ToString();
+
+  CHECK(result->ParseFromString(tree_data));
+  CHECK_EQ(result->timestamp(), latest_tree_timestamp_);
+
+  return this->LOOKUP_OK;
+}
+
+
+// This must be called with "lock_" held.
+void LevelDB::InsertEntryMapping(int64_t sequence_number, const string& hash) {
+  if (!id_by_hash_.insert(make_pair(hash, sequence_number)).second) {
+    // This is a duplicate hash under a new sequence number.
+    // Make sure we track the entry with the lowest sequence number:
+    id_by_hash_[hash] = min(id_by_hash_[hash], sequence_number);
+  }
+  if (sequence_number == contiguous_size_) {
+    ++contiguous_size_;
+    for (auto i = sparse_entries_.find(contiguous_size_);
+         i != sparse_entries_.end() && *i == contiguous_size_;) {
+      ++contiguous_size_;
+      i = sparse_entries_.erase(i);
+    }
+  } else {
+    // It's not contiguous, put it with the other sparse entries.
+    CHECK(sparse_entries_.insert(sequence_number).second)
+        << "sequence number " << sequence_number << " already assigned.";
+  }
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/leveldb_db.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/leveldb_db.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/leveldb_db.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/leveldb_db.h	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,96 @@
+#ifndef CERT_TRANS_LOG_LEVELDB_DB_H_
+#define CERT_TRANS_LOG_LEVELDB_DB_H_
+
+#include "config.h"
+
+#include <leveldb/db.h>
+#ifdef HAVE_LEVELDB_FILTER_POLICY_H
+#include <leveldb/filter_policy.h>
+#endif
+#include <stdint.h>
+#include <map>
+#include <memory>
+#include <mutex>
+#include <set>
+#include <unordered_map>
+#include <vector>
+
+#include "base/macros.h"
+#include "log/database.h"
+#include "proto/ct.pb.h"
+
+namespace cert_trans {
+
+
+class LevelDB : public Database {
+ public:
+  static const size_t kTimestampBytesIndexed;
+
+  explicit LevelDB(const std::string& dbfile);
+  ~LevelDB() = default;
+
+  // Implement abstract functions, see database.h for comments.
+  Database::WriteResult CreateSequencedEntry_(
+      const LoggedEntry& logged) override;
+
+  Database::LookupResult LookupByHash(const std::string& hash,
+                                      LoggedEntry* result) const override;
+
+  Database::LookupResult LookupByIndex(int64_t sequence_number,
+                                       LoggedEntry* result) const override;
+
+  std::unique_ptr<Database::Iterator> ScanEntries(
+      int64_t start_index) const override;
+
+  Database::WriteResult WriteTreeHead_(const ct::SignedTreeHead& sth) override;
+
+  Database::LookupResult LatestTreeHead(
+      ct::SignedTreeHead* result) const override;
+
+  int64_t TreeSize() const override;
+
+  void AddNotifySTHCallback(
+      const Database::NotifySTHCallback* callback) override;
+
+  void RemoveNotifySTHCallback(
+      const Database::NotifySTHCallback* callback) override;
+
+  void InitializeNode(const std::string& node_id) override;
+
+  Database::LookupResult NodeId(std::string* node_id) override;
+
+ private:
+  class Iterator;
+
+  void BuildIndex();
+  Database::LookupResult LatestTreeHeadNoLock(
+      ct::SignedTreeHead* result) const;
+  void InsertEntryMapping(int64_t sequence_number, const std::string& hash);
+
+  mutable std::mutex lock_;
+#ifdef HAVE_LEVELDB_FILTER_POLICY_H
+  // filter_policy_ must be valid for at least as long as db_ is, so
+  // keep this order.
+  const std::unique_ptr<const leveldb::FilterPolicy> filter_policy_;
+#endif
+  std::unique_ptr<leveldb::DB> db_;
+
+  int64_t contiguous_size_;
+  std::unordered_map<std::string, int64_t> id_by_hash_;
+
+  // This is a mapping of the non-contiguous entries of the log (which
+  // can happen while it is being fetched). When entries here become
+  // contiguous with the beginning of the tree, they are removed.
+  std::set<int64_t> sparse_entries_;
+
+  uint64_t latest_tree_timestamp_;
+  std::string latest_timestamp_key_;
+  cert_trans::DatabaseNotifierHelper callbacks_;
+
+  DISALLOW_COPY_AND_ASSIGN(LevelDB);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_LEVELDB_DB_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/logged_entry.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/logged_entry.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/logged_entry.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/logged_entry.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,164 @@
+#include "log/logged_entry.h"
+
+#include "proto/cert_serializer.h"
+#include "proto/serializer.h"
+#include "util/util.h"
+
+using cert_trans::serialization::SerializeResult;
+using ct::CertInfo;
+using ct::LogEntry;
+using ct::PreCert;
+using ct::SignedCertificateTimestamp;
+using std::string;
+using util::RandomString;
+
+namespace cert_trans {
+
+
+string LoggedEntry::Hash() const {
+  return Sha256Hasher::Sha256Digest(Serializer::LeafData(entry()));
+}
+
+
+bool LoggedEntry::SerializeForLeaf(string* dst) const {
+  return Serializer::SerializeSCTMerkleTreeLeaf(sct(), entry(), dst) ==
+         SerializeResult::OK;
+}
+
+
+bool LoggedEntry::SerializeExtraData(string* dst) const {
+  switch (entry().type()) {
+    case ct::X509_ENTRY:
+      return SerializeX509Chain(entry().x509_entry(), dst) ==
+             SerializeResult::OK;
+    case ct::PRECERT_ENTRY:
+      return SerializePrecertChainEntry(entry().precert_entry(), dst) ==
+             SerializeResult::OK;
+    case ct::PRECERT_ENTRY_V2:
+      // TODO(mhs): V2 implementation needs to be provided.
+      LOG(FATAL) << "CT V2 not yet implemented";
+      break;
+    case ct::X_JSON_ENTRY:
+      dst->clear();
+      return true;
+    case ct::UNKNOWN_ENTRY_TYPE:
+      // We'll handle this below, along with any unknown unknown types too.
+      break;
+  }
+  LOG(FATAL) << "Unknown entry type " << entry().type();
+}
+
+
+bool LoggedEntry::CopyFromClientLogEntry(const AsyncLogClient::Entry& entry) {
+  if (entry.leaf.timestamped_entry().entry_type() != ct::X509_ENTRY &&
+      entry.leaf.timestamped_entry().entry_type() != ct::PRECERT_ENTRY &&
+      entry.leaf.timestamped_entry().entry_type() != ct::X_JSON_ENTRY) {
+    LOG(INFO) << "unsupported entry_type: "
+              << entry.leaf.timestamped_entry().entry_type();
+    return false;
+  }
+
+  Clear();
+
+  ct::SignedCertificateTimestamp* const sct(mutable_contents()->mutable_sct());
+  sct->set_version(ct::V1);
+  sct->set_timestamp(entry.leaf.timestamped_entry().timestamp());
+  sct->set_extensions(entry.leaf.timestamped_entry().extensions());
+
+  // It may look like you should just be able to copy entry.entry over
+  // contents.entry, but entry.entry is incomplete (when the same
+  // information is available in entry.leaf, it will be missing from
+  // entry.entry). So we still need to fill in some missing bits...
+  LogEntry* const log_entry(mutable_contents()->mutable_entry());
+  log_entry->CopyFrom(entry.entry);
+  log_entry->set_type(entry.leaf.timestamped_entry().entry_type());
+  switch (contents().entry().type()) {
+    case ct::X509_ENTRY: {
+      log_entry->mutable_x509_entry()->set_leaf_certificate(
+          entry.leaf.timestamped_entry().signed_entry().x509());
+      break;
+    }
+
+    case ct::PRECERT_ENTRY: {
+      PreCert* const precert(
+          log_entry->mutable_precert_entry()->mutable_pre_cert());
+      precert->set_issuer_key_hash(entry.leaf.timestamped_entry()
+                                       .signed_entry()
+                                       .precert()
+                                       .issuer_key_hash());
+      precert->set_tbs_certificate(entry.leaf.timestamped_entry()
+                                       .signed_entry()
+                                       .precert()
+                                       .tbs_certificate());
+      break;
+    }
+
+    case ct::X_JSON_ENTRY: {
+      log_entry->mutable_x_json_entry()->set_json(
+          entry.leaf.timestamped_entry().signed_entry().json());
+      break;
+    }
+
+    case ct::PRECERT_ENTRY_V2: {
+      // TODO(mhs): V2 implementation here + other changes above
+      LOG(FATAL) << "CT V2 not yet implemented";
+      break;
+    }
+
+    default:
+      LOG(FATAL) << "unknown entry type";
+  }
+
+  return true;
+}
+
+
+void LoggedEntry::RandomForTest() {
+  const char kKeyID[] =
+      "b69d879e3f2c4402556dcda2f6b2e02ff6b6df4789c53000e14f4b125ae847aa";
+
+  mutable_sct()->set_version(ct::V1);
+  mutable_sct()->mutable_id()->set_key_id(util::BinaryString(kKeyID));
+  mutable_sct()->set_timestamp(util::TimeInMilliseconds());
+  mutable_sct()->clear_extensions();
+
+  const int random_bits(rand());
+  ct::LogEntryType type(random_bits & 1 ? ct::X509_ENTRY : ct::PRECERT_ENTRY);
+  ct::LogEntry* const entry(mutable_entry());
+
+  entry->set_type(type);
+  entry->clear_x509_entry();
+  entry->clear_precert_entry();
+
+  if (type == ct::X509_ENTRY) {
+    entry->mutable_x509_entry()->set_leaf_certificate(RandomString(512, 1024));
+    if (random_bits & 2) {
+      entry->mutable_x509_entry()->add_certificate_chain(
+          RandomString(512, 1024));
+
+      if (random_bits & 4) {
+        entry->mutable_x509_entry()->add_certificate_chain(
+            RandomString(512, 1024));
+      }
+    }
+  } else {
+    entry->mutable_precert_entry()->mutable_pre_cert()->set_issuer_key_hash(
+        RandomString(32, 32));
+    entry->mutable_precert_entry()->mutable_pre_cert()->set_tbs_certificate(
+        RandomString(512, 1024));
+    entry->mutable_precert_entry()->set_pre_certificate(
+        RandomString(512, 1024));
+    if (random_bits & 2) {
+      entry->mutable_precert_entry()->add_precertificate_chain(
+          RandomString(512, 1024));
+
+      if (random_bits & 4) {
+        entry->mutable_precert_entry()->add_precertificate_chain(
+            RandomString(512, 1024));
+      }
+    }
+  }
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/logged_entry.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/logged_entry.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/logged_entry.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/logged_entry.h	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,104 @@
+#ifndef CERT_TRANS_LOG_LOGGED_ENTRY_H_
+#define CERT_TRANS_LOG_LOGGED_ENTRY_H_
+
+#include <glog/logging.h>
+
+#include "client/async_log_client.h"
+#include "merkletree/serial_hasher.h"
+#include "proto/ct.pb.h"
+
+namespace cert_trans {
+
+class LoggedEntry : private ct::LoggedEntryPB {
+ public:
+  // Pull only what is used.
+  using LoggedEntryPB::Clear;
+  using LoggedEntryPB::DebugString;
+  using LoggedEntryPB::ParseFromArray;
+  using LoggedEntryPB::ParseFromString;
+  using LoggedEntryPB::SerializeToString;
+  using LoggedEntryPB::Swap;
+  using LoggedEntryPB::clear_sequence_number;
+  using LoggedEntryPB::contents;
+  using LoggedEntryPB::has_sequence_number;
+  using LoggedEntryPB::sequence_number;
+  using LoggedEntryPB::merkle_leaf_hash;
+  using LoggedEntryPB::set_merkle_leaf_hash;
+  using LoggedEntryPB::set_sequence_number;
+  using LoggedEntryPB::CopyFrom;
+  void CopyFrom(const LoggedEntry& from) {
+    LoggedEntryPB::CopyFrom(from);
+  }
+
+  std::string Hash() const;
+
+  uint64_t timestamp() const {
+    return sct().timestamp();
+  }
+
+  const ct::SignedCertificateTimestamp& sct() const {
+    return contents().sct();
+  }
+
+  ct::SignedCertificateTimestamp* mutable_sct() {
+    return mutable_contents()->mutable_sct();
+  }
+
+  const ct::LogEntry& entry() const {
+    return contents().entry();
+  }
+
+  ct::LogEntry* mutable_entry() {
+    return mutable_contents()->mutable_entry();
+  }
+
+  bool SerializeForDatabase(std::string* dst) const {
+    return contents().SerializeToString(dst);
+  }
+
+  bool ParseFromDatabase(const std::string& src) {
+    return mutable_contents()->ParseFromString(src);
+  }
+
+  bool SerializeForLeaf(std::string* dst) const;
+  bool SerializeExtraData(std::string* dst) const;
+
+  // Note that this method will not fully populate the SCT.
+  bool CopyFromClientLogEntry(const AsyncLogClient::Entry& entry);
+
+  // FIXME(benl): unify with TestSigner?
+  void RandomForTest();
+};
+
+
+inline bool operator==(const LoggedEntry& lhs, const LoggedEntry& rhs) {
+  // TODO(alcutter): Do this properly
+  std::string l_str, r_str;
+  CHECK(lhs.SerializeToString(&l_str));
+  CHECK(rhs.SerializeToString(&r_str));
+  return l_str == r_str;
+}
+
+
+inline bool operator==(const ct::LogEntry& lhs, const ct::LogEntry& rhs) {
+  // TODO(alcutter): Do this properly
+  std::string l_str, r_str;
+  CHECK(lhs.SerializeToString(&l_str));
+  CHECK(rhs.SerializeToString(&r_str));
+  return l_str == r_str;
+}
+
+
+inline bool operator==(const ct::SignedCertificateTimestamp& lhs,
+                       const ct::SignedCertificateTimestamp& rhs) {
+  // TODO(alcutter): Do this properly
+  std::string l_str, r_str;
+  CHECK(lhs.SerializeToString(&l_str));
+  CHECK(rhs.SerializeToString(&r_str));
+  return l_str == r_str;
+}
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_LOGGED_ENTRY_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/logged_entry_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/logged_entry_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/logged_entry_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/logged_entry_test.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,7 @@
+#include "log/logged_entry.h"
+
+#include <gtest/gtest.h>
+
+typedef testing::Types<cert_trans::LoggedEntry> TestType;
+
+#include "log/logged_test-inl.h"
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/logged_test-inl.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/logged_test-inl.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/logged_test-inl.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/logged_test-inl.h	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,107 @@
+/* -*- indent-tabs-mode: nil -*- */
+#ifndef CERT_TRANS_LOG_LOGGED_TEST_INL_H_
+#define CERT_TRANS_LOG_LOGGED_TEST_INL_H_
+
+#include <string>
+
+#include "proto/cert_serializer.h"
+#include "util/testing.h"
+
+
+template <class Logged>
+class LoggedTest : public ::testing::Test {
+ protected:
+};
+
+TYPED_TEST_CASE(LoggedTest, TestType);
+
+TYPED_TEST(LoggedTest, NonEmptyHash) {
+  TypeParam l1;
+  l1.RandomForTest();
+
+  EXPECT_FALSE(l1.Hash().empty());
+}
+
+TYPED_TEST(LoggedTest, SequenceIsPreserved) {
+  TypeParam l1;
+  l1.set_sequence_number(42);
+  EXPECT_EQ(l1.sequence_number(), (int64_t)42);
+}
+
+TYPED_TEST(LoggedTest, SequenceIsNotPreserved) {
+  TypeParam l1;
+  l1.set_sequence_number(42);
+  EXPECT_EQ(l1.sequence_number(), (int64_t)42);
+
+  std::string s1;
+  EXPECT_TRUE(l1.SerializeForDatabase(&s1));
+
+  TypeParam l2;
+  EXPECT_TRUE(l2.ParseFromDatabase(s1));
+  EXPECT_FALSE(l2.has_sequence_number());
+}
+
+TYPED_TEST(LoggedTest, DifferentHash) {
+  TypeParam l1;
+  l1.RandomForTest();
+
+  TypeParam l2;
+  l2.RandomForTest();
+
+  EXPECT_NE(l1.Hash(), l2.Hash());
+}
+
+TYPED_TEST(LoggedTest, SerializationPreservesHash) {
+  TypeParam l1;
+  l1.RandomForTest();
+
+  std::string s1;
+  EXPECT_TRUE(l1.SerializeForDatabase(&s1));
+
+  TypeParam l2;
+  EXPECT_TRUE(l2.ParseFromDatabase(s1));
+
+  EXPECT_EQ(l1.Hash(), l2.Hash());
+}
+
+TYPED_TEST(LoggedTest, SerializationPreservesMerkleSerialization) {
+  TypeParam l1;
+  l1.RandomForTest();
+
+  std::string d1;
+  EXPECT_TRUE(l1.SerializeForDatabase(&d1));
+
+  TypeParam l2;
+  EXPECT_TRUE(l2.ParseFromDatabase(d1));
+
+  std::string s1;
+  EXPECT_TRUE(l1.SerializeForLeaf(&s1));
+  std::string s2;
+  EXPECT_TRUE(l2.SerializeForLeaf(&s2));
+
+  EXPECT_EQ(s1, s2);
+}
+
+TYPED_TEST(LoggedTest, DifferentMerkleSerialization) {
+  TypeParam l1;
+  l1.RandomForTest();
+
+  TypeParam l2;
+  l2.RandomForTest();
+
+  std::string s1;
+  EXPECT_TRUE(l1.SerializeForLeaf(&s1));
+  std::string s2;
+  EXPECT_TRUE(l2.SerializeForLeaf(&s2));
+
+  EXPECT_NE(s1, s2);
+}
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  ConfigureSerializerForV1CT();
+  srand(time(NULL));
+  return RUN_ALL_TESTS();
+}
+
+#endif  // CERT_TRANS_LOG_LOGGED_TEST_INL_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_lookup.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_lookup.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_lookup.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_lookup.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,226 @@
+#include "log/log_lookup.h"
+
+#include <glog/logging.h>
+#include <stdint.h>
+#include <stdlib.h>
+#include <map>
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "base/time_support.h"
+#include "merkletree/merkle_tree.h"
+#include "merkletree/serial_hasher.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+#include "util/util.h"
+
+using ct::MerkleAuditProof;
+using ct::ShortMerkleAuditProof;
+using ct::SignedTreeHead;
+using std::bind;
+using std::lock_guard;
+using std::make_pair;
+using std::map;
+using std::mutex;
+using std::placeholders::_1;
+using std::string;
+using std::unique_lock;
+using std::unique_ptr;
+using std::vector;
+using util::HexString;
+
+namespace cert_trans {
+
+
+static const int kCtimeBufSize = 26;
+
+
+LogLookup::LogLookup(ReadOnlyDatabase* db)
+    : db_(CHECK_NOTNULL(db)),
+      cert_tree_(unique_ptr<Sha256Hasher>(new Sha256Hasher)),
+      latest_tree_head_(),
+      update_from_sth_cb_(bind(&LogLookup::UpdateFromSTH, this, _1)) {
+  db_->AddNotifySTHCallback(&update_from_sth_cb_);
+}
+
+
+LogLookup::~LogLookup() {
+  db_->RemoveNotifySTHCallback(&update_from_sth_cb_);
+}
+
+
+void LogLookup::UpdateFromSTH(const SignedTreeHead& sth) {
+  lock_guard<mutex> lock(lock_);
+
+  CHECK_EQ(ct::V1, sth.version())
+      << "Tree head signed with an unknown version";
+
+  if (sth.timestamp() == latest_tree_head_.timestamp())
+    return;
+
+  CHECK_LE(0, sth.tree_size());
+  if (sth.timestamp() <= latest_tree_head_.timestamp() ||
+      static_cast<uint64_t>(sth.tree_size()) < cert_tree_.LeafCount()) {
+    LOG(WARNING) << "Database replied with an STH that is older than ours: "
+                 << "Our STH:\n" << latest_tree_head_.DebugString()
+                 << "Database STH:\n" << sth.DebugString();
+    return;
+  }
+
+  // Record the new hashes: append all of them, die on any error.
+  // TODO(ekasper): make tree signer write leaves out to the database,
+  // so that we don't have to read the entries in.
+  string leaf_hash;
+  auto it(db_->ScanEntries(cert_tree_.LeafCount()));
+  // LeafCount() is potentially unsigned here but as this is using memory
+  // the count can never get close to overflow in 64 bits.
+  CHECK_LE(cert_tree_.LeafCount(), static_cast<uint64_t>(INT64_MAX));
+
+  for (int64_t sequence_number = cert_tree_.LeafCount();
+       sequence_number < sth.tree_size(); ++sequence_number) {
+    LoggedEntry logged;
+    // TODO(ekasper): perhaps some of these errors can/should be
+    // handled more gracefully. E.g. we could retry a failed update
+    // a number of times -- but until we know under which conditions
+    // the database might fail (database busy?), just die.
+    CHECK(it->GetNextEntry(&logged))
+        << "Latest STH has " << sth.tree_size() << "entries but we failed to "
+        << "retrieve entry number " << sequence_number;
+    CHECK(logged.has_sequence_number())
+        << "Logged entry has no sequence number";
+    CHECK_EQ(sequence_number, logged.sequence_number());
+
+    leaf_hash = LeafHash(logged);
+    // TODO(ekasper): plug in the log public key so that we can verify the STH.
+    CHECK_EQ(static_cast<size_t>(sequence_number + 1),
+             cert_tree_.AddLeafHash(leaf_hash));
+    // Duplicate leaves shouldn't really happen but are not a problem either:
+    // we just return the Merkle proof of the first occurrence.
+    leaf_index_.insert(make_pair(leaf_hash, sequence_number));
+  }
+  CHECK_EQ(HexString(cert_tree_.CurrentRoot()),
+           HexString(sth.sha256_root_hash()))
+      << "Computed root hash and stored STH root hash do not match";
+  LOG(INFO) << "Found " << sth.tree_size() - latest_tree_head_.tree_size()
+            << " new log entries";
+  latest_tree_head_.CopyFrom(sth);
+
+  const time_t last_update(static_cast<time_t>(latest_tree_head_.timestamp() /
+                                               kNumMillisPerSecond));
+  char buf[kCtimeBufSize];
+  LOG(INFO) << "Tree successfully updated at " << ctime_r(&last_update, buf);
+}
+
+
+LogLookup::LookupResult LogLookup::GetIndex(const string& merkle_leaf_hash,
+                                            int64_t* index) {
+  unique_lock<mutex> lock(lock_);
+  const int64_t myindex(GetIndexInternal(lock, merkle_leaf_hash));
+
+  if (myindex < 0) {
+    return NOT_FOUND;
+  } else {
+    *index = myindex;
+    return OK;
+  }
+}
+
+
+// Look up by SHA256-hash of the certificate.
+LogLookup::LookupResult LogLookup::AuditProof(const string& merkle_leaf_hash,
+                                              MerkleAuditProof* proof) {
+  unique_lock<mutex> lock(lock_);
+
+  const int64_t leaf_index(GetIndexInternal(lock, merkle_leaf_hash));
+  if (leaf_index < 0) {
+    return NOT_FOUND;
+  }
+
+  CHECK_GE(leaf_index, 0);
+  proof->set_version(ct::V1);
+  proof->set_tree_size(cert_tree_.LeafCount());
+  proof->set_timestamp(latest_tree_head_.timestamp());
+  proof->set_leaf_index(leaf_index);
+
+  proof->clear_path_node();
+  vector<string> audit_path = cert_tree_.PathToCurrentRoot(leaf_index + 1);
+  for (size_t i = 0; i < audit_path.size(); ++i)
+    proof->add_path_node(audit_path[i]);
+
+  proof->mutable_id()->CopyFrom(latest_tree_head_.id());
+  proof->mutable_tree_head_signature()->CopyFrom(
+      latest_tree_head_.signature());
+  return OK;
+}
+
+
+LogLookup::LookupResult LogLookup::AuditProof(int64_t leaf_index,
+                                              size_t tree_size,
+                                              ShortMerkleAuditProof* proof) {
+  lock_guard<mutex> lock(lock_);
+
+  proof->set_leaf_index(leaf_index);
+
+  proof->clear_path_node();
+  vector<string> audit_path =
+      cert_tree_.PathToRootAtSnapshot(leaf_index + 1, tree_size);
+  for (size_t i = 0; i < audit_path.size(); ++i)
+    proof->add_path_node(audit_path[i]);
+
+  return OK;
+}
+
+
+// Look up by SHA256-hash of the certificate and tree size.
+LogLookup::LookupResult LogLookup::AuditProof(const string& merkle_leaf_hash,
+                                              size_t tree_size,
+                                              ShortMerkleAuditProof* proof) {
+  int64_t leaf_index;
+  if (GetIndex(merkle_leaf_hash, &leaf_index) != OK)
+    return NOT_FOUND;
+
+  CHECK_GE(leaf_index, 0);
+  return AuditProof(leaf_index, tree_size, proof);
+}
+
+
+string LogLookup::RootAtSnapshot(size_t tree_size) {
+  lock_guard<mutex> lock(lock_);
+  return cert_tree_.RootAtSnapshot(tree_size);
+}
+
+
+string LogLookup::LeafHash(const LoggedEntry& logged) const {
+  string serialized_leaf;
+  CHECK(logged.SerializeForLeaf(&serialized_leaf));
+  // We do not need to take the lock for this call into cert_tree_, as
+  // this is merely a const forwarder (to another const, thread-safe
+  // method).
+  return cert_tree_.LeafHash(serialized_leaf);
+}
+
+
+unique_ptr<CompactMerkleTree> LogLookup::GetCompactMerkleTree(
+    SerialHasher* hasher) {
+  lock_guard<mutex> lock(lock_);
+  return unique_ptr<CompactMerkleTree>(
+      new CompactMerkleTree(&cert_tree_, unique_ptr<SerialHasher>(hasher)));
+}
+
+
+int64_t LogLookup::GetIndexInternal(const unique_lock<mutex>& lock,
+                                    const string& merkle_leaf_hash) const {
+  CHECK(lock.owns_lock());
+
+  const map<string, int64_t>::const_iterator it(
+      leaf_index_.find(merkle_leaf_hash));
+  if (it == leaf_index_.end())
+    return -1;
+
+  CHECK_GE(it->second, 0);
+  return it->second;
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_lookup.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_lookup.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_lookup.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_lookup.h	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,92 @@
+#ifndef CERT_TRANS_LOG_LOG_LOOKUP_H_
+#define CERT_TRANS_LOG_LOG_LOOKUP_H_
+
+#include <stdint.h>
+#include <map>
+#include <mutex>
+#include <string>
+
+#include "base/macros.h"
+#include "log/database.h"
+#include "merkletree/compact_merkle_tree.h"
+#include "merkletree/merkle_tree.h"
+#include "proto/ct.pb.h"
+
+namespace cert_trans {
+
+
+// Lookups into the database. Read-only, so could also be a mirror.
+// Keeps the entire Merkle Tree in memory to serve audit proofs.
+class LogLookup {
+ public:
+  // The constructor loads the content from the database.
+  explicit LogLookup(ReadOnlyDatabase* db);
+  ~LogLookup();
+
+  enum LookupResult {
+    OK,
+    NOT_FOUND,
+  };
+
+  LookupResult GetIndex(const std::string& merkle_leaf_hash, int64_t* index);
+
+  // Look up by hash of the logged item.
+  // TODO(pphaneuf): Looking up an audit proof without a tree size is
+  // unreliable in the case of multiple CT servers (some might be
+  // behind). New code should avoid this variant.
+  LookupResult AuditProof(const std::string& merkle_leaf_hash,
+                          ct::MerkleAuditProof* proof);
+
+  // Look up by index of the logged item and tree_size.
+  LookupResult AuditProof(int64_t index, size_t tree_size,
+                          ct::ShortMerkleAuditProof* proof);
+
+  // Look up by hash of the logged item and tree_size.
+  LookupResult AuditProof(const std::string& merkle_leaf_hash,
+                          size_t tree_size, ct::ShortMerkleAuditProof* proof);
+
+  // Get a consitency proof between two tree heads
+  std::vector<std::string> ConsistencyProof(size_t first, size_t second) {
+    std::lock_guard<std::mutex> lock(lock_);
+    return cert_tree_.SnapshotConsistency(first, second);
+  }
+
+  const ct::SignedTreeHead& GetSTH() const {
+    std::lock_guard<std::mutex> lock(lock_);
+    return latest_tree_head_;
+  }
+
+  std::string RootAtSnapshot(size_t tree_size);
+
+  std::string LeafHash(const LoggedEntry& logged) const;
+
+  // Creates a CompactMerkleTree based on the current state of our MerkleTree.
+  // Takes ownership of |hasher|.
+  std::unique_ptr<CompactMerkleTree> GetCompactMerkleTree(
+      SerialHasher* hasher);
+
+ private:
+  void UpdateFromSTH(const ct::SignedTreeHead& sth);
+  int64_t GetIndexInternal(const std::unique_lock<std::mutex>& lock,
+                           const std::string& merkle_leaf_hash) const;
+
+  mutable std::mutex lock_;
+  // We keep a hash -> index mapping in memory so that we can quickly serve
+  // Merkle proofs without having to query the database at all.
+  // Note that 32 bytes is an overkill and we can optimize this to use
+  // a shorter prefix (possibly with a multimap).
+  std::map<std::string, int64_t> leaf_index_;
+
+  ReadOnlyDatabase* const db_;
+  MerkleTree cert_tree_;
+  ct::SignedTreeHead latest_tree_head_;
+
+  const Database::NotifySTHCallback update_from_sth_cb_;
+
+  DISALLOW_COPY_AND_ASSIGN(LogLookup);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_LOG_LOOKUP_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_lookup_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_lookup_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_lookup_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_lookup_test.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,239 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include <gtest/gtest.h>
+#include <memory>
+#include <string>
+
+#include "log/etcd_consistent_store.h"
+#include "log/file_db.h"
+#include "log/file_storage.h"
+#include "log/log_lookup.h"
+#include "log/log_signer.h"
+#include "log/log_verifier.h"
+#include "log/logged_entry.h"
+#include "log/sqlite_db.h"
+#include "log/test_db.h"
+#include "log/test_signer.h"
+#include "log/tree_signer.h"
+#include "merkletree/merkle_verifier.h"
+#include "merkletree/serial_hasher.h"
+#include "proto/cert_serializer.h"
+#include "util/fake_etcd.h"
+#include "util/mock_masterelection.h"
+#include "util/sync_task.h"
+#include "util/testing.h"
+#include "util/thread_pool.h"
+#include "util/util.h"
+
+namespace {
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::Database;
+using cert_trans::EntryHandle;
+using cert_trans::EtcdClient;
+using cert_trans::FakeEtcdClient;
+using cert_trans::FileDB;
+using cert_trans::LogLookup;
+using cert_trans::LoggedEntry;
+using cert_trans::MockMasterElection;
+using cert_trans::SQLiteDB;
+using cert_trans::ThreadPool;
+using cert_trans::TreeSigner;
+using ct::MerkleAuditProof;
+using ct::SequenceMapping;
+using std::make_shared;
+using std::shared_ptr;
+using std::string;
+using std::unique_ptr;
+using testing::NiceMock;
+
+
+template <class T>
+class LogLookupTest : public ::testing::Test {
+ protected:
+  LogLookupTest()
+      : test_db_(),
+        base_(make_shared<libevent::Base>()),
+        event_pump_(base_),
+        etcd_client_(base_.get()),
+        pool_(2),
+        store_(base_.get(), &pool_, &etcd_client_, &election_, "/root", "id"),
+        test_signer_(),
+        log_signer_(TestSigner::DefaultLogSigner()),
+        tree_signer_(std::chrono::duration<double>(0), db(),
+                     unique_ptr<CompactMerkleTree>(new CompactMerkleTree(
+                         unique_ptr<Sha256Hasher>(new Sha256Hasher))),
+                     &store_, log_signer_.get()),
+        verifier_(TestSigner::DefaultLogSigVerifier(),
+                  new MerkleVerifier(
+                      unique_ptr<Sha256Hasher>(new Sha256Hasher))) {
+    // Set some noddy STH so that we can call UpdateTree on the Tree Signer.
+    store_.SetServingSTH(ct::SignedTreeHead());
+    // Force an empty sequence mapping file:
+    {
+      util::SyncTask task(&pool_);
+      EtcdClient::Response r;
+      etcd_client_.ForceSet("/root/sequence_mapping", "", &r, task.task());
+      task.Wait();
+    }
+  }
+
+
+  void CreateSequencedEntry(LoggedEntry* logged_cert, int64_t seq) {
+    CHECK_NOTNULL(logged_cert);
+    CHECK_GE(seq, 0);
+    logged_cert->clear_sequence_number();
+
+    CHECK(this->store_.AddPendingEntry(logged_cert).ok());
+
+    EntryHandle<SequenceMapping> mapping;
+    CHECK(this->store_.GetSequenceMapping(&mapping).ok());
+    SequenceMapping::Mapping* m(mapping.MutableEntry()->add_mapping());
+    m->set_sequence_number(seq);
+    m->set_entry_hash(logged_cert->Hash());
+    CHECK(this->store_.UpdateSequenceMapping(&mapping).ok());
+  }
+
+  void UpdateTree() {
+    // first need to populate the local DB with the sequenced entries in etcd:
+    EntryHandle<SequenceMapping> mapping;
+    CHECK(this->store_.GetSequenceMapping(&mapping).ok());
+
+    for (const auto& m : mapping.Entry().mapping()) {
+      EntryHandle<LoggedEntry> entry;
+      CHECK_EQ(util::Status::OK,
+               this->store_.GetPendingEntryForHash(m.entry_hash(), &entry));
+      entry.MutableEntry()->set_sequence_number(m.sequence_number());
+      CHECK_EQ(this->db()->OK,
+               this->db()->CreateSequencedEntry(entry.Entry()));
+    }
+
+    // then do the actual update.
+    EXPECT_EQ(TreeSigner::OK, this->tree_signer_.UpdateTree());
+    this->db()->WriteTreeHead(this->tree_signer_.LatestSTH());
+  }
+
+  T* db() const {
+    return test_db_.db();
+  }
+
+
+  TestDB<T> test_db_;
+  shared_ptr<libevent::Base> base_;
+  libevent::EventPumpThread event_pump_;
+  FakeEtcdClient etcd_client_;
+  ThreadPool pool_;
+  NiceMock<MockMasterElection> election_;
+  cert_trans::EtcdConsistentStore store_;
+  TestSigner test_signer_;
+  unique_ptr<LogSigner> log_signer_;
+  TreeSigner tree_signer_;
+  LogVerifier verifier_;
+};
+
+
+typedef testing::Types<FileDB, SQLiteDB> Databases;
+
+TYPED_TEST_CASE(LogLookupTest, Databases);
+
+
+TYPED_TEST(LogLookupTest, Lookup) {
+  LoggedEntry logged_cert;
+  this->test_signer_.CreateUnique(&logged_cert);
+  this->CreateSequencedEntry(&logged_cert, 0);
+
+  MerkleAuditProof proof;
+  this->UpdateTree();
+
+  LogLookup lookup(this->db());
+  // Look the new entry up.
+  EXPECT_EQ(LogLookup::OK,
+            lookup.AuditProof(logged_cert.merkle_leaf_hash(), &proof));
+}
+
+
+TYPED_TEST(LogLookupTest, NotFound) {
+  LoggedEntry logged_cert;
+  this->test_signer_.CreateUnique(&logged_cert);
+  this->CreateSequencedEntry(&logged_cert, 0);
+
+  MerkleAuditProof proof;
+  this->UpdateTree();
+
+  LogLookup lookup(this->db());
+
+  // Look up using a wrong hash.
+  string hash = this->test_signer_.UniqueHash();
+  EXPECT_EQ(LogLookup::NOT_FOUND, lookup.AuditProof(hash, &proof));
+}
+
+
+TYPED_TEST(LogLookupTest, Update) {
+  LogLookup lookup(this->db());
+  LoggedEntry logged_cert;
+  this->test_signer_.CreateUnique(&logged_cert);
+  this->CreateSequencedEntry(&logged_cert, 0);
+
+  MerkleAuditProof proof;
+  this->UpdateTree();
+
+  // Look the new entry up.
+  EXPECT_EQ(LogLookup::OK,
+            lookup.AuditProof(logged_cert.merkle_leaf_hash(), &proof));
+}
+
+
+// Verify that the audit proof constructed is correct (assuming the signer
+// operates correctly). TODO(ekasper): KAT tests.
+TYPED_TEST(LogLookupTest, Verify) {
+  LoggedEntry logged_cert;
+  this->test_signer_.CreateUnique(&logged_cert);
+  this->CreateSequencedEntry(&logged_cert, 0);
+
+  MerkleAuditProof proof;
+  this->UpdateTree();
+
+  LogLookup lookup(this->db());
+  // Look the new entry up.
+  EXPECT_EQ(LogLookup::OK,
+            lookup.AuditProof(logged_cert.merkle_leaf_hash(), &proof));
+  EXPECT_EQ(LogVerifier::VERIFY_OK,
+            this->verifier_.VerifyMerkleAuditProof(logged_cert.entry(),
+                                                   logged_cert.sct(), proof));
+}
+
+
+// Build a bigger tree so that we actually verify a non-empty path.
+TYPED_TEST(LogLookupTest, VerifyWithPath) {
+  LoggedEntry logged_certs[13];
+
+  // Make the tree not balanced for extra fun.
+  for (int i = 0; i < 13; ++i) {
+    this->test_signer_.CreateUnique(&logged_certs[i]);
+    this->CreateSequencedEntry(&logged_certs[i], i);
+  }
+
+  this->UpdateTree();
+
+  LogLookup lookup(this->db());
+  MerkleAuditProof proof;
+
+  for (int i = 0; i < 13; ++i) {
+    EXPECT_EQ(LogLookup::OK,
+              lookup.AuditProof(logged_certs[i].merkle_leaf_hash(), &proof));
+    EXPECT_EQ(LogVerifier::VERIFY_OK,
+              this->verifier_.VerifyMerkleAuditProof(logged_certs[i].entry(),
+                                                     logged_certs[i].sct(),
+                                                     proof));
+  }
+}
+
+
+}  // namespace
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  ConfigureSerializerForV1CT();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_signer.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_signer.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_signer.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_signer.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,347 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "log/log_signer.h"
+
+#include <glog/logging.h>
+#include <openssl/evp.h>
+#include <openssl/opensslv.h>
+#include <stdint.h>
+
+#include "merkletree/serial_hasher.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+#include "util/util.h"
+
+using cert_trans::Verifier;
+using cert_trans::serialization::SerializeResult;
+using cert_trans::serialization::DeserializeResult;
+using ct::DigitallySigned;
+using ct::LogEntry;
+using ct::LogEntryType;
+using ct::SignedCertificateTimestamp;
+using ct::SignedTreeHead;
+using std::string;
+
+#if OPENSSL_VERSION_NUMBER < 0x10000000
+#error "Need OpenSSL >= 1.0.0"
+#endif
+
+namespace {
+
+LogSigVerifier::VerifyResult ConvertStatus(const Verifier::Status status) {
+  switch (status) {
+    case Verifier::OK:
+      return LogSigVerifier::OK;
+    case Verifier::HASH_ALGORITHM_MISMATCH:
+      return LogSigVerifier::HASH_ALGORITHM_MISMATCH;
+    case Verifier::SIGNATURE_ALGORITHM_MISMATCH:
+      return LogSigVerifier::SIGNATURE_ALGORITHM_MISMATCH;
+    case Verifier::INVALID_SIGNATURE:
+      return LogSigVerifier::INVALID_SIGNATURE;
+  }
+  LOG(FATAL) << "Unexpected status " << status;
+}
+
+}  // namespace
+
+LogSigner::LogSigner(EVP_PKEY* pkey) : cert_trans::Signer(pkey) {
+}
+
+LogSigner::~LogSigner() {
+}
+
+LogSigner::SignResult LogSigner::SignV1CertificateTimestamp(
+    uint64_t timestamp, const string& leaf_certificate,
+    const string& extensions, string* result) const {
+  SignedCertificateTimestamp sct;
+  sct.set_version(ct::V1);
+  sct.set_timestamp(timestamp);
+  sct.set_extensions(extensions);
+
+  LogEntry entry;
+  entry.set_type(ct::X509_ENTRY);
+  entry.mutable_x509_entry()->set_leaf_certificate(leaf_certificate);
+
+  string serialized_input;
+  SerializeResult res =
+      Serializer::SerializeSCTSignatureInput(sct, entry, &serialized_input);
+
+  if (res != SerializeResult::OK)
+    return GetSerializeError(res);
+
+  DigitallySigned signature;
+  Sign(serialized_input, &signature);
+  CHECK_EQ(SerializeResult::OK,
+           Serializer::SerializeDigitallySigned(signature, result));
+  return OK;
+}
+
+LogSigner::SignResult LogSigner::SignV1PrecertificateTimestamp(
+    uint64_t timestamp, const string& issuer_key_hash,
+    const string& tbs_certificate, const string& extensions,
+    string* result) const {
+  SignedCertificateTimestamp sct;
+  sct.set_version(ct::V1);
+  sct.set_timestamp(timestamp);
+  sct.set_extensions(extensions);
+
+  LogEntry entry;
+  entry.set_type(ct::PRECERT_ENTRY);
+  entry.mutable_precert_entry()->mutable_pre_cert()->set_issuer_key_hash(
+      issuer_key_hash);
+  entry.mutable_precert_entry()->mutable_pre_cert()->set_tbs_certificate(
+      tbs_certificate);
+
+  string serialized_input;
+  SerializeResult res =
+      Serializer::SerializeSCTSignatureInput(sct, entry, &serialized_input);
+
+  if (res != SerializeResult::OK)
+    return GetSerializeError(res);
+
+  DigitallySigned signature;
+  Sign(serialized_input, &signature);
+  CHECK_EQ(SerializeResult::OK,
+           Serializer::SerializeDigitallySigned(signature, result));
+  return OK;
+}
+
+LogSigner::SignResult LogSigner::SignCertificateTimestamp(
+    const LogEntry& entry, SignedCertificateTimestamp* sct) const {
+  CHECK(sct->has_timestamp())
+      << "Attempt to sign an SCT with a missing timestamp";
+
+  string serialized_input;
+  SerializeResult res =
+      Serializer::SerializeSCTSignatureInput(*sct, entry, &serialized_input);
+
+  if (res != SerializeResult::OK)
+    return GetSerializeError(res);
+  Sign(serialized_input, sct->mutable_signature());
+  sct->mutable_id()->set_key_id(KeyID());
+  return OK;
+}
+
+LogSigner::SignResult LogSigner::SignV1TreeHead(uint64_t timestamp,
+                                                int64_t tree_size,
+                                                const string& root_hash,
+                                                string* result) const {
+  CHECK_GE(tree_size, 0);
+  string serialized_sth;
+  SerializeResult res =
+      Serializer::SerializeV1STHSignatureInput(timestamp, tree_size, root_hash,
+                                               &serialized_sth);
+
+  if (res != SerializeResult::OK)
+    return GetSerializeError(res);
+
+  DigitallySigned signature;
+  Sign(serialized_sth, &signature);
+  CHECK_EQ(SerializeResult::OK,
+           Serializer::SerializeDigitallySigned(signature, result));
+  return OK;
+}
+
+LogSigner::SignResult LogSigner::SignTreeHead(SignedTreeHead* sth) const {
+  string serialized_sth;
+  SerializeResult res =
+      Serializer::SerializeSTHSignatureInput(*sth, &serialized_sth);
+  if (res != SerializeResult::OK)
+    return GetSerializeError(res);
+  Sign(serialized_sth, sth->mutable_signature());
+  sth->mutable_id()->set_key_id(KeyID());
+  return OK;
+}
+
+// static
+LogSigner::SignResult LogSigner::GetSerializeError(SerializeResult result) {
+  SignResult sign_result;
+  switch (result) {
+    case SerializeResult::INVALID_ENTRY_TYPE:
+      sign_result = INVALID_ENTRY_TYPE;
+      break;
+    case SerializeResult::EMPTY_CERTIFICATE:
+      sign_result = EMPTY_CERTIFICATE;
+      break;
+    case SerializeResult::CERTIFICATE_TOO_LONG:
+      sign_result = CERTIFICATE_TOO_LONG;
+      break;
+    case SerializeResult::INVALID_HASH_LENGTH:
+      sign_result = INVALID_HASH_LENGTH;
+      break;
+    case SerializeResult::UNSUPPORTED_VERSION:
+      sign_result = UNSUPPORTED_VERSION;
+      break;
+    case SerializeResult::EXTENSIONS_TOO_LONG:
+      sign_result = EXTENSIONS_TOO_LONG;
+      break;
+    default:
+      LOG(FATAL) << "Unexpected Serializer error code " << result;
+  }
+  return sign_result;
+}
+
+LogSigVerifier::LogSigVerifier(EVP_PKEY* pkey) : Verifier(pkey) {
+}
+
+LogSigVerifier::~LogSigVerifier() {
+}
+
+LogSigVerifier::VerifyResult LogSigVerifier::VerifyV1CertSCTSignature(
+    uint64_t timestamp, const string& leaf_cert, const string& extensions,
+    const string& serialized_sig) const {
+  DigitallySigned signature;
+  DeserializeResult result =
+      Deserializer::DeserializeDigitallySigned(serialized_sig, &signature);
+  if (result != DeserializeResult::OK) {
+    LOG(WARNING) << "DeserializeDigitallySigned returned " << result;
+    return GetDeserializeSignatureError(result);
+  }
+
+  SignedCertificateTimestamp sct;
+  sct.set_version(ct::V1);
+  sct.set_timestamp(timestamp);
+  sct.set_extensions(extensions);
+
+  LogEntry entry;
+  entry.set_type(ct::X509_ENTRY);
+  entry.mutable_x509_entry()->set_leaf_certificate(leaf_cert);
+
+  string serialized_sct;
+  SerializeResult serialize_result =
+      Serializer::SerializeSCTSignatureInput(sct, entry, &serialized_sct);
+
+  if (serialize_result != SerializeResult::OK)
+    return GetSerializeError(serialize_result);
+  return ConvertStatus(Verify(serialized_sct, signature));
+}
+
+LogSigVerifier::VerifyResult LogSigVerifier::VerifyV1PrecertSCTSignature(
+    uint64_t timestamp, const string& issuer_key_hash, const string& tbs_cert,
+    const string& extensions, const string& serialized_sig) const {
+  DigitallySigned signature;
+  DeserializeResult result =
+      Deserializer::DeserializeDigitallySigned(serialized_sig, &signature);
+  if (result != DeserializeResult::OK)
+    return GetDeserializeSignatureError(result);
+
+  SignedCertificateTimestamp sct;
+  sct.set_version(ct::V1);
+  sct.set_timestamp(timestamp);
+  sct.set_extensions(extensions);
+
+  LogEntry entry;
+  entry.set_type(ct::PRECERT_ENTRY);
+  entry.mutable_precert_entry()->mutable_pre_cert()->set_issuer_key_hash(
+      issuer_key_hash);
+  entry.mutable_precert_entry()->mutable_pre_cert()->set_tbs_certificate(
+      tbs_cert);
+
+  string serialized_sct;
+  SerializeResult serialize_result =
+      Serializer::SerializeSCTSignatureInput(sct, entry, &serialized_sct);
+  if (serialize_result != SerializeResult::OK)
+    return GetSerializeError(serialize_result);
+  return ConvertStatus(Verify(serialized_sct, signature));
+}
+
+
+LogSigVerifier::VerifyResult LogSigVerifier::VerifySCTSignature(
+    const LogEntry& entry, const SignedCertificateTimestamp& sct) const {
+  // Try to catch key mismatches early.
+  if (sct.id().has_key_id() && sct.id().key_id() != KeyID()) {
+    LOG(WARNING) << "Key ID mismatch, got: "
+                 << util::HexString(sct.id().key_id())
+                 << " expected: " << util::HexString(KeyID());
+    return KEY_ID_MISMATCH;
+  }
+
+  string serialized_input;
+  SerializeResult serialize_result =
+      Serializer::SerializeSCTSignatureInput(sct, entry, &serialized_input);
+  if (serialize_result != SerializeResult::OK)
+    return GetSerializeError(serialize_result);
+  return ConvertStatus(Verify(serialized_input, sct.signature()));
+}
+
+LogSigVerifier::VerifyResult LogSigVerifier::VerifyV1STHSignature(
+    uint64_t timestamp, int64_t tree_size, const string& root_hash,
+    const string& serialized_sig) const {
+  CHECK_GE(tree_size, 0);
+  DigitallySigned signature;
+  DeserializeResult result =
+      Deserializer::DeserializeDigitallySigned(serialized_sig, &signature);
+  if (result != DeserializeResult::OK)
+    return GetDeserializeSignatureError(result);
+
+  string serialized_sth;
+  SerializeResult serialize_result =
+      Serializer::SerializeV1STHSignatureInput(timestamp, tree_size, root_hash,
+                                               &serialized_sth);
+  if (serialize_result != SerializeResult::OK)
+    return GetSerializeError(serialize_result);
+  return ConvertStatus(Verify(serialized_sth, signature));
+}
+
+LogSigVerifier::VerifyResult LogSigVerifier::VerifySTHSignature(
+    const SignedTreeHead& sth) const {
+  if (sth.id().has_key_id() && sth.id().key_id() != KeyID())
+    return KEY_ID_MISMATCH;
+  string serialized_sth;
+  SerializeResult serialize_result =
+      Serializer::SerializeSTHSignatureInput(sth, &serialized_sth);
+  if (serialize_result != SerializeResult::OK)
+    return GetSerializeError(serialize_result);
+  return ConvertStatus(Verify(serialized_sth, sth.signature()));
+}
+
+// static
+LogSigVerifier::VerifyResult LogSigVerifier::GetSerializeError(
+    SerializeResult result) {
+  VerifyResult verify_result;
+  switch (result) {
+    case SerializeResult::INVALID_ENTRY_TYPE:
+      verify_result = INVALID_ENTRY_TYPE;
+      break;
+    case SerializeResult::EMPTY_CERTIFICATE:
+      verify_result = EMPTY_CERTIFICATE;
+      break;
+    case SerializeResult::CERTIFICATE_TOO_LONG:
+      verify_result = CERTIFICATE_TOO_LONG;
+      break;
+    case SerializeResult::INVALID_HASH_LENGTH:
+      verify_result = INVALID_HASH_LENGTH;
+      break;
+    case SerializeResult::UNSUPPORTED_VERSION:
+      verify_result = UNSUPPORTED_VERSION;
+      break;
+    case SerializeResult::EXTENSIONS_TOO_LONG:
+      verify_result = EXTENSIONS_TOO_LONG;
+      break;
+    default:
+      LOG(FATAL) << "Unexpected Serializer error code " << result;
+  }
+  return verify_result;
+}
+
+// static
+LogSigVerifier::VerifyResult LogSigVerifier::GetDeserializeSignatureError(
+    DeserializeResult result) {
+  VerifyResult verify_result;
+  switch (result) {
+    case DeserializeResult::INPUT_TOO_SHORT:
+      verify_result = SIGNATURE_TOO_SHORT;
+      break;
+    case DeserializeResult::INVALID_HASH_ALGORITHM:
+      verify_result = INVALID_HASH_ALGORITHM;
+      break;
+    case DeserializeResult::INVALID_SIGNATURE_ALGORITHM:
+      verify_result = INVALID_SIGNATURE_ALGORITHM;
+      break;
+    case DeserializeResult::INPUT_TOO_LONG:
+      verify_result = SIGNATURE_TOO_LONG;
+      break;
+    default:
+      LOG(FATAL) << "Unexpected Deserializer error code " << result;
+  }
+  return verify_result;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_signer.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_signer.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_signer.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_signer.h	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,114 @@
+#ifndef CERT_TRANS_LOG_LOG_SIGNER_H_
+#define CERT_TRANS_LOG_LOG_SIGNER_H_
+
+#include <openssl/evp.h>
+#include <openssl/x509.h>  // for i2d_PUBKEY
+#include <stdint.h>
+
+#include "log/signer.h"
+#include "log/verifier.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+
+class LogSigner : public cert_trans::Signer {
+ public:
+  explicit LogSigner(EVP_PKEY* pkey);
+  virtual ~LogSigner();
+
+  enum SignResult {
+    OK,
+    INVALID_ENTRY_TYPE,
+    EMPTY_CERTIFICATE,
+    CERTIFICATE_TOO_LONG,
+    INVALID_HASH_LENGTH,
+    UNSUPPORTED_VERSION,
+    EXTENSIONS_TOO_LONG,
+  };
+
+  // The protobuf-agnostic library version:
+  // sign the cert timestamp and return the result as a serialized
+  // signature string.
+  // In accordance with the spec, timestamp should be UTC time,
+  // since January 1, 1970, 00:00, in milliseconds.
+  SignResult SignV1CertificateTimestamp(uint64_t timestamp,
+                                        const std::string& leaf_certificate,
+                                        const std::string& extensions,
+                                        std::string* result) const;
+
+  SignResult SignV1PrecertificateTimestamp(uint64_t timestamp,
+                                           const std::string& issuer_key_hash,
+                                           const std::string& tbs_certificate,
+                                           const std::string& extensions,
+                                           std::string* result) const;
+
+  // Sign the cert timestamp and write the resulting DigitallySigned
+  // signature message into |sct|.
+  SignResult SignCertificateTimestamp(
+      const ct::LogEntry& entry, ct::SignedCertificateTimestamp* sct) const;
+
+  SignResult SignV1TreeHead(uint64_t timestamp, int64_t tree_size,
+                            const std::string& root_hash,
+                            std::string* result) const;
+
+  SignResult SignTreeHead(ct::SignedTreeHead* sth) const;
+
+ private:
+  static SignResult GetSerializeError(
+      cert_trans::serialization::SerializeResult result);
+};
+
+class LogSigVerifier : public cert_trans::Verifier {
+ public:
+  explicit LogSigVerifier(EVP_PKEY* pkey);
+  virtual ~LogSigVerifier();
+
+  enum VerifyResult {
+    OK,
+    INVALID_HASH_ALGORITHM,
+    INVALID_SIGNATURE_ALGORITHM,
+    SIGNATURE_TOO_SHORT,
+    SIGNATURE_TOO_LONG,
+    INVALID_ENTRY_TYPE,
+    EMPTY_CERTIFICATE,
+    CERTIFICATE_TOO_LONG,
+    HASH_ALGORITHM_MISMATCH,
+    SIGNATURE_ALGORITHM_MISMATCH,
+    INVALID_SIGNATURE,
+    INVALID_HASH_LENGTH,
+    UNSUPPORTED_VERSION,
+    EXTENSIONS_TOO_LONG,
+    KEY_ID_MISMATCH,
+  };
+
+  // The protobuf-agnostic library version.
+  VerifyResult VerifyV1CertSCTSignature(uint64_t timestamp,
+                                        const std::string& leaf_cert,
+                                        const std::string& extensions,
+                                        const std::string& signature) const;
+
+  VerifyResult VerifyV1PrecertSCTSignature(uint64_t timestamp,
+                                           const std::string& issuer_key_hash,
+                                           const std::string& tbs_cert,
+                                           const std::string& extensions,
+                                           const std::string& signature) const;
+
+  VerifyResult VerifySCTSignature(
+      const ct::LogEntry& entry,
+      const ct::SignedCertificateTimestamp& sct) const;
+
+  // The protobuf-agnostic library version.
+  VerifyResult VerifyV1STHSignature(uint64_t timestamp, int64_t tree_size,
+                                    const std::string& root_hash,
+                                    const std::string& signature) const;
+
+  VerifyResult VerifySTHSignature(const ct::SignedTreeHead& sth) const;
+
+ private:
+  static VerifyResult GetSerializeError(
+      cert_trans::serialization::SerializeResult result);
+
+  static VerifyResult GetDeserializeSignatureError(
+      cert_trans::serialization::DeserializeResult result);
+};
+
+#endif  // CERT_TRANS_LOG_LOG_SIGNER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_signer_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_signer_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_signer_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_signer_test.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,995 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <stdint.h>
+#include <string>
+
+#include "log/log_signer.h"
+#include "log/test_signer.h"
+#include "proto/cert_serializer.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+namespace {
+
+using cert_trans::serialization::SerializeResult;
+using cert_trans::serialization::DeserializeResult;
+using ct::LogEntry;
+using ct::SignedCertificateTimestamp;
+using ct::DigitallySigned;
+using ct::SignedTreeHead;
+using std::string;
+
+// A slightly shorter notation for constructing hex strings from binary blobs.
+string H(const string& byte_string) {
+  return util::HexString(byte_string);
+}
+
+class LogSignerTest : public ::testing::Test {
+ protected:
+  LogSignerTest() : signer_(NULL), verifier_(NULL) {
+  }
+
+  void SetUp() {
+    signer_ = TestSigner::DefaultLogSigner();
+    verifier_ = TestSigner::DefaultLogSigVerifier();
+  }
+
+  ~LogSignerTest() {
+    delete signer_;
+    delete verifier_;
+  }
+
+  static string SerializedSignature(const DigitallySigned& signature) {
+    string serialized_sig;
+    CHECK_EQ(SerializeResult::OK,
+             Serializer::SerializeDigitallySigned(signature, &serialized_sig));
+    return serialized_sig;
+  }
+
+  LogSigner* signer_;
+  LogSigVerifier* verifier_;
+  TestSigner test_signer_;
+};
+
+TEST_F(LogSignerTest, KeyIDKatTest) {
+  SignedCertificateTimestamp default_sct;
+  TestSigner::SetDefaults(&default_sct);
+  EXPECT_EQ(signer_->KeyID(), default_sct.id().key_id());
+  EXPECT_EQ(verifier_->KeyID(), default_sct.id().key_id());
+}
+
+TEST_F(LogSignerTest, VerifyCertSCTKatTest) {
+  LogEntry default_entry;
+  TestSigner::SetDefaults(&default_entry);
+
+  SignedCertificateTimestamp default_sct;
+  TestSigner::SetDefaults(&default_sct);
+
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, default_sct));
+
+  CHECK_EQ(default_entry.type(), ct::X509_ENTRY);
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1CertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.x509_entry().leaf_certificate(),
+                default_sct.extensions(),
+                SerializedSignature(default_sct.signature())));
+}
+
+TEST_F(LogSignerTest, VerifyPrecertSCTKatTest) {
+  LogEntry default_entry;
+  TestSigner::SetPrecertDefaults(&default_entry);
+
+  SignedCertificateTimestamp default_sct;
+  TestSigner::SetPrecertDefaults(&default_sct);
+
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, default_sct));
+
+  CHECK_EQ(default_entry.type(), ct::PRECERT_ENTRY);
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1PrecertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.precert_entry().pre_cert().issuer_key_hash(),
+                default_entry.precert_entry().pre_cert().tbs_certificate(),
+                default_sct.extensions(),
+                SerializedSignature(default_sct.signature())));
+}
+
+TEST_F(LogSignerTest, VerifySTHKatTest) {
+  SignedTreeHead default_sth;
+  TestSigner::SetDefaults(&default_sth);
+
+  EXPECT_EQ(LogSigVerifier::OK, verifier_->VerifySTHSignature(default_sth));
+
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1STHSignature(
+                default_sth.timestamp(), default_sth.tree_size(),
+                default_sth.sha256_root_hash(),
+                SerializedSignature(default_sth.signature())));
+}
+
+TEST_F(LogSignerTest, SignAndVerifyCertSCT) {
+  LogEntry default_entry;
+  TestSigner::SetDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct;
+  TestSigner::SetDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  sct.clear_signature();
+  ASSERT_FALSE(sct.has_signature());
+
+  EXPECT_EQ(LogSigner::OK,
+            signer_->SignCertificateTimestamp(default_entry, &sct));
+  EXPECT_TRUE(sct.has_signature());
+  EXPECT_EQ(default_sct.signature().hash_algorithm(),
+            sct.signature().hash_algorithm());
+  EXPECT_EQ(default_sct.signature().sig_algorithm(),
+            sct.signature().sig_algorithm());
+  // We should get a fresh signature.
+  EXPECT_NE(H(default_sct.signature().signature()),
+            H(sct.signature().signature()));
+  // But it should still be valid.
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  // The second version.
+  CHECK_EQ(default_entry.type(), ct::X509_ENTRY);
+  string serialized_sig;
+  EXPECT_EQ(LogSigner::OK, signer_->SignV1CertificateTimestamp(
+                               default_sct.timestamp(),
+                               default_entry.x509_entry().leaf_certificate(),
+                               default_sct.extensions(), &serialized_sig));
+
+  string default_serialized_sig = SerializedSignature(default_sct.signature());
+  EXPECT_NE(H(default_serialized_sig), H(serialized_sig));
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1CertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.x509_entry().leaf_certificate(),
+                default_sct.extensions(), serialized_sig));
+}
+
+TEST_F(LogSignerTest, SignAndVerifyPrecertSCT) {
+  LogEntry default_entry;
+  TestSigner::SetPrecertDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct;
+  TestSigner::SetPrecertDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  sct.clear_signature();
+  ASSERT_FALSE(sct.has_signature());
+
+  EXPECT_EQ(LogSigner::OK,
+            signer_->SignCertificateTimestamp(default_entry, &sct));
+  EXPECT_TRUE(sct.has_signature());
+  EXPECT_EQ(default_sct.signature().hash_algorithm(),
+            sct.signature().hash_algorithm());
+  EXPECT_EQ(default_sct.signature().sig_algorithm(),
+            sct.signature().sig_algorithm());
+  // We should get a fresh signature.
+  EXPECT_NE(H(default_sct.signature().signature()),
+            H(sct.signature().signature()));
+  // But it should still be valid.
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  // The second version.
+  CHECK_EQ(default_entry.type(), ct::PRECERT_ENTRY);
+  string serialized_sig;
+  EXPECT_EQ(LogSigner::OK,
+            signer_->SignV1PrecertificateTimestamp(
+                default_sct.timestamp(),
+                default_entry.precert_entry().pre_cert().issuer_key_hash(),
+                default_entry.precert_entry().pre_cert().tbs_certificate(),
+                default_sct.extensions(), &serialized_sig));
+
+  string default_serialized_sig = SerializedSignature(default_sct.signature());
+  EXPECT_NE(H(default_serialized_sig), H(serialized_sig));
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1PrecertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.precert_entry().pre_cert().issuer_key_hash(),
+                default_entry.precert_entry().pre_cert().tbs_certificate(),
+                default_sct.extensions(), serialized_sig));
+}
+
+TEST_F(LogSignerTest, SignAndVerifySTH) {
+  SignedTreeHead default_sth, sth;
+  TestSigner::SetDefaults(&default_sth);
+  sth.CopyFrom(default_sth);
+  sth.clear_signature();
+  ASSERT_FALSE(sth.has_signature());
+
+  EXPECT_EQ(LogSigner::OK, signer_->SignTreeHead(&sth));
+  EXPECT_TRUE(sth.has_signature());
+  EXPECT_EQ(default_sth.signature().hash_algorithm(),
+            sth.signature().hash_algorithm());
+  EXPECT_EQ(default_sth.signature().sig_algorithm(),
+            sth.signature().sig_algorithm());
+  // We should get a fresh signature.
+  EXPECT_NE(H(default_sth.signature().signature()),
+            H(sth.signature().signature()));
+  // But it should still be valid.
+  EXPECT_EQ(LogSigVerifier::OK, verifier_->VerifySTHSignature(sth));
+
+  // The second version.
+  string serialized_sig;
+  EXPECT_EQ(LogSigner::OK,
+            signer_->SignV1TreeHead(default_sth.timestamp(),
+                                    default_sth.tree_size(),
+                                    default_sth.sha256_root_hash(),
+                                    &serialized_sig));
+
+  string default_serialized_sig = SerializedSignature(default_sth.signature());
+  EXPECT_NE(H(default_serialized_sig), H(serialized_sig));
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1STHSignature(default_sth.timestamp(),
+                                            default_sth.tree_size(),
+                                            default_sth.sha256_root_hash(),
+                                            default_serialized_sig));
+}
+
+TEST_F(LogSignerTest, SignAndVerifyCertSCTApiCrossCheck) {
+  LogEntry default_entry;
+  TestSigner::SetDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct;
+  TestSigner::SetDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  sct.clear_signature();
+
+  EXPECT_EQ(LogSigner::OK,
+            signer_->SignCertificateTimestamp(default_entry, &sct));
+
+  // Serialize and verify.
+  string serialized_sig;
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeDigitallySigned(sct.signature(),
+                                                 &serialized_sig));
+
+  CHECK_EQ(default_entry.type(), ct::X509_ENTRY);
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1CertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.x509_entry().leaf_certificate(),
+                default_sct.extensions(), serialized_sig));
+
+  // The second version.
+  serialized_sig.clear();
+  EXPECT_EQ(LogSigner::OK, signer_->SignV1CertificateTimestamp(
+                               default_sct.timestamp(),
+                               default_entry.x509_entry().leaf_certificate(),
+                               default_sct.extensions(), &serialized_sig));
+
+  // Deserialize and verify.
+  sct.clear_signature();
+  EXPECT_EQ(DeserializeResult::OK,
+            Deserializer::DeserializeDigitallySigned(serialized_sig,
+                                                     sct.mutable_signature()));
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct));
+}
+
+TEST_F(LogSignerTest, SignAndVerifyPrecertSCTApiCrossCheck) {
+  LogEntry default_entry;
+  TestSigner::SetPrecertDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct;
+  TestSigner::SetPrecertDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  sct.clear_signature();
+
+  EXPECT_EQ(LogSigner::OK,
+            signer_->SignCertificateTimestamp(default_entry, &sct));
+
+  // Serialize and verify.
+  string serialized_sig;
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeDigitallySigned(sct.signature(),
+                                                 &serialized_sig));
+
+  CHECK_EQ(default_entry.type(), ct::PRECERT_ENTRY);
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1PrecertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.precert_entry().pre_cert().issuer_key_hash(),
+                default_entry.precert_entry().pre_cert().tbs_certificate(),
+                default_sct.extensions(), serialized_sig));
+
+  // The second version.
+  serialized_sig.clear();
+  EXPECT_EQ(LogSigner::OK,
+            signer_->SignV1PrecertificateTimestamp(
+                default_sct.timestamp(),
+                default_entry.precert_entry().pre_cert().issuer_key_hash(),
+                default_entry.precert_entry().pre_cert().tbs_certificate(),
+                default_sct.extensions(), &serialized_sig));
+
+  // Deserialize and verify.
+  sct.clear_signature();
+  EXPECT_EQ(DeserializeResult::OK,
+            Deserializer::DeserializeDigitallySigned(serialized_sig,
+                                                     sct.mutable_signature()));
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct));
+}
+
+TEST_F(LogSignerTest, SignAndVerifySTHApiCrossCheck) {
+  SignedTreeHead default_sth, sth;
+  TestSigner::SetDefaults(&default_sth);
+  sth.CopyFrom(default_sth);
+  sth.clear_signature();
+
+  EXPECT_EQ(LogSigner::OK, signer_->SignTreeHead(&sth));
+
+  // Serialize and verify.
+  string serialized_sig;
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeDigitallySigned(sth.signature(),
+                                                 &serialized_sig));
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1STHSignature(default_sth.timestamp(),
+                                            default_sth.tree_size(),
+                                            default_sth.sha256_root_hash(),
+                                            serialized_sig));
+
+  // The second version.
+  serialized_sig.clear();
+  EXPECT_EQ(LogSigner::OK,
+            signer_->SignV1TreeHead(default_sth.timestamp(),
+                                    default_sth.tree_size(),
+                                    default_sth.sha256_root_hash(),
+                                    &serialized_sig));
+
+  // Deserialize and verify.
+  sth.clear_signature();
+  EXPECT_EQ(DeserializeResult::OK,
+            Deserializer::DeserializeDigitallySigned(serialized_sig,
+                                                     sth.mutable_signature()));
+  EXPECT_EQ(LogSigVerifier::OK, verifier_->VerifySTHSignature(sth));
+}
+
+TEST_F(LogSignerTest, SignInvalidType) {
+  LogEntry default_entry, entry;
+  TestSigner::SetDefaults(&default_entry);
+
+  entry.CopyFrom(default_entry);
+  entry.set_type(ct::UNKNOWN_ENTRY_TYPE);
+  SignedCertificateTimestamp default_sct, sct;
+  TestSigner::SetDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  sct.clear_signature();
+
+  string serialized_sig;
+  EXPECT_EQ(LogSigner::INVALID_ENTRY_TYPE,
+            signer_->SignCertificateTimestamp(entry, &sct));
+}
+
+TEST_F(LogSignerTest, SignEmptyCert) {
+  LogEntry default_entry;
+  TestSigner::SetDefaults(&default_entry);
+
+  CHECK_EQ(ct::X509_ENTRY, default_entry.type());
+  LogEntry entry;
+  entry.CopyFrom(default_entry);
+  entry.mutable_x509_entry()->clear_leaf_certificate();
+
+  SignedCertificateTimestamp default_sct, sct;
+  TestSigner::SetDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  sct.clear_signature();
+
+  EXPECT_EQ(LogSigner::EMPTY_CERTIFICATE,
+            signer_->SignCertificateTimestamp(entry, &sct));
+
+  string serialized_sig;
+  string empty_cert;
+  EXPECT_EQ(LogSigner::EMPTY_CERTIFICATE,
+            signer_->SignV1CertificateTimestamp(default_sct.timestamp(),
+                                                empty_cert,
+                                                default_sct.extensions(),
+                                                &serialized_sig));
+}
+
+TEST_F(LogSignerTest, SignEmptyPreCert) {
+  LogEntry default_entry;
+  TestSigner::SetPrecertDefaults(&default_entry);
+
+  CHECK_EQ(ct::PRECERT_ENTRY, default_entry.type());
+  LogEntry entry;
+  entry.CopyFrom(default_entry);
+  entry.mutable_precert_entry()->mutable_pre_cert()->clear_tbs_certificate();
+
+  SignedCertificateTimestamp default_sct, sct;
+  TestSigner::SetPrecertDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  sct.clear_signature();
+
+  EXPECT_EQ(LogSigner::EMPTY_CERTIFICATE,
+            signer_->SignCertificateTimestamp(entry, &sct));
+
+  string serialized_sig;
+  string empty_cert;
+  EXPECT_EQ(LogSigner::EMPTY_CERTIFICATE,
+            signer_->SignV1PrecertificateTimestamp(
+                default_sct.timestamp(),
+                default_entry.precert_entry().pre_cert().issuer_key_hash(),
+                empty_cert, default_sct.extensions(), &serialized_sig));
+}
+
+TEST_F(LogSignerTest, SignInvalidIssuerKeyHash) {
+  LogEntry default_entry;
+  TestSigner::SetPrecertDefaults(&default_entry);
+
+  CHECK_EQ(ct::PRECERT_ENTRY, default_entry.type());
+  LogEntry entry;
+  entry.CopyFrom(default_entry);
+  entry.mutable_precert_entry()->mutable_pre_cert()->clear_issuer_key_hash();
+
+  SignedCertificateTimestamp default_sct, sct;
+  TestSigner::SetPrecertDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  sct.clear_signature();
+
+  EXPECT_EQ(LogSigner::INVALID_HASH_LENGTH,
+            signer_->SignCertificateTimestamp(entry, &sct));
+
+  string serialized_sig;
+  string bad_hash("too short");
+  EXPECT_EQ(LogSigner::INVALID_HASH_LENGTH,
+            signer_->SignV1PrecertificateTimestamp(
+                default_sct.timestamp(), bad_hash,
+                default_entry.precert_entry().pre_cert().tbs_certificate(),
+                default_sct.extensions(), &serialized_sig));
+}
+
+TEST_F(LogSignerTest, SignBadRootHash) {
+  SignedTreeHead default_sth, sth;
+  TestSigner::SetDefaults(&default_sth);
+  sth.CopyFrom(default_sth);
+  sth.clear_signature();
+  sth.set_sha256_root_hash("bad");
+
+  EXPECT_EQ(LogSigner::INVALID_HASH_LENGTH, signer_->SignTreeHead(&sth));
+
+  string serialized_sig;
+  EXPECT_EQ(LogSigner::INVALID_HASH_LENGTH,
+            signer_->SignV1TreeHead(default_sth.timestamp(),
+                                    default_sth.tree_size(), "bad",
+                                    &serialized_sig));
+}
+
+TEST_F(LogSignerTest, VerifyChangeCertSCTTimestamp) {
+  LogEntry default_entry;
+  TestSigner::SetDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct;
+  TestSigner::SetDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  uint64_t new_timestamp = default_sct.timestamp() + 1000;
+
+  sct.set_timestamp(new_timestamp);
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  CHECK_EQ(ct::X509_ENTRY, default_entry.type());
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1CertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.x509_entry().leaf_certificate(),
+                default_sct.extensions(),
+                SerializedSignature(default_sct.signature())));
+
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifyV1CertSCTSignature(
+                new_timestamp, default_entry.x509_entry().leaf_certificate(),
+                default_sct.extensions(),
+                SerializedSignature(default_sct.signature())));
+}
+
+TEST_F(LogSignerTest, VerifyChangePrecertSCTTimestamp) {
+  LogEntry default_entry;
+  TestSigner::SetPrecertDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct;
+  TestSigner::SetPrecertDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  uint64_t new_timestamp = default_sct.timestamp() + 1000;
+
+  sct.set_timestamp(new_timestamp);
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  CHECK_EQ(ct::PRECERT_ENTRY, default_entry.type());
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1PrecertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.precert_entry().pre_cert().issuer_key_hash(),
+                default_entry.precert_entry().pre_cert().tbs_certificate(),
+                default_sct.extensions(),
+                SerializedSignature(default_sct.signature())));
+
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifyV1PrecertSCTSignature(
+                new_timestamp,
+                default_entry.precert_entry().pre_cert().issuer_key_hash(),
+                default_entry.precert_entry().pre_cert().tbs_certificate(),
+                default_sct.extensions(),
+                SerializedSignature(default_sct.signature())));
+}
+
+TEST_F(LogSignerTest, VerifyChangeSTHTimestamp) {
+  SignedTreeHead default_sth, sth;
+  TestSigner::SetDefaults(&default_sth);
+  sth.CopyFrom(default_sth);
+  EXPECT_EQ(LogSigVerifier::OK, verifier_->VerifySTHSignature(sth));
+
+  uint64_t new_timestamp = default_sth.timestamp() + 1000;
+  sth.set_timestamp(new_timestamp);
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifySTHSignature(sth));
+
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1STHSignature(
+                default_sth.timestamp(), default_sth.tree_size(),
+                default_sth.sha256_root_hash(),
+                SerializedSignature(default_sth.signature())));
+
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifyV1STHSignature(
+                new_timestamp, default_sth.tree_size(),
+                default_sth.sha256_root_hash(),
+                SerializedSignature(default_sth.signature())));
+}
+
+TEST_F(LogSignerTest, VerifyChangeCert) {
+  LogEntry default_entry;
+  TestSigner::SetDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct, sct2;
+  TestSigner::SetDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  CHECK_EQ(ct::X509_ENTRY, default_entry.type());
+  LogEntry entry;
+  entry.CopyFrom(default_entry);
+  string new_cert = test_signer_.UniqueFakeCertBytestring();
+  entry.mutable_x509_entry()->set_leaf_certificate(new_cert);
+
+  // Check that we can successfully sign and verify the new sct.
+  sct2.CopyFrom(sct);
+  EXPECT_EQ(LogSigner::OK, signer_->SignCertificateTimestamp(entry, &sct2));
+  EXPECT_EQ(LogSigVerifier::OK, verifier_->VerifySCTSignature(entry, sct2));
+
+  // We should not be able to verify the new cert with the old signature.
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifySCTSignature(entry, sct));
+
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1CertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.x509_entry().leaf_certificate(),
+                default_sct.extensions(),
+                SerializedSignature(default_sct.signature())));
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifyV1CertSCTSignature(
+                default_sct.timestamp(), new_cert, default_sct.extensions(),
+                SerializedSignature(default_sct.signature())));
+}
+
+TEST_F(LogSignerTest, VerifyChangePrecert) {
+  LogEntry default_entry;
+  TestSigner::SetPrecertDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct, sct2;
+  TestSigner::SetPrecertDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  CHECK_EQ(ct::PRECERT_ENTRY, default_entry.type());
+  LogEntry entry;
+  entry.CopyFrom(default_entry);
+  string new_cert = test_signer_.UniqueFakeCertBytestring();
+  entry.mutable_precert_entry()->mutable_pre_cert()->set_tbs_certificate(
+      new_cert);
+
+  // Check that we can successfully sign and verify the new sct.
+  sct2.CopyFrom(sct);
+  EXPECT_EQ(LogSigner::OK, signer_->SignCertificateTimestamp(entry, &sct2));
+  EXPECT_EQ(LogSigVerifier::OK, verifier_->VerifySCTSignature(entry, sct2));
+
+  // We should not be able to verify the new cert with the old signature.
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifySCTSignature(entry, sct));
+
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1PrecertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.precert_entry().pre_cert().issuer_key_hash(),
+                default_entry.precert_entry().pre_cert().tbs_certificate(),
+                default_sct.extensions(),
+                SerializedSignature(default_sct.signature())));
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifyV1PrecertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.precert_entry().pre_cert().issuer_key_hash(),
+                new_cert, default_sct.extensions(),
+                SerializedSignature(default_sct.signature())));
+}
+
+TEST_F(LogSignerTest, VerifyChangeIssuerKeyHash) {
+  LogEntry default_entry;
+  TestSigner::SetPrecertDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct, sct2;
+  TestSigner::SetPrecertDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  CHECK_EQ(ct::PRECERT_ENTRY, default_entry.type());
+  LogEntry entry;
+  entry.CopyFrom(default_entry);
+  string new_hash = test_signer_.UniqueHash();
+  entry.mutable_precert_entry()->mutable_pre_cert()->set_issuer_key_hash(
+      new_hash);
+
+  // Check that we can successfully sign and verify the new sct.
+  sct2.CopyFrom(sct);
+  EXPECT_EQ(LogSigner::OK, signer_->SignCertificateTimestamp(entry, &sct2));
+  EXPECT_EQ(LogSigVerifier::OK, verifier_->VerifySCTSignature(entry, sct2));
+
+  // We should not be able to verify the new cert with the old signature.
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifySCTSignature(entry, sct));
+
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1PrecertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.precert_entry().pre_cert().issuer_key_hash(),
+                default_entry.precert_entry().pre_cert().tbs_certificate(),
+                default_sct.extensions(),
+                SerializedSignature(default_sct.signature())));
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifyV1PrecertSCTSignature(
+                default_sct.timestamp(), new_hash,
+                default_entry.precert_entry().pre_cert().tbs_certificate(),
+                default_sct.extensions(),
+                SerializedSignature(default_sct.signature())));
+}
+
+TEST_F(LogSignerTest, VerifyChangeCertExtensions) {
+  LogEntry default_entry;
+  TestSigner::SetDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct, sct2;
+  TestSigner::SetDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1CertSCTSignature(
+                sct.timestamp(), default_entry.x509_entry().leaf_certificate(),
+                sct.extensions(), SerializedSignature(sct.signature())));
+
+  sct.set_extensions("hello");
+  // Check that we can successfully sign and verify the new sct.
+  sct2.CopyFrom(sct);
+  EXPECT_EQ(LogSigner::OK,
+            signer_->SignCertificateTimestamp(default_entry, &sct2));
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct2));
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1CertSCTSignature(
+                sct2.timestamp(),
+                default_entry.x509_entry().leaf_certificate(),
+                sct2.extensions(), SerializedSignature(sct2.signature())));
+
+  // We should not be able to verify the new data with the old signature.
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifyV1CertSCTSignature(
+                sct.timestamp(), default_entry.x509_entry().leaf_certificate(),
+                sct.extensions(), SerializedSignature(sct.signature())));
+}
+
+TEST_F(LogSignerTest, VerifyChangePrecertExtensions) {
+  LogEntry default_entry;
+  TestSigner::SetPrecertDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct, sct2;
+  TestSigner::SetPrecertDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1PrecertSCTSignature(
+                sct.timestamp(),
+                default_entry.precert_entry().pre_cert().issuer_key_hash(),
+                default_entry.precert_entry().pre_cert().tbs_certificate(),
+                sct.extensions(), SerializedSignature(sct.signature())));
+
+  sct.set_extensions("hello");
+  // Check that we can successfully sign and verify the new sct.
+  sct2.CopyFrom(sct);
+  EXPECT_EQ(LogSigner::OK,
+            signer_->SignCertificateTimestamp(default_entry, &sct2));
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct2));
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1PrecertSCTSignature(
+                sct2.timestamp(),
+                default_entry.precert_entry().pre_cert().issuer_key_hash(),
+                default_entry.precert_entry().pre_cert().tbs_certificate(),
+                sct2.extensions(), SerializedSignature(sct2.signature())));
+
+  // We should not be able to verify the new data with the old signature.
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifyV1PrecertSCTSignature(
+                sct.timestamp(),
+                default_entry.precert_entry().pre_cert().issuer_key_hash(),
+                default_entry.precert_entry().pre_cert().tbs_certificate(),
+                sct.extensions(), SerializedSignature(sct.signature())));
+}
+
+TEST_F(LogSignerTest, VerifyChangeTreeSize) {
+  SignedTreeHead default_sth, sth;
+  TestSigner::SetDefaults(&default_sth);
+  sth.CopyFrom(default_sth);
+  EXPECT_EQ(LogSigVerifier::OK, verifier_->VerifySTHSignature(sth));
+
+  ASSERT_GE(default_sth.tree_size(), 0);
+  int64_t new_tree_size = default_sth.tree_size() + 1;
+  ASSERT_GE(new_tree_size, 0);
+  sth.set_tree_size(new_tree_size);
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifySTHSignature(sth));
+
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1STHSignature(
+                default_sth.timestamp(), default_sth.tree_size(),
+                default_sth.sha256_root_hash(),
+                SerializedSignature(default_sth.signature())));
+
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifyV1STHSignature(
+                default_sth.timestamp(), new_tree_size,
+                default_sth.sha256_root_hash(),
+                SerializedSignature(default_sth.signature())));
+}
+
+TEST_F(LogSignerTest, VerifySCTBadHashAlgorithm) {
+  LogEntry default_entry;
+  TestSigner::SetDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct;
+  TestSigner::SetDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  CHECK_NE(DigitallySigned::SHA224, sct.signature().hash_algorithm());
+  sct.mutable_signature()->set_hash_algorithm(DigitallySigned::SHA224);
+  EXPECT_EQ(LogSigVerifier::HASH_ALGORITHM_MISMATCH,
+            verifier_->VerifySCTSignature(default_entry, sct));
+}
+
+TEST_F(LogSignerTest, VerifySTHBadHashAlgorithm) {
+  SignedTreeHead default_sth, sth;
+  TestSigner::SetDefaults(&default_sth);
+  sth.CopyFrom(default_sth);
+  EXPECT_EQ(LogSigVerifier::OK, verifier_->VerifySTHSignature(sth));
+
+  CHECK_NE(DigitallySigned::SHA224, sth.signature().hash_algorithm());
+  sth.mutable_signature()->set_hash_algorithm(DigitallySigned::SHA224);
+  EXPECT_EQ(LogSigVerifier::HASH_ALGORITHM_MISMATCH,
+            verifier_->VerifySTHSignature(sth));
+}
+
+TEST_F(LogSignerTest, VerifySCTBadSignatureAlgorithm) {
+  LogEntry default_entry;
+  TestSigner::SetDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct;
+  TestSigner::SetDefaults(&default_sct);
+  sct.CopyFrom(default_sct);
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  CHECK_NE(DigitallySigned::DSA, sct.signature().sig_algorithm());
+  sct.mutable_signature()->set_sig_algorithm(DigitallySigned::DSA);
+  EXPECT_EQ(LogSigVerifier::SIGNATURE_ALGORITHM_MISMATCH,
+            verifier_->VerifySCTSignature(default_entry, sct));
+}
+
+TEST_F(LogSignerTest, VerifySTHBadSignatureAlgorithm) {
+  SignedTreeHead default_sth, sth;
+  TestSigner::SetDefaults(&default_sth);
+  sth.CopyFrom(default_sth);
+  EXPECT_EQ(LogSigVerifier::OK, verifier_->VerifySTHSignature(sth));
+
+  CHECK_NE(DigitallySigned::DSA, sth.signature().sig_algorithm());
+  sth.mutable_signature()->set_sig_algorithm(DigitallySigned::DSA);
+  EXPECT_EQ(LogSigVerifier::SIGNATURE_ALGORITHM_MISMATCH,
+            verifier_->VerifySTHSignature(sth));
+}
+
+TEST_F(LogSignerTest, VerifyBadSCTSignature) {
+  LogEntry default_entry;
+  TestSigner::SetDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct;
+  TestSigner::SetDefaults(&default_sct);
+  // Too short.
+  sct.CopyFrom(default_sct);
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  string bad_signature = default_sct.signature().signature();
+  bad_signature.erase(bad_signature.end() - 1);
+  sct.mutable_signature()->set_signature(bad_signature);
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifySCTSignature(default_entry, sct));
+
+  // Too long.
+  // OpenSSL ECDSA Verify parses *up to* a given number of bytes,
+  // rather than exactly the given number of bytes, and hence appending
+  // garbage in the end still results in a valid signature.
+  // sct.CopyFrom(default_sct);
+  // EXPECT_EQ(LogSigVerifier::OK, verifier_->VerifySCTSignature(sct));
+
+  // bad_signature = default_sct.signature().signature();
+  // bad_signature.push_back(0x42);
+
+  // sct.mutable_signature()->set_signature(bad_signature);
+  // EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+  // verifier_->VerifySCTSignature(sct));
+
+  // Flip the lsb of each byte one by one.
+  for (size_t i = 0; i < default_sct.signature().signature().size(); ++i) {
+    sct.CopyFrom(default_sct);
+    EXPECT_EQ(LogSigVerifier::OK,
+              verifier_->VerifySCTSignature(default_entry, sct));
+
+    bad_signature = default_sct.signature().signature();
+    bad_signature[i] ^= 0x01;
+    sct.mutable_signature()->set_signature(bad_signature);
+    EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+              verifier_->VerifySCTSignature(default_entry, sct));
+  }
+}
+
+TEST_F(LogSignerTest, VerifyBadSTHSignature) {
+  SignedTreeHead default_sth, sth;
+  TestSigner::SetDefaults(&default_sth);
+  // Too short.
+  sth.CopyFrom(default_sth);
+  EXPECT_EQ(LogSigVerifier::OK, verifier_->VerifySTHSignature(sth));
+
+  string bad_signature = default_sth.signature().signature();
+  bad_signature.erase(bad_signature.end() - 1);
+  sth.mutable_signature()->set_signature(bad_signature);
+  EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+            verifier_->VerifySTHSignature(sth));
+
+  // Too long.
+  // OpenSSL ECDSA Verify parses *up to* a given number of bytes,
+  // rather than exactly the given number of bytes, and hence appending
+  // garbage in the end still results in a valid signature.
+  // sth.CopyFrom(default_sth);
+  // EXPECT_EQ(LogSigVerifier::OK, verifier_->VerifySTHSignature(sth));
+
+  // bad_signature = default_sth.signature().signature();
+  // bad_signature.push_back(0x42);
+
+  // sth.mutable_signature()->set_signature(bad_signature);
+  // EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+  // verifier_->VerifySTHSignature(sth));
+
+  // Flip the lsb of each byte one by one.
+  for (size_t i = 0; i < default_sth.signature().signature().size(); ++i) {
+    sth.CopyFrom(default_sth);
+    EXPECT_EQ(LogSigVerifier::OK, verifier_->VerifySTHSignature(sth));
+
+    bad_signature = default_sth.signature().signature();
+    bad_signature[i] ^= 0x01;
+    sth.mutable_signature()->set_signature(bad_signature);
+    EXPECT_EQ(LogSigVerifier::INVALID_SIGNATURE,
+              verifier_->VerifySTHSignature(sth));
+  }
+}
+
+TEST_F(LogSignerTest, VerifyBadSerializedSCTSignature) {
+  LogEntry default_entry;
+  TestSigner::SetDefaults(&default_entry);
+  SignedCertificateTimestamp default_sct, sct;
+  TestSigner::SetDefaults(&default_sct);
+  string serialized_sig = SerializedSignature(default_sct.signature());
+
+  CHECK_EQ(ct::X509_ENTRY, default_entry.type());
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1CertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.x509_entry().leaf_certificate(),
+                default_sct.extensions(), serialized_sig));
+  // Too short.
+  string bad_signature = serialized_sig.substr(0, serialized_sig.size() - 1);
+  EXPECT_EQ(LogSigVerifier::SIGNATURE_TOO_SHORT,
+            verifier_->VerifyV1CertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.x509_entry().leaf_certificate(),
+                default_sct.extensions(), bad_signature));
+  // Too long.
+  bad_signature = serialized_sig;
+  bad_signature.push_back(0x42);
+  EXPECT_EQ(LogSigVerifier::SIGNATURE_TOO_LONG,
+            verifier_->VerifyV1CertSCTSignature(
+                default_sct.timestamp(),
+                default_entry.x509_entry().leaf_certificate(),
+                default_sct.extensions(), bad_signature));
+
+  // Flip the lsb of each byte one by one.
+  for (size_t i = 0; i < serialized_sig.size(); ++i) {
+    bad_signature = serialized_sig;
+    bad_signature[i] ^= 0x01;
+    // Error codes vary, depending on which byte was flipped.
+    EXPECT_NE(LogSigVerifier::OK,
+              verifier_->VerifyV1CertSCTSignature(
+                  default_sct.timestamp(),
+                  default_entry.x509_entry().leaf_certificate(),
+                  default_sct.extensions(), bad_signature));
+  }
+}
+
+TEST_F(LogSignerTest, VerifyBadSerializedSTHSignature) {
+  SignedTreeHead default_sth, sth;
+  TestSigner::SetDefaults(&default_sth);
+  string serialized_sig = SerializedSignature(default_sth.signature());
+  EXPECT_EQ(LogSigVerifier::OK,
+            verifier_->VerifyV1STHSignature(default_sth.timestamp(),
+                                            default_sth.tree_size(),
+                                            default_sth.sha256_root_hash(),
+                                            serialized_sig));
+  // Too short.
+  string bad_signature = serialized_sig.substr(0, serialized_sig.size() - 1);
+  EXPECT_EQ(LogSigVerifier::SIGNATURE_TOO_SHORT,
+            verifier_->VerifyV1STHSignature(default_sth.timestamp(),
+                                            default_sth.tree_size(),
+                                            default_sth.sha256_root_hash(),
+                                            bad_signature));
+  // Too long.
+  bad_signature = serialized_sig;
+  bad_signature.push_back(0x42);
+  EXPECT_EQ(LogSigVerifier::SIGNATURE_TOO_LONG,
+            verifier_->VerifyV1STHSignature(default_sth.timestamp(),
+                                            default_sth.tree_size(),
+                                            default_sth.sha256_root_hash(),
+                                            bad_signature));
+
+  // Flip the lsb of each byte one by one.
+  for (size_t i = 0; i < serialized_sig.size(); ++i) {
+    bad_signature = serialized_sig;
+    bad_signature[i] ^= 0x01;
+    // Error codes vary, depending on which byte was flipped.
+    EXPECT_NE(LogSigVerifier::OK,
+              verifier_->VerifyV1STHSignature(default_sth.timestamp(),
+                                              default_sth.tree_size(),
+                                              default_sth.sha256_root_hash(),
+                                              bad_signature));
+  }
+}
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  ConfigureSerializerForV1CT();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_verifier.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_verifier.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_verifier.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_verifier.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,129 @@
+#include "log/log_verifier.h"
+
+#include <glog/logging.h>
+#include <stdint.h>
+
+#include "log/cert_submission_handler.h"
+#include "log/log_signer.h"
+#include "merkletree/merkle_verifier.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+#include "util/util.h"
+
+using cert_trans::serialization::SerializeResult;
+using ct::LogEntry;
+using ct::MerkleAuditProof;
+using ct::SignedCertificateTimestamp;
+using ct::SignedTreeHead;
+using std::string;
+
+LogVerifier::LogVerifier(LogSigVerifier* sig_verifier,
+                         MerkleVerifier* merkle_verifier)
+    : sig_verifier_(sig_verifier), merkle_verifier_(merkle_verifier) {
+}
+
+LogVerifier::~LogVerifier() {
+  delete sig_verifier_;
+  delete merkle_verifier_;
+}
+
+LogVerifier::LogVerifyResult LogVerifier::VerifySignedCertificateTimestamp(
+    const LogEntry& entry, const SignedCertificateTimestamp& sct,
+    uint64_t begin_range, uint64_t end_range, string* merkle_leaf_hash) const {
+  if (!IsBetween(sct.timestamp(), begin_range, end_range))
+    return INVALID_TIMESTAMP;
+
+  // TODO(ekasper): separate format and signature errors.
+  if (sig_verifier_->VerifySCTSignature(entry, sct) != LogSigVerifier::OK)
+    return INVALID_SIGNATURE;
+  string serialized_leaf;
+  // If SCT verification succeeded, then we should never fail here.
+  if (merkle_leaf_hash != NULL) {
+    CHECK_EQ(SerializeResult::OK,
+             Serializer::SerializeSCTMerkleTreeLeaf(sct, entry,
+                                                    &serialized_leaf));
+    merkle_leaf_hash->assign(merkle_verifier_->LeafHash(serialized_leaf));
+  }
+  return VERIFY_OK;
+}
+
+LogVerifier::LogVerifyResult LogVerifier::VerifySignedCertificateTimestamp(
+    const LogEntry& entry, const SignedCertificateTimestamp& sct,
+    string* merkle_leaf_hash) const {
+  // Allow a bit of slack, say 1 second into the future.
+  return VerifySignedCertificateTimestamp(entry, sct, 0,
+                                          util::TimeInMilliseconds() + 1000,
+                                          merkle_leaf_hash);
+}
+
+LogVerifier::LogVerifyResult LogVerifier::VerifySignedTreeHead(
+    const SignedTreeHead& sth, uint64_t begin_range,
+    uint64_t end_range) const {
+  if (!IsBetween(sth.timestamp(), begin_range, end_range))
+    return INVALID_TIMESTAMP;
+
+  if (sig_verifier_->VerifySTHSignature(sth) != LogSigVerifier::OK)
+    return INVALID_SIGNATURE;
+  return VERIFY_OK;
+}
+
+LogVerifier::LogVerifyResult LogVerifier::VerifySignedTreeHead(
+    const SignedTreeHead& sth) const {
+  // Allow a bit of slack, say 1 second into the future.
+  return VerifySignedTreeHead(sth, 0, util::TimeInMilliseconds() + 1000);
+}
+
+LogVerifier::LogVerifyResult LogVerifier::VerifyMerkleAuditProof(
+    const LogEntry& entry, const SignedCertificateTimestamp& sct,
+    const MerkleAuditProof& merkle_proof) const {
+  if (!IsBetween(merkle_proof.timestamp(), sct.timestamp(),
+                 util::TimeInMilliseconds() + 1000))
+    return INCONSISTENT_TIMESTAMPS;
+
+  string serialized_leaf;
+  SerializeResult serialize_result =
+      Serializer::SerializeSCTMerkleTreeLeaf(sct, entry, &serialized_leaf);
+
+  if (serialize_result != SerializeResult::OK)
+    return INVALID_FORMAT;
+
+  std::vector<string> path;
+  for (int i = 0; i < merkle_proof.path_node_size(); ++i)
+    path.push_back(merkle_proof.path_node(i));
+
+  // Leaf indexing in the MerkleTree starts from 1.
+  string root_hash =
+      merkle_verifier_->RootFromPath(merkle_proof.leaf_index() + 1,
+                                     merkle_proof.tree_size(), path,
+                                     serialized_leaf);
+
+  if (root_hash.empty())
+    return INVALID_MERKLE_PATH;
+
+  SignedTreeHead sth;
+  sth.set_version(merkle_proof.version());
+  sth.mutable_id()->CopyFrom(merkle_proof.id());
+  sth.set_timestamp(merkle_proof.timestamp());
+  sth.set_tree_size(merkle_proof.tree_size());
+  sth.set_sha256_root_hash(root_hash);
+  sth.mutable_signature()->CopyFrom(merkle_proof.tree_head_signature());
+
+  if (sig_verifier_->VerifySTHSignature(sth) != LogSigVerifier::OK)
+    return INVALID_SIGNATURE;
+  return VERIFY_OK;
+}
+
+/* static */
+bool LogVerifier::IsBetween(uint64_t timestamp, uint64_t earliest,
+                            uint64_t latest) {
+  return timestamp >= earliest && timestamp <= latest;
+}
+
+bool LogVerifier::VerifyConsistency(
+    const ct::SignedTreeHead& sth1, const ct::SignedTreeHead& sth2,
+    const std::vector<std::string>& proof) const {
+  return merkle_verifier_->VerifyConsistency(sth1.tree_size(),
+                                             sth2.tree_size(),
+                                             sth1.sha256_root_hash(),
+                                             sth2.sha256_root_hash(), proof);
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_verifier.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_verifier.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/log_verifier.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/log_verifier.h	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,124 @@
+#ifndef CERT_TRANS_LOG_LOG_VERIFIER_H_
+#define CERT_TRANS_LOG_LOG_VERIFIER_H_
+
+#include <glog/logging.h>
+#include <stdint.h>
+
+#include "base/macros.h"
+#include "log/log_signer.h"
+#include "proto/ct.pb.h"
+
+class MerkleVerifier;
+
+// A verifier for verifying signed statements of the log.
+// TODO(ekasper): unit tests.
+class LogVerifier {
+ public:
+  LogVerifier(LogSigVerifier* sig_verifier, MerkleVerifier* tree_verifier);
+  ~LogVerifier();
+
+  enum LogVerifyResult {
+    VERIFY_OK,
+    // Invalid format
+    INVALID_FORMAT,
+    // Invalid timestamp
+    INVALID_TIMESTAMP,
+    // Timestamps differ.
+    INCONSISTENT_TIMESTAMPS,
+    // The signature does not verify.
+    INVALID_SIGNATURE,
+    // The Merkle path is not valid for the given index
+    // and tree size
+    INVALID_MERKLE_PATH,
+  };
+
+  static std::string VerifyResultString(LogVerifyResult result) {
+    switch (result) {
+      case VERIFY_OK:
+        return "Verify OK.";
+      case INVALID_FORMAT:
+        return "Invalid format.";
+      case INVALID_TIMESTAMP:
+        return "Invalid timestamp.";
+      case INCONSISTENT_TIMESTAMPS:
+        return "Inconsistent timestamps.";
+      case INVALID_SIGNATURE:
+        return "Invalid signature.";
+      case INVALID_MERKLE_PATH:
+        return "Invalid Merkle path.";
+    }
+
+    LOG(FATAL) << "unknown value for LogVerifyResult enum: " << result;
+    // It should not be possible for control to reach this point but this
+    // avoids a compilation warning on some platforms.
+    abort();
+  }
+
+  std::string KeyID() const {
+    return sig_verifier_->KeyID();
+  }
+
+  // Verify that the timestamp is in the given range,
+  // and the signature is valid.
+  // Timestamps are given in milliseconds, since January 1, 1970,
+  // 00:00 UTC time.
+  LogVerifyResult VerifySignedCertificateTimestamp(
+      const ct::LogEntry& entry, const ct::SignedCertificateTimestamp& sct,
+      uint64_t begin_range, uint64_t end_range,
+      std::string* merkle_leaf_hash) const;
+
+  // Verify that the timestamp is not in the future, and the signature is
+  // valid.
+  LogVerifyResult VerifySignedCertificateTimestamp(
+      const ct::LogEntry& entry, const ct::SignedCertificateTimestamp& sct,
+      std::string* merkle_leaf_hash) const;
+
+  LogVerifyResult VerifySignedCertificateTimestamp(
+      const ct::LogEntry& entry, const ct::SignedCertificateTimestamp& sct,
+      uint64_t begin_range, uint64_t end_range) const {
+    return VerifySignedCertificateTimestamp(entry, sct, begin_range, end_range,
+                                            NULL);
+  }
+  // Verify that the timestamp is not in the future, and the signature is
+  // valid.
+  LogVerifyResult VerifySignedCertificateTimestamp(
+      const ct::LogEntry& entry,
+      const ct::SignedCertificateTimestamp& sct) const {
+    return VerifySignedCertificateTimestamp(entry, sct, NULL);
+  }
+
+  // Verify that the timestamp is in the given range,
+  // and the signature is valid.
+  // Timestamps are given in milliseconds, since January 1, 1970,
+  // 00:00 UTC time.
+  LogVerifyResult VerifySignedTreeHead(const ct::SignedTreeHead& sth,
+                                       uint64_t begin_range,
+                                       uint64_t end_range) const;
+
+  // Verify that the timestamp is not in the future, and the signature is
+  // valid.
+  LogVerifyResult VerifySignedTreeHead(const ct::SignedTreeHead& sth) const;
+
+  // Verify that
+  // (1) The audit proof signature is valid
+  // (2) sct timestamp <= audit proof timestamp <= now
+  // Does not verify the SCT signature (or even require one).
+  LogVerifyResult VerifyMerkleAuditProof(
+      const ct::LogEntry& entry, const ct::SignedCertificateTimestamp& sct,
+      const ct::MerkleAuditProof& merkle_proof) const;
+
+  bool VerifyConsistency(const ct::SignedTreeHead& sth1,
+                         const ct::SignedTreeHead& sth2,
+                         const std::vector<std::string>& proof) const;
+
+ private:
+  LogSigVerifier* sig_verifier_;
+  MerkleVerifier* merkle_verifier_;
+
+  static bool IsBetween(uint64_t timestamp, uint64_t earliest,
+                        uint64_t latest);
+
+  DISALLOW_COPY_AND_ASSIGN(LogVerifier);
+};
+
+#endif  // CERT_TRANS_LOG_LOG_VERIFIER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/mock_consistent_store.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/mock_consistent_store.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/mock_consistent_store.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/mock_consistent_store.h	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,61 @@
+#ifndef CERT_TRANS_LOG_MOCK_CONSISTENT_STORE_H_
+#define CERT_TRANS_LOG_MOCK_CONSISTENT_STORE_H_
+
+#include <gmock/gmock.h>
+
+#include "log/consistent_store.h"
+
+namespace cert_trans {
+
+class MockConsistentStore : public ConsistentStore {
+ public:
+  MOCK_CONST_METHOD0_T(NextAvailableSequenceNumber, util::StatusOr<int64_t>());
+
+  MOCK_METHOD1_T(SetServingSTH, util::Status(const ct::SignedTreeHead&));
+
+  MOCK_CONST_METHOD0_T(GetServingSTH, util::StatusOr<ct::SignedTreeHead>());
+
+  MOCK_METHOD1_T(AddPendingEntry, util::Status(LoggedEntry* entry));
+
+  MOCK_CONST_METHOD2_T(GetPendingEntryForHash,
+                       util::Status(const std::string& hash,
+                                    EntryHandle<LoggedEntry>* entry));
+
+  MOCK_CONST_METHOD1_T(
+      GetPendingEntries,
+      util::Status(std::vector<EntryHandle<LoggedEntry>>* entries));
+
+  MOCK_CONST_METHOD1_T(
+      GetSequenceMapping,
+      util::Status(EntryHandle<ct::SequenceMapping>* mapping));
+
+  MOCK_METHOD1_T(UpdateSequenceMapping,
+                 util::Status(EntryHandle<ct::SequenceMapping>* mapping));
+
+  MOCK_CONST_METHOD0_T(GetClusterNodeState,
+                       util::StatusOr<ct::ClusterNodeState>());
+
+  MOCK_METHOD1_T(SetClusterNodeState,
+                 util::Status(const ct::ClusterNodeState& state));
+
+  MOCK_METHOD2_T(WatchServingSTH,
+                 void(const ConsistentStore::ServingSTHCallback& cb,
+                      util::Task* task));
+
+  MOCK_METHOD2_T(WatchClusterNodeStates,
+                 void(const ConsistentStore::ClusterNodeStateCallback& cb,
+                      util::Task* task));
+
+  MOCK_METHOD2_T(WatchClusterConfig,
+                 void(const ConsistentStore::ClusterConfigCallback& cb,
+                      util::Task* task));
+
+  MOCK_METHOD1(SetClusterConfig, util::Status(const ct::ClusterConfig&));
+
+  MOCK_METHOD0(CleanupOldEntries, util::StatusOr<int64_t>());
+};
+
+}  // namespace cert_log
+
+
+#endif  // CERT_TRANS_LOG_MOCK_CONSISTENT_STORE_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/signer.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/signer.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/signer.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/signer.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,71 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "log/signer.h"
+
+#include <glog/logging.h>
+#include <openssl/evp.h>
+#include <openssl/opensslv.h>
+#include <stdint.h>
+
+#include "log/verifier.h"
+#include "proto/ct.pb.h"
+#include "util/util.h"
+
+#if OPENSSL_VERSION_NUMBER < 0x10000000
+#error "Need OpenSSL >= 1.0.0"
+#endif
+
+using cert_trans::Verifier;
+
+namespace cert_trans {
+
+Signer::Signer(EVP_PKEY* pkey) : pkey_(CHECK_NOTNULL(pkey)) {
+  switch (pkey_->type) {
+    case EVP_PKEY_EC:
+      hash_algo_ = ct::DigitallySigned::SHA256;
+      sig_algo_ = ct::DigitallySigned::ECDSA;
+      break;
+    case EVP_PKEY_RSA:
+      hash_algo_ = ct::DigitallySigned::SHA256;
+      sig_algo_ = ct::DigitallySigned::RSA;
+      break;
+    default:
+      LOG(FATAL) << "Unsupported key type " << pkey_->type;
+  }
+  key_id_ = Verifier::ComputeKeyID(pkey_.get());
+}
+
+std::string Signer::KeyID() const {
+  return key_id_;
+}
+
+void Signer::Sign(const std::string& data,
+                  ct::DigitallySigned* signature) const {
+  signature->set_hash_algorithm(hash_algo_);
+  signature->set_sig_algorithm(sig_algo_);
+  signature->set_signature(RawSign(data));
+}
+
+Signer::Signer()
+    : hash_algo_(ct::DigitallySigned::NONE),
+      sig_algo_(ct::DigitallySigned::ANONYMOUS) {
+}
+
+std::string Signer::RawSign(const std::string& data) const {
+  EVP_MD_CTX ctx;
+  EVP_MD_CTX_init(&ctx);
+  // NOTE: this syntax for setting the hash function requires OpenSSL >= 1.0.0.
+  CHECK_EQ(1, EVP_SignInit(&ctx, EVP_sha256()));
+  CHECK_EQ(1, EVP_SignUpdate(&ctx, data.data(), data.size()));
+  unsigned int sig_size = EVP_PKEY_size(pkey_.get());
+  unsigned char* sig = new unsigned char[sig_size];
+
+  CHECK_EQ(1, EVP_SignFinal(&ctx, sig, &sig_size, pkey_.get()));
+
+  EVP_MD_CTX_cleanup(&ctx);
+  std::string ret(reinterpret_cast<char*>(sig), sig_size);
+
+  delete[] sig;
+  return ret;
+}
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/signer.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/signer.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/signer.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/signer.h	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,43 @@
+// A base class for signing unstructured data.  This class is mockable.
+
+#ifndef CERT_TRANS_LOG_SIGNER_H_
+#define CERT_TRANS_LOG_SIGNER_H_
+
+#include <openssl/evp.h>
+#include <openssl/x509.h>  // for i2d_PUBKEY
+#include <stdint.h>
+
+#include "base/macros.h"
+#include "proto/ct.pb.h"
+#include "util/openssl_scoped_types.h"
+
+namespace cert_trans {
+
+class Signer {
+ public:
+  explicit Signer(EVP_PKEY* pkey);
+  virtual ~Signer() = default;
+
+  virtual std::string KeyID() const;
+
+  virtual void Sign(const std::string& data,
+                    ct::DigitallySigned* signature) const;
+
+ protected:
+  // A constructor for mocking.
+  Signer();
+
+ private:
+  std::string RawSign(const std::string& data) const;
+
+  ScopedEVP_PKEY pkey_;
+  ct::DigitallySigned::HashAlgorithm hash_algo_;
+  ct::DigitallySigned::SignatureAlgorithm sig_algo_;
+  std::string key_id_;
+
+  DISALLOW_COPY_AND_ASSIGN(Signer);
+};
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_SIGNER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/signer_verifier_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/signer_verifier_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/signer_verifier_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/signer_verifier_test.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,155 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <stdint.h>
+#include <string>
+
+#include "log/signer.h"
+#include "log/test_signer.h"
+#include "log/verifier.h"
+#include "proto/cert_serializer.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+using cert_trans::Verifier;
+using ct::DigitallySigned;
+using std::string;
+
+namespace cert_trans {
+namespace {
+
+const char kTestString[] = "abc";
+
+class SignerVerifierTest : public ::testing::Test {
+ protected:
+  SignerVerifierTest() : signer_(NULL), verifier_(NULL) {
+  }
+
+  void SetUp() {
+    signer_ = TestSigner::DefaultSigner();
+    verifier_ = TestSigner::DefaultVerifier();
+  }
+
+  ~SignerVerifierTest() {
+    delete signer_;
+    delete verifier_;
+  }
+
+  static string SerializedSignature(const DigitallySigned& signature) {
+    string serialized_sig;
+    CHECK_EQ(cert_trans::serialization::SerializeResult::OK,
+             Serializer::SerializeDigitallySigned(signature, &serialized_sig));
+    return serialized_sig;
+  }
+
+  Signer* signer_;
+  Verifier* verifier_;
+};
+
+// Check that the keys of the signer and verifier are consistent.
+TEST_F(SignerVerifierTest, KeyID) {
+  EXPECT_FALSE(signer_->KeyID().empty());
+  EXPECT_EQ(signer_->KeyID(), verifier_->KeyID());
+}
+
+// TODO(ekasper): Check the example ECDSA signature for P-256, see
+// http://www.nsa.gov/ia/_files/ecdsa.pdf, section D.1.
+
+// Check that a well-known signature on well-know data verifies.
+TEST_F(SignerVerifierTest, CheckSignature) {
+  DigitallySigned signature;
+  string data;
+  signature.set_hash_algorithm(DigitallySigned::SHA256);
+  signature.set_sig_algorithm(DigitallySigned::ECDSA);
+  TestSigner::SetDefaults(&data, signature.mutable_signature());
+
+  EXPECT_EQ(Verifier::OK, verifier_->Verify(data, signature));
+}
+
+// Check that a signature on a test string verifies.  Also check that
+// successive signatures of the same data are different.
+TEST_F(SignerVerifierTest, SignAndVerify) {
+  // Sign the test string.
+  DigitallySigned signature1;
+  signer_->Sign(kTestString, &signature1);
+
+  // Check that the signature verifies.
+  EXPECT_EQ(DigitallySigned::SHA256, signature1.hash_algorithm());
+  EXPECT_EQ(DigitallySigned::ECDSA, signature1.sig_algorithm());
+  EXPECT_EQ(Verifier::OK, verifier_->Verify(kTestString, signature1));
+
+  // Sign the test string a second time.
+  DigitallySigned signature2;
+  signer_->Sign(kTestString, &signature2);
+
+  // Check that the signature is different but still verifies.
+  EXPECT_NE(signature1.signature(), signature2.signature());
+  EXPECT_EQ(DigitallySigned::SHA256, signature2.hash_algorithm());
+  EXPECT_EQ(DigitallySigned::ECDSA, signature2.sig_algorithm());
+  EXPECT_EQ(Verifier::OK, verifier_->Verify(kTestString, signature2));
+}
+
+// Check various error cases.
+TEST_F(SignerVerifierTest, Errors) {
+  DigitallySigned signature;
+  string data;
+  TestSigner::SetDefaults(&data, signature.mutable_signature());
+  signature.set_hash_algorithm(DigitallySigned::SHA256);
+  signature.set_sig_algorithm(DigitallySigned::ECDSA);
+  EXPECT_EQ(Verifier::OK, verifier_->Verify(data, signature));
+
+  const string good_signature = signature.signature();
+
+  // Empty signature.
+  signature.clear_signature();
+  EXPECT_EQ(Verifier::INVALID_SIGNATURE, verifier_->Verify(data, signature));
+
+  // Signature too short.
+  signature.set_signature(
+      good_signature.substr(0, good_signature.length() - 1));
+  EXPECT_EQ(Verifier::INVALID_SIGNATURE, verifier_->Verify(data, signature));
+
+  // Signature too long.
+  // OpenSSL ECDSA Verify parses *up to* a given number of bytes,
+  // rather than exactly the given number of bytes, and hence appending
+  // garbage in the end still results in a valid signature.
+  signature.set_signature(good_signature);
+  signature.mutable_signature()->append(1, 'c');
+  // EXPECT_EQ(Verifier::INVALID_SIGNATURE, verifier_->Verify(data,
+  // signature));
+
+  // Flip the lsb of each byte one by one.
+  signature.set_signature(good_signature);
+  for (size_t i = 0; i < good_signature.size(); ++i) {
+    signature.mutable_signature()->at(i) ^= 0x01;
+  }
+  EXPECT_EQ(Verifier::INVALID_SIGNATURE, verifier_->Verify(data, signature));
+
+  // Check algorithm mismatch.
+  signature.set_signature(good_signature);
+  signature.set_hash_algorithm(DigitallySigned::MD5);
+  signature.set_sig_algorithm(DigitallySigned::ECDSA);
+  EXPECT_EQ(Verifier::HASH_ALGORITHM_MISMATCH,
+            verifier_->Verify(data, signature));
+
+  signature.set_hash_algorithm(DigitallySigned::SHA256);
+  signature.set_sig_algorithm(DigitallySigned::RSA);
+  EXPECT_EQ(Verifier::SIGNATURE_ALGORITHM_MISMATCH,
+            verifier_->Verify(data, signature));
+
+  // Change data.
+  data.append("foo");
+  signature.set_sig_algorithm(DigitallySigned::ECDSA);
+  EXPECT_EQ(Verifier::INVALID_SIGNATURE, verifier_->Verify(data, signature));
+}
+
+}  // namespace
+}  // namespace cert_trans
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  ConfigureSerializerForV1CT();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/sqlite_db.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/sqlite_db.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/sqlite_db.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/sqlite_db.cc	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,580 @@
+#include "log/sqlite_db.h"
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <sqlite3.h>
+
+#include "log/sqlite_statement.h"
+#include "monitoring/latency.h"
+#include "monitoring/monitoring.h"
+#include "util/util.h"
+
+using std::unique_ptr;
+using std::chrono::milliseconds;
+using std::lock_guard;
+using std::mutex;
+using std::ostringstream;
+using std::string;
+using std::unique_lock;
+
+// Several of these flags pass their value directly through to SQLite PRAGMA
+// statements, see the SQLite documentation
+// (https://www.sqlite.org/pragma.html) for a description of the various
+// values available and the implications they have.
+
+// TODO(pphaneuf): For now, just a flag, but ideally, when adding a
+// new node, it would do an initial load of its local database with
+// "synchronous" set to OFF, then put it back before starting normal
+// operation.
+DEFINE_string(sqlite_synchronous_mode, "FULL",
+              "Which SQLite synchronous option to use, see SQLite pragma "
+              "documentation for details.");
+
+DEFINE_string(sqlite_journal_mode, "WAL",
+              "Which SQLite journal_mode option to use, see SQLite pragma "
+              "documentation for defails.");
+
+DEFINE_int32(sqlite_cache_size, 100000,
+             "Number of 1KB btree pages to keep in memory.");
+
+DEFINE_bool(sqlite_batch_into_transactions, true,
+            "Whether to batch operations into transactions behind the "
+            "scenes.");
+DEFINE_int32(sqlite_transaction_batch_size, 400,
+             "Max number of operations to batch into one transaction.");
+
+namespace cert_trans {
+namespace {
+
+
+static Latency<milliseconds, string> latency_by_op_ms(
+    "sqlitedb_latency_by_operation_ms", "operation",
+    "Database latency in ms broken out by operation");
+
+
+sqlite3* SQLiteOpen(const string& dbfile) {
+  ScopedLatency scoped_latency(latency_by_op_ms.GetScopedLatency("open"));
+  sqlite3* retval;
+
+  const int ret(
+      sqlite3_open_v2(dbfile.c_str(), &retval, SQLITE_OPEN_READWRITE, NULL));
+  if (ret == SQLITE_OK) {
+    return retval;
+  }
+  CHECK_EQ(SQLITE_CANTOPEN, ret) << sqlite3_errmsg(retval);
+
+  // We have to close and reopen to avoid memory leaks.
+  CHECK_EQ(SQLITE_OK, sqlite3_close(retval)) << sqlite3_errmsg(retval);
+  retval = nullptr;
+
+  CHECK_EQ(SQLITE_OK,
+           sqlite3_open_v2(dbfile.c_str(), &retval,
+                           SQLITE_OPEN_READWRITE | SQLITE_OPEN_CREATE,
+                           nullptr)) << sqlite3_errmsg(retval);
+  CHECK_EQ(SQLITE_OK, sqlite3_exec(retval,
+                                   "CREATE TABLE leaves(hash BLOB, "
+                                   "entry BLOB, sequence INTEGER UNIQUE)",
+                                   nullptr, nullptr, nullptr)) <<
+      sqlite3_errmsg(retval);
+  CHECK_EQ(SQLITE_OK, sqlite3_exec(retval,
+                                   "CREATE INDEX leaves_hash_idx ON "
+                                   "leaves(hash)",
+                                   nullptr, nullptr, nullptr)) <<
+      sqlite3_errmsg(retval);;
+  CHECK_EQ(SQLITE_OK,
+           sqlite3_exec(
+               retval,
+               "CREATE TABLE trees(sth BLOB UNIQUE, timestamp INTEGER UNIQUE)",
+               nullptr, nullptr, nullptr)) << sqlite3_errmsg(retval);
+
+  CHECK_EQ(SQLITE_OK,
+           sqlite3_exec(retval, "CREATE TABLE node(node_id BLOB UNIQUE)",
+                        nullptr, nullptr, nullptr)) << sqlite3_errmsg(retval);
+
+  LOG(INFO) << "New SQLite database created in " << dbfile;
+
+  return retval;
+}
+
+
+}  // namespace
+
+
+class SQLiteDB::Iterator : public Database::Iterator {
+ public:
+  Iterator(const SQLiteDB* db, int64_t start_index)
+      : db_(CHECK_NOTNULL(db)), next_index_(start_index) {
+    CHECK_GE(next_index_, 0);
+  }
+
+  bool GetNextEntry(LoggedEntry* entry) override {
+    CHECK_NOTNULL(entry);
+    unique_lock<mutex> lock(db_->lock_);
+    if (next_index_ < db_->tree_size_) {
+      CHECK_EQ(db_->LookupByIndex(lock, next_index_, entry), db_->LOOKUP_OK);
+      ++next_index_;
+      return true;
+    }
+
+    const bool retval(db_->LookupNextIndex(lock, next_index_, entry) ==
+                      db_->LOOKUP_OK);
+    if (retval) {
+      next_index_ = entry->sequence_number() + 1;
+    }
+
+    return retval;
+  }
+
+ private:
+  const SQLiteDB* const db_;
+  int64_t next_index_;
+};
+
+
+SQLiteDB::SQLiteDB(const string& dbfile)
+    : db_(SQLiteOpen(dbfile)),
+      tree_size_(0),
+      transaction_size_(0),
+      in_transaction_(false) {
+  unique_lock<mutex> lock(lock_);
+  {
+    ostringstream oss;
+    oss << "PRAGMA synchronous = " << FLAGS_sqlite_synchronous_mode;
+    sqlite::Statement statement(db_, oss.str().c_str());
+    CHECK_EQ(SQLITE_DONE, statement.Step()) << sqlite3_errmsg(db_);
+    LOG(WARNING) << "SQLite \"synchronous\" pragma set to "
+                 << FLAGS_sqlite_synchronous_mode;
+    if (FLAGS_sqlite_batch_into_transactions) {
+      LOG(WARNING) << "SQLite running with batched transactions, you should "
+                   << "set sqlite_synchronous_mode = FULL !";
+    }
+  }
+
+  {
+    ostringstream oss;
+    oss << "PRAGMA journal_mode = " << FLAGS_sqlite_journal_mode;
+    sqlite::Statement statement(db_, oss.str().c_str());
+    CHECK_EQ(SQLITE_ROW, statement.Step()) << sqlite3_errmsg(db_);
+    string mode;
+    statement.GetBlob(0, &mode);
+    CHECK_STRCASEEQ(mode.c_str(), FLAGS_sqlite_journal_mode.c_str());
+    CHECK_EQ(SQLITE_DONE, statement.Step()) << sqlite3_errmsg(db_);
+  }
+
+  {
+    ostringstream oss;
+    oss << "PRAGMA cache_size = " << FLAGS_sqlite_cache_size;
+    sqlite::Statement statement(db_, oss.str().c_str());
+    CHECK_EQ(SQLITE_DONE, statement.Step()) << sqlite3_errmsg(db_);
+  }
+
+  BeginTransaction(lock);
+}
+
+
+SQLiteDB::~SQLiteDB() {
+  CHECK_EQ(SQLITE_OK, sqlite3_close(db_)) << sqlite3_errmsg(db_);
+}
+
+
+Database::WriteResult SQLiteDB::CreateSequencedEntry_(
+    const LoggedEntry& logged) {
+  ScopedLatency latency(
+      latency_by_op_ms.GetScopedLatency("create_sequenced_entry"));
+  unique_lock<mutex> lock(lock_);
+
+  MaybeStartNewTransaction(lock);
+
+  sqlite::Statement statement(db_,
+                              "INSERT INTO leaves(hash, entry, sequence) "
+                              "VALUES(?, ?, ?)");
+  const string hash(logged.Hash());
+  statement.BindBlob(0, hash);
+
+  string data;
+  CHECK(logged.SerializeForDatabase(&data));
+  statement.BindBlob(1, data);
+
+  CHECK(logged.has_sequence_number());
+  statement.BindUInt64(2, logged.sequence_number());
+
+  int ret = statement.Step();
+  if (ret == SQLITE_CONSTRAINT) {
+    // Check whether we're trying to store a hash/sequence pair which already
+    // exists - if it's identical we'll return OK as it could be the fetcher.
+    sqlite::Statement s2(
+        db_, "SELECT sequence, hash FROM leaves WHERE sequence = ?");
+    s2.BindUInt64(0, logged.sequence_number());
+    if (s2.Step() == SQLITE_ROW) {
+      string existing_hash;
+      s2.GetBlob(1, &existing_hash);
+
+      if (logged.sequence_number() == tree_size_) {
+        ++tree_size_;
+      }
+
+      if (hash == existing_hash) {
+        return this->OK;
+      }
+    }
+    return this->SEQUENCE_NUMBER_ALREADY_IN_USE;
+  }
+  CHECK_EQ(SQLITE_DONE, ret) << sqlite3_errmsg(db_);
+
+  if (logged.sequence_number() == tree_size_) {
+    ++tree_size_;
+  }
+
+  return this->OK;
+}
+
+
+Database::LookupResult SQLiteDB::LookupByHash(const string& hash,
+                                              LoggedEntry* result) const {
+  CHECK_NOTNULL(result);
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("lookup_by_hash"));
+
+  lock_guard<mutex> lock(lock_);
+
+  sqlite::Statement statement(db_,
+                              "SELECT entry, sequence FROM leaves "
+                              "WHERE hash = ? ORDER BY sequence LIMIT 1");
+
+  statement.BindBlob(0, hash);
+
+  int ret = statement.Step();
+  if (ret == SQLITE_DONE) {
+    return this->NOT_FOUND;
+  }
+  CHECK_EQ(SQLITE_ROW, ret) << sqlite3_errmsg(db_);
+
+  string data;
+  statement.GetBlob(0, &data);
+  CHECK(result->ParseFromDatabase(data));
+
+  if (statement.GetType(1) == SQLITE_NULL) {
+    result->clear_sequence_number();
+  } else {
+    result->set_sequence_number(statement.GetUInt64(1));
+    if (result->sequence_number() == tree_size_) {
+      ++tree_size_;
+    }
+  }
+
+  return this->LOOKUP_OK;
+}
+
+
+Database::LookupResult SQLiteDB::LookupByIndex(int64_t sequence_number,
+                                               LoggedEntry* result) const {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("lookup_by_index"));
+  unique_lock<mutex> lock(lock_);
+
+  return LookupByIndex(lock, sequence_number, result);
+}
+
+
+Database::LookupResult SQLiteDB::LookupByIndex(const unique_lock<mutex>& lock,
+                                               int64_t sequence_number,
+                                               LoggedEntry* result) const {
+  CHECK(lock.owns_lock());
+  CHECK_GE(sequence_number, 0);
+  CHECK_NOTNULL(result);
+  sqlite::Statement statement(db_,
+                              "SELECT entry, hash FROM leaves "
+                              "WHERE sequence = ?");
+  statement.BindUInt64(0, sequence_number);
+  int ret = statement.Step();
+  if (ret == SQLITE_DONE) {
+    return this->NOT_FOUND;
+  }
+
+  string data;
+  statement.GetBlob(0, &data);
+  CHECK(result->ParseFromDatabase(data));
+
+  string hash;
+  statement.GetBlob(1, &hash);
+
+  CHECK_EQ(result->Hash(), hash);
+
+  result->set_sequence_number(sequence_number);
+  if (result->sequence_number() == tree_size_) {
+    ++tree_size_;
+  }
+
+  return this->LOOKUP_OK;
+}
+
+
+Database::LookupResult SQLiteDB::LookupNextIndex(
+    const unique_lock<mutex>& lock, int64_t sequence_number,
+    LoggedEntry* result) const {
+  CHECK(lock.owns_lock());
+  CHECK_GE(sequence_number, 0);
+  CHECK_NOTNULL(result);
+  sqlite::Statement statement(db_,
+                              "SELECT entry, hash, sequence FROM leaves "
+                              "WHERE sequence >= ? ORDER BY sequence");
+  statement.BindUInt64(0, sequence_number);
+  if (statement.Step() == SQLITE_DONE) {
+    return this->NOT_FOUND;
+  }
+
+  string data;
+  statement.GetBlob(0, &data);
+  CHECK(result->ParseFromDatabase(data));
+
+  string hash;
+  statement.GetBlob(1, &hash);
+
+  CHECK_EQ(result->Hash(), hash);
+
+  result->set_sequence_number(statement.GetUInt64(2));
+  if (result->sequence_number() == tree_size_) {
+    ++tree_size_;
+  }
+
+  return this->LOOKUP_OK;
+}
+
+
+unique_ptr<Database::Iterator> SQLiteDB::ScanEntries(
+    int64_t start_index) const {
+  return unique_ptr<Iterator>(new Iterator(this, start_index));
+}
+
+
+Database::WriteResult SQLiteDB::WriteTreeHead_(const ct::SignedTreeHead& sth) {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("write_tree_head"));
+  unique_lock<mutex> lock(lock_);
+
+  sqlite::Statement statement(db_,
+                              "INSERT INTO trees(timestamp, sth) "
+                              "VALUES(?, ?)");
+  statement.BindUInt64(0, sth.timestamp());
+
+  string sth_data;
+  CHECK(sth.SerializeToString(&sth_data));
+  statement.BindBlob(1, sth_data);
+
+  int r2 = statement.Step();
+  if (r2 == SQLITE_CONSTRAINT) {
+    sqlite::Statement s2(db_,
+                         "SELECT timestamp,sth FROM trees "
+                         "WHERE timestamp = ?");
+    s2.BindUInt64(0, sth.timestamp());
+    CHECK_EQ(SQLITE_ROW, s2.Step()) << sqlite3_errmsg(db_);
+    string existing_sth_data;
+    s2.GetBlob(1, &existing_sth_data);
+    if (existing_sth_data == sth_data) {
+      LOG(WARNING) << "Attempted to store indentical STH in DB.";
+      return this->OK;
+    }
+    return this->DUPLICATE_TREE_HEAD_TIMESTAMP;
+  }
+  CHECK_EQ(SQLITE_DONE, r2) << sqlite3_errmsg(db_);
+
+  EndTransaction(lock);
+  BeginTransaction(lock);
+
+  // Do not call the callbacks while holding the lock, as they might
+  // want to perform some lookups.
+  lock.unlock();
+  callbacks_.Call(sth);
+
+  return this->OK;
+}
+
+
+Database::LookupResult SQLiteDB::LatestTreeHead(
+    ct::SignedTreeHead* result) const {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("latest_tree_head"));
+  unique_lock<mutex> lock(lock_);
+
+  return LatestTreeHeadNoLock(lock, result);
+}
+
+
+int64_t SQLiteDB::TreeSize() const {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("tree_size"));
+  unique_lock<mutex> lock(lock_);
+
+  CHECK_GE(tree_size_, 0);
+  sqlite::Statement statement(
+      db_,
+      "SELECT sequence FROM leaves WHERE sequence >= ? ORDER BY sequence");
+  statement.BindUInt64(0, tree_size_);
+
+  int ret(statement.Step());
+  while (ret == SQLITE_ROW) {
+    const sqlite3_uint64 sequence(statement.GetUInt64(0));
+
+    if (sequence != static_cast<uint64_t>(tree_size_)) {
+      return tree_size_;
+    }
+
+    ++tree_size_;
+    ret = statement.Step();
+  }
+  CHECK_EQ(SQLITE_DONE, ret) << sqlite3_errmsg(db_);
+
+  return tree_size_;
+}
+
+
+void SQLiteDB::AddNotifySTHCallback(
+    const Database::NotifySTHCallback* callback) {
+  unique_lock<mutex> lock(lock_);
+
+  callbacks_.Add(callback);
+
+  ct::SignedTreeHead sth;
+  if (LatestTreeHeadNoLock(lock, &sth) == this->LOOKUP_OK) {
+    // Do not call the callback while holding the lock, as they might
+    // want to perform some lookups.
+    lock.unlock();
+    (*callback)(sth);
+  }
+}
+
+
+void SQLiteDB::RemoveNotifySTHCallback(
+    const Database::NotifySTHCallback* callback) {
+  lock_guard<mutex> lock(lock_);
+
+  callbacks_.Remove(callback);
+}
+
+
+void SQLiteDB::InitializeNode(const string& node_id) {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("initialize_node"));
+  CHECK(!node_id.empty());
+  unique_lock<mutex> lock(lock_);
+  string existing_id;
+  if (NodeId(lock, &existing_id) != this->NOT_FOUND) {
+    LOG(FATAL) << "Attempting to initialize DB beloging to node with node_id: "
+               << existing_id;
+  }
+  sqlite::Statement statement(db_, "INSERT INTO node(node_id) VALUES(?)");
+  statement.BindBlob(0, node_id);
+
+  const int result(statement.Step());
+  CHECK_EQ(SQLITE_DONE, result) << sqlite3_errmsg(db_);
+}
+
+
+Database::LookupResult SQLiteDB::NodeId(string* node_id) {
+  unique_lock<mutex> lock(lock_);
+  return NodeId(lock, CHECK_NOTNULL(node_id));
+}
+
+
+Database::LookupResult SQLiteDB::NodeId(const unique_lock<mutex>& lock,
+                                        string* node_id) {
+  ScopedLatency latency(latency_by_op_ms.GetScopedLatency("set_node_id"));
+  CHECK(lock.owns_lock());
+  CHECK_NOTNULL(node_id);
+  sqlite::Statement statement(db_, "SELECT node_id FROM node");
+
+  int result(statement.Step());
+  if (result == SQLITE_DONE) {
+    return this->NOT_FOUND;
+  }
+  CHECK_EQ(SQLITE_ROW, result) << sqlite3_errmsg(db_);
+
+  statement.GetBlob(0, node_id);
+  result = statement.Step();
+  // There can only be one!
+  CHECK_EQ(SQLITE_DONE, result) << sqlite3_errmsg(db_);
+  return this->LOOKUP_OK;
+}
+
+
+void SQLiteDB::BeginTransaction(const unique_lock<mutex>& lock) {
+  CHECK(lock.owns_lock());
+  if (FLAGS_sqlite_batch_into_transactions) {
+    CHECK_EQ(0, transaction_size_);
+    CHECK(!in_transaction_);
+    VLOG(1) << "Beginning new transaction.";
+    sqlite::Statement s(db_, "BEGIN TRANSACTION");
+    CHECK_EQ(SQLITE_DONE, s.Step()) << sqlite3_errmsg(db_);
+    in_transaction_ = true;
+  }
+}
+
+
+void SQLiteDB::EndTransaction(const unique_lock<mutex>& lock) {
+  CHECK(lock.owns_lock());
+  if (FLAGS_sqlite_batch_into_transactions) {
+    CHECK(in_transaction_);
+    VLOG(1) << "Committing transaction.";
+    {
+      sqlite::Statement s(db_, "END TRANSACTION");
+      CHECK_EQ(SQLITE_DONE, s.Step()) << sqlite3_errmsg(db_);
+    }
+    {
+      sqlite::Statement s(db_, "PRAGMA wal_checkpoint(TRUNCATE)");
+      CHECK_EQ(SQLITE_ROW, s.Step()) << sqlite3_errmsg(db_);
+      CHECK_EQ(SQLITE_DONE, s.Step()) << sqlite3_errmsg(db_);
+    }
+
+    transaction_size_ = 0;
+    in_transaction_ = false;
+  }
+}
+
+
+void SQLiteDB::MaybeStartNewTransaction(const unique_lock<mutex>& lock) {
+  CHECK(lock.owns_lock());
+  if (FLAGS_sqlite_batch_into_transactions &&
+      transaction_size_ >= FLAGS_sqlite_transaction_batch_size) {
+    VLOG(1) << "Rolling over into new transaction.";
+    EndTransaction(lock);
+    BeginTransaction(lock);
+  }
+  ++transaction_size_;
+}
+
+
+void SQLiteDB::ForceNotifySTH() {
+  unique_lock<mutex> lock(lock_);
+
+  ct::SignedTreeHead sth;
+  const Database::LookupResult db_result =
+      this->LatestTreeHeadNoLock(lock, &sth);
+  if (db_result == Database::NOT_FOUND) {
+    return;
+  }
+
+  CHECK(db_result == Database::LOOKUP_OK);
+
+  // Do not call the callbacks while holding the lock, as they might
+  // want to perform some lookups.
+  lock.unlock();
+  callbacks_.Call(sth);
+}
+
+
+Database::LookupResult SQLiteDB::LatestTreeHeadNoLock(
+    const unique_lock<mutex>& lock, ct::SignedTreeHead* result) const {
+  CHECK(lock.owns_lock());
+  sqlite::Statement statement(db_,
+                              "SELECT sth FROM trees WHERE timestamp IN "
+                              "(SELECT MAX(timestamp) FROM trees)");
+
+  int ret = statement.Step();
+  if (ret == SQLITE_DONE) {
+    return this->NOT_FOUND;
+  }
+  CHECK_EQ(SQLITE_ROW, ret) << sqlite3_errmsg(db_);
+
+  string sth;
+  statement.GetBlob(0, &sth);
+  CHECK(result->ParseFromString(sth));
+
+  return this->LOOKUP_OK;
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/sqlite_db.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/sqlite_db.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/sqlite_db.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/sqlite_db.h	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,93 @@
+#ifndef CERT_TRANS_LOG_SQLITE_DB_H_
+#define CERT_TRANS_LOG_SQLITE_DB_H_
+
+#include <mutex>
+#include <string>
+
+#include "base/macros.h"
+#include "log/database.h"
+#include "log/logged_entry.h"
+
+struct sqlite3;
+
+namespace cert_trans {
+
+
+class SQLiteDB : public Database {
+ public:
+  explicit SQLiteDB(const std::string& dbfile);
+
+  ~SQLiteDB();
+
+  typedef Database::WriteResult WriteResult;
+  typedef Database::LookupResult LookupResult;
+
+  WriteResult CreateSequencedEntry_(const LoggedEntry& logged) override;
+
+  LookupResult LookupByHash(const std::string& hash,
+                            LoggedEntry* result) const override;
+
+  LookupResult LookupByIndex(int64_t sequence_number,
+                             LoggedEntry* result) const override;
+
+  std::unique_ptr<Database::Iterator> ScanEntries(
+      int64_t start_index) const override;
+
+  WriteResult WriteTreeHead_(const ct::SignedTreeHead& sth) override;
+
+  LookupResult LatestTreeHead(ct::SignedTreeHead* result) const override;
+
+  int64_t TreeSize() const override;
+
+  void AddNotifySTHCallback(
+      const Database::NotifySTHCallback* callback) override;
+
+  void RemoveNotifySTHCallback(
+      const Database::NotifySTHCallback* callback) override;
+
+  void InitializeNode(const std::string& node_id) override;
+  LookupResult NodeId(std::string* node_id) override;
+
+  // Force an STH notification. This is needed only for ct-dns-server,
+  // which shares a SQLite database with ct-server, but needs to
+  // refresh itself occasionally.
+  void ForceNotifySTH();
+
+ private:
+  class Iterator;
+
+  LookupResult LookupByIndex(const std::unique_lock<std::mutex>& lock,
+                             int64_t sequence_number,
+                             LoggedEntry* result) const;
+  // This finds the next entry with a sequence number equal or greater
+  // to the one specified.
+  LookupResult LookupNextIndex(const std::unique_lock<std::mutex>& lock,
+                               int64_t sequence_number,
+                               LoggedEntry* result) const;
+  LookupResult LatestTreeHeadNoLock(const std::unique_lock<std::mutex>& lock,
+                                    ct::SignedTreeHead* result) const;
+  LookupResult NodeId(const std::unique_lock<std::mutex>& lock,
+                      std::string* node_id);
+
+  void BeginTransaction(const std::unique_lock<std::mutex>& lock);
+
+  void EndTransaction(const std::unique_lock<std::mutex>& lock);
+
+  void MaybeStartNewTransaction(const std::unique_lock<std::mutex>& lock);
+
+  mutable std::mutex lock_;
+  sqlite3* const db_;
+  // This is marked mutable, as it is a lazily updated cache updated
+  // from some of the getters.
+  mutable int64_t tree_size_;
+  DatabaseNotifierHelper callbacks_;
+  int64_t transaction_size_;
+  bool in_transaction_;
+
+  DISALLOW_COPY_AND_ASSIGN(SQLiteDB);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_SQLITE_DB_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/sqlite_statement.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/sqlite_statement.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/sqlite_statement.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/sqlite_statement.h	2017-01-15 10:56:31.042591151 +0100
@@ -0,0 +1,69 @@
+#ifndef CERT_TRANS_LOG_SQLITE_STATEMENT_H_
+#define CERT_TRANS_LOG_SQLITE_STATEMENT_H_
+
+#include <glog/logging.h>
+#include <sqlite3.h>
+#include <string>
+
+#include "base/macros.h"
+
+namespace sqlite {
+
+// Reduce the ugliness of the sqlite3 API.
+class Statement {
+ public:
+  Statement(sqlite3* db, const char* sql) : stmt_(NULL) {
+    int ret = sqlite3_prepare_v2(db, sql, -1, &stmt_, NULL);
+    if (ret != SQLITE_OK)
+      LOG(ERROR) << "ret = " << ret << ", err = " << sqlite3_errmsg(db)
+                 << ", sql = " << sql << std::endl;
+
+    CHECK_EQ(SQLITE_OK, ret);
+  }
+
+  ~Statement() {
+    int ret = sqlite3_finalize(stmt_);
+    // can get SQLITE_CONSTRAINT if an insert failed due to a duplicate key.
+    CHECK(ret == SQLITE_OK || ret == SQLITE_CONSTRAINT);
+  }
+
+  // Fields start at 0! |value| must have lifetime that covers its
+  // use, which is up until the SQL statement finishes executing
+  // (i.e. after the last Step()).
+  void BindBlob(unsigned field, const std::string& value) {
+    CHECK_EQ(SQLITE_OK, sqlite3_bind_blob(stmt_, field + 1, value.data(),
+                                          value.length(), NULL));
+  }
+
+  void BindUInt64(unsigned field, sqlite3_uint64 value) {
+    CHECK_EQ(SQLITE_OK, sqlite3_bind_int64(stmt_, field + 1, value));
+  }
+
+  void GetBlob(unsigned column, std::string* value) {
+    const void* data = sqlite3_column_blob(stmt_, column);
+    CHECK_NOTNULL(data);
+    value->assign(static_cast<const char*>(data),
+                  sqlite3_column_bytes(stmt_, column));
+  }
+
+  sqlite3_uint64 GetUInt64(unsigned column) {
+    return sqlite3_column_int64(stmt_, column);
+  }
+
+  int GetType(unsigned column) {
+    return sqlite3_column_type(stmt_, column);
+  }
+
+  int Step() {
+    return sqlite3_step(stmt_);
+  }
+
+ private:
+  sqlite3_stmt* stmt_;
+
+  DISALLOW_COPY_AND_ASSIGN(Statement);
+};
+
+}  // namespace sqlite
+
+#endif  // CERT_TRANS_LOG_SQLITE_STATEMENT_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/strict_consistent_store.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/strict_consistent_store.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/strict_consistent_store.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/strict_consistent_store.cc	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,58 @@
+#include "log/strict_consistent_store.h"
+
+using ct::SignedTreeHead;
+using util::Status;
+using util::StatusOr;
+
+namespace cert_trans {
+
+
+StrictConsistentStore::StrictConsistentStore(const MasterElection* election,
+                                             ConsistentStore* peer)
+    : election_(CHECK_NOTNULL(election)), peer_(CHECK_NOTNULL(peer)) {
+}
+
+
+StatusOr<int64_t> StrictConsistentStore::NextAvailableSequenceNumber() const {
+  if (!election_->IsMaster()) {
+    return Status(util::error::PERMISSION_DENIED, "Not currently master.");
+  }
+  return peer_->NextAvailableSequenceNumber();
+}
+
+
+Status StrictConsistentStore::SetServingSTH(const SignedTreeHead& new_sth) {
+  if (!election_->IsMaster()) {
+    return Status(util::error::PERMISSION_DENIED, "Not currently master.");
+  }
+  return peer_->SetServingSTH(new_sth);
+}
+
+
+Status StrictConsistentStore::UpdateSequenceMapping(
+    EntryHandle<ct::SequenceMapping>* entry) {
+  if (!election_->IsMaster()) {
+    return Status(util::error::PERMISSION_DENIED, "Not currently master.");
+  }
+  return peer_->UpdateSequenceMapping(entry);
+}
+
+
+Status StrictConsistentStore::SetClusterConfig(
+    const ct::ClusterConfig& config) {
+  if (!election_->IsMaster()) {
+    return Status(util::error::PERMISSION_DENIED, "Not currently master.");
+  }
+  return peer_->SetClusterConfig(config);
+}
+
+
+StatusOr<int64_t> StrictConsistentStore::CleanupOldEntries() {
+  if (!election_->IsMaster()) {
+    return Status(util::error::PERMISSION_DENIED, "Not currently master.");
+  }
+  return peer_->CleanupOldEntries();
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/strict_consistent_store.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/strict_consistent_store.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/strict_consistent_store.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/strict_consistent_store.h	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,97 @@
+#ifndef CERT_TRANS_LOG_STRICT_CONSISTENT_STORE_H_
+#define CERT_TRANS_LOG_STRICT_CONSISTENT_STORE_H_
+
+#include "log/consistent_store.h"
+#include "log/logged_entry.h"
+#include "util/masterelection.h"
+
+namespace cert_trans {
+
+// A wrapper around a ConsistentStore which will not allow changes to
+// the cluster state which should only be performed by the current master
+// unless this node /is/ the current master.
+//
+// Note that while this is better than just gating the start of a high-level
+// action (especially a long running action, e.g. a signing run) with a check
+// to IsMaster(), it is still necessarily racy because etcd doesn't support
+// atomic updates across keys.)
+class StrictConsistentStore : public ConsistentStore {
+ public:
+  // Takes ownership of |peer|, but not |election|
+  StrictConsistentStore(const MasterElection* election, ConsistentStore* peer);
+
+  virtual ~StrictConsistentStore() = default;
+
+  // Methods requiring that the caller is currently master:
+
+  util::StatusOr<int64_t> NextAvailableSequenceNumber() const override;
+
+  util::Status SetServingSTH(const ct::SignedTreeHead& new_sth) override;
+
+  util::Status UpdateSequenceMapping(
+      EntryHandle<ct::SequenceMapping>* entry) override;
+
+  util::Status SetClusterConfig(const ct::ClusterConfig& config) override;
+
+  util::StatusOr<int64_t> CleanupOldEntries() override;
+
+  // Other methods:
+
+  util::StatusOr<ct::SignedTreeHead> GetServingSTH() const override {
+    return peer_->GetServingSTH();
+  }
+
+  util::Status AddPendingEntry(LoggedEntry* entry) override {
+    return peer_->AddPendingEntry(entry);
+  }
+
+  util::Status GetPendingEntryForHash(
+      const std::string& hash,
+      EntryHandle<LoggedEntry>* entry) const override {
+    return peer_->GetPendingEntryForHash(hash, entry);
+  }
+
+  util::Status GetPendingEntries(
+      std::vector<EntryHandle<LoggedEntry>>* entries) const override {
+    return peer_->GetPendingEntries(entries);
+  }
+
+  util::Status GetSequenceMapping(
+      EntryHandle<ct::SequenceMapping>* entry) const override {
+    return peer_->GetSequenceMapping(entry);
+  }
+
+  util::StatusOr<ct::ClusterNodeState> GetClusterNodeState() const override {
+    return peer_->GetClusterNodeState();
+  }
+
+  util::Status SetClusterNodeState(
+      const ct::ClusterNodeState& state) override {
+    return peer_->SetClusterNodeState(state);
+  }
+
+  void WatchServingSTH(const ConsistentStore::ServingSTHCallback& cb,
+                       util::Task* task) override {
+    return peer_->WatchServingSTH(cb, task);
+  }
+
+  void WatchClusterNodeStates(
+      const ConsistentStore::ClusterNodeStateCallback& cb,
+      util::Task* task) override {
+    return peer_->WatchClusterNodeStates(cb, task);
+  }
+
+  void WatchClusterConfig(const ConsistentStore::ClusterConfigCallback& cb,
+                          util::Task* task) override {
+    return peer_->WatchClusterConfig(cb, task);
+  }
+
+ private:
+  const MasterElection* const election_;  // Not owned by us
+  const std::unique_ptr<ConsistentStore> peer_;
+};
+
+
+}  // namespace
+
+#endif  // CERT_TRANS_LOG_STRICT_CONSISTENT_STORE_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/strict_consistent_store_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/strict_consistent_store_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/strict_consistent_store_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/strict_consistent_store_test.cc	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,135 @@
+#include "log/strict_consistent_store.h"
+
+#include <gflags/gflags.h>
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "log/logged_entry.h"
+#include "log/mock_consistent_store.h"
+#include "util/mock_masterelection.h"
+#include "util/status.h"
+#include "util/status_test_util.h"
+#include "util/statusor.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+DECLARE_int32(node_state_ttl_seconds);
+
+namespace cert_trans {
+
+using ct::SequenceMapping;
+using testing::_;
+using testing::NiceMock;
+using testing::Return;
+using util::Status;
+using util::StatusOr;
+using util::testing::StatusIs;
+
+
+class StrictConsistentStoreTest : public ::testing::TestWithParam<bool> {
+ public:
+  StrictConsistentStoreTest()
+      : peer_(new NiceMock<MockConsistentStore>()),
+        strict_store_(&election_, peer_) {
+    ON_CALL(election_, IsMaster()).WillByDefault(Return(IsMaster()));
+  }
+
+ protected:
+  bool IsMaster() const {
+    return GetParam();
+  }
+
+  NiceMock<MockMasterElection> election_;
+  // strict_store_ takes ownership of this:
+  NiceMock<MockConsistentStore>* peer_;
+  StrictConsistentStore strict_store_;
+};
+
+
+TEST_P(StrictConsistentStoreTest, TestNextAvailableSequenceNumber) {
+  if (IsMaster()) {
+    EXPECT_CALL(*peer_, NextAvailableSequenceNumber()).WillOnce(Return(123));
+  } else {
+    EXPECT_CALL(*peer_, NextAvailableSequenceNumber()).Times(0);
+  }
+
+  util::StatusOr<int64_t> seq(strict_store_.NextAvailableSequenceNumber());
+
+  if (IsMaster()) {
+    EXPECT_EQ(123, seq.ValueOrDie());
+  } else {
+    EXPECT_FALSE(seq.ok());
+    EXPECT_THAT(seq.status(), StatusIs(util::error::PERMISSION_DENIED));
+  }
+}
+
+
+TEST_P(StrictConsistentStoreTest, TestSetServingSTH) {
+  if (IsMaster()) {
+    EXPECT_CALL(*peer_, SetServingSTH(_)).WillOnce(Return(util::Status::OK));
+  } else {
+    EXPECT_CALL(*peer_, SetServingSTH(_)).Times(0);
+  }
+
+  ct::SignedTreeHead sth;
+  sth.set_timestamp(234);
+  util::Status status(strict_store_.SetServingSTH(sth));
+
+  if (IsMaster()) {
+    EXPECT_OK(status);
+  } else {
+    EXPECT_THAT(status, StatusIs(util::error::PERMISSION_DENIED));
+  }
+}
+
+
+TEST_P(StrictConsistentStoreTest, TestUpdateSequenceMapping) {
+  if (IsMaster()) {
+    EXPECT_CALL(*peer_, UpdateSequenceMapping(_))
+        .WillOnce(Return(util::Status::OK));
+  } else {
+    EXPECT_CALL(*peer_, UpdateSequenceMapping(_)).Times(0);
+  }
+
+  EntryHandle<SequenceMapping> mapping;
+  util::Status status(strict_store_.UpdateSequenceMapping(&mapping));
+
+  if (IsMaster()) {
+    EXPECT_TRUE(status.ok());
+  } else {
+    EXPECT_FALSE(status.ok());
+    EXPECT_THAT(status, StatusIs(util::error::PERMISSION_DENIED));
+  }
+}
+
+
+TEST_P(StrictConsistentStoreTest, TestClusterConfig) {
+  if (IsMaster()) {
+    EXPECT_CALL(*peer_, SetClusterConfig(_))
+        .WillOnce(Return(util::Status::OK));
+  } else {
+    EXPECT_CALL(*peer_, SetClusterConfig(_)).Times(0);
+  }
+
+  ct::ClusterConfig conf;
+  util::Status status(strict_store_.SetClusterConfig(conf));
+
+  if (IsMaster()) {
+    EXPECT_TRUE(status.ok());
+  } else {
+    EXPECT_THAT(status, StatusIs(util::error::PERMISSION_DENIED));
+  }
+}
+
+
+INSTANTIATE_TEST_CASE_P(MasterInstance, StrictConsistentStoreTest,
+                        testing::Values(true, false));
+
+
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/test_db.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/test_db.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/test_db.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/test_db.h	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,78 @@
+#ifndef CERT_TRANS_LOG_TEST_DB_H_
+#define CERT_TRANS_LOG_TEST_DB_H_
+
+#include <sys/stat.h>
+
+#include "log/database.h"
+#include "log/file_db.h"
+#include "log/file_storage.h"
+#include "log/leveldb_db.h"
+#include "log/logged_entry.h"
+#include "log/sqlite_db.h"
+#include "util/test_db.h"
+
+static const unsigned kCertStorageDepth = 3;
+static const unsigned kTreeStorageDepth = 8;
+
+template <>
+void TestDB<cert_trans::FileDB>::Setup() {
+  std::string certs_dir = tmp_.TmpStorageDir() + "/certs";
+  std::string tree_dir = tmp_.TmpStorageDir() + "/tree";
+  std::string meta_dir = tmp_.TmpStorageDir() + "/meta";
+  CHECK_ERR(mkdir(certs_dir.c_str(), 0700));
+  CHECK_ERR(mkdir(tree_dir.c_str(), 0700));
+  CHECK_ERR(mkdir(meta_dir.c_str(), 0700));
+
+  db_.reset(new cert_trans::FileDB(
+      new cert_trans::FileStorage(certs_dir, kCertStorageDepth),
+      new cert_trans::FileStorage(tree_dir, kTreeStorageDepth),
+      new cert_trans::FileStorage(meta_dir, 0)));
+}
+
+template <>
+cert_trans::FileDB* TestDB<cert_trans::FileDB>::SecondDB() {
+  std::string certs_dir = this->tmp_.TmpStorageDir() + "/certs";
+  std::string tree_dir = this->tmp_.TmpStorageDir() + "/tree";
+  std::string meta_dir = this->tmp_.TmpStorageDir() + "/meta";
+  return new cert_trans::FileDB(
+      new cert_trans::FileStorage(certs_dir, kCertStorageDepth),
+      new cert_trans::FileStorage(tree_dir, kTreeStorageDepth),
+      new cert_trans::FileStorage(meta_dir, 0));
+}
+
+template <>
+void TestDB<cert_trans::SQLiteDB>::Setup() {
+  db_.reset(new cert_trans::SQLiteDB(tmp_.TmpStorageDir() + "/sqlite"));
+}
+
+template <>
+cert_trans::SQLiteDB* TestDB<cert_trans::SQLiteDB>::SecondDB() {
+  return new cert_trans::SQLiteDB(tmp_.TmpStorageDir() + "/sqlite");
+}
+
+template <>
+void TestDB<cert_trans::LevelDB>::Setup() {
+  db_.reset(new cert_trans::LevelDB(tmp_.TmpStorageDir() + "/leveldb"));
+}
+
+template <>
+cert_trans::LevelDB* TestDB<cert_trans::LevelDB>::SecondDB() {
+  // LevelDB won't allow the same DB to be opened concurrently so we have to
+  // close the original.
+  db_.reset();
+  return new cert_trans::LevelDB(tmp_.TmpStorageDir() + "/leveldb");
+}
+
+// Not a Database; we just use the same template for setup.
+template <>
+void TestDB<cert_trans::FileStorage>::Setup() {
+  db_.reset(
+      new cert_trans::FileStorage(tmp_.TmpStorageDir(), kCertStorageDepth));
+}
+
+template <>
+cert_trans::FileStorage* TestDB<cert_trans::FileStorage>::SecondDB() {
+  return new cert_trans::FileStorage(tmp_.TmpStorageDir(), kCertStorageDepth);
+}
+
+#endif  // CERT_TRANS_LOG_TEST_DB_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/test_signer.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/test_signer.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/test_signer.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/test_signer.cc	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,480 @@
+#include "log/test_signer.h"
+
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <openssl/bio.h>
+#include <openssl/evp.h>
+#include <openssl/pem.h>
+#include <openssl/rand.h>
+#include <stdlib.h>
+#include <string>
+
+#include "log/log_signer.h"
+#include "log/logged_entry.h"
+#include "log/signer.h"
+#include "log/verifier.h"
+#include "merkletree/serial_hasher.h"
+#include "merkletree/tree_hasher.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+#include "util/openssl_scoped_types.h"
+#include "util/util.h"
+
+using cert_trans::LoggedEntry;
+using cert_trans::ScopedBIO;
+using cert_trans::Signer;
+using cert_trans::Verifier;
+using ct::DigitallySigned;
+using ct::LogEntry;
+using ct::PrecertChainEntry;
+using ct::SignedCertificateTimestamp;
+using ct::SignedTreeHead;
+using ct::X509ChainEntry;
+using std::string;
+using std::unique_ptr;
+
+namespace {
+
+// A slightly shorter notation for constructing binary blobs from test vectors.
+string B(const char* hexstring) {
+  return util::BinaryString(hexstring);
+}
+
+// A slightly shorter notation for constructing hex strings from binary blobs.
+std::string H(const std::string& byte_string) {
+  return util::HexString(byte_string);
+}
+
+const char kDefaultDerCert[] =
+    "308202ca30820233a003020102020102300d06092a864886f70d01010505003055310b300"
+    "906035504061302474231243022060355040a131b4365727469666963617465205472616e"
+    "73706172656e6379204341310e300c0603550408130557616c65733110300e06035504071"
+    "3074572772057656e301e170d3132303630313030303030305a170d323230363031303030"
+    "3030305a3052310b30090603550406130247423121301f060355040a13184365727469666"
+    "963617465205472616e73706172656e6379310e300c0603550408130557616c6573311030"
+    "0e060355040713074572772057656e30819f300d06092a864886f70d010101050003818d0"
+    "030818902818100b8742267898b99ba6bfd6e6f7ada8e54337f58feb7227c46248437ba5f"
+    "89b007cbe1ecb4545b38ed23fddbf6b9742cafb638157f68184776a1b38ab39318ddd7344"
+    "89b4d750117cd83a220a7b52f295d1e18571469a581c23c68c57d973761d9787a091fb586"
+    "4936b166535e21b427e3c6d690b2e91a87f36b7ec26f59ce53b50203010001a381ac3081a"
+    "9301d0603551d0e041604141184e1187c87956dffc31dd0521ff564efbeae8d307d060355"
+    "1d23047630748014a3b8d89ba2690dfb48bbbf87c1039ddce56256c6a159a4573055310b3"
+    "00906035504061302474231243022060355040a131b436572746966696361746520547261"
+    "6e73706172656e6379204341310e300c0603550408130557616c65733110300e060355040"
+    "713074572772057656e82010030090603551d1304023000300d06092a864886f70d010105"
+    "050003818100292ecf6e46c7a0bcd69051739277710385363341c0a9049637279707ae23c"
+    "c5128a4bdea0d480ed0206b39e3a77a2b0c49b0271f4140ab75c1de57aba498e09459b479"
+    "cf92a4d5d5dd5cbe3f0a11e25f04078df88fc388b61b867a8de46216c0e17c31fc7d8003e"
+    "cc37be22292f84242ab87fb08bd4dfa3c1b9ce4d3ee6667da";
+
+const char kDefaultDerPrecert[] =
+    "308202df30820248a003020102020107300d06092a864886f70d01010505003055310b300"
+    "906035504061302474231243022060355040a131b4365727469666963617465205472616e"
+    "73706172656e6379204341310e300c0603550408130557616c65733110300e06035504071"
+    "3074572772057656e301e170d3132303630313030303030305a170d323230363031303030"
+    "3030305a3052310b30090603550406130247423121301f060355040a13184365727469666"
+    "963617465205472616e73706172656e6379310e300c0603550408130557616c6573311030"
+    "0e060355040713074572772057656e30819f300d06092a864886f70d010101050003818d0"
+    "030818902818100bed8893cc8f177efc548df4961443f999aeda90471992f818bf8b61d0d"
+    "f19d6eec3d596c9b43e60033a501c8cffcc438f49f5edb3662aaaecf180e7c9b59fc4bd46"
+    "5c18c406b3b70cdde52d5dec42aaef913c2173592c76130f2399de6ccd6e75e04ccea7d7e"
+    "4bdf4bacb16b5fe6972974bca8bcb3e8468dec941e945fdf98310203010001a381c13081b"
+    "e301d0603551d0e04160414a4998f6b0abefd0e549bd56f221da976d0ce57d6307d060355"
+    "1d2304763074801436331299dbdc389d1cccfe31c08b8932501a8f7ca159a4573055310b3"
+    "00906035504061302474231243022060355040a131b436572746966696361746520547261"
+    "6e73706172656e6379204341310e300c0603550408130557616c65733110300e060355040"
+    "713074572772057656e82010030090603551d13040230003013060a2b06010401d6790204"
+    "030101ff04020500300d06092a864886f70d010105050003818100baccef72c1ae51a83fd"
+    "1d3f5c76ccd646010e8abab447756747049e5213ec54c38f612723cf94abe9b6d7bb9b402"
+    "1ff39d36612566aba1d6ef2a3be66f0a9bb31e8927c97f983a51b1039843dda4399b4ddc3"
+    "09b7c22b5d31eeed18a5ae2525a1c3a8be126cf53d54583f684f0882b950cb5fd9362ea2b"
+    "df982bc70d273b9085";
+
+const char kDefaultKeyHash[] =
+    "2518ce9dcf869f18562d21cf7d040cbacc75371f019f8bea8cbe2f5f6619472d";
+
+const char kDefaultDerTbsCert[] =
+    "30820233a003020102020107300d06092a864886f70d01010505003055310b30090603550"
+    "4061302474231243022060355040a131b4365727469666963617465205472616e73706172"
+    "656e6379204341310e300c0603550408130557616c65733110300e0603550407130745727"
+    "72057656e301e170d3132303630313030303030305a170d3232303630313030303030305a"
+    "3052310b30090603550406130247423121301f060355040a1318436572746966696361746"
+    "5205472616e73706172656e6379310e300c0603550408130557616c65733110300e060355"
+    "040713074572772057656e30819f300d06092a864886f70d010101050003818d003081890"
+    "2818100bed8893cc8f177efc548df4961443f999aeda90471992f818bf8b61d0df19d6eec"
+    "3d596c9b43e60033a501c8cffcc438f49f5edb3662aaaecf180e7c9b59fc4bd465c18c406"
+    "b3b70cdde52d5dec42aaef913c2173592c76130f2399de6ccd6e75e04ccea7d7e4bdf4bac"
+    "b16b5fe6972974bca8bcb3e8468dec941e945fdf98310203010001a381ac3081a9301d060"
+    "3551d0e04160414a4998f6b0abefd0e549bd56f221da976d0ce57d6307d0603551d230476"
+    "3074801436331299dbdc389d1cccfe31c08b8932501a8f7ca159a4573055310b300906035"
+    "504061302474231243022060355040a131b4365727469666963617465205472616e737061"
+    "72656e6379204341310e300c0603550408130557616c65733110300e06035504071307457"
+    "2772057656e82010030090603551d1304023000";
+
+// Some time in September 2012.
+const uint64_t kDefaultSCTTimestamp = 1348589665525LL;
+
+const char kDefaultCertSCTSignature[] =
+    "3046022100d3f7690e7ee80d9988a54a3821056393e9eb0c686ad67fbae3686c888fb1a3c"
+    "e022100f9a51c6065bbba7ad7116a31bea1c31dbed6a921e1df02e4b403757fae3254ae";
+
+const char kDefaultPrecertSCTSignature[] =
+    "304502206f247c7d1abe2b8f6c4530f99474f9ebe90629d21f76616389336f177ed7a7d00"
+    "221009d3a60c2b407ab5a725a692fc79d0d301d6da61baec43175ed07514c535f1120";
+
+// Some time in September 2012.
+const uint64_t kDefaultSTHTimestamp = 1348589667204LL;
+
+const int64_t kDefaultTreeSize = 42;
+
+// *Some* hash that we pretend is a valid root hash.
+const char kDefaultRootHash[] =
+    "18041bd4665083001fba8c5411d2d748e8abbfdcdfd9218cb02b68a78e7d4c23";
+
+const char kDefaultSTHSerialized[] =
+    "000100000139fe354384000000000000002a18041bd4665083001fba8c5411d2d748e8abb"
+    "fdcdfd9218cb02b68a78e7d4c23";
+
+const char kDefaultSTHSignature[] =
+    "3046022100befd8060563763a5e49ba53e6443c13f7624fd6403178113736e16012aca983"
+    "e022100f572568dbfe9a86490eb915c4ee16ad5ecd708fed35ed4e5cd1b2c3f087b4130";
+
+
+const char kEcP256PrivateKey[] =
+    "-----BEGIN EC PRIVATE KEY-----\n"
+    "MHcCAQEEIG8QAquNnarN6Ik2cMIZtPBugh9wNRe0e309MCmDfBGuoAoGCCqGSM49\n"
+    "AwEHoUQDQgAES0AfBkjr7b8b19p5Gk8plSAN16wWXZyhYsH6FMCEUK60t7pem/ck\n"
+    "oPX8hupuaiJzJS0ZQ0SEoJGlFxkUFwft5g==\n"
+    "-----END EC PRIVATE KEY-----\n";
+
+const char kEcP256PublicKey[] =
+    "-----BEGIN PUBLIC KEY-----\n"
+    "MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAES0AfBkjr7b8b19p5Gk8plSAN16wW\n"
+    "XZyhYsH6FMCEUK60t7pem/ckoPX8hupuaiJzJS0ZQ0SEoJGlFxkUFwft5g==\n"
+    "-----END PUBLIC KEY-----\n";
+
+const char kKeyID[] =
+    "b69d879e3f2c4402556dcda2f6b2e02ff6b6df4789c53000e14f4b125ae847aa";
+
+EVP_PKEY* PrivateKeyFromPem(const string& pemkey) {
+  // BIO_new_mem_buf is read-only.
+  ScopedBIO bio(
+      BIO_new_mem_buf(const_cast<char*>(pemkey.data()), pemkey.size()));
+  EVP_PKEY* pkey = PEM_read_bio_PrivateKey(bio.get(), NULL, NULL, NULL);
+  CHECK_NOTNULL(pkey);
+  return pkey;
+}
+
+EVP_PKEY* PublicKeyFromPem(const string& pemkey) {
+  ScopedBIO bio(
+      BIO_new_mem_buf(const_cast<char*>(pemkey.data()), pemkey.size()));
+  EVP_PKEY* pkey = PEM_read_bio_PUBKEY(bio.get(), NULL, NULL, NULL);
+  CHECK_NOTNULL(pkey);
+  return pkey;
+}
+
+}  // namespace
+
+TestSigner::TestSigner()
+    : default_signer_(NULL),
+      counter_(0),
+      default_cert_(B(kDefaultDerCert)),
+      tree_hasher_(unique_ptr<Sha256Hasher>(new Sha256Hasher)) {
+  counter_ = util::TimeInMilliseconds();
+  srand(counter_);
+  EVP_PKEY* pkey = PrivateKeyFromPem(kEcP256PrivateKey);
+  CHECK_NOTNULL(pkey);
+  default_signer_ = new LogSigner(pkey);
+}
+
+TestSigner::~TestSigner() {
+  delete default_signer_;
+}
+
+// Caller owns result.
+// Call as many times as required to get a fresh copy every time.
+// static
+Signer* TestSigner::DefaultSigner() {
+  EVP_PKEY* pkey = PrivateKeyFromPem(kEcP256PrivateKey);
+  CHECK_NOTNULL(pkey);
+  return new Signer(pkey);
+}
+
+// Caller owns result.
+// Call as many times as required to get a fresh copy every time.
+// static
+LogSigner* TestSigner::DefaultLogSigner() {
+  EVP_PKEY* pkey = PrivateKeyFromPem(kEcP256PrivateKey);
+  CHECK_NOTNULL(pkey);
+  return new LogSigner(pkey);
+}
+
+// Caller owns result.
+// Call as many times as required to get a fresh copy every time.
+// static
+Verifier* TestSigner::DefaultVerifier() {
+  EVP_PKEY* pubkey = PublicKeyFromPem(kEcP256PublicKey);
+  CHECK_NOTNULL(pubkey);
+  return new Verifier(pubkey);
+}
+
+// Caller owns result.
+// Call as many times as required to get a fresh copy every time.
+// static
+LogSigVerifier* TestSigner::DefaultLogSigVerifier() {
+  EVP_PKEY* pubkey = PublicKeyFromPem(kEcP256PublicKey);
+  CHECK_NOTNULL(pubkey);
+  return new LogSigVerifier(pubkey);
+}
+
+// static
+void TestSigner::SetDefaults(string* data, string* signature) {
+  *data = B(kDefaultSTHSerialized);
+  *signature = B(kDefaultSTHSignature);
+}
+
+// static
+void TestSigner::SetDefaults(LogEntry* entry) {
+  entry->set_type(ct::X509_ENTRY);
+  entry->mutable_x509_entry()->set_leaf_certificate(B(kDefaultDerCert));
+}
+
+// static
+void TestSigner::SetDefaults(SignedCertificateTimestamp* sct) {
+  sct->set_version(ct::V1);
+  sct->mutable_id()->set_key_id(B(kKeyID));
+  sct->set_timestamp(kDefaultSCTTimestamp);
+  sct->clear_extensions();
+  sct->mutable_signature()->set_hash_algorithm(DigitallySigned::SHA256);
+  sct->mutable_signature()->set_sig_algorithm(DigitallySigned::ECDSA);
+  sct->mutable_signature()->set_signature(B(kDefaultCertSCTSignature));
+}
+
+// static
+void TestSigner::SetPrecertDefaults(LogEntry* entry) {
+  entry->set_type(ct::PRECERT_ENTRY);
+  entry->mutable_precert_entry()->set_pre_certificate(B(kDefaultDerPrecert));
+  entry->mutable_precert_entry()->mutable_pre_cert()->set_issuer_key_hash(
+      B(kDefaultKeyHash));
+  entry->mutable_precert_entry()->mutable_pre_cert()->set_tbs_certificate(
+      B(kDefaultDerTbsCert));
+}
+
+// static
+void TestSigner::SetPrecertDefaults(SignedCertificateTimestamp* sct) {
+  sct->set_version(ct::V1);
+  sct->mutable_id()->set_key_id(B(kKeyID));
+  sct->set_timestamp(kDefaultSCTTimestamp);
+  sct->clear_extensions();
+  sct->mutable_signature()->set_hash_algorithm(DigitallySigned::SHA256);
+  sct->mutable_signature()->set_sig_algorithm(DigitallySigned::ECDSA);
+  sct->mutable_signature()->set_signature(B(kDefaultPrecertSCTSignature));
+}
+
+// static
+void TestSigner::SetDefaults(LoggedEntry* logged_cert) {
+  // Some time in September 2012.
+  SetDefaults(logged_cert->mutable_sct());
+  SetDefaults(logged_cert->mutable_entry());
+}
+
+// static
+void TestSigner::SetDefaults(SignedTreeHead* tree_head) {
+  tree_head->set_version(ct::V1);
+  tree_head->mutable_id()->set_key_id(B(kKeyID));
+  tree_head->set_timestamp(kDefaultSTHTimestamp);
+  tree_head->set_tree_size(kDefaultTreeSize);
+  tree_head->set_sha256_root_hash(B(kDefaultRootHash));
+  tree_head->mutable_signature()->set_hash_algorithm(DigitallySigned::SHA256);
+  tree_head->mutable_signature()->set_sig_algorithm(DigitallySigned::ECDSA);
+  tree_head->mutable_signature()->set_signature(B(kDefaultSTHSignature));
+}
+
+string TestSigner::UniqueFakeCertBytestring() {
+  string counter_suffix = Serializer::SerializeUint(counter_++, 8);
+  int length = (rand() % 512) + 512 - counter_suffix.size();
+
+  string ret;
+  while (length >= 256) {
+    unsigned offset = rand() & 0xff;
+    DCHECK_LE(offset + 256, default_cert_.size());
+    ret.append(default_cert_.substr(offset, 256));
+    length -= 256;
+  }
+
+  if (length > 0) {
+    int offset = rand() & 0xff;
+    ret.append(default_cert_.substr(offset, length));
+  }
+
+  ret.append(counter_suffix);
+  return ret;
+}
+
+string TestSigner::UniqueHash() {
+  string counter = Serializer::SerializeUint(counter_++, 8);
+  return Sha256Hasher::Sha256Digest(counter);
+}
+
+void TestSigner::CreateUnique(LogEntry* entry) {
+  int random_bits = rand();
+  ct::LogEntryType type = random_bits & 1 ? ct::X509_ENTRY : ct::PRECERT_ENTRY;
+
+  entry->set_type(type);
+  entry->clear_x509_entry();
+  entry->clear_precert_entry();
+
+  if (type == ct::X509_ENTRY) {
+    entry->mutable_x509_entry()->set_leaf_certificate(
+        UniqueFakeCertBytestring());
+    if (random_bits & 2) {
+      entry->mutable_x509_entry()->add_certificate_chain(
+          UniqueFakeCertBytestring());
+
+      if (random_bits & 4) {
+        entry->mutable_x509_entry()->add_certificate_chain(
+            UniqueFakeCertBytestring());
+      }
+    }
+  } else {
+    entry->mutable_precert_entry()->set_pre_certificate(
+        UniqueFakeCertBytestring());
+    entry->mutable_precert_entry()->mutable_pre_cert()->set_issuer_key_hash(
+        UniqueHash());
+    entry->mutable_precert_entry()->mutable_pre_cert()->set_tbs_certificate(
+        UniqueFakeCertBytestring());
+    if (random_bits & 2) {
+      entry->mutable_precert_entry()->add_precertificate_chain(
+          UniqueFakeCertBytestring());
+
+      if (random_bits & 4) {
+        entry->mutable_precert_entry()->add_precertificate_chain(
+            UniqueFakeCertBytestring());
+      }
+    }
+  }
+}
+
+void TestSigner::CreateUnique(LoggedEntry* logged_cert) {
+  FillData(logged_cert);
+  logged_cert->set_sequence_number(rand());
+
+  CHECK_EQ(LogSigner::OK,
+           default_signer_->SignCertificateTimestamp(
+               logged_cert->entry(), logged_cert->mutable_sct()));
+}
+
+void TestSigner::CreateUniqueFakeSignature(LoggedEntry* logged_cert) {
+  FillData(logged_cert);
+
+  logged_cert->mutable_sct()->mutable_signature()->set_hash_algorithm(
+      DigitallySigned::SHA256);
+  logged_cert->mutable_sct()->mutable_signature()->set_sig_algorithm(
+      DigitallySigned::ECDSA);
+  logged_cert->mutable_sct()->mutable_signature()->set_signature(
+      B(kDefaultCertSCTSignature));
+}
+
+void TestSigner::CreateUnique(SignedTreeHead* sth) {
+  sth->set_version(ct::V1);
+  sth->set_timestamp(util::TimeInMilliseconds());
+  sth->set_tree_size(rand());
+  sth->set_sha256_root_hash(UniqueHash());
+  CHECK_EQ(LogSigner::OK, default_signer_->SignTreeHead(sth));
+}
+
+// static
+void TestSigner::TestEqualDigitallySigned(const DigitallySigned& ds0,
+                                          const DigitallySigned& ds1) {
+  EXPECT_EQ(ds0.hash_algorithm(), ds1.hash_algorithm());
+  EXPECT_EQ(ds0.sig_algorithm(), ds1.sig_algorithm());
+  EXPECT_EQ(H(ds0.signature()), H(ds1.signature()));
+}
+
+// static
+void TestSigner::TestEqualX509Entries(const X509ChainEntry& entry0,
+                                      const X509ChainEntry& entry1) {
+  EXPECT_EQ(H(entry0.leaf_certificate()), H(entry1.leaf_certificate()));
+  EXPECT_EQ(entry0.certificate_chain_size(), entry1.certificate_chain_size());
+  for (int i = 0; i < entry0.certificate_chain_size(); ++i)
+    EXPECT_EQ(H(entry0.certificate_chain(i)), H(entry1.certificate_chain(i)));
+}
+
+// static
+void TestSigner::TestEqualPreEntries(const PrecertChainEntry& entry0,
+                                     const PrecertChainEntry& entry1) {
+  EXPECT_EQ(H(entry0.pre_certificate()), H(entry1.pre_certificate()));
+  EXPECT_EQ(entry0.precertificate_chain_size(),
+            entry1.precertificate_chain_size());
+  for (int i = 0; i < entry0.precertificate_chain_size(); ++i)
+    EXPECT_EQ(H(entry0.precertificate_chain(i)),
+              H(entry1.precertificate_chain(i)));
+
+  EXPECT_EQ(H(entry0.pre_cert().issuer_key_hash()),
+            H(entry1.pre_cert().issuer_key_hash()));
+  EXPECT_EQ(H(entry0.pre_cert().tbs_certificate()),
+            H(entry1.pre_cert().tbs_certificate()));
+}
+
+// static
+void TestSigner::TestEqualEntries(const LogEntry& entry0,
+                                  const LogEntry& entry1) {
+  EXPECT_EQ(entry0.type(), entry1.type());
+  if (entry0.type() == ct::X509_ENTRY)
+    TestEqualX509Entries(entry0.x509_entry(), entry1.x509_entry());
+  if (entry1.type() == ct::PRECERT_ENTRY)
+    TestEqualPreEntries(entry0.precert_entry(), entry1.precert_entry());
+}
+
+// static
+void TestSigner::TestEqualSCTs(const SignedCertificateTimestamp& sct0,
+                               const SignedCertificateTimestamp& sct1) {
+  EXPECT_EQ(sct0.version(), sct1.version());
+  EXPECT_EQ(sct0.id().key_id(), sct1.id().key_id());
+  EXPECT_EQ(sct0.timestamp(), sct1.timestamp());
+  TestEqualDigitallySigned(sct0.signature(), sct1.signature());
+}
+
+// static
+void TestSigner::TestEqualLoggedCerts(const LoggedEntry& c0,
+                                      const LoggedEntry& c1) {
+  TestEqualEntries(c0.entry(), c1.entry());
+  TestEqualSCTs(c0.sct(), c1.sct());
+
+  EXPECT_EQ(H(c0.Hash()), H(c1.Hash()));
+  EXPECT_EQ(c0.has_sequence_number(), c1.has_sequence_number());
+  // Defaults to 0 if not set.
+  EXPECT_EQ(c0.sequence_number(), c1.sequence_number());
+}
+
+// static
+void TestSigner::TestEqualTreeHeads(const SignedTreeHead& sth0,
+                                    const SignedTreeHead& sth1) {
+  EXPECT_EQ(sth0.version(), sth1.version());
+  EXPECT_EQ(sth0.id().key_id(), sth1.id().key_id());
+  EXPECT_EQ(sth0.tree_size(), sth1.tree_size());
+  EXPECT_EQ(sth0.timestamp(), sth1.timestamp());
+  EXPECT_EQ(H(sth0.sha256_root_hash()), H(sth1.sha256_root_hash()));
+  TestEqualDigitallySigned(sth0.signature(), sth1.signature());
+}
+
+void TestSigner::FillData(LoggedEntry* logged_cert) {
+  logged_cert->mutable_sct()->set_version(ct::V1);
+  logged_cert->mutable_sct()->mutable_id()->set_key_id(B(kKeyID));
+  logged_cert->mutable_sct()->set_timestamp(util::TimeInMilliseconds());
+  logged_cert->mutable_sct()->clear_extensions();
+
+  CreateUnique(logged_cert->mutable_entry());
+
+  CHECK_EQ(logged_cert->Hash(),
+           Sha256Hasher::Sha256Digest(
+               Serializer::LeafData(logged_cert->entry())));
+  string serialized_leaf;
+  CHECK_EQ(cert_trans::serialization::SerializeResult::OK,
+           Serializer::SerializeSCTMerkleTreeLeaf(logged_cert->sct(),
+                                                  logged_cert->entry(),
+                                                  &serialized_leaf));
+  logged_cert->set_merkle_leaf_hash(tree_hasher_.HashLeaf(serialized_leaf));
+
+  logged_cert->clear_sequence_number();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/test_signer.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/test_signer.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/test_signer.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/test_signer.h	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,122 @@
+#ifndef CERT_TRANS_LOG_TEST_SIGNER_H_
+#define CERT_TRANS_LOG_TEST_SIGNER_H_
+
+#include <gtest/gtest.h>
+#include <stdint.h>
+#include <string>
+
+#include "log/log_signer.h"
+#include "merkletree/tree_hasher.h"
+
+namespace cert_trans {
+class LoggedEntry;
+class Signer;
+class Verifier;
+}
+
+// Helper class for database tests that generates test data
+// that roughly resembles real certificate data in shape and size.
+class TestSigner {
+ public:
+  TestSigner();
+  ~TestSigner();
+
+  static cert_trans::Signer* DefaultSigner();
+  static LogSigner* DefaultLogSigner();
+
+  static cert_trans::Verifier* DefaultVerifier();
+  static LogSigVerifier* DefaultLogSigVerifier();
+
+  // A string and its signature.
+  static void SetDefaults(std::string* data, std::string* signature);
+
+  // For KAT tests: an SCT with a valid signature.
+  // The default type is X509_ENTRY.
+  static void SetDefaults(ct::LogEntry* entry);
+
+  static void SetDefaults(ct::SignedCertificateTimestamp* sct);
+
+  static void SetPrecertDefaults(ct::LogEntry* entry);
+
+  static void SetPrecertDefaults(ct::SignedCertificateTimestamp* sct);
+
+  // For KAT tests: a logged cert with a valid hash and signature.
+  // TODO(ekasper): add an intermediate for better coverage.
+  static void SetDefaults(cert_trans::LoggedEntry* logged_cert);
+
+  // For KAT tests: a tree head with a valid signature.
+  // Uses SHA256 for the tree hash.
+  static void SetDefaults(ct::SignedTreeHead* tree_head);
+
+  // simulate a cert DER string - 512-1023 randomized (not random!) bytes.
+  // The bytes are obtained by (a) copying chunks of 256 bytes from
+  // offsets 0 - 255 of the default cert and (b) appending a counter value
+  // (derived from current time) to further guarantee no collisions.
+  // (Note that real DER certs always start with 0x30...)
+  std::string UniqueFakeCertBytestring();
+
+  // Sha256(counter).
+  std::string UniqueHash();
+
+  // Generates a randomized entry as follows:
+  // type - chosen randomly between all options
+  // leaf_certificate - 512-1023 randomized (not random!) bytes.
+  // intermediates - 50%, none; 25%, 1; 25%, 2.
+  void CreateUnique(ct::LogEntry* entry);
+
+  // timestamp - current
+  // signature - valid signature from the default signer
+  // hash - valid sha256 hash of the leaf certificate
+  // sequence number - cleared
+  void CreateUnique(cert_trans::LoggedEntry* logged_cert);
+
+  // Same as above but set the default signature to avoid overhead from
+  // signing.
+  void CreateUniqueFakeSignature(cert_trans::LoggedEntry* logged_cert);
+
+  // Generates a randomized entry as follows:
+  // timestamp - current
+  // tree size - [0, RAND_MAX]
+  // root hash - random unique hash
+  // signature - valid on the above
+  void CreateUnique(ct::SignedTreeHead* sth);
+
+  // Helper methods for unit tests. Compare protobufs with a set of
+  // EXPECT_EQ macros.
+
+  static void TestEqualDigitallySigned(const ct::DigitallySigned& ds0,
+                                       const ct::DigitallySigned& ds1);
+
+  static void TestEqualX509Entries(const ct::X509ChainEntry& entry0,
+                                   const ct::X509ChainEntry& entry1);
+
+  static void TestEqualPreEntries(const ct::PrecertChainEntry& entry0,
+                                  const ct::PrecertChainEntry& entry1);
+
+  static void TestEqualEntries(const ct::LogEntry& entry0,
+                               const ct::LogEntry& entry1);
+
+  static void TestEqualSCTs(const ct::SignedCertificateTimestamp& sct0,
+                            const ct::SignedCertificateTimestamp& sct1);
+
+  static void TestEqualLoggedCerts(const cert_trans::LoggedEntry& c1,
+                                   const cert_trans::LoggedEntry& c2);
+
+  static void TestEqualTreeHeads(const ct::SignedTreeHead& sth1,
+                                 const ct::SignedTreeHead& sth2);
+
+
+ private:
+  // Fill everything apart from the signature.
+  void FillData(cert_trans::LoggedEntry* logged_cert);
+
+  LogSigner* default_signer_;
+  // ct::SignedCertificateTimestamp default_sct_;
+  // ct::SignedTreeHead default_sth_;
+  uint64_t counter_;
+  // Binary blob.
+  std::string default_cert_;
+  TreeHasher tree_hasher_;
+};
+
+#endif  // CERT_TRANS_LOG_TEST_SIGNER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/tree_signer.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/tree_signer.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/tree_signer.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/tree_signer.cc	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,323 @@
+#include "log/tree_signer.h"
+
+#include <glog/logging.h>
+#include <stdint.h>
+#include <algorithm>
+#include <chrono>
+#include <set>
+#include <unordered_map>
+
+#include "log/database.h"
+#include "log/log_signer.h"
+#include "proto/serializer.h"
+#include "util/status.h"
+#include "util/util.h"
+
+using ct::ClusterNodeState;
+using ct::SequenceMapping;
+using ct::SequenceMapping_Mapping;
+using ct::SignedTreeHead;
+using std::chrono::duration;
+using std::chrono::milliseconds;
+using std::chrono::system_clock;
+using std::make_pair;
+using std::map;
+using std::max;
+using std::move;
+using std::pair;
+using std::sort;
+using std::string;
+using std::unique_ptr;
+using std::unordered_map;
+using std::vector;
+using util::Status;
+using util::StatusOr;
+using util::TimeInMilliseconds;
+using util::ToBase64;
+
+namespace cert_trans {
+namespace {
+
+
+bool LessThanBySequence(const SequenceMapping::Mapping& lhs,
+                        const SequenceMapping::Mapping& rhs) {
+  CHECK(lhs.has_sequence_number());
+  CHECK(rhs.has_sequence_number());
+  return lhs.sequence_number() < rhs.sequence_number();
+}
+
+
+}  // namespace
+
+
+// Comparator for ordering pending hashes.
+// Order by timestamp then hash.
+bool PendingEntriesOrder::operator()(const EntryHandle<LoggedEntry>& x,
+                                     const EntryHandle<LoggedEntry>& y) const {
+  CHECK(x.Entry().contents().sct().has_timestamp());
+  CHECK(y.Entry().contents().sct().has_timestamp());
+  const uint64_t x_time(x.Entry().contents().sct().timestamp());
+  const uint64_t y_time(y.Entry().contents().sct().timestamp());
+  if (x_time < y_time) {
+    return true;
+  } else if (x_time > y_time) {
+    return false;
+  }
+
+  // Fallback to Hash as a final tie-breaker:
+  return x.Entry().Hash() < y.Entry().Hash();
+}
+
+
+TreeSigner::TreeSigner(const duration<double>& guard_window, Database* db,
+                       unique_ptr<CompactMerkleTree> merkle_tree,
+                       ConsistentStore* consistent_store, LogSigner* signer)
+    : guard_window_(guard_window),
+      db_(db),
+      consistent_store_(consistent_store),
+      signer_(signer),
+      cert_tree_(move(merkle_tree)),
+      latest_tree_head_() {
+  CHECK(cert_tree_);
+  // Try to get any STH previously published by this node.
+  const StatusOr<ClusterNodeState> node_state(
+      consistent_store_->GetClusterNodeState());
+  CHECK(node_state.ok() ||
+        node_state.status().CanonicalCode() == util::error::NOT_FOUND)
+      << "Problem fetching this node's previous state: "
+      << node_state.status();
+  if (node_state.ok()) {
+    latest_tree_head_ = node_state.ValueOrDie().newest_sth();
+  }
+}
+
+
+uint64_t TreeSigner::LastUpdateTime() const {
+  return latest_tree_head_.timestamp();
+}
+
+
+Status TreeSigner::SequenceNewEntries() {
+  const system_clock::time_point now(system_clock::now());
+  StatusOr<int64_t> status_or_sequence_number(
+      consistent_store_->NextAvailableSequenceNumber());
+  if (!status_or_sequence_number.ok()) {
+    return status_or_sequence_number.status();
+  }
+  int64_t next_sequence_number(status_or_sequence_number.ValueOrDie());
+  CHECK_GE(next_sequence_number, 0);
+  VLOG(1) << "Next available sequence number: " << next_sequence_number;
+
+  EntryHandle<SequenceMapping> mapping;
+  Status status(consistent_store_->GetSequenceMapping(&mapping));
+  if (!status.ok()) {
+    return status;
+  }
+
+  // Hashes which are already sequenced.
+  unordered_map<string, pair<int64_t, bool /*present*/>> sequenced_hashes;
+  for (const auto& m : mapping.Entry().mapping()) {
+    // Go home clang-format, you're drunk.
+    CHECK(sequenced_hashes
+              .insert(make_pair(m.entry_hash(),
+                                make_pair(m.sequence_number(), false)))
+              .second);
+  }
+
+  vector<EntryHandle<LoggedEntry>> pending_entries;
+  status = consistent_store_->GetPendingEntries(&pending_entries);
+  if (!status.ok()) {
+    return status;
+  }
+  sort(pending_entries.begin(), pending_entries.end(), PendingEntriesOrder());
+
+  VLOG(1) << "Sequencing " << pending_entries.size() << " entr"
+          << (pending_entries.size() == 1 ? "y" : "ies");
+
+  // We're going to update the sequence mapping based on the following rules:
+  // 1) existing sequence mappings whose corresponding PendingEntry still
+  //    exists will remain in the mappings file.
+  // 2) PendingEntries which do not have a corresponding sequence mapping will
+  //    gain one.
+  // 3) mappings whose corresponding PendingEntry no longer exists will be
+  //    removed from the sequence mapping file.
+  google::protobuf::RepeatedPtrField<SequenceMapping_Mapping> new_mapping;
+  map<int64_t, const LoggedEntry*> seq_to_entry;
+  int num_sequenced(0);
+  for (auto& pending_entry : pending_entries) {
+    const string& pending_hash(pending_entry.Entry().Hash());
+    const system_clock::time_point cert_time(
+        milliseconds(pending_entry.Entry().timestamp()));
+    if (now - cert_time < guard_window_) {
+      VLOG(1) << "Entry too recent: "
+              << ToBase64(pending_entry.Entry().Hash());
+      continue;
+    }
+    const auto seq_it(sequenced_hashes.find(pending_hash));
+    SequenceMapping::Mapping* const seq_mapping(new_mapping.Add());
+
+    if (seq_it == sequenced_hashes.end()) {
+      // Need to sequence this one.
+      VLOG(1) << ToBase64(pending_hash) << " = " << next_sequence_number;
+
+      // Record the sequence -> hash mapping
+      seq_mapping->set_sequence_number(next_sequence_number);
+      seq_mapping->set_entry_hash(pending_entry.Entry().Hash());
+      pending_entry.MutableEntry()->set_sequence_number(next_sequence_number);
+      ++num_sequenced;
+      ++next_sequence_number;
+    } else {
+      VLOG(1) << "Previously sequenced " << ToBase64(pending_hash) << " = "
+              << seq_it->second.first;
+      CHECK(!seq_it->second.second /*present*/)
+          << "Saw same sequenced cert twice.";
+      CHECK(!pending_entry.Entry().has_sequence_number());
+      seq_it->second.second = true;  // present
+
+      seq_mapping->set_entry_hash(seq_it->first);
+      seq_mapping->set_sequence_number(seq_it->second.first);
+      pending_entry.MutableEntry()->set_sequence_number(seq_it->second.first);
+    }
+    CHECK(seq_to_entry
+              .insert(make_pair(pending_entry.Entry().sequence_number(),
+                                pending_entry.MutableEntry()))
+              .second);
+  }
+
+  const StatusOr<SignedTreeHead> serving_sth(
+      consistent_store_->GetServingSTH());
+  if (!serving_sth.ok()) {
+    LOG(WARNING) << "Failed to get ServingSTH: " << serving_sth.status();
+    return serving_sth.status();
+  }
+
+  // Sanity check: make sure no hashes above the serving_sth level vanished:
+  CHECK_LE(serving_sth.ValueOrDie().tree_size(), INT64_MAX);
+  const int64_t serving_tree_size(serving_sth.ValueOrDie().tree_size());
+  for (const auto& s : sequenced_hashes) {
+    if (!s.second.second /*present*/) {
+      // if it disappeared, check it's underwater:
+      CHECK_LT(s.second.first, serving_tree_size);
+    }
+  }
+
+  if (new_mapping.size() > 0) {
+    sort(new_mapping.begin(), new_mapping.end(), LessThanBySequence);
+    CHECK_LE(new_mapping.Get(0).sequence_number(), serving_tree_size);
+  }
+
+  // Update the mapping proto with our new mappings
+  mapping.MutableEntry()->mutable_mapping()->Swap(&new_mapping);
+
+  // Store updated sequence->hash mappings in the consistent store
+  status = consistent_store_->UpdateSequenceMapping(&mapping);
+  if (!status.ok()) {
+    return status;
+  }
+
+  // Now add the sequenced entries to our local DB so that the local signer can
+  // incorporate them.
+  for (auto it(seq_to_entry.find(db_->TreeSize())); it != seq_to_entry.end();
+       ++it) {
+    VLOG(1) << "Adding to local DB: " << it->first;
+    CHECK_EQ(it->first, it->second->sequence_number());
+    CHECK_EQ(Database::OK, db_->CreateSequencedEntry(*(it->second)));
+  }
+
+  VLOG(1) << "Sequenced " << num_sequenced << " entries.";
+
+  return Status::OK;
+}
+
+
+// DB_ERROR: the database is inconsistent with our inner self.
+// However, if the database itself is giving inconsistent answers, or failing
+// reads/writes, then we die.
+typename TreeSigner::UpdateResult TreeSigner::UpdateTree() {
+  // Try to make local timestamps unique, but there's always a chance that
+  // multiple nodes in the cluster may make STHs with the same timestamp.
+  // That'll get handled by the Serving STH selection code.
+  uint64_t min_timestamp = LastUpdateTime() + 1;
+
+  // Add any newly sequenced entries from our local DB.
+  auto it(db_->ScanEntries(cert_tree_->LeafCount()));
+  for (int64_t i(cert_tree_->LeafCount());; ++i) {
+    LoggedEntry logged;
+    if (!it->GetNextEntry(&logged) || logged.sequence_number() != i) {
+      break;
+    }
+    CHECK_EQ(logged.sequence_number(), i);
+    AppendToTree(logged);
+    min_timestamp = max(min_timestamp, logged.sct().timestamp());
+  }
+  int64_t next_seq(cert_tree_->LeafCount());
+  CHECK_GE(next_seq, 0);
+
+  // Our tree is consistent with the database, i.e., each leaf in the tree has
+  // a matching sequence number in the database (at least assuming overwriting
+  // the sequence number is not allowed).
+  SignedTreeHead new_sth;
+  TimestampAndSign(min_timestamp, &new_sth);
+
+  // We don't actually store this STH anywhere durable yet, but rather let the
+  // caller decide what to do with it.  (In practice, this will mean that it's
+  // pushed out to this node's ClusterNodeState so that it becomes a candidate
+  // for the cluster-wide Serving STH.)
+  latest_tree_head_.CopyFrom(new_sth);
+  return OK;
+}
+
+
+bool TreeSigner::Append(const LoggedEntry& logged) {
+  // Serialize for inclusion in the tree.
+  string serialized_leaf;
+  CHECK(logged.SerializeForLeaf(&serialized_leaf));
+
+  CHECK_LE(cert_tree_->LeafCount(), static_cast<uint64_t>(INT64_MAX));
+  CHECK_EQ(logged.sequence_number(),
+           static_cast<int64_t>(cert_tree_->LeafCount()));
+  // Commit the sequence number of this certificate locally
+  Database::WriteResult db_result = db_->CreateSequencedEntry(logged);
+
+  if (db_result != Database::OK) {
+    CHECK_EQ(Database::SEQUENCE_NUMBER_ALREADY_IN_USE, db_result);
+    LOG(ERROR) << "Attempt to assign duplicate sequence number "
+               << cert_tree_->LeafCount();
+    return false;
+  }
+
+  // Update in-memory tree.
+  cert_tree_->AddLeaf(serialized_leaf);
+  return true;
+}
+
+
+void TreeSigner::AppendToTree(const LoggedEntry& logged) {
+  // Serialize for inclusion in the tree.
+  string serialized_leaf;
+  CHECK(logged.SerializeForLeaf(&serialized_leaf));
+
+  // Update in-memory tree.
+  cert_tree_->AddLeaf(serialized_leaf);
+}
+
+
+void TreeSigner::TimestampAndSign(uint64_t min_timestamp,
+                                  SignedTreeHead* sth) {
+  sth->set_version(ct::V1);
+  sth->set_sha256_root_hash(cert_tree_->CurrentRoot());
+  uint64_t timestamp = TimeInMilliseconds();
+  if (timestamp < min_timestamp)
+    // TODO(ekasper): shouldn't really happen if everyone's clocks are in sync;
+    // log a warning if the skew is over some threshold?
+    timestamp = min_timestamp;
+  sth->set_timestamp(timestamp);
+  sth->set_tree_size(cert_tree_->LeafCount());
+  LogSigner::SignResult ret = signer_->SignTreeHead(sth);
+  if (ret != LogSigner::OK)
+    // Make this one a hard fail. There is really no excuse for it.
+    abort();
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/tree_signer.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/tree_signer.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/tree_signer.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/tree_signer.h	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,94 @@
+#ifndef CERT_TRANS_LOG_TREE_SIGNER_H_
+#define CERT_TRANS_LOG_TREE_SIGNER_H_
+
+#include <stdint.h>
+#include <algorithm>
+#include <chrono>
+
+#include "log/cluster_state_controller.h"
+#include "log/consistent_store.h"
+#include "log/logged_entry.h"
+#include "merkletree/compact_merkle_tree.h"
+#include "proto/ct.pb.h"
+
+
+namespace util {
+class Status;
+}  // namespace util
+
+class LogSigner;
+
+
+namespace cert_trans {
+
+class Database;
+
+
+// Signer for appending new entries to the log.
+// This is the single authority that assigns sequence numbers to new entries,
+// timestamps and signs tree heads. The signer process assumes there are
+// no other signers during its lifetime -- when it discovers the database has
+// received tree updates it has not written, it does not try to recover,
+// but rather reports an error.
+class TreeSigner {
+ public:
+  // No transfer of ownership for params other than merkle_tree whose contents
+  // is moved into this object.
+  TreeSigner(const std::chrono::duration<double>& guard_window, Database* db,
+             std::unique_ptr<CompactMerkleTree> merkle_tree,
+             cert_trans::ConsistentStore* consistent_store, LogSigner* signer);
+
+  enum UpdateResult {
+    OK,
+    // The database is inconsistent with our view.
+    DB_ERROR,
+    // We don't have fresh enough data locally to sign.
+    INSUFFICIENT_DATA,
+  };
+
+  // Latest Tree Head timestamp;
+  uint64_t LastUpdateTime() const;
+
+  util::Status SequenceNewEntries();
+
+  // Simplest update mechanism: take all pending entries and append
+  // (in random order) to the tree. Checks that the update it writes
+  // to the database is consistent with the latest STH.
+  UpdateResult UpdateTree();
+
+  // Latest Tree Head (does not build a new tree, just retrieves the
+  // result of the most recent build).
+  const ct::SignedTreeHead& LatestSTH() const {
+    return latest_tree_head_;
+  }
+
+ private:
+  bool Append(const LoggedEntry& logged);
+  void AppendToTree(const LoggedEntry& logged_cert);
+  void TimestampAndSign(uint64_t min_timestamp, ct::SignedTreeHead* sth);
+
+  const std::chrono::duration<double> guard_window_;
+  Database* const db_;
+  cert_trans::ConsistentStore* const consistent_store_;
+  LogSigner* const signer_;
+  const std::unique_ptr<CompactMerkleTree> cert_tree_;
+  ct::SignedTreeHead latest_tree_head_;
+
+  template <class T>
+  friend class TreeSignerTest;
+};
+
+
+// Comparator for ordering pending hashes.
+// Order by timestamp then hash.
+struct PendingEntriesOrder
+    : std::binary_function<const cert_trans::EntryHandle<LoggedEntry>&,
+                           const cert_trans::EntryHandle<LoggedEntry>&, bool> {
+  bool operator()(const cert_trans::EntryHandle<LoggedEntry>& x,
+                  const cert_trans::EntryHandle<LoggedEntry>& y) const;
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_TREE_SIGNER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/tree_signer_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/tree_signer_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/tree_signer_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/tree_signer_test.cc	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,337 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include <gtest/gtest.h>
+#include <stdint.h>
+#include <memory>
+#include <string>
+
+#include "log/etcd_consistent_store.h"
+#include "log/file_db.h"
+#include "log/log_signer.h"
+#include "log/log_verifier.h"
+#include "log/sqlite_db.h"
+#include "log/test_db.h"
+#include "log/test_signer.h"
+#include "log/tree_signer.h"
+#include "merkletree/merkle_verifier.h"
+#include "proto/cert_serializer.h"
+#include "proto/ct.pb.h"
+#include "util/fake_etcd.h"
+#include "util/mock_masterelection.h"
+#include "util/status_test_util.h"
+#include "util/sync_task.h"
+#include "util/testing.h"
+#include "util/thread_pool.h"
+#include "util/util.h"
+
+namespace cert_trans {
+
+using cert_trans::EntryHandle;
+using cert_trans::LoggedEntry;
+using cert_trans::MockMasterElection;
+using ct::ClusterNodeState;
+using ct::SequenceMapping;
+using ct::SignedTreeHead;
+using std::make_shared;
+using std::move;
+using std::shared_ptr;
+using std::string;
+using std::unique_ptr;
+using std::unordered_map;
+using std::vector;
+using testing::NiceMock;
+using util::Status;
+
+
+// TODO(alcutter): figure out if/how we can keep abstract rather than
+// hardcoding LoggedEntry in here.
+template <class T>
+class TreeSignerTest : public ::testing::Test {
+ protected:
+  TreeSignerTest()
+      : test_db_(),
+        base_(make_shared<libevent::Base>()),
+        event_pump_(base_),
+        etcd_client_(base_.get()),
+        pool_(2),
+        test_signer_(),
+        verifier_(),
+        tree_signer_() {
+  }
+
+  void SetUp() {
+    test_db_.reset(new TestDB<T>);
+    verifier_.reset(new LogVerifier(
+        TestSigner::DefaultLogSigVerifier(),
+        new MerkleVerifier(unique_ptr<Sha256Hasher>(new Sha256Hasher))));
+    store_.reset(new EtcdConsistentStore(base_.get(), &pool_, &etcd_client_,
+                                         &election_, "/root", "id"));
+    log_signer_.reset(TestSigner::DefaultLogSigner());
+    tree_signer_.reset(
+        new TreeSigner(std::chrono::duration<double>(0), db(),
+                       unique_ptr<CompactMerkleTree>(new CompactMerkleTree(
+                           unique_ptr<Sha256Hasher>(new Sha256Hasher))),
+                       store_.get(), log_signer_.get()));
+    // Set a default empty STH so that we can call UpdateTree() on the signer.
+    store_->SetServingSTH(SignedTreeHead());
+    // Force an empty sequence mapping file:
+    {
+      util::SyncTask task(&pool_);
+      EtcdClient::Response r;
+      etcd_client_.ForceSet("/root/sequence_mapping", "", &r, task.task());
+      task.Wait();
+    }
+  }
+
+  void AddPendingEntry(LoggedEntry* logged_cert) const {
+    logged_cert->clear_sequence_number();
+    CHECK(this->store_->AddPendingEntry(logged_cert).ok());
+  }
+
+  void DeletePendingEntry(const LoggedEntry& logged_cert) const {
+    EntryHandle<LoggedEntry> e;
+    CHECK_EQ(Status::OK,
+             this->store_->GetPendingEntryForHash(logged_cert.Hash(), &e));
+    CHECK_EQ(Status::OK, this->store_->DeleteEntry(e));
+  }
+
+  void AddSequencedEntry(LoggedEntry* logged_cert, int64_t seq) const {
+    logged_cert->clear_sequence_number();
+    CHECK(this->store_->AddPendingEntry(logged_cert).ok());
+
+    // This below would normally be done by TreeSigner::SequenceNewEntries()
+    EntryHandle<LoggedEntry> entry;
+    EntryHandle<SequenceMapping> mapping;
+    CHECK(this->store_->GetSequenceMapping(&mapping).ok());
+    SequenceMapping::Mapping* m(mapping.MutableEntry()->add_mapping());
+    m->set_sequence_number(seq);
+    m->set_entry_hash(logged_cert->Hash());
+    CHECK(this->store_->UpdateSequenceMapping(&mapping).ok());
+    logged_cert->set_sequence_number(seq);
+    CHECK_EQ(Database::OK, this->db()->CreateSequencedEntry(*logged_cert));
+  }
+
+
+  TreeSigner* GetSimilar() {
+    return new TreeSigner(std::chrono::duration<double>(0), db(),
+                          unique_ptr<CompactMerkleTree>(new CompactMerkleTree(
+                              *tree_signer_->cert_tree_,
+                              unique_ptr<Sha256Hasher>(new Sha256Hasher))),
+                          store_.get(), log_signer_.get());
+  }
+
+  T* db() const {
+    return test_db_->db();
+  }
+  unique_ptr<TestDB<T>> test_db_;
+  shared_ptr<libevent::Base> base_;
+  libevent::EventPumpThread event_pump_;
+  FakeEtcdClient etcd_client_;
+  ThreadPool pool_;
+  NiceMock<MockMasterElection> election_;
+  std::unique_ptr<EtcdConsistentStore> store_;
+  TestSigner test_signer_;
+  unique_ptr<LogVerifier> verifier_;
+  unique_ptr<LogSigner> log_signer_;
+  unique_ptr<TreeSigner> tree_signer_;
+};
+
+typedef testing::Types<FileDB, SQLiteDB> Databases;
+
+
+EntryHandle<LoggedEntry> H(const LoggedEntry& l) {
+  EntryHandle<LoggedEntry> handle;
+  handle.MutableEntry()->CopyFrom(l);
+  return handle;
+}
+
+
+TYPED_TEST_CASE(TreeSignerTest, Databases);
+
+TYPED_TEST(TreeSignerTest, PendingEntriesOrder) {
+  PendingEntriesOrder ordering;
+  LoggedEntry lowest;
+  this->test_signer_.CreateUnique(&lowest);
+
+  // Can't be lower than itself!
+  EXPECT_FALSE(ordering(H(lowest), H(lowest)));
+
+  // check timestamp:
+  LoggedEntry higher_timestamp(lowest);
+  higher_timestamp.mutable_sct()->set_timestamp(lowest.timestamp() + 1);
+  EXPECT_TRUE(ordering(H(lowest), H(higher_timestamp)));
+  EXPECT_FALSE(ordering(H(higher_timestamp), H(lowest)));
+
+  // check hash fallback:
+  LoggedEntry higher_hash(lowest);
+  while (higher_hash.Hash() <= lowest.Hash()) {
+    this->test_signer_.CreateUnique(&higher_hash);
+    higher_hash.mutable_sct()->set_timestamp(lowest.timestamp());
+  }
+  EXPECT_TRUE(ordering(H(lowest), H(higher_hash)));
+  EXPECT_FALSE(ordering(H(higher_hash), H(lowest)));
+}
+
+
+// TODO(ekasper): KAT tests.
+TYPED_TEST(TreeSignerTest, Sign) {
+  LoggedEntry logged_cert;
+  this->test_signer_.CreateUnique(&logged_cert);
+  this->AddPendingEntry(&logged_cert);
+  // this->AddSequencedEntry(&logged_cert, 0);
+  EXPECT_OK(this->tree_signer_->SequenceNewEntries());
+  EXPECT_EQ(TreeSigner::OK, this->tree_signer_->UpdateTree());
+
+  const SignedTreeHead sth(this->tree_signer_->LatestSTH());
+  EXPECT_EQ(1U, sth.tree_size());
+  EXPECT_EQ(sth.timestamp(), this->tree_signer_->LastUpdateTime());
+}
+
+
+TYPED_TEST(TreeSignerTest, Timestamp) {
+  LoggedEntry logged_cert;
+  this->test_signer_.CreateUnique(&logged_cert);
+  this->AddSequencedEntry(&logged_cert, 0);
+
+  EXPECT_EQ(TreeSigner::OK, this->tree_signer_->UpdateTree());
+  uint64_t last_update = this->tree_signer_->LastUpdateTime();
+  EXPECT_GE(last_update, logged_cert.sct().timestamp());
+
+  // Now create a second entry with a timestamp some time in the future
+  // and verify that the signer's timestamp is greater than that.
+  uint64_t future = last_update + 10000;
+  LoggedEntry logged_cert2;
+  this->test_signer_.CreateUnique(&logged_cert2);
+  logged_cert2.mutable_sct()->set_timestamp(future);
+  this->AddSequencedEntry(&logged_cert2, 1);
+
+  EXPECT_EQ(TreeSigner::OK, this->tree_signer_->UpdateTree());
+  EXPECT_GE(this->tree_signer_->LastUpdateTime(), future);
+}
+
+
+TYPED_TEST(TreeSignerTest, Verify) {
+  LoggedEntry logged_cert;
+  this->test_signer_.CreateUnique(&logged_cert);
+  this->AddSequencedEntry(&logged_cert, 0);
+
+  EXPECT_EQ(TreeSigner::OK, this->tree_signer_->UpdateTree());
+
+  const SignedTreeHead sth(this->tree_signer_->LatestSTH());
+  EXPECT_EQ(LogVerifier::VERIFY_OK,
+            this->verifier_->VerifySignedTreeHead(sth));
+}
+
+
+TYPED_TEST(TreeSignerTest, ResumeClean) {
+  LoggedEntry logged_cert;
+  this->test_signer_.CreateUnique(&logged_cert);
+  this->AddSequencedEntry(&logged_cert, 0);
+
+  EXPECT_EQ(TreeSigner::OK, this->tree_signer_->UpdateTree());
+  const SignedTreeHead sth(this->tree_signer_->LatestSTH());
+  {
+    // Simulate the caller of UpdateTree() pushing this new tree out to the
+    // cluster.
+    ClusterNodeState node_state;
+    *node_state.mutable_newest_sth() = sth;
+    CHECK_EQ(util::Status::OK, this->store_->SetClusterNodeState(node_state));
+  }
+
+  unique_ptr<TreeSigner> signer2(this->GetSimilar());
+
+  // Update
+  EXPECT_EQ(TreeSigner::OK, signer2->UpdateTree());
+
+  const SignedTreeHead sth2(signer2->LatestSTH());
+  EXPECT_LT(sth.timestamp(), sth2.timestamp());
+  EXPECT_EQ(sth.sha256_root_hash(), sth2.sha256_root_hash());
+  EXPECT_EQ(sth.tree_size(), sth2.tree_size());
+}
+
+
+// Test resuming when the tree head signature is lagging behind the
+// sequence number commits.
+TYPED_TEST(TreeSignerTest, ResumePartialSign) {
+  EXPECT_EQ(TreeSigner::OK, this->tree_signer_->UpdateTree());
+  const SignedTreeHead sth(this->tree_signer_->LatestSTH());
+  {
+    // Simulate the caller of UpdateTree() pushing this new tree out to the
+    // cluster.
+    ClusterNodeState node_state;
+    *node_state.mutable_newest_sth() = sth;
+    CHECK_EQ(util::Status::OK, this->store_->SetClusterNodeState(node_state));
+  }
+
+  LoggedEntry logged_cert;
+  this->test_signer_.CreateUnique(&logged_cert);
+  this->AddSequencedEntry(&logged_cert, 0);
+
+  unique_ptr<TreeSigner> signer2(this->GetSimilar());
+  EXPECT_EQ(TreeSigner::OK, signer2->UpdateTree());
+  const SignedTreeHead sth2(signer2->LatestSTH());
+  // The signer should have picked up the sequence number commit.
+  EXPECT_EQ(1U, sth2.tree_size());
+  EXPECT_LT(sth.timestamp(), sth2.timestamp());
+  EXPECT_NE(sth.sha256_root_hash(), sth2.sha256_root_hash());
+}
+
+
+TYPED_TEST(TreeSignerTest, SignEmpty) {
+  EXPECT_EQ(TreeSigner::OK, this->tree_signer_->UpdateTree());
+
+  const SignedTreeHead sth(this->tree_signer_->LatestSTH());
+  EXPECT_GT(sth.timestamp(), 0U);
+  EXPECT_EQ(sth.tree_size(), 0U);
+}
+
+
+TYPED_TEST(TreeSignerTest, SequenceNewEntriesCleansUpOldSequenceMappings) {
+  LoggedEntry logged_cert;
+  this->test_signer_.CreateUnique(&logged_cert);
+  this->AddPendingEntry(&logged_cert);
+  EXPECT_OK(this->tree_signer_->SequenceNewEntries());
+  EXPECT_EQ(TreeSigner::OK, this->tree_signer_->UpdateTree());
+  EXPECT_EQ(Status::OK,
+            this->store_->SetServingSTH(this->tree_signer_->LatestSTH()));
+  sleep(1);
+
+  {
+    EntryHandle<SequenceMapping> mapping;
+    CHECK_EQ(Status::OK, this->store_->GetSequenceMapping(&mapping));
+    EXPECT_EQ(1, mapping.Entry().mapping_size());
+    EXPECT_EQ(logged_cert.Hash(), mapping.Entry().mapping(0).entry_hash());
+  }
+
+  unordered_map<string, LoggedEntry> new_logged_certs;
+  for (int i(0); i < 2; ++i) {
+    LoggedEntry c;
+    this->test_signer_.CreateUnique(&c);
+    this->AddPendingEntry(&c);
+    new_logged_certs.insert(make_pair(c.Hash(), c));
+  }
+  this->DeletePendingEntry(logged_cert);
+  LOG(INFO) << "2";
+  EXPECT_OK(this->tree_signer_->SequenceNewEntries());
+
+  {
+    EntryHandle<SequenceMapping> mapping;
+    CHECK_EQ(Status::OK, this->store_->GetSequenceMapping(&mapping));
+    CHECK_GE(mapping.Entry().mapping_size(), 0);
+    EXPECT_EQ(new_logged_certs.size(),
+              static_cast<size_t>(mapping.Entry().mapping_size()));
+    for (int i(0); i < mapping.Entry().mapping_size(); ++i) {
+      const auto& m(mapping.Entry().mapping(i));
+      EXPECT_NE(new_logged_certs.end(), new_logged_certs.find(m.entry_hash()));
+    }
+  }
+}
+
+
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  ConfigureSerializerForV1CT();
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/verifier.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/verifier.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/verifier.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/verifier.cc	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,86 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "log/verifier.h"
+
+#include <glog/logging.h>
+#include <openssl/evp.h>
+#include <openssl/opensslv.h>
+#include <stdint.h>
+
+#include "merkletree/serial_hasher.h"
+#include "proto/ct.pb.h"
+#include "util/util.h"
+
+#if OPENSSL_VERSION_NUMBER < 0x10000000
+#error "Need OpenSSL >= 1.0.0"
+#endif
+
+using ct::DigitallySigned;
+
+namespace cert_trans {
+
+Verifier::Verifier(EVP_PKEY* pkey) : pkey_(CHECK_NOTNULL(pkey)) {
+  switch (pkey_->type) {
+    case EVP_PKEY_EC:
+      hash_algo_ = DigitallySigned::SHA256;
+      sig_algo_ = DigitallySigned::ECDSA;
+      break;
+    case EVP_PKEY_RSA:
+      hash_algo_ = DigitallySigned::SHA256;
+      sig_algo_ = DigitallySigned::RSA;
+      break;
+    default:
+      LOG(FATAL) << "Unsupported key type " << pkey_->type;
+  }
+  key_id_ = ComputeKeyID(pkey_.get());
+}
+
+std::string Verifier::KeyID() const {
+  return key_id_;
+}
+
+Verifier::Status Verifier::Verify(const std::string& input,
+                                  const DigitallySigned& signature) const {
+  if (signature.hash_algorithm() != hash_algo_)
+    return HASH_ALGORITHM_MISMATCH;
+  if (signature.sig_algorithm() != sig_algo_)
+    return SIGNATURE_ALGORITHM_MISMATCH;
+  if (!RawVerify(input, signature.signature()))
+    return INVALID_SIGNATURE;
+  return OK;
+}
+
+// static
+std::string Verifier::ComputeKeyID(EVP_PKEY* pkey) {
+  // i2d_PUBKEY sets the algorithm and (for ECDSA) named curve parameter and
+  // encodes the key as an X509_PUBKEY (i.e., subjectPublicKeyInfo).
+  int buf_len = i2d_PUBKEY(pkey, NULL);
+  CHECK_GT(buf_len, 0);
+  unsigned char* buf = new unsigned char[buf_len];
+  unsigned char* p = buf;
+  CHECK_EQ(i2d_PUBKEY(pkey, &p), buf_len);
+  const std::string keystring(reinterpret_cast<char*>(buf), buf_len);
+  const std::string ret(Sha256Hasher::Sha256Digest(keystring));
+  delete[] buf;
+  return ret;
+}
+
+Verifier::Verifier()
+    : hash_algo_(DigitallySigned::NONE),
+      sig_algo_(DigitallySigned::ANONYMOUS) {
+}
+
+bool Verifier::RawVerify(const std::string& data,
+                         const std::string& sig_string) const {
+  EVP_MD_CTX ctx;
+  EVP_MD_CTX_init(&ctx);
+  // NOTE: this syntax for setting the hash function requires OpenSSL >= 1.0.0.
+  CHECK_EQ(1, EVP_VerifyInit(&ctx, EVP_sha256()));
+  CHECK_EQ(1, EVP_VerifyUpdate(&ctx, data.data(), data.size()));
+  bool ret = (EVP_VerifyFinal(&ctx, reinterpret_cast<const unsigned char*>(
+                                        sig_string.data()),
+                              sig_string.size(), pkey_.get()) == 1);
+  EVP_MD_CTX_cleanup(&ctx);
+  return ret;
+}
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/verifier.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/verifier.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/log/verifier.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/log/verifier.h	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,53 @@
+// A base class for verifying signatures of unstructured data.  This class is
+// mockable.
+
+#ifndef CERT_TRANS_LOG_VERIFIER_H_
+#define CERT_TRANS_LOG_VERIFIER_H_
+
+#include <openssl/evp.h>
+#include <openssl/x509.h>  // for i2d_PUBKEY
+#include <stdint.h>
+
+#include "base/macros.h"
+#include "proto/ct.pb.h"
+#include "util/openssl_scoped_types.h"
+
+namespace cert_trans {
+
+class Verifier {
+ public:
+  enum Status {
+    OK,
+    HASH_ALGORITHM_MISMATCH,
+    SIGNATURE_ALGORITHM_MISMATCH,
+    INVALID_SIGNATURE,
+  };
+
+  explicit Verifier(EVP_PKEY* pkey);
+  virtual ~Verifier() = default;
+
+  virtual std::string KeyID() const;
+
+  virtual Status Verify(const std::string& input,
+                        const ct::DigitallySigned& signature) const;
+
+  static std::string ComputeKeyID(EVP_PKEY* pkey);
+
+ protected:
+  // A constructor for mocking.
+  Verifier();
+
+ private:
+  bool RawVerify(const std::string& data, const std::string& sig_string) const;
+
+  ScopedEVP_PKEY pkey_;
+  ct::DigitallySigned::HashAlgorithm hash_algo_;
+  ct::DigitallySigned::SignatureAlgorithm sig_algo_;
+  std::string key_id_;
+
+  DISALLOW_COPY_AND_ASSIGN(Verifier);
+};
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_LOG_VERIFIER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/compact_merkle_tree.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/compact_merkle_tree.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/compact_merkle_tree.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/compact_merkle_tree.cc	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,167 @@
+#include "merkletree/compact_merkle_tree.h"
+
+#include <assert.h>
+#include <glog/logging.h>
+#include <stddef.h>
+#include <string>
+#include <vector>
+
+#include "merkletree/merkle_tree_math.h"
+
+using cert_trans::MerkleTreeInterface;
+using std::move;
+using std::string;
+using std::unique_ptr;
+
+CompactMerkleTree::CompactMerkleTree(unique_ptr<SerialHasher> hasher)
+    : MerkleTreeInterface(),
+      treehasher_(move(hasher)),
+      leaf_count_(0),
+      leaves_processed_(0),
+      level_count_(0),
+      root_(treehasher_.HashEmpty()) {
+}
+
+CompactMerkleTree::CompactMerkleTree(MerkleTree* model,
+                                     unique_ptr<SerialHasher> hasher)
+    : MerkleTreeInterface(),
+      tree_(std::max<int64_t>(0, CHECK_NOTNULL(model)->LevelCount() - 1)),
+      treehasher_(move(hasher)),
+      leaf_count_(model->LeafCount()),
+      leaves_processed_(0),
+      level_count_(model->LevelCount()),
+      root_(treehasher_.HashEmpty()) {
+  if (model->LeafCount() == 0) {
+    return;
+  }
+  // Get the inclusion proof path to the last entry in the tree, which by
+  // definition must consist purely of left-hand nodes.
+  std::vector<string> path(model->PathToCurrentRoot(model->LeafCount()));
+  if (!path.empty()) {
+    /* We have to do some juggling here as tree_[] differs from our MerkleTree
+    // structure in that incomplete right-hand subtrees 'fall-through' to lower
+    // levels:
+    //
+    // MerkleTree structure for 3 leaves:
+    //      R
+    //     / \
+    //    /   \
+    //   AB    c
+    //  / \
+    // a   b
+    //
+    // Compact tree represents this as:
+    //      R
+    //     / \
+    //    /   \
+    //   AB    .
+    //         |
+    //         c
+    // or:
+    // tree_[1] = AB
+    // tree_[0] = c  // (c) has "fallen-through" to the lowest level
+    //
+    // The inclusion proof path for the right-most entry effectively
+    // describes the state of the tree immediately before the right-most
+    // entry was added.
+    // Since the inclusion proof path consists exclusively of left-hand
+    // nodes and each entry in the path covers the maximum sub-tree possible,
+    // we can use this to directly construct the Compact respresentation of
+    // the tree before the newest entry was added.
+    */
+
+    // index into tree_, starting at the leaf level:
+    int level(0);
+    std::vector<string>::const_iterator i = path.begin();
+    size_t size_of_previous_tree(model->LeafCount() - 1);
+    for (; size_of_previous_tree != 0; size_of_previous_tree >>= 1) {
+      if ((size_of_previous_tree & 1) != 0) {
+        // if the level'th bit in the previous tree size is set, then we have
+        // a proof path entry for this level (because proof entries cover the
+        // maximum possible sub-tree.)
+        tree_[level] = *i;
+        i++;
+      }
+      level++;
+    }
+    assert(i == path.end());
+  }
+
+  // Now tree_ should contain a representation of the tree state just before
+  // the last entry was added, so we PushBack the final right-hand entry
+  // here, which will perform any recalculations necessary to reach the final
+  // tree.
+  PushBack(0, model->LeafHash(model->LeafCount()));
+  assert(model->CurrentRoot() == CurrentRoot());
+  assert(model->LeafCount() == LeafCount());
+  assert(model->LevelCount() == LevelCount());
+}
+
+
+CompactMerkleTree::CompactMerkleTree(const CompactMerkleTree& other,
+                                     unique_ptr<SerialHasher> hasher)
+    : tree_(other.tree_),
+      treehasher_(move(hasher)),
+      leaf_count_(other.leaf_count_),
+      leaves_processed_(other.leaves_processed_),
+      level_count_(other.level_count_),
+      root_(other.root_) {
+}
+
+CompactMerkleTree::~CompactMerkleTree() {
+}
+
+
+size_t CompactMerkleTree::AddLeaf(const string& data) {
+  return AddLeafHash(treehasher_.HashLeaf(data));
+}
+
+size_t CompactMerkleTree::AddLeafHash(const string& hash) {
+  PushBack(0, hash);
+  // Update level count: a k-level tree can hold 2^{k-1} leaves,
+  // so increment level count every time we overflow a power of two.
+  // Do not update the root; we evaluate the tree lazily.
+  if (MerkleTreeMath::IsPowerOfTwoPlusOne(++leaf_count_))
+    ++level_count_;
+  return leaf_count_;
+}
+
+string CompactMerkleTree::CurrentRoot() {
+  UpdateRoot();
+  return root_;
+}
+
+void CompactMerkleTree::PushBack(size_t level, string node) {
+  assert(node.size() == treehasher_.DigestSize());
+  if (tree_.size() <= level) {
+    // First node at a new level.
+    tree_.push_back(node);
+  } else if (tree_[level].empty()) {
+    // Lone left sibling.
+    tree_[level] = node;
+  } else {
+    // Left sibling waiting: hash together and propagate up.
+    PushBack(level + 1, treehasher_.HashChildren(tree_[level], node));
+    tree_[level].clear();
+  }
+}
+
+void CompactMerkleTree::UpdateRoot() {
+  if (leaves_processed_ == LeafCount())
+    return;
+
+  string right_sibling;
+
+  for (size_t level = 0; level < tree_.size(); ++level) {
+    if (!tree_[level].empty()) {
+      // A lonely left sibling gets pulled up as a right sibling.
+      if (right_sibling.empty())
+        right_sibling = tree_[level];
+      else
+        right_sibling = treehasher_.HashChildren(tree_[level], right_sibling);
+    }
+  }
+
+  root_ = right_sibling;
+  leaves_processed_ = LeafCount();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/compact_merkle_tree.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/compact_merkle_tree.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/compact_merkle_tree.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/compact_merkle_tree.h	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,158 @@
+#ifndef CERT_TRANS_MERKLETREE_COMPACT_MERKLE_TREE_H_
+#define CERT_TRANS_MERKLETREE_COMPACT_MERKLE_TREE_H_
+
+#include <stddef.h>
+#include <memory>
+#include <string>
+#include <vector>
+
+#include "merkletree/merkle_tree.h"
+#include "merkletree/merkle_tree_interface.h"
+#include "merkletree/tree_hasher.h"
+
+class SerialHasher;
+
+// A memory-efficient version of Merkle Trees; like MerkleTree
+// (see merkletree/merkle_tree.h) but can only add new leaves and report
+// its current root (i.e., it cannot do paths, snapshots or consistency).
+//
+// This class is thread-compatible, but not thread-safe.
+class CompactMerkleTree : public cert_trans::MerkleTreeInterface {
+ public:
+  // The constructor takes a pointer to some concrete hash function
+  // instantiation of the SerialHasher abstract class.
+  explicit CompactMerkleTree(std::unique_ptr<SerialHasher> hasher);
+  CompactMerkleTree(const CompactMerkleTree& other,
+                    std::unique_ptr<SerialHasher> hasher);
+
+  explicit CompactMerkleTree(CompactMerkleTree&& other) = default;
+
+  // Creates a new CompactMerkleTree based on the data present in the
+  // (non-compact) MerkleTree |model|.
+  // Takes ownership of |hasher|, does not use |model| after the
+  // construction.
+  // TODO(pphaneuf): This should take a const reference to the model,
+  // but implementation details currently make this too difficult.
+  // TODO(pphaneuf): It should also get its |hasher| from |model|,
+  // somehow.
+  CompactMerkleTree(MerkleTree* model, std::unique_ptr<SerialHasher> hasher);
+
+  virtual ~CompactMerkleTree();
+
+  // Length of a node (i.e., a hash), in bytes.
+  virtual size_t NodeSize() const {
+    return treehasher_.DigestSize();
+  };
+
+  // Number of leaves in the tree.
+  virtual size_t LeafCount() const {
+    return leaf_count_;
+  }
+
+  // Return the leaf hash, but do not append the data to the tree.
+  virtual std::string LeafHash(const std::string& data) const {
+    return treehasher_.HashLeaf(data);
+  }
+
+  // Number of levels. An empty tree has 0 levels, a tree with 1 leaf has
+  // 1 level, a tree with 2 leaves has 2 levels, and a tree with n leaves has
+  // ceil(log2(n)) + 1 levels.
+  virtual size_t LevelCount() const {
+    return level_count_;
+  }
+
+  // Add a new leaf to the hash tree.
+  //
+  // (We update intermediate hashes as soon as a node becomes "fixed"
+  // (However, we evaluate the root lazily, and do not update it here.)
+  //
+  // Returns the position of the leaf in the tree. Indexing starts at 1,
+  // so position = number of leaves in the tree after this update.
+  //
+  // @param data Binary input blob
+  virtual size_t AddLeaf(const std::string& data);
+
+  // Add a new leaf to the hash tree. It is the caller's responsibility
+  // to ensure that the hash is correct.
+  //
+  // (We update intermediate hashes as soon as a node becomes "fixed"
+  // (However, we evaluate the root lazily, and do not update it here.)
+  //
+  // Returns the position of the leaf in the tree. Indexing starts at 1,
+  // so position = number of leaves in the tree after this update.
+  //
+  // @param hash leaf hash
+  virtual size_t AddLeafHash(const std::string& hash);
+
+  // Get the current root of the tree.
+  // Update the root to reflect the current shape of the tree,
+  // and return the tree digest.
+  //
+  // Returns the hash of an empty string if the tree has no leaves
+  // (and hence, no root).
+  virtual std::string CurrentRoot();
+
+ private:
+  // Append a node to the level.
+  void PushBack(size_t level, std::string node);
+
+  void UpdateRoot();
+  // Since the tree is append-only to the right, at any given point in time,
+  // at each level, all nodes that have a right sibling are fixed and will
+  // no longer change. Thus we store, for each level i, only the last lone
+  // left node (if one exists) or an empty string otherwise (tree_[i]).
+  //
+  //        ___hash___
+  //       |          |
+  //    __ h20__    __.
+  //   |       |   |
+  //  h10     h11  .
+  //  | |     | |  |
+  // a0 a1   a2 a3 a4
+  //
+  // is internally represented, top-down
+  //
+  // --------
+  // | h20  |      tree_[2]
+  // --------
+  // |      |      tree_[1]
+  // --------
+  // |  a4  |      tree_[0]
+  // --------
+  //
+  // After adding a 6th hash a5, the tree becomes
+  //
+  //        ___ hash'___
+  //       |            |
+  //    __ h20__     __.
+  //   |        |   |
+  //  h10     h11   h12
+  //  | |     | |   | |
+  // a0 a1   a2 a3 a4 a5
+  //
+  // and its internal representation is
+  //
+  // --------
+  // | h20  |      tree_[2]
+  // --------
+  // | h12  |      tree_[1]
+  // --------
+  // |      |      tree_[0]
+  // --------
+
+  std::vector<std::string> tree_;
+  TreeHasher treehasher_;
+  // True number of leaves in the tree.
+  size_t leaf_count_;
+  // Number of leaves propagated up to the root,
+  // to keep track of lazy evaluation.
+  size_t leaves_processed_;
+  // True number of levels in the tree. Note that the tree_ itself
+  // contains the root only if it's balanced, so tree_.size() does not always
+  // match true level count.
+  size_t level_count_;
+  // The root for |leaves_processed_| leaves.
+  std::string root_;
+};
+
+#endif  // CERT_TRANS_MERKLETREE_COMPACT_MERKLE_TREE_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree.cc	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,291 @@
+#include "merkletree/merkle_tree.h"
+
+#include <assert.h>
+#include <stddef.h>
+#include <string>
+#include <vector>
+
+#include "merkletree/merkle_tree_math.h"
+
+using cert_trans::MerkleTreeInterface;
+using std::move;
+using std::string;
+using std::unique_ptr;
+
+MerkleTree::MerkleTree(unique_ptr<SerialHasher> hasher)
+    : MerkleTreeInterface(),
+      treehasher_(move(hasher)),
+      leaves_processed_(0),
+      level_count_(0) {
+}
+
+MerkleTree::~MerkleTree() {
+}
+
+size_t MerkleTree::AddLeaf(const string& data) {
+  return AddLeafHash(treehasher_.HashLeaf(data));
+}
+
+size_t MerkleTree::AddLeafHash(const string& hash) {
+  if (LazyLevelCount() == 0) {
+    AddLevel();
+    // The first leaf hash is also the first root.
+    leaves_processed_ = 1;
+  }
+  PushBack(0, hash);
+  size_t leaf_count = LeafCount();
+  // Update level count: a k-level tree can hold 2^{k-1} leaves,
+  // so increment level count every time we overflow a power of two.
+  // Do not update the root; we evaluate the tree lazily.
+  if (MerkleTreeMath::IsPowerOfTwoPlusOne(leaf_count))
+    ++level_count_;
+  // Return the current leaf count.
+  return leaf_count;
+}
+
+string MerkleTree::CurrentRoot() {
+  return RootAtSnapshot(LeafCount());
+}
+
+string MerkleTree::RootAtSnapshot(size_t snapshot) {
+  if (snapshot == 0)
+    return treehasher_.HashEmpty();
+  size_t leaf_count = LeafCount();
+  if (snapshot > leaf_count)
+    return string();
+  if (snapshot >= leaves_processed_)
+    return UpdateToSnapshot(snapshot);
+  // snapshot < leaves_processed_: recompute the snapshot root.
+  return RecomputePastSnapshot(snapshot, 0, NULL);
+}
+
+std::vector<string> MerkleTree::PathToCurrentRoot(size_t leaf) {
+  return PathToRootAtSnapshot(leaf, LeafCount());
+}
+
+std::vector<string> MerkleTree::PathToRootAtSnapshot(size_t leaf,
+                                                     size_t snapshot) {
+  std::vector<string> path;
+  size_t leaf_count = LeafCount();
+  if (leaf > snapshot || snapshot > leaf_count || leaf == 0)
+    return path;
+  return PathFromNodeToRootAtSnapshot(leaf - 1, 0, snapshot);
+}
+
+std::vector<string> MerkleTree::SnapshotConsistency(size_t snapshot1,
+                                                    size_t snapshot2) {
+  std::vector<string> proof;
+  size_t leaf_count = LeafCount();
+  if (snapshot1 == 0 || snapshot1 >= snapshot2 || snapshot2 > leaf_count)
+    return proof;
+
+  size_t level = 0;
+  // Rightmost node in snapshot1.
+  size_t node = snapshot1 - 1;
+  // Compute the (compressed) path to the root of snapshot2.
+  // Everything left of 'node' is equal in both trees; no need to record.
+  while (MerkleTreeMath::IsRightChild(node)) {
+    node = MerkleTreeMath::Parent(node);
+    ++level;
+  }
+
+  if (snapshot2 > leaves_processed_) {
+    // Bring the tree sufficiently up to date.
+    UpdateToSnapshot(snapshot2);
+  }
+
+  // Record the node, unless we already reached the root of snapshot1.
+  if (node)
+    proof.push_back(Node(level, node));
+
+  // Now record the path from this node to the root of snapshot2.
+  std::vector<string> path =
+      PathFromNodeToRootAtSnapshot(node, level, snapshot2);
+  proof.insert(proof.end(), path.begin(), path.end());
+  return proof;
+}
+
+string MerkleTree::UpdateToSnapshot(size_t snapshot) {
+  if (snapshot == 0)
+    return treehasher_.HashEmpty();
+  if (snapshot == 1)
+    return Node(0, 0);
+  if (snapshot == leaves_processed_)
+    return Root();
+  assert(snapshot <= LeafCount());
+  assert(snapshot > leaves_processed_);
+
+  // Update tree, moving up level-by-level.
+  size_t level = 0;
+  // Index of the first node to be processed at the current level.
+  size_t first_node = leaves_processed_;
+  // Index of the last node.
+  size_t last_node = snapshot - 1;
+
+  // Process level-by-level until we converge to a single node.
+  // (first_node, last_node) = (0, 0) means we have reached the root level.
+  while (last_node) {
+    if (LazyLevelCount() <= level + 1) {
+      AddLevel();
+    } else if (NodeCount(level + 1) ==
+               MerkleTreeMath::Parent(first_node) + 1) {
+      // The leftmost parent at level 'level+1' may already exist,
+      // so we need to update it. Nuke the old parent.
+      PopBack(level + 1);
+    }
+
+    // Compute the parents of new nodes at the current level.
+    // Start with a left sibling and parse an even number of nodes.
+    for (size_t j = first_node & ~1; j < last_node; j += 2) {
+      PushBack(level + 1,
+               treehasher_.HashChildren(Node(level, j), Node(level, j + 1)));
+    }
+    // If the last node at the current level is a left sibling,
+    // dummy-propagate it one level up.
+    if (!MerkleTreeMath::IsRightChild(last_node))
+      PushBack(level + 1, Node(level, last_node));
+
+    first_node = MerkleTreeMath::Parent(first_node);
+    last_node = MerkleTreeMath::Parent(last_node);
+    ++level;
+  };
+
+  leaves_processed_ = snapshot;
+  return Root();
+}
+
+string MerkleTree::RecomputePastSnapshot(size_t snapshot, size_t node_level,
+                                         string* node) {
+  size_t level = 0;
+  // Index of the rightmost node at the current level for this snapshot.
+  size_t last_node = snapshot - 1;
+
+  if (snapshot == leaves_processed_) {
+    // Nothing to recompute.
+    if (node && LazyLevelCount() > node_level) {
+      if (node_level > 0) {
+        node->assign(LastNode(node_level));
+      } else {
+        // Leaf level: grab the last processed leaf.
+        node->assign(Node(node_level, last_node));
+      }
+    }
+    return Root();
+  }
+
+  assert(snapshot < leaves_processed_);
+
+  // Recompute nodes on the path of the last leaf.
+  while (MerkleTreeMath::IsRightChild(last_node)) {
+    if (node && node_level == level)
+      node->assign(Node(level, last_node));
+    // Left sibling and parent exist in the snapshot, and are equal to
+    // those in the tree; no need to rehash, move one level up.
+    last_node = MerkleTreeMath::Parent(last_node);
+    ++level;
+  }
+
+  // Now last_node is the index of a left sibling with no right sibling.
+  // Record the node.
+  string subtree_root = Node(level, last_node);
+
+  if (node && node_level == level)
+    node->assign(subtree_root);
+
+  while (last_node) {
+    if (MerkleTreeMath::IsRightChild(last_node)) {
+      // Recompute the parent of tree_[level][last_node].
+      subtree_root =
+          treehasher_.HashChildren(Node(level, last_node - 1), subtree_root);
+    }
+    // Else the parent is a dummy copy of the current node; do nothing.
+
+    last_node = MerkleTreeMath::Parent(last_node);
+    ++level;
+    if (node && node_level == level)
+      node->assign(subtree_root);
+  }
+
+  return subtree_root;
+}
+
+std::vector<string> MerkleTree::PathFromNodeToRootAtSnapshot(size_t node,
+                                                             size_t level,
+                                                             size_t snapshot) {
+  std::vector<string> path;
+  if (snapshot == 0)
+    return path;
+  // Index of the last node.
+  size_t last_node = (snapshot - 1) >> level;
+  if (level >= level_count_ || node > last_node || snapshot > LeafCount())
+    return path;
+
+  if (snapshot > leaves_processed_) {
+    // Bring the tree sufficiently up to date.
+    UpdateToSnapshot(snapshot);
+  }
+
+  // Move up, recording the sibling of the current node at each level.
+  while (last_node) {
+    size_t sibling = MerkleTreeMath::Sibling(node);
+    if (sibling < last_node) {
+      // The sibling is not the last node of the level in the snapshot
+      // tree, so its value is correct in the tree.
+      path.push_back(Node(level, sibling));
+    } else if (sibling == last_node) {
+      // The sibling is the last node of the level in the snapshot tree,
+      // so we get its value for the snapshot. Get the root in the same pass.
+      string recompute_node;
+      RecomputePastSnapshot(snapshot, level, &recompute_node);
+      path.push_back(recompute_node);
+    }
+    // Else sibling > last_node so the sibling does not exist. Do nothing.
+    // Continue moving up in the tree, ignoring dummy copies.
+
+    node = MerkleTreeMath::Parent(node);
+    last_node = MerkleTreeMath::Parent(last_node);
+    ++level;
+  };
+
+  return path;
+}
+
+string MerkleTree::Node(size_t level, size_t index) const {
+  assert(NodeCount(level) > index);
+  return tree_[level].substr(index * treehasher_.DigestSize(),
+                             treehasher_.DigestSize());
+}
+
+string MerkleTree::Root() const {
+  assert(tree_.back().size() == treehasher_.DigestSize());
+  return tree_.back();
+}
+
+size_t MerkleTree::NodeCount(size_t level) const {
+  assert(LazyLevelCount() > level);
+  return tree_[level].size() / treehasher_.DigestSize();
+}
+
+string MerkleTree::LastNode(size_t level) const {
+  assert(NodeCount(level) >= 1U);
+  return tree_[level].substr(tree_[level].size() - treehasher_.DigestSize());
+}
+
+void MerkleTree::PopBack(size_t level) {
+  assert(NodeCount(level) >= 1U);
+  tree_[level].erase(tree_[level].size() - treehasher_.DigestSize());
+}
+
+void MerkleTree::PushBack(size_t level, string node) {
+  assert(node.size() == treehasher_.DigestSize());
+  assert(LazyLevelCount() > level);
+  tree_[level].append(node);
+}
+
+void MerkleTree::AddLevel() {
+  tree_.push_back(string());
+}
+
+size_t MerkleTree::LazyLevelCount() const {
+  return tree_.size();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree.h	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,212 @@
+#ifndef CERT_TRANS_MERKLETREE_MERKLE_TREE_H_
+#define CERT_TRANS_MERKLETREE_MERKLE_TREE_H_
+
+#include <stddef.h>
+#include <memory>
+#include <string>
+#include <vector>
+
+#include "merkletree/merkle_tree_interface.h"
+#include "merkletree/tree_hasher.h"
+
+class SerialHasher;
+
+// Class for manipulating Merkle Hash Trees, as specified in the
+// Certificate Transparency specificationdoc/sunlight.xml
+// Implement binary Merkle Hash Trees, using an arbitrary hash function
+// provided by the SerialHasher interface.
+// Rather than using the hash function directly, we use a TreeHasher that
+// does domain separation for leaves and nodes, and thus ensures collision
+// resistance.
+//
+// This class is thread-compatible, but not thread-safe.
+class MerkleTree : public cert_trans::MerkleTreeInterface {
+ public:
+  // The constructor takes a pointer to some concrete hash function
+  // instantiation of the SerialHasher abstract class.
+  explicit MerkleTree(std::unique_ptr<SerialHasher> hasher);
+  virtual ~MerkleTree();
+
+  // Length of a node (i.e., a hash), in bytes.
+  virtual size_t NodeSize() const {
+    return treehasher_.DigestSize();
+  };
+
+  // Number of leaves in the tree.
+  virtual size_t LeafCount() const {
+    return tree_.empty() ? 0 : NodeCount(0);
+  }
+
+  // The |leaf|th leaf hash in the tree. Indexing starts from 1.
+  std::string LeafHash(size_t leaf) const {
+    if (leaf == 0 || leaf > LeafCount())
+      return std::string();
+    return Node(0, leaf - 1);
+  }
+
+  // Return the leaf hash, but do not append the data to the tree.
+  virtual std::string LeafHash(const std::string& data) const {
+    return treehasher_.HashLeaf(data);
+  }
+
+  // Number of levels. An empty tree has 0 levels, a tree with 1 leaf has
+  // 1 level, a tree with 2 leaves has 2 levels, and a tree with n leaves has
+  // ceil(log2(n)) + 1 levels.
+  virtual size_t LevelCount() const {
+    return level_count_;
+  }
+
+  // Add a new leaf to the hash tree. Stores the hash of the leaf data in the
+  // tree structure, does not store the data itself.
+  //
+  // (We will evaluate the tree lazily, and not update the root here.)
+  //
+  // Returns the position of the leaf in the tree. Indexing starts at 1,
+  // so position = number of leaves in the tree after this update.
+  //
+  // @param data Binary input blob
+  virtual size_t AddLeaf(const std::string& data);
+
+  // Add a new leaf to the hash tree. Stores the provided hash in the
+  // tree structure.  It is the caller's responsibility to ensure that
+  // the hash is correct.
+  //
+  // (We will evaluate the tree lazily, and not update the root here.)
+  //
+  // Returns the position of the leaf in the tree. Indexing starts at 1,
+  // so position = number of leaves in the tree after this update.
+  //
+  // @param hash leaf hash
+  virtual size_t AddLeafHash(const std::string& hash);
+
+  // Get the current root of the tree.
+  // Update the root to reflect the current shape of the tree,
+  // and return the tree digest.
+  //
+  // Returns the hash of an empty string if the tree has no leaves
+  // (and hence, no root).
+  virtual std::string CurrentRoot();
+
+  // Get the root of the tree for a previous snapshot,
+  // where snapshot 0 is an empty tree, snapshot 1 is the tree with
+  // 1 leaf, etc.
+  //
+  // Returns an empty string if the snapshot requested is in the future
+  // (i.e., the tree is not large enough).
+  //
+  // @param snapshot point in time (= number of leaves at that point).
+  std::string RootAtSnapshot(size_t snapshot);
+
+  // Get the Merkle path from leaf to root.
+  //
+  // Returns a vector of node hashes, ordered by levels from leaf to root.
+  // The first element is the sibling of the leaf hash, and the last element
+  // is one below the root.
+  // Returns an empty vector if the tree is not large enough
+  // or the leaf index is 0.
+  //
+  // @param leaf the index of the leaf the path is for.
+  std::vector<std::string> PathToCurrentRoot(size_t leaf);
+
+  // Get the Merkle path from leaf to the root of a previous snapshot.
+  //
+  // Returns a vector of node hashes, ordered by levels from leaf to
+  // root.  The first element is the sibling of the leaf hash, and the
+  // last element is one below the root.  Returns an empty vector if
+  // the leaf index is 0, the snapshot requested is in the future or
+  // the snapshot tree is not large enough.
+  //
+  // @param leaf the index of the leaf the path is for.
+  // @param snapshot point in time (= number of leaves at that point)
+  std::vector<std::string> PathToRootAtSnapshot(size_t leaf, size_t snapshot);
+
+  // Get the Merkle consistency proof between two snapshots.
+  // Returns a vector of node hashes, ordered according to levels.
+  // Returns an empty vector if snapshot1 is 0, snapshot 1 >= snapshot2,
+  // or one of the snapshots requested is in the future.
+  //
+  // @param snapshot1 the first point in time
+  // @param snapshot2 the second point in time
+  std::vector<std::string> SnapshotConsistency(size_t snapshot1,
+                                               size_t snapshot2);
+
+ private:
+  // Update to a given snapshot, return the root.
+  std::string UpdateToSnapshot(size_t snapshot);
+  // Return the root of a past snapshot.
+  // If node is not NULL, additionally record the rightmost node
+  // for the given snapshot and node_level.
+  std::string RecomputePastSnapshot(size_t snapshot, size_t node_level,
+                                    std::string* node);
+  // Path from a node at a given level (both indexed starting with 0)
+  // to the root at a given snapshot.
+  std::vector<std::string> PathFromNodeToRootAtSnapshot(size_t node_index,
+                                                        size_t level,
+                                                        size_t snapshot);
+  // Get the |index|-th node at level |level|. Indexing starts at 0;
+  // caller is responsible for ensuring tree is sufficiently up to date.
+  std::string Node(size_t level, size_t index) const;
+
+  // Get the current root (of the lazily evaluated tree).
+  // Caller is responsible for keeping track of the lazy evaluation status.
+  std::string Root() const;
+
+  // Get the current node count (of the lazily evaluated tree).
+  // Caller is responsible for keeping track of the lazy evaluation status.
+  size_t NodeCount(size_t level) const;
+
+  // Last node of the given level.
+  std::string LastNode(size_t level) const;
+
+  // Pop the last node of the level.
+  void PopBack(size_t level);
+
+  // Append a node to the level.
+  void PushBack(size_t level, std::string node);
+
+  // Start a new level.
+  void AddLevel();
+
+  // Current level count of the lazily evaluated tree.
+  size_t LazyLevelCount() const;
+  // A container for nodes, organized according to levels and sorted
+  // left-to-right in each level. tree_[0] is the leaf level, etc.
+  // The hash of nodes tree_[i][j] and tree_[i][j+1] (j even) is stored
+  // at tree_[i+1][j/2]. When tree_[i][j] is the last node of the level with
+  // no right sibling, we store its dummy copy: tree_[i+1][j/2] = tree_[i][j].
+  //
+  // For example, a tree with 5 leaf hashes a0, a1, a2, a3, a4
+  //
+  //        __ hash__
+  //       |         |
+  //    __ h20__     a4
+  //   |        |
+  //  h10     h11
+  //  | |     | |
+  // a0 a1   a2 a3
+  //
+  // is internally represented, top-down
+  //
+  // --------
+  // | hash |                        tree_[3]
+  // --------------
+  // | h20  | a4  |                  tree_[2]
+  // -------------------
+  // | h10  | h11 | a4 |             tree_[1]
+  // -----------------------------
+  // | a0   | a1  | a2 | a3 | a4 |   tree_[0]
+  // -----------------------------
+  //
+  // Since the tree is append-only from the right, at any given point in time,
+  // at each level, all nodes computed so far, except possibly the last node,
+  // are fixed and will no longer change.
+  std::vector<std::string> tree_;
+  TreeHasher treehasher_;
+  // Number of leaves propagated up to the root,
+  // to keep track of lazy evaluation.
+  size_t leaves_processed_;
+  // The "true" level count for a fully evaluated tree.
+  size_t level_count_;
+};
+
+#endif  // CERT_TRANS_MERKLETREE_MERKLE_TREE_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_interface.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_interface.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_interface.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_interface.h	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,66 @@
+// An interface for Merkle trees.  It makes it easier to write code that works
+// with all all flavors of Merkle trees.
+
+#ifndef CERT_TRANS_MERKLETREE_MERKLE_TREE_INTERFACE_H_
+#define CERT_TRANS_MERKLETREE_MERKLE_TREE_INTERFACE_H_
+
+#include <stddef.h>
+#include <string>
+
+#include "base/macros.h"
+
+namespace cert_trans {
+
+// An interface for Merkle trees.  See specializations in
+// merkletree/merkle_tree.h and merkletree/compact_merkle_tree.h.
+class MerkleTreeInterface {
+ public:
+  MerkleTreeInterface() = default;
+  virtual ~MerkleTreeInterface() = default;
+
+  // Length of a node (i.e., a hash), in bytes.
+  virtual size_t NodeSize() const = 0;
+
+  // Number of leaves in the tree.
+  virtual size_t LeafCount() const = 0;
+
+  // Returns the leaf hash, but do not append the data to the tree.
+  virtual std::string LeafHash(const std::string& data) const = 0;
+
+  // Number of levels. An empty tree has 0 levels, a tree with 1 leaf has
+  // 1 level, a tree with 2 leaves has 2 levels, and a tree with n leaves has
+  // ceil(log2(n)) + 1 levels.
+  virtual size_t LevelCount() const = 0;
+
+  // Add a new leaf to the hash tree.
+  //
+  // Returns the position of the leaf in the tree. Indexing starts at 1,
+  // so position = number of leaves in the tree after this update.
+  //
+  // @param data Binary input blob
+  virtual size_t AddLeaf(const std::string& data) = 0;
+
+  // Add a new leaf to the hash tree. It is the caller's responsibility
+  // to ensure that the hash is correct.
+  //
+  // Returns the position of the leaf in the tree. Indexing starts at 1,
+  // so position = number of leaves in the tree after this update.
+  //
+  // @param hash leaf hash
+  virtual size_t AddLeafHash(const std::string& hash) = 0;
+
+  // Get the current root of the tree.
+  // Update the root to reflect the current shape of the tree,
+  // and return the tree digest.
+  //
+  // Returns the hash of an empty string if the tree has no leaves
+  // (and hence, no root).
+  virtual std::string CurrentRoot() = 0;
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(MerkleTreeInterface);
+};
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_MERKLETREE_MERKLE_TREE_INTERFACE_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_large_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_large_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_large_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_large_test.cc	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,68 @@
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <stddef.h>
+#include <stdint.h>
+#include <sys/resource.h>
+#include <string>
+#include <vector>
+
+#include "merkletree/merkle_tree.h"
+#include "merkletree/serial_hasher.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+namespace {
+
+using std::string;
+using std::unique_ptr;
+
+class MerkleTreeLargeTest : public ::testing::Test {
+ protected:
+  string data_;
+  MerkleTreeLargeTest() : data_(string(1024, 0x42)) {
+  }
+};
+
+TEST_F(MerkleTreeLargeTest, BuildLargeTree) {
+  std::vector<MerkleTree*> trees;
+  int original_log_level = FLAGS_minloglevel;
+  for (size_t tree_size = 1024; tree_size <= 4194304; tree_size *= 4) {
+    FLAGS_minloglevel = 0;
+    LOG(INFO) << "Building a tree with " << tree_size << " leaves";
+    FLAGS_minloglevel = original_log_level;
+
+    struct rusage ru;
+    getrusage(RUSAGE_SELF, &ru);
+    long max_rss_before = ru.ru_maxrss;
+    MerkleTree* tree(
+        new MerkleTree(unique_ptr<Sha256Hasher>(new Sha256Hasher)));
+    trees.push_back(tree);
+    uint64_t time_before = util::TimeInMilliseconds();
+
+    for (size_t i = 0; i < tree_size; ++i)
+      tree->AddLeaf(data_);
+    EXPECT_FALSE(tree->CurrentRoot().empty());
+    EXPECT_TRUE(tree->LeafCount() == tree_size);
+    getrusage(RUSAGE_SELF, &ru);
+    uint64_t time_after = util::TimeInMilliseconds();
+
+    FLAGS_minloglevel = 0;
+    LOG(INFO) << "Peak RSS delta (as reported by getrusage()) was "
+              << ru.ru_maxrss - max_rss_before << " kB";
+
+    LOG(INFO) << "Elapsed time: " << time_after - time_before << " ms";
+    FLAGS_minloglevel = original_log_level;
+  }
+
+  for (size_t i = 0; i < trees.size(); ++i) {
+    EXPECT_FALSE(trees[i]->CurrentRoot().empty());
+    delete trees[i];
+  }
+}
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_math.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_math.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_math.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_math.cc	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,29 @@
+#include "merkletree/merkle_tree_math.h"
+
+#include <stddef.h>
+
+// static
+bool MerkleTreeMath::IsPowerOfTwoPlusOne(size_t leaf_count) {
+  if (leaf_count == 0)
+    return false;
+  if (leaf_count == 1)
+    return true;
+  // leaf_count is a power of two plus one if and only if
+  // ((leaf_count -1) & (leaf_count - 2)) has no bits set.
+  return (((leaf_count - 1) & (leaf_count - 2)) == 0);
+}
+
+// Index of the parent node in the parent level of the tree.
+size_t MerkleTreeMath::Parent(size_t leaf) {
+  return leaf >> 1;
+}
+
+// True if the node is a right child; false if it is the left (or only) child.
+bool MerkleTreeMath::IsRightChild(size_t leaf) {
+  return leaf & 1;
+}
+
+// Index of the node's (left or right) sibling in the same level.
+size_t MerkleTreeMath::Sibling(size_t leaf) {
+  return IsRightChild(leaf) ? (leaf - 1) : (leaf + 1);
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_math.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_math.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_math.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_math.h	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,24 @@
+#ifndef CERT_TRANS_MERKLETREE_MERKLE_TREE_MATH_H_
+#define CERT_TRANS_MERKLETREE_MERKLE_TREE_MATH_H_
+
+#include <stddef.h>
+
+class MerkleTreeMath {
+ public:
+  static bool IsPowerOfTwoPlusOne(size_t leaf_count);
+
+  // Index of the parent node in the parent level of the tree.
+  static size_t Parent(size_t leaf);
+
+  // True if the node is a right child; false if it is the left (or only)
+  // child.
+  static bool IsRightChild(size_t leaf);
+
+  // Index of the node's (left or right) sibling in the same level.
+  static size_t Sibling(size_t leaf);
+
+ private:
+  MerkleTreeMath();
+};
+
+#endif  // CERT_TRANS_MERKLETREE_MERKLE_TREE_MATH_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_tree_test.cc	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,848 @@
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <stddef.h>
+#include <stdint.h>
+#include <stdlib.h>
+#include <time.h>
+#include <string>
+#include <vector>
+
+#include "merkletree/compact_merkle_tree.h"
+#include "merkletree/merkle_tree.h"
+#include "merkletree/merkle_verifier.h"
+#include "merkletree/serial_hasher.h"
+#include "merkletree/tree_hasher.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+namespace {
+
+using std::string;
+using std::unique_ptr;
+
+// REFERENCE IMPLEMENTATIONS
+
+// Get the largest power of two smaller than i.
+int DownToPowerOfTwo(int i) {
+  CHECK_GE(i, 2);
+  // Find the smallest power of two greater than or equal to i.
+  int split = 1;
+  do {
+    split <<= 1;
+  } while (split < i);
+
+  // Get the largest power of two smaller than i.
+  return split >> 1;
+}
+
+// Reference implementation of Merkle hash, for cross-checking.
+string ReferenceMerkleTreeHash(string inputs[], int input_size,
+                               TreeHasher* treehasher) {
+  if (!input_size)
+    return treehasher->HashEmpty();
+  if (input_size == 1)
+    return treehasher->HashLeaf(inputs[0]);
+
+  const int split = DownToPowerOfTwo(input_size);
+
+  return treehasher->HashChildren(
+      ReferenceMerkleTreeHash(&inputs[0], split, treehasher),
+      ReferenceMerkleTreeHash(&inputs[split], input_size - split, treehasher));
+}
+
+// Reference implementation of Merkle paths. Path from leaf to root,
+// excluding the leaf and root themselves.
+std::vector<string> ReferenceMerklePath(string inputs[], int input_size,
+                                        int leaf, TreeHasher* treehasher) {
+  std::vector<string> path;
+  if (leaf > input_size || leaf == 0)
+    return path;
+
+  if (input_size == 1)
+    return path;
+
+  const int split = DownToPowerOfTwo(input_size);
+
+  std::vector<string> subpath;
+  if (leaf <= split) {
+    subpath = ReferenceMerklePath(&inputs[0], split, leaf, treehasher);
+    path.insert(path.end(), subpath.begin(), subpath.end());
+    path.push_back(ReferenceMerkleTreeHash(&inputs[split], input_size - split,
+                                           treehasher));
+  } else {
+    subpath = ReferenceMerklePath(&inputs[split], input_size - split,
+                                  leaf - split, treehasher);
+    path.insert(path.end(), subpath.begin(), subpath.end());
+    path.push_back(ReferenceMerkleTreeHash(&inputs[0], split, treehasher));
+  }
+
+  return path;
+}
+
+// Reference implementation of snapshot consistency.
+// Call with have_root1 = true.
+std::vector<string> ReferenceSnapshotConsistency(string inputs[],
+                                                 int snapshot2, int snapshot1,
+                                                 TreeHasher* treehasher,
+                                                 bool have_root1) {
+  std::vector<string> proof;
+  if (snapshot1 == 0 || snapshot1 > snapshot2)
+    return proof;
+  if (snapshot1 == snapshot2) {
+    // Consistency proof for two equal subtrees is empty.
+    if (!have_root1)
+      // Record the hash of this subtree unless it's the root for which
+      // the proof was originally requested. (This happens when the snapshot1
+      // tree is balanced.)
+      proof.push_back(ReferenceMerkleTreeHash(inputs, snapshot1, treehasher));
+    return proof;
+  }
+
+  // 0 < snapshot1 < snapshot2
+  const int split = DownToPowerOfTwo(snapshot2);
+
+  std::vector<string> subproof;
+  if (snapshot1 <= split) {
+    // Root of snapshot1 is in the left subtree of snapshot2.
+    // Prove that the left subtrees are consistent.
+    subproof = ReferenceSnapshotConsistency(inputs, split, snapshot1,
+                                            treehasher, have_root1);
+    proof.insert(proof.end(), subproof.begin(), subproof.end());
+    // Record the hash of the right subtree (only present in snapshot2).
+    proof.push_back(ReferenceMerkleTreeHash(&inputs[split], snapshot2 - split,
+                                            treehasher));
+  } else {
+    // Snapshot1 root is at the same level as snapshot2 root.
+    // Prove that the right subtrees are consistent. The right subtree
+    // doesn't contain the root of snapshot1, so set have_root1 = false.
+    subproof =
+        ReferenceSnapshotConsistency(&inputs[split], snapshot2 - split,
+                                     snapshot1 - split, treehasher, false);
+    proof.insert(proof.end(), subproof.begin(), subproof.end());
+    // Record the hash of the left subtree (equal in both trees).
+    proof.push_back(ReferenceMerkleTreeHash(&inputs[0], split, treehasher));
+  }
+  return proof;
+}
+
+class MerkleTreeTest : public ::testing::Test {
+ protected:
+  TreeHasher tree_hasher_;
+  std::vector<string> data_;
+  MerkleTreeTest() : tree_hasher_(unique_ptr<Sha256Hasher>(new Sha256Hasher)) {
+    for (int i = 0; i < 256; ++i)
+      data_.push_back(string(1, i));
+  }
+};
+
+class MerkleTreeFuzzTest : public MerkleTreeTest {
+ protected:
+  MerkleTreeFuzzTest() : MerkleTreeTest() {
+  }
+  void SetUp() {
+    srand(time(NULL));
+  }
+};
+
+class CompactMerkleTreeTest : public MerkleTreeTest {};
+
+class CompactMerkleTreeFuzzTest : public MerkleTreeFuzzTest {
+ protected:
+  string RandomLeaf(size_t len) {
+    string r;
+    for (size_t i = 0; i < len; ++i) {
+      r += uint8_t(rand() % 0xff);
+    }
+    return r;
+  }
+};
+
+unique_ptr<Sha256Hasher> NewSha256Hasher() {
+  return unique_ptr<Sha256Hasher>(new Sha256Hasher);
+}
+
+// FUZZ TESTS AGAINST REFERENCE IMPLEMENTATIONS
+
+// Make random root queries and check against the reference hash.
+TEST_F(MerkleTreeFuzzTest, RootFuzz) {
+  for (size_t tree_size = 1; tree_size <= data_.size(); ++tree_size) {
+    MerkleTree tree(NewSha256Hasher());
+    for (size_t j = 0; j < tree_size; ++j)
+      tree.AddLeaf(data_[j]);
+    // Since the tree is evaluated lazily, the order of queries is significant.
+    // Generate a random sequence of 8 queries for each tree.
+    for (size_t j = 0; j < 8; ++j) {
+      // A snapshot in the range 0...tree_size.
+      const size_t snapshot = rand() % (tree_size + 1);
+      EXPECT_EQ(tree.RootAtSnapshot(snapshot),
+                ReferenceMerkleTreeHash(data_.data(), snapshot,
+                                        &tree_hasher_));
+    }
+  }
+}
+
+TEST_F(CompactMerkleTreeTest, RootFuzz) {
+  for (size_t tree_size = 1; tree_size <= data_.size(); ++tree_size) {
+    CompactMerkleTree tree(NewSha256Hasher());
+    for (size_t j = 0; j < tree_size; ++j) {
+      tree.AddLeaf(data_[j]);
+      // Since the tree is evaluated lazily, the tree state is significant
+      // when querying the root hash. Flip a coin and decide whether to
+      // query now or later.
+      if (rand() & 1) {
+        EXPECT_EQ(tree.CurrentRoot(),
+                  ReferenceMerkleTreeHash(data_.data(), j + 1, &tree_hasher_));
+      }
+    }
+  }
+}
+
+// Make random path queries and check against the reference implementation.
+TEST_F(MerkleTreeFuzzTest, PathFuzz) {
+  for (size_t tree_size = 1; tree_size <= data_.size(); ++tree_size) {
+    MerkleTree tree(NewSha256Hasher());
+    for (size_t j = 0; j < tree_size; ++j)
+      tree.AddLeaf(data_[j]);
+
+    // Since the tree is evaluated lazily, the order of queries is significant.
+    // Generate a random sequence of 8 queries for each tree.
+    for (size_t j = 0; j < 8; ++j) {
+      // A snapshot in the range 0... length.
+      const size_t snapshot = rand() % (tree_size + 1);
+      // A leaf in the range 0... snapshot.
+      const size_t leaf = rand() % (snapshot + 1);
+      EXPECT_EQ(tree.PathToRootAtSnapshot(leaf, snapshot),
+                ReferenceMerklePath(data_.data(), snapshot, leaf,
+                                    &tree_hasher_));
+    }
+  }
+}
+
+// Make random proof queries and check against the reference implementation.
+TEST_F(MerkleTreeFuzzTest, ConsistencyFuzz) {
+  for (size_t tree_size = 1; tree_size <= data_.size(); ++tree_size) {
+    MerkleTree tree(NewSha256Hasher());
+    for (size_t j = 0; j < tree_size; ++j)
+      tree.AddLeaf(data_[j]);
+
+    // Since the tree is evaluated lazily, the order of queries is significant.
+    // Generate a random sequence of 8 queries for each tree.
+    for (size_t j = 0; j < 8; ++j) {
+      // A snapshot in the range 0... length.
+      const size_t snapshot2 = rand() % (tree_size + 1);
+      // A snapshot in the range 0... snapshot.
+      const size_t snapshot1 = rand() % (snapshot2 + 1);
+      EXPECT_EQ(tree.SnapshotConsistency(snapshot1, snapshot2),
+                ReferenceSnapshotConsistency(data_.data(), snapshot2,
+                                             snapshot1, &tree_hasher_, true));
+    }
+  }
+}
+
+// KNOWN ANSWER TESTS
+
+typedef struct {
+  const char* str;
+  int length_bytes;
+} TestVector;
+
+// A slightly shorter notation for constructing binary blobs from test vectors.
+#define S(t) util::BinaryString(string(t.str, 2 * t.length_bytes))
+// The reverse
+#define H(t) util::HexString(t)
+
+// The hash of an empty tree is the hash of the empty string.
+// (see SerialHasherTest and http://csrc.nist.gov/groups/STM/cavp/)
+const TestVector kSHA256EmptyTreeHash = {
+    "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", 32};
+
+// Inputs to the reference tree, which has eight leaves.
+const TestVector kInputs[8] = {
+    {"", 0},
+    {"00", 1},
+    {"10", 1},
+    {"2021", 2},
+    {"3031", 2},
+    {"40414243", 4},
+    {"5051525354555657", 8},
+    {"606162636465666768696a6b6c6d6e6f", 16},
+};
+
+// Level counts for number of leaves in [1, 8]
+const size_t kLevelCounts[8] = {1, 2, 3, 3, 4, 4, 4, 4};
+
+// Incremental roots from building the reference tree from inputs leaf-by-leaf.
+// Generated from ReferenceMerkleTreeHash.
+const TestVector kSHA256Roots[8] = {
+    {"6e340b9cffb37a989ca544e6bb780a2c78901d3fb33738768511a30617afa01d", 32},
+    {"fac54203e7cc696cf0dfcb42c92a1d9dbaf70ad9e621f4bd8d98662f00e3c125", 32},
+    {"aeb6bcfe274b70a14fb067a5e5578264db0fa9b51af5e0ba159158f329e06e77", 32},
+    {"d37ee418976dd95753c1c73862b9398fa2a2cf9b4ff0fdfe8b30cd95209614b7", 32},
+    {"4e3bbb1f7b478dcfe71fb631631519a3bca12c9aefca1612bfce4c13a86264d4", 32},
+    {"76e67dadbcdf1e10e1b74ddc608abd2f98dfb16fbce75277b5232a127f2087ef", 32},
+    {"ddb89be403809e325750d3d263cd78929c2942b7942a34b77e122c9594a74c8c", 32},
+    {"5dc9da79a70659a9ad559cb701ded9a2ab9d823aad2f4960cfe370eff4604328", 32}};
+
+TEST_F(MerkleTreeTest, RootTestVectors) {
+  // The first tree: add nodes one by one.
+  MerkleTree tree1(NewSha256Hasher());
+  EXPECT_EQ(tree1.LeafCount(), 0U);
+  EXPECT_EQ(tree1.LevelCount(), 0U);
+  EXPECT_STREQ(H(tree1.CurrentRoot()).c_str(), kSHA256EmptyTreeHash.str);
+  for (size_t i = 0; i < 8; ++i) {
+    tree1.AddLeaf(S(kInputs[i]));
+    EXPECT_EQ(tree1.LeafCount(), i + 1);
+    EXPECT_EQ(tree1.LevelCount(), kLevelCounts[i]);
+    EXPECT_STREQ(H(tree1.CurrentRoot()).c_str(), kSHA256Roots[i].str);
+    EXPECT_STREQ(H(tree1.RootAtSnapshot(0)).c_str(), kSHA256EmptyTreeHash.str);
+    for (size_t j = 0; j <= i; ++j) {
+      EXPECT_STREQ(H(tree1.RootAtSnapshot(j + 1)).c_str(),
+                   kSHA256Roots[j].str);
+    }
+
+    for (size_t j = i + 1; j < 8; ++j) {
+      EXPECT_EQ(tree1.RootAtSnapshot(j + 1), string());
+    }
+  }
+
+  // The second tree: add all nodes at once.
+  MerkleTree tree2(NewSha256Hasher());
+  for (int i = 0; i < 8; ++i) {
+    tree2.AddLeaf(S(kInputs[i]));
+  }
+  EXPECT_EQ(tree2.LeafCount(), 8U);
+  EXPECT_EQ(tree2.LevelCount(), kLevelCounts[7]);
+  EXPECT_STREQ(H(tree2.CurrentRoot()).c_str(), kSHA256Roots[7].str);
+
+  // The third tree: add nodes in two chunks.
+  MerkleTree tree3(NewSha256Hasher());
+  // Add three nodes.
+  for (int i = 0; i < 3; ++i) {
+    tree3.AddLeaf(S(kInputs[i]));
+  }
+  EXPECT_EQ(tree3.LeafCount(), 3U);
+  EXPECT_EQ(tree3.LevelCount(), kLevelCounts[2]);
+  EXPECT_STREQ(H(tree3.CurrentRoot()).c_str(), kSHA256Roots[2].str);
+  // Add the remaining nodes.
+  for (int i = 3; i < 8; ++i) {
+    tree3.AddLeaf(S(kInputs[i]));
+  }
+  EXPECT_EQ(tree3.LeafCount(), 8U);
+  EXPECT_EQ(tree3.LevelCount(), kLevelCounts[7]);
+  EXPECT_STREQ(H(tree3.CurrentRoot()).c_str(), kSHA256Roots[7].str);
+}
+
+TEST_F(CompactMerkleTreeTest, RootTestVectors) {
+  // The first tree: add nodes one by one.
+  CompactMerkleTree tree1(NewSha256Hasher());
+  EXPECT_EQ(tree1.LeafCount(), 0U);
+  EXPECT_EQ(tree1.LevelCount(), 0U);
+  EXPECT_STREQ(H(tree1.CurrentRoot()).c_str(), kSHA256EmptyTreeHash.str);
+  for (size_t i = 0; i < 8; ++i) {
+    tree1.AddLeaf(S(kInputs[i]));
+    EXPECT_EQ(tree1.LeafCount(), i + 1);
+    EXPECT_EQ(tree1.LevelCount(), kLevelCounts[i]);
+    EXPECT_STREQ(H(tree1.CurrentRoot()).c_str(), kSHA256Roots[i].str);
+  }
+
+  // The second tree: add all nodes at once.
+  CompactMerkleTree tree2(NewSha256Hasher());
+  for (int i = 0; i < 8; ++i) {
+    tree2.AddLeaf(S(kInputs[i]));
+  }
+  EXPECT_EQ(tree2.LeafCount(), 8U);
+  EXPECT_EQ(tree2.LevelCount(), kLevelCounts[7]);
+  EXPECT_STREQ(H(tree2.CurrentRoot()).c_str(), kSHA256Roots[7].str);
+
+  // The third tree: add nodes in two chunks.
+  CompactMerkleTree tree3(NewSha256Hasher());
+  // Add three nodes.
+  for (int i = 0; i < 3; ++i) {
+    tree3.AddLeaf(S(kInputs[i]));
+  }
+  EXPECT_EQ(tree3.LeafCount(), 3U);
+  EXPECT_EQ(tree3.LevelCount(), kLevelCounts[2]);
+  EXPECT_STREQ(H(tree3.CurrentRoot()).c_str(), kSHA256Roots[2].str);
+  // Add the remaining nodes.
+  for (int i = 3; i < 8; ++i) {
+    tree3.AddLeaf(S(kInputs[i]));
+  }
+  EXPECT_EQ(tree3.LeafCount(), 8U);
+  EXPECT_EQ(tree3.LevelCount(), kLevelCounts[7]);
+  EXPECT_STREQ(H(tree3.CurrentRoot()).c_str(), kSHA256Roots[7].str);
+}
+
+TEST_F(CompactMerkleTreeTest, TestCopyCtorWithRootTestVectors) {
+  MerkleTree tree1(NewSha256Hasher());
+  CompactMerkleTree refctree1(NewSha256Hasher());
+  EXPECT_EQ(tree1.LeafCount(), 0U);
+  EXPECT_EQ(tree1.LevelCount(), 0U);
+  EXPECT_STREQ(H(tree1.CurrentRoot()).c_str(), kSHA256EmptyTreeHash.str);
+  for (size_t i = 0; i < 8; ++i) {
+    tree1.AddLeaf(S(kInputs[i]));
+    refctree1.AddLeaf(S(kInputs[i]));
+  }
+  EXPECT_EQ(tree1.LeafCount(), 8U);
+  EXPECT_EQ(tree1.LevelCount(), kLevelCounts[7]);
+  EXPECT_STREQ(H(tree1.CurrentRoot()).c_str(), kSHA256Roots[7].str);
+
+  CompactMerkleTree ctree1(&tree1, NewSha256Hasher());
+  EXPECT_EQ(tree1.LeafCount(), ctree1.LeafCount());
+  EXPECT_EQ(tree1.LevelCount(), ctree1.LevelCount());
+  EXPECT_EQ(tree1.CurrentRoot(), ctree1.CurrentRoot());
+}
+
+TEST_F(CompactMerkleTreeTest, TestCopyCtorThenAddLeafWithRootTestVectors) {
+  MerkleTree tree(NewSha256Hasher());
+  EXPECT_EQ(tree.LeafCount(), 0U);
+  EXPECT_EQ(tree.LevelCount(), 0U);
+  EXPECT_STREQ(H(tree.CurrentRoot()).c_str(), kSHA256EmptyTreeHash.str);
+  for (size_t i = 0; i < 5; ++i) {
+    tree.AddLeaf(S(kInputs[i]));
+  }
+  EXPECT_EQ(tree.LeafCount(), 5U);
+  EXPECT_EQ(tree.LevelCount(), kLevelCounts[4]);
+  EXPECT_STREQ(H(tree.CurrentRoot()).c_str(), kSHA256Roots[4].str);
+  CompactMerkleTree ctree(&tree, NewSha256Hasher());
+  EXPECT_EQ(tree.LeafCount(), ctree.LeafCount());
+  EXPECT_EQ(tree.LevelCount(), ctree.LevelCount());
+  EXPECT_EQ(tree.CurrentRoot(), ctree.CurrentRoot());
+
+  // Add the remaining nodes.
+  for (int i = 5; i < 6; ++i) {
+    tree.AddLeaf(S(kInputs[i]));
+    ctree.AddLeaf(S(kInputs[i]));
+  }
+  EXPECT_EQ(tree.LeafCount(), 6U);
+  EXPECT_EQ(tree.LevelCount(), kLevelCounts[5]);
+  EXPECT_STREQ(H(tree.CurrentRoot()).c_str(), kSHA256Roots[5].str);
+  EXPECT_EQ(tree.LeafCount(), ctree.LeafCount());
+  EXPECT_EQ(tree.LevelCount(), ctree.LevelCount());
+  EXPECT_EQ(tree.CurrentRoot(), ctree.CurrentRoot());
+}
+
+TEST_F(CompactMerkleTreeFuzzTest, CopyCtorForLargerTreesThenAppend) {
+  for (size_t tree_size = 1; tree_size <= 512; ++tree_size) {
+    // Build a tree of |tree_size| from random leaves
+    MerkleTree tree(NewSha256Hasher());
+    for (size_t i = 0; i < tree_size; ++i) {
+      const string l(RandomLeaf(256));
+      tree.AddLeaf(l);
+    }
+    EXPECT_EQ(tree.LeafCount(), tree_size);
+    // Now build a CompactMerkleTree using |tree| as the model
+    CompactMerkleTree ctree(&tree, NewSha256Hasher());
+    // And check that the public interface concurs
+    EXPECT_EQ(tree.LeafCount(), ctree.LeafCount());
+    EXPECT_EQ(tree.LevelCount(), ctree.LevelCount());
+    EXPECT_EQ(tree.CurrentRoot(), ctree.CurrentRoot());
+    // Now add a bunch more nodes and check that the compact tree
+    // doesn't diverge from the reference tree:
+    for (size_t i = 0; i < 256; ++i) {
+      const string l(RandomLeaf(256));
+      tree.AddLeaf(l);
+      ctree.AddLeaf(l);
+      EXPECT_EQ(tree.LeafCount(), ctree.LeafCount());
+      EXPECT_EQ(tree.LevelCount(), ctree.LevelCount());
+      EXPECT_EQ(tree.CurrentRoot(), ctree.CurrentRoot());
+    }
+  }
+}
+
+// Some paths for the reference tree.
+typedef struct {
+  int leaf;
+  int snapshot;
+  int path_length;
+  TestVector path[3];
+} PathTestVector;
+
+// Generated from ReferenceMerklePath.
+const PathTestVector kSHA256Paths[6] = {
+    {0, 0, 0, {{"", 0}, {"", 0}, {"", 0}}},
+    {1, 1, 0, {{"", 0}, {"", 0}, {"", 0}}},
+    {1,
+     8,
+     3,
+     {{"96a296d224f285c67bee93c30f8a309157f0daa35dc5b87e410b78630a09cfc7", 32},
+      {"5f083f0a1a33ca076a95279832580db3e0ef4584bdff1f54c8a360f50de3031e", 32},
+      {"6b47aaf29ee3c2af9af889bc1fb9254dabd31177f16232dd6aab035ca39bf6e4",
+       32}}},
+    {6,
+     8,
+     3,
+     {{"bc1a0643b12e4d2d7c77918f44e0f4f79a838b6cf9ec5b5c283e1f4d88599e6b", 32},
+      {"ca854ea128ed050b41b35ffc1b87b8eb2bde461e9e3b5596ece6b9d5975a0ae0", 32},
+      {"d37ee418976dd95753c1c73862b9398fa2a2cf9b4ff0fdfe8b30cd95209614b7",
+       32}}},
+    {3,
+     3,
+     1,
+     {{"fac54203e7cc696cf0dfcb42c92a1d9dbaf70ad9e621f4bd8d98662f00e3c125", 32},
+      {"", 0},
+      {"", 0}}},
+    {2,
+     5,
+     3,
+     {{"6e340b9cffb37a989ca544e6bb780a2c78901d3fb33738768511a30617afa01d", 32},
+      {"5f083f0a1a33ca076a95279832580db3e0ef4584bdff1f54c8a360f50de3031e", 32},
+      {"bc1a0643b12e4d2d7c77918f44e0f4f79a838b6cf9ec5b5c283e1f4d88599e6b",
+       32}}}};
+
+TEST_F(MerkleTreeTest, PathTestVectors) {
+  // First tree: build in one go.
+  MerkleTree tree1(NewSha256Hasher());
+  for (int i = 0; i < 8; ++i) {
+    tree1.AddLeaf(S(kInputs[i]));
+  }
+  EXPECT_EQ(tree1.LeafCount(), 8U);
+  EXPECT_STREQ(H(tree1.CurrentRoot()).c_str(), kSHA256Roots[7].str);
+
+  EXPECT_TRUE(tree1.PathToCurrentRoot(9).empty());
+  for (int i = 0; i < 6; ++i) {
+    std::vector<string> path =
+        tree1.PathToRootAtSnapshot(kSHA256Paths[i].leaf,
+                                   kSHA256Paths[i].snapshot);
+    std::vector<string> kat_path;
+    for (int j = 0; j < kSHA256Paths[i].path_length; ++j)
+      kat_path.push_back(S(kSHA256Paths[i].path[j]));
+    EXPECT_EQ(path, kat_path);
+  }
+
+  // Second tree: build incrementally.
+  MerkleTree tree2(NewSha256Hasher());
+  EXPECT_EQ(tree2.PathToCurrentRoot(0), tree1.PathToRootAtSnapshot(0, 0));
+  EXPECT_TRUE(tree2.PathToCurrentRoot(1).empty());
+  for (int i = 0; i < 8; ++i) {
+    tree2.AddLeaf(S(kInputs[i]));
+    for (int j = 0; j <= i + 1; ++j) {
+      EXPECT_EQ(tree1.PathToRootAtSnapshot(j, i + 1),
+                tree2.PathToCurrentRoot(j));
+    }
+    for (int j = i + 2; j <= 9; ++j)
+      EXPECT_TRUE(tree1.PathToRootAtSnapshot(j, i + 1).empty());
+  }
+}
+
+typedef struct {
+  int snapshot1;
+  int snapshot2;
+  int proof_length;
+  TestVector proof[3];
+} ProofTestVector;
+
+// Generated from ReferenceSnapshotConsistency.
+const ProofTestVector kSHA256Proofs[4] = {
+    {1, 1, 0, {{"", 0}, {"", 0}, {"", 0}}},
+    {1,
+     8,
+     3,
+     {{"96a296d224f285c67bee93c30f8a309157f0daa35dc5b87e410b78630a09cfc7", 32},
+      {"5f083f0a1a33ca076a95279832580db3e0ef4584bdff1f54c8a360f50de3031e", 32},
+      {"6b47aaf29ee3c2af9af889bc1fb9254dabd31177f16232dd6aab035ca39bf6e4",
+       32}}},
+    {6,
+     8,
+     3,
+     {{"0ebc5d3437fbe2db158b9f126a1d118e308181031d0a949f8dededebc558ef6a", 32},
+      {"ca854ea128ed050b41b35ffc1b87b8eb2bde461e9e3b5596ece6b9d5975a0ae0", 32},
+      {"d37ee418976dd95753c1c73862b9398fa2a2cf9b4ff0fdfe8b30cd95209614b7",
+       32}}},
+    {2,
+     5,
+     2,
+     {{"5f083f0a1a33ca076a95279832580db3e0ef4584bdff1f54c8a360f50de3031e", 32},
+      {"bc1a0643b12e4d2d7c77918f44e0f4f79a838b6cf9ec5b5c283e1f4d88599e6b", 32},
+      {"", 0}}}};
+
+TEST_F(MerkleTreeTest, ConsistencyTestVectors) {
+  MerkleTree tree1(NewSha256Hasher());
+  for (int i = 0; i < 8; ++i) {
+    tree1.AddLeaf(S(kInputs[i]));
+  }
+  EXPECT_EQ(tree1.LeafCount(), 8U);
+  EXPECT_STREQ(H(tree1.CurrentRoot()).c_str(), kSHA256Roots[7].str);
+
+  for (int i = 0; i < 4; ++i) {
+    std::vector<string> proof =
+        tree1.SnapshotConsistency(kSHA256Proofs[i].snapshot1,
+                                  kSHA256Proofs[i].snapshot2);
+    std::vector<string> kat_proof;
+    for (int j = 0; j < kSHA256Proofs[i].proof_length; ++j)
+      kat_proof.push_back(S(kSHA256Proofs[i].proof[j]));
+    EXPECT_EQ(proof, kat_proof);
+  }
+}
+
+TEST_F(MerkleTreeTest, AddLeafHash) {
+  const char* kHashValue = "0123456789abcdef0123456789abcdef";
+  MerkleTree tree(NewSha256Hasher());
+  size_t index = tree.AddLeafHash(kHashValue);
+  EXPECT_EQ(1U, index);
+  EXPECT_EQ(kHashValue, tree.LeafHash(index));
+}
+
+TEST_F(CompactMerkleTreeTest, TestCloneEmptyTreeProducesWorkingTree) {
+  MerkleTree tree(NewSha256Hasher());
+  CompactMerkleTree compact(&tree, NewSha256Hasher());
+  EXPECT_STREQ(H(compact.CurrentRoot()).c_str(), kSHA256EmptyTreeHash.str);
+}
+
+// VERIFICATION TESTS
+
+class MerkleVerifierTest : public MerkleTreeTest {
+ protected:
+  MerkleVerifier verifier_;
+  MerkleVerifierTest()
+      : MerkleTreeTest(),
+        verifier_(unique_ptr<Sha256Hasher>(new Sha256Hasher)) {
+  }
+
+  void VerifierCheck(int leaf, int tree_size, const std::vector<string>& path,
+                     const string& root, const string& data) {
+    // Verify the original path.
+    EXPECT_EQ(H(verifier_.RootFromPath(leaf, tree_size, path, data)), H(root));
+    EXPECT_TRUE(verifier_.VerifyPath(leaf, tree_size, path, root, data));
+
+    // Wrong leaf index.
+    EXPECT_FALSE(verifier_.VerifyPath(leaf - 1, tree_size, path, root, data));
+    EXPECT_FALSE(verifier_.VerifyPath(leaf + 1, tree_size, path, root, data));
+    EXPECT_FALSE(verifier_.VerifyPath(leaf ^ 2, tree_size, path, root, data));
+
+    // Wrong tree height.
+    EXPECT_FALSE(verifier_.VerifyPath(leaf, tree_size * 2, path, root, data));
+    EXPECT_FALSE(verifier_.VerifyPath(leaf, tree_size / 2, path, root, data));
+
+    // Wrong leaf.
+    const char wrong_leaf[] = "WrongLeaf";
+    EXPECT_FALSE(verifier_.VerifyPath(leaf, tree_size, path, root,
+                                      string(wrong_leaf, 9)));
+
+    // Wrong root.
+    EXPECT_FALSE(verifier_.VerifyPath(leaf, tree_size, path,
+                                      S(kSHA256EmptyTreeHash), data));
+
+    // Wrong paths.
+    std::vector<string> wrong_path;
+
+    // Modify a single element on the path.
+    for (size_t j = 0; j < path.size(); ++j) {
+      wrong_path = path;
+      wrong_path[j] = S(kSHA256EmptyTreeHash);
+      EXPECT_FALSE(
+          verifier_.VerifyPath(leaf, tree_size, wrong_path, root, data));
+    }
+
+    // Add garbage at the end of the path.
+    wrong_path = path;
+    wrong_path.push_back(string());
+    EXPECT_FALSE(
+        verifier_.VerifyPath(leaf, tree_size, wrong_path, root, data));
+    wrong_path.pop_back();
+
+    wrong_path.push_back(root);
+    EXPECT_FALSE(
+        verifier_.VerifyPath(leaf, tree_size, wrong_path, root, data));
+    wrong_path.pop_back();
+
+    // Remove a node from the end.
+    if (!wrong_path.empty()) {
+      wrong_path.pop_back();
+      EXPECT_FALSE(
+          verifier_.VerifyPath(leaf, tree_size, wrong_path, root, data));
+    }
+
+    // Add garbage in the beginning of the path.
+    wrong_path.clear();
+    wrong_path.push_back(string());
+    wrong_path.insert(wrong_path.end(), path.begin(), path.end());
+    EXPECT_FALSE(
+        verifier_.VerifyPath(leaf, tree_size, wrong_path, root, data));
+
+    wrong_path[0] = root;
+    EXPECT_FALSE(
+        verifier_.VerifyPath(leaf, tree_size, wrong_path, root, data));
+  }
+
+  void VerifierConsistencyCheck(int snapshot1, int snapshot2,
+                                const string& root1, const string& root2,
+                                const std::vector<string>& proof) {
+    // Verify the original consistency proof.
+    EXPECT_TRUE(verifier_.VerifyConsistency(snapshot1, snapshot2, root1, root2,
+                                            proof));
+
+    if (proof.empty())
+      // For simplicity test only non-trivial proofs that have root1 != root2
+      // snapshot1 != 0 and snapshot1 != snapshot2.
+      return;
+
+    // Wrong snapshot index.
+    EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1 - 1, snapshot2, root1,
+                                             root2, proof));
+    EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1 + 1, snapshot2, root1,
+                                             root2, proof));
+    EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1 ^ 2, snapshot2, root1,
+                                             root2, proof));
+
+    // Wrong tree height.
+    EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1, snapshot2 * 2, root1,
+                                             root2, proof));
+    EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1, snapshot2 / 2, root1,
+                                             root2, proof));
+
+    // Wrong root.
+    const char wrong_root[] = "WrongRoot";
+    const string bwrong_root(wrong_root, 9);
+    EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1, snapshot2, root1,
+                                             bwrong_root, proof));
+    EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1, snapshot2, bwrong_root,
+                                             root2, proof));
+    // Swap roots.
+    EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1, snapshot2, root2,
+                                             root1, proof));
+
+    // Wrong proofs.
+    std::vector<string> wrong_proof;
+    // Empty proof.
+    EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1, snapshot2, root1,
+                                             root2, wrong_proof));
+
+    // Modify a single element in the proof.
+    for (size_t j = 0; j < proof.size(); ++j) {
+      wrong_proof = proof;
+      wrong_proof[j] = S(kSHA256EmptyTreeHash);
+      EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1, snapshot2, root1,
+                                               root2, wrong_proof));
+    }
+
+    // Add garbage at the end of the proof.
+    wrong_proof = proof;
+    wrong_proof.push_back(string());
+    EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1, snapshot2, root1,
+                                             root2, wrong_proof));
+    wrong_proof.pop_back();
+
+    wrong_proof.push_back(proof.back());
+    EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1, snapshot2, root1,
+                                             root2, wrong_proof));
+    wrong_proof.pop_back();
+
+    // Remove a node from the end.
+    wrong_proof.pop_back();
+    EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1, snapshot2, root1,
+                                             root2, wrong_proof));
+
+    // Add garbage in the beginning of the proof.
+    wrong_proof.clear();
+    wrong_proof.push_back(string());
+    wrong_proof.insert(wrong_proof.end(), proof.begin(), proof.end());
+    EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1, snapshot2, root1,
+                                             root2, wrong_proof));
+
+    wrong_proof[0] = proof[0];
+    EXPECT_FALSE(verifier_.VerifyConsistency(snapshot1, snapshot2, root1,
+                                             root2, wrong_proof));
+  }
+};
+
+TEST_F(MerkleVerifierTest, VerifyPath) {
+  std::vector<string> path;
+  // Various invalid paths.
+  EXPECT_FALSE(verifier_.VerifyPath(0, 0, path, string(), string()));
+  EXPECT_FALSE(verifier_.VerifyPath(0, 1, path, string(), string()));
+  EXPECT_FALSE(verifier_.VerifyPath(1, 0, path, string(), string()));
+  EXPECT_FALSE(verifier_.VerifyPath(2, 1, path, string(), string()));
+
+  EXPECT_FALSE(
+      verifier_.VerifyPath(0, 0, path, S(kSHA256EmptyTreeHash), string()));
+  EXPECT_FALSE(
+      verifier_.VerifyPath(0, 1, path, S(kSHA256EmptyTreeHash), string()));
+  EXPECT_FALSE(
+      verifier_.VerifyPath(1, 0, path, S(kSHA256EmptyTreeHash), string()));
+  EXPECT_FALSE(
+      verifier_.VerifyPath(2, 1, path, S(kSHA256EmptyTreeHash), string()));
+
+  // Known good paths.
+  // i = 0 is an invalid path.
+  for (int i = 1; i < 6; ++i) {
+    // Construct the path.
+    path.clear();
+    for (int j = 0; j < kSHA256Paths[i].path_length; ++j)
+      path.push_back(S(kSHA256Paths[i].path[j]));
+    VerifierCheck(kSHA256Paths[i].leaf, kSHA256Paths[i].snapshot, path,
+                  S(kSHA256Roots[kSHA256Paths[i].snapshot - 1]),
+                  S(kInputs[kSHA256Paths[i].leaf - 1]));
+  }
+
+  // More tests with reference path generator.
+  string root;
+  for (size_t tree_size = 1; tree_size <= data_.size() / 2; ++tree_size) {
+    // Repeat for each leaf in range.
+    for (size_t leaf = 1; leaf <= tree_size; ++leaf) {
+      path = ReferenceMerklePath(data_.data(), tree_size, leaf, &tree_hasher_);
+      root = ReferenceMerkleTreeHash(data_.data(), tree_size, &tree_hasher_);
+      VerifierCheck(leaf, tree_size, path, root, data_[leaf - 1]);
+    }
+  }
+}
+
+TEST_F(MerkleVerifierTest, VerifyConsistencyProof) {
+  std::vector<string> proof;
+  string root1, root2;
+  // Snapshots that are always consistent.
+  EXPECT_TRUE(verifier_.VerifyConsistency(0, 0, root1, root2, proof));
+  EXPECT_TRUE(verifier_.VerifyConsistency(0, 1, root1, root2, proof));
+  EXPECT_TRUE(verifier_.VerifyConsistency(1, 1, root1, root2, proof));
+
+  // Invalid consistency proofs.
+  // Time travel to the past.
+  EXPECT_FALSE(verifier_.VerifyConsistency(1, 0, root1, root2, proof));
+  EXPECT_FALSE(verifier_.VerifyConsistency(2, 1, root1, root2, proof));
+  // Empty proof.
+  EXPECT_FALSE(verifier_.VerifyConsistency(1, 2, root1, root2, proof));
+
+  root1 = S(kSHA256EmptyTreeHash);
+  // Roots don't match.
+  EXPECT_FALSE(verifier_.VerifyConsistency(0, 0, root1, root2, proof));
+  EXPECT_FALSE(verifier_.VerifyConsistency(1, 1, root1, root2, proof));
+  // Roots match but the proof is not empty.
+  root2 = S(kSHA256EmptyTreeHash);
+  proof.push_back(S(kSHA256EmptyTreeHash));
+  EXPECT_FALSE(verifier_.VerifyConsistency(0, 0, root1, root2, proof));
+  EXPECT_FALSE(verifier_.VerifyConsistency(0, 1, root1, root2, proof));
+  EXPECT_FALSE(verifier_.VerifyConsistency(1, 1, root1, root2, proof));
+
+  // Known good proofs.
+  for (int i = 0; i < 4; ++i) {
+    proof.clear();
+    for (int j = 0; j < kSHA256Proofs[i].proof_length; ++j)
+      proof.push_back(S(kSHA256Proofs[i].proof[j]));
+    const int snapshot1 = kSHA256Proofs[i].snapshot1;
+    const int snapshot2 = kSHA256Proofs[i].snapshot2;
+    VerifierConsistencyCheck(snapshot1, snapshot2,
+                             S(kSHA256Roots[snapshot1 - 1]),
+                             S(kSHA256Roots[snapshot2 - 1]), proof);
+  }
+
+  // More tests with reference proof generator.
+  for (size_t tree_size = 1; tree_size <= data_.size() / 2; ++tree_size) {
+    root2 = ReferenceMerkleTreeHash(data_.data(), tree_size, &tree_hasher_);
+    // Repeat for each snapshot in range.
+    for (size_t snapshot = 1; snapshot <= tree_size; ++snapshot) {
+      proof = ReferenceSnapshotConsistency(data_.data(), tree_size, snapshot,
+                                           &tree_hasher_, true);
+      root1 = ReferenceMerkleTreeHash(data_.data(), snapshot, &tree_hasher_);
+      VerifierConsistencyCheck(snapshot, tree_size, root1, root2, proof);
+    }
+  }
+}
+
+#undef S
+#undef H
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_verifier.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_verifier.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_verifier.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_verifier.cc	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,138 @@
+#include "merkletree/merkle_verifier.h"
+
+#include <stddef.h>
+#include <vector>
+
+using std::move;
+using std::string;
+using std::unique_ptr;
+
+MerkleVerifier::MerkleVerifier(unique_ptr<SerialHasher> hasher)
+    : treehasher_(move(hasher)) {
+}
+
+MerkleVerifier::~MerkleVerifier() {
+}
+
+static inline size_t Parent(size_t leaf) {
+  return leaf >> 1;
+}
+
+static inline bool IsRightChild(size_t leaf) {
+  return leaf & 1;
+}
+
+bool MerkleVerifier::VerifyPath(size_t leaf, size_t tree_size,
+                                const std::vector<string>& path,
+                                const string& root, const string& data) {
+  string path_root = RootFromPath(leaf, tree_size, path, data);
+  if (path_root.empty())
+    return false;
+  return path_root == root;
+}
+
+string MerkleVerifier::RootFromPath(size_t leaf, size_t tree_size,
+                                    const std::vector<string>& path,
+                                    const string& data) {
+  if (leaf > tree_size || leaf == 0)
+    // No valid path exists.
+    return string();
+
+  size_t node = leaf - 1;
+  size_t last_node = tree_size - 1;
+
+  string node_hash = LeafHash(data);
+  std::vector<string>::const_iterator it = path.begin();
+
+  while (last_node) {
+    if (it == path.end())
+      // We've reached the end but we're not done yet.
+      return string();
+    if (IsRightChild(node))
+      node_hash = treehasher_.HashChildren(*it++, node_hash);
+    else if (node < last_node)
+      node_hash = treehasher_.HashChildren(node_hash, *it++);
+    // Else the sibling does not exist and the parent is a dummy copy.
+    // Do nothing.
+
+    node = Parent(node);
+    last_node = Parent(last_node);
+  }
+
+  // Check that we've reached the end.
+  if (it != path.end())
+    return string();
+  return node_hash;
+}
+
+bool MerkleVerifier::VerifyConsistency(size_t snapshot1, size_t snapshot2,
+                                       const string& root1,
+                                       const string& root2,
+                                       const std::vector<string>& proof) {
+  if (snapshot1 > snapshot2)
+    // Can't go back in time.
+    return false;
+  if (snapshot1 == snapshot2)
+    return root1 == root2 && proof.empty();
+  if (snapshot1 == 0)
+    // Any snapshot greater than 0 is consistent with snapshot 0.
+    return proof.empty();
+  // Now 0 < snapshot1 < snapshot2.
+  // Verify the roots.
+  size_t node = snapshot1 - 1;
+  size_t last_node = snapshot2 - 1;
+  if (proof.empty())
+    return false;
+  std::vector<string>::const_iterator it = proof.begin();
+  // Move up until the first mutable node.
+  while (IsRightChild(node)) {
+    node = Parent(node);
+    last_node = Parent(last_node);
+  }
+
+  string node1_hash;
+  string node2_hash;
+  if (node)
+    node2_hash = node1_hash = *it++;
+  else
+    // The tree at snapshot1 was balanced, nothing to verify for root1.
+    node2_hash = node1_hash = root1;
+  while (node) {
+    if (it == proof.end())
+      return false;
+
+    if (IsRightChild(node)) {
+      node1_hash = treehasher_.HashChildren(*it, node1_hash);
+      node2_hash = treehasher_.HashChildren(*it, node2_hash);
+      ++it;
+    } else if (node < last_node)
+      // The sibling only exists in the later tree. The parent in the
+      // snapshot1 tree is a dummy copy.
+      node2_hash = treehasher_.HashChildren(node2_hash, *it++);
+    // Else the sibling does not exist in either tree. Do nothing.
+
+    node = Parent(node);
+    last_node = Parent(last_node);
+  }
+
+  // Verify the first root.
+  if (node1_hash != root1)
+    return false;
+
+  // Continue until the second root.
+  while (last_node) {
+    if (it == proof.end())
+      // We've reached the end but we're not done yet.
+      return false;
+
+    node2_hash = treehasher_.HashChildren(node2_hash, *it++);
+    last_node = Parent(last_node);
+  }
+
+  // Verify the second root.
+  return node2_hash == root2 && it == proof.end();
+}
+
+string MerkleVerifier::LeafHash(const std::string& data) {
+  return treehasher_.HashLeaf(data);
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_verifier.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_verifier.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_verifier.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/merkle_verifier.h	2017-01-15 10:56:31.043591151 +0100
@@ -0,0 +1,57 @@
+#ifndef CERT_TRANS_MERKLETREE_MERKLE_VERIFIER_H_
+#define CERT_TRANS_MERKLETREE_MERKLE_VERIFIER_H_
+
+#include <stddef.h>
+#include <memory>
+#include <vector>
+
+#include "merkletree/tree_hasher.h"
+
+class SerialHasher;
+
+// Class for verifying paths emitted by MerkleTrees.
+// TODO: consistency proofs between snapshots.
+
+class MerkleVerifier {
+ public:
+  MerkleVerifier(std::unique_ptr<SerialHasher> hasher);
+  ~MerkleVerifier();
+
+  // Verify Merkle path. Return true iff the path is a valid proof for
+  // the leaf in the tree, i.e., iff 0 < leaf <= tree_size and path
+  // is a valid path from the leaf hash of data to the root.
+  //
+  // @param leaf index of the leaf.
+  // @param tree_size number of leaves in the tree.
+  // @param path a vector of node hashes ordered according to levels from leaf
+  // to root. Does not include the leaf hash or the root.
+  // @ param root The root hash
+  // @ param data The leaf data
+  bool VerifyPath(size_t leaf, size_t tree_size,
+                  const std::vector<std::string>& path,
+                  const std::string& root, const std::string& data);
+
+  // Compute the root corresponding to a Merkle audit path.
+  // Returns an empty string if the path is not valid.
+  //
+  // @param leaf index of the leaf.
+  // @param tree_size number of leaves in the tree.
+  // @param path a vector of node hashes ordered according to levels from leaf
+  // to root. Does not include the leaf hash or the root.
+  // @ param data The leaf data
+  std::string RootFromPath(size_t leaf, size_t tree_size,
+                           const std::vector<std::string>& path,
+                           const std::string& data);
+
+  bool VerifyConsistency(size_t snapshot1, size_t snapshot2,
+                         const std::string& root1, const std::string& root2,
+                         const std::vector<std::string>& proof);
+
+  // Return the leaf hash corresponding to the leaf input.
+  std::string LeafHash(const std::string& data);
+
+ private:
+  TreeHasher treehasher_;
+};
+
+#endif  // CERT_TRANS_MERKLETREE_MERKLE_VERIFIER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/serial_hasher.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/serial_hasher.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/serial_hasher.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/serial_hasher.cc	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,46 @@
+#include "merkletree/serial_hasher.h"
+
+#include <openssl/sha.h>
+#include <stddef.h>
+
+using std::string;
+using std::unique_ptr;
+
+const size_t Sha256Hasher::kDigestSize = SHA256_DIGEST_LENGTH;
+
+Sha256Hasher::Sha256Hasher() : initialized_(false) {
+}
+
+void Sha256Hasher::Reset() {
+  SHA256_Init(&ctx_);
+  initialized_ = true;
+}
+
+void Sha256Hasher::Update(const std::string& data) {
+  if (!initialized_)
+    Reset();
+
+  SHA256_Update(&ctx_, data.data(), data.size());
+}
+
+string Sha256Hasher::Final() {
+  if (!initialized_)
+    Reset();
+
+  unsigned char hash[SHA256_DIGEST_LENGTH];
+  SHA256_Final(hash, &ctx_);
+  initialized_ = false;
+  return string(reinterpret_cast<char*>(hash), SHA256_DIGEST_LENGTH);
+}
+
+unique_ptr<SerialHasher> Sha256Hasher::Create() const {
+  return unique_ptr<SerialHasher>(new Sha256Hasher);
+}
+
+// static
+string Sha256Hasher::Sha256Digest(const string& data) {
+  Sha256Hasher hasher;
+  hasher.Reset();
+  hasher.Update(data);
+  return hasher.Final();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/serial_hasher.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/serial_hasher.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/serial_hasher.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/serial_hasher.h	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,61 @@
+#ifndef CERT_TRANS_MERKLETREE_SERIAL_HASHER_H_
+#define CERT_TRANS_MERKLETREE_SERIAL_HASHER_H_
+
+#include <openssl/sha.h>
+#include <stddef.h>
+#include <memory>
+#include <string>
+
+#include "base/macros.h"
+
+class SerialHasher {
+ public:
+  SerialHasher() = default;
+  virtual ~SerialHasher() = default;
+
+  virtual size_t DigestSize() const = 0;
+
+  // Reset the context. Must be called before the first Update() call.
+  // Optionally it can be called after each Final() call; however
+  // doing so is a no-op since Final() will leave the hasher in a
+  // reset state.
+  virtual void Reset() = 0;
+
+  // Update the hash context with (binary) data.
+  virtual void Update(const std::string& data) = 0;
+
+  // Finalize the hash context and return the binary digest blob.
+  virtual std::string Final() = 0;
+
+  // A virtual constructor, creates a new instance of the same type.
+  virtual std::unique_ptr<SerialHasher> Create() const = 0;
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(SerialHasher);
+};
+
+class Sha256Hasher : public SerialHasher {
+ public:
+  Sha256Hasher();
+
+  size_t DigestSize() const {
+    return kDigestSize;
+  }
+
+  void Reset();
+  void Update(const std::string& data);
+  std::string Final();
+  std::unique_ptr<SerialHasher> Create() const;
+
+  // Create a new hasher and call Reset(), Update(), and Final().
+  static std::string Sha256Digest(const std::string& data);
+
+ private:
+  SHA256_CTX ctx_;
+  bool initialized_;
+  static const size_t kDigestSize;
+
+  DISALLOW_COPY_AND_ASSIGN(Sha256Hasher);
+};
+
+#endif  // CERT_TRANS_MERKLETREE_SERIAL_HASHER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/serial_hasher_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/serial_hasher_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/serial_hasher_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/serial_hasher_test.cc	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,128 @@
+#include <gtest/gtest.h>
+#include <stddef.h>
+#include <string>
+
+#include "merkletree/serial_hasher.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+namespace {
+
+using std::string;
+using std::unique_ptr;
+
+const char kTestString[] = "Hello world!";
+const size_t kTestStringLength = 12;
+
+typedef struct {
+  size_t input_length;
+  const char* input;
+  const char* output;
+} HashTestVector;
+
+// A couple of SHA-256 test vectors from http://csrc.nist.gov/groups/STM/cavp/
+HashTestVector test_sha256[] = {
+    {0, "",
+     "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"},
+    {8, "5738c929c4f4ccb6",
+     "963bb88f27f512777aab6c8b1a02c70ec0ad651d428f870036e1917120fb48bf"},
+    {63,
+     "e2f76e97606a872e317439f1a03fcd92e632e5bd4e7cbc4e97f1afc19a16fde9"
+     "2d77cbe546416b51640cddb92af996534dfd81edb17c4424cf1ac4d75aceeb",
+     "18041bd4665083001fba8c5411d2d748e8abbfdcdfd9218cb02b68a78e7d4c23"},
+    // to indicate the end
+    {0, NULL, NULL}};
+
+// A slightly shorter notation for constructing binary blobs from test vectors.
+#define S(t, n) util::BinaryString(string((t), (2 * n)))
+// The reverse
+#define H(t) util::HexString(t)
+
+template <class T>
+HashTestVector* TestVectors();
+
+template <>
+HashTestVector* TestVectors<Sha256Hasher>() {
+  return test_sha256;
+}
+
+template <class T>
+class SerialHasherTest : public ::testing::Test {
+ protected:
+  SerialHasher* hasher_;
+  HashTestVector* test_vectors_;
+
+  SerialHasherTest() : hasher_(new T()), test_vectors_(TestVectors<T>()) {
+  }
+
+  ~SerialHasherTest() {
+    delete hasher_;
+  }
+};
+
+typedef ::testing::Types<Sha256Hasher> Hashers;
+
+TYPED_TEST_CASE(SerialHasherTest, Hashers);
+
+// Known Answer Tests
+TYPED_TEST(SerialHasherTest, TestVectors) {
+  string input, output, digest;
+
+  for (size_t i = 0; this->test_vectors_[i].input != NULL; ++i) {
+    this->hasher_->Reset();
+    this->hasher_->Update(
+        S(this->test_vectors_[i].input, this->test_vectors_[i].input_length));
+    digest = this->hasher_->Final();
+    EXPECT_STREQ(H(digest).c_str(), this->test_vectors_[i].output);
+  }
+}
+
+// Test fragmented updates
+TYPED_TEST(SerialHasherTest, Update) {
+  string input(kTestString, kTestStringLength), output, digest;
+
+  this->hasher_->Reset();
+  this->hasher_->Update(input);
+  digest = this->hasher_->Final();
+  EXPECT_EQ(digest.size(), this->hasher_->DigestSize());
+
+  // The same in two chunks
+  this->hasher_->Reset();
+  this->hasher_->Update(input.substr(0, kTestStringLength / 2));
+  this->hasher_->Update(input.substr(kTestStringLength / 2));
+  output = this->hasher_->Final();
+  EXPECT_EQ(H(digest), H(output));
+}
+
+TYPED_TEST(SerialHasherTest, Create) {
+  string input, output, digest;
+
+  for (size_t i = 0; this->test_vectors_[i].input != NULL; ++i) {
+    unique_ptr<SerialHasher> new_hasher(this->hasher_->Create());
+    new_hasher->Reset();
+    new_hasher->Update(
+        S(this->test_vectors_[i].input, this->test_vectors_[i].input_length));
+    digest = new_hasher->Final();
+    EXPECT_STREQ(H(digest).c_str(), this->test_vectors_[i].output);
+  }
+}
+
+TEST(Sha256Test, StaticDigest) {
+  string input, output, digest;
+
+  for (size_t i = 0; test_sha256[i].input != NULL; ++i) {
+    digest = Sha256Hasher::Sha256Digest(
+        S(test_sha256[i].input, test_sha256[i].input_length));
+    EXPECT_STREQ(H(digest).c_str(), test_sha256[i].output);
+  }
+}
+
+#undef S
+#undef H
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/sparse_merkle_tree.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/sparse_merkle_tree.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/sparse_merkle_tree.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/sparse_merkle_tree.cc	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,212 @@
+#include "cpp/merkletree/sparse_merkle_tree.h"
+
+#include <stddef.h>
+#include <algorithm>
+#include <vector>
+
+#include "merkletree/merkle_tree_math.h"
+#include "util/util.h"
+
+using std::make_pair;
+using std::ostream;
+using std::ostringstream;
+using std::reverse;
+using std::string;
+using std::unique_ptr;
+using std::unordered_map;
+using std::vector;
+
+
+const vector<string>* GetNullHashes(const TreeHasher& hasher) {
+  static unique_ptr<const vector<string>> null_hashes;
+  if (!null_hashes) {
+    vector<string> r{hasher.HashLeaf("")};
+    const int end(hasher.DigestSize() * 8);
+    CHECK_LT(0, end);
+    for (int i(1); i < end; ++i) {
+      r.emplace_back(hasher.HashChildren(r.back(), r.back()));
+    }
+    reverse(r.begin(), r.end());
+    null_hashes.reset(new vector<string>(std::move(r)));
+  }
+  return null_hashes.get();
+}
+
+
+SparseMerkleTree::SparseMerkleTree(SerialHasher* hasher)
+    : treehasher_(unique_ptr<SerialHasher>(hasher)),
+      null_hashes_(GetNullHashes(treehasher_)) {
+}
+
+
+void SparseMerkleTree::EnsureHaveLevel(size_t level) {
+  if (tree_.size() < (level + 1)) {
+    tree_.resize(level + 1);
+  }
+}
+
+
+void SparseMerkleTree::SetLeaf(const Path& path, const string& data) {
+  CHECK_EQ(treehasher_.DigestSize(), path.size());
+  // Mark the tree dirty:
+  root_hash_.clear();
+  string leaf_hash(treehasher_.HashLeaf(data));
+
+  IndexType node_index(0);
+  for (int depth(0); depth <= kDigestSizeBits; ++depth) {
+    node_index += PathBit(path, depth);
+    EnsureHaveLevel(depth);
+    auto it(tree_[depth].find(node_index));
+    if (it == tree_[depth].end()) {
+      CHECK(tree_[depth]
+                .emplace(make_pair(node_index, TreeNode(path, leaf_hash)))
+                .second);
+      return;
+    } else if (it->second.type_ == TreeNode::INTERNAL) {
+      // Mark the internal node hash dirty
+      it->second.hash_.clear();
+    } else if (*it->second.path_ == path) {
+      // replacement
+      CHECK_EQ(TreeNode::LEAF, it->second.type_);
+      it->second.hash_ = std::move(leaf_hash);
+      return;
+    } else {
+      // restructure: push the existing node down a level and replace this one
+      // with an INTERNAL node
+      CHECK_LT(depth, kDigestSizeBits);
+      EnsureHaveLevel(depth + 1);
+      IndexType child_index((node_index << 1) +
+                            PathBit(*it->second.path_, depth + 1));
+      CHECK(tree_[depth + 1]
+                .emplace(make_pair(child_index, std::move(it->second)))
+                .second);
+      it->second.type_ = TreeNode::INTERNAL;
+      it->second.hash_.clear();
+    }
+    node_index <<= 1;
+  }
+  LOG(FATAL) << "Failed to set " << path << " to " << data;
+}
+
+
+void SparseMerkleTree::DumpTree(ostream* os, size_t depth,
+                                IndexType index) const {
+  if (tree_.size() <= depth) {
+    return;
+  }
+  const string indent((depth + 1) * 2, '-');
+  for (int side(0); side < 2; ++side) {
+    auto child(tree_[depth].find(index + side));
+    if (child != tree_[depth].end()) {
+      *os << indent << side << ": " << child->second.DebugString() << "\n";
+      DumpTree(os, depth + 1, (index + side) << 1);
+    }
+  }
+}
+
+
+string SparseMerkleTree::Dump() const {
+  ostringstream ret;
+  ret << "\nTree [Root: " << util::ToBase64(root_hash_) << "]:\n";
+  if (!tree_.empty()) {
+    DumpTree(&ret, 0, 0);
+  }
+  return ret.str();
+}
+
+
+string SparseMerkleTree::CalculateSubtreeHash(size_t depth, IndexType index) {
+  if (tree_.size() <= depth) {
+    return null_hashes_->at(depth);
+  }
+
+  auto it(tree_[depth].find(index));
+  if (it != tree_[depth].end()) {
+    switch (it->second.type_) {
+      case TreeNode::INTERNAL: {
+        if (!it->second.hash_.empty()) {
+          return it->second.hash_;
+        }
+        IndexType left_child_index(index << 1);
+        const string left(CalculateSubtreeHash(depth + 1, left_child_index));
+        const string right(
+            CalculateSubtreeHash(depth + 1, left_child_index + 1));
+        it->second.hash_.assign(treehasher_.HashChildren(left, right));
+        return it->second.hash_;
+      }
+
+      case TreeNode::LEAF: {
+        string ret(it->second.hash_);
+        const int64_t signed_depth(depth);
+        CHECK_LE(0, signed_depth);
+        for (int i(kDigestSizeBits - 1); i > signed_depth; --i) {
+          if (PathBit(*(it->second.path_), i) == 0) {
+            ret = treehasher_.HashChildren(ret, null_hashes_->at(i));
+          } else {
+            ret = treehasher_.HashChildren(null_hashes_->at(i), ret);
+          }
+        }
+        // TODO(alcutter): maybe cache this?
+        return ret;
+      }
+    }
+    LOG(FATAL) << "Unknown node type " << it->second.type_ << " !";
+  }
+
+  return null_hashes_->at(depth);
+}
+
+
+string SparseMerkleTree::CurrentRoot() {
+  if (root_hash_.empty()) {
+    root_hash_ = treehasher_.HashChildren(CalculateSubtreeHash(0, 0),
+                                          CalculateSubtreeHash(0, 1));
+  }
+  return root_hash_;
+}
+
+
+std::vector<string> SparseMerkleTree::InclusionProof(const Path& path) {
+  // TODO(alcutter): implement
+  LOG(FATAL) << "Not implemented.";
+}
+
+
+string SparseMerkleTree::TreeNode::DebugString() const {
+  ostringstream os;
+  os << "[TreeNode type: ";
+  switch (type_) {
+    case INTERNAL:
+      os << "I";
+      break;
+    case LEAF:
+      os << "L";
+      break;
+  }
+
+  os << " hash: ";
+  if (!hash_.empty()) {
+    os << util::ToBase64(hash_);
+  } else {
+    os << "(unset)";
+  }
+
+  if (path_) {
+    os << " path: ";
+    os << *path_;
+  }
+  os << "]";
+  return os.str();
+}
+
+
+ostream& operator<<(ostream& out, const SparseMerkleTree::Path& path) {
+  for (size_t i(0); i < path.size(); ++i) {
+    uint8_t t(path[i]);
+    for (size_t b(8); b > 0; --b) {
+      out << (t & 0x80 ? '1' : '0');
+      t <<= 1;
+    }
+  }
+  return out;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/sparse_merkle_tree.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/sparse_merkle_tree.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/sparse_merkle_tree.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/sparse_merkle_tree.h	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,250 @@
+#ifndef CERT_TRANS_MERKLETREE_SPARSE_MERKLE_TREE_H
+#define CERT_TRANS_MERKLETREE_SPARSE_MERKLE_TREE_H
+
+#include <glog/logging.h>
+#include <stddef.h>
+#include <array>
+#include <string>
+#include <unordered_map>
+#include <vector>
+
+#include "merkletree/merkle_tree_interface.h"
+#include "merkletree/tree_hasher.h"
+
+class SerialHasher;
+
+
+// Calculates the set of "null" hashes:
+// ...H(H(H("")||H(""))||H("")||(H(""))||...)...
+//
+// Visible out here because it's useful for testing too.
+const std::vector<std::string>* GetNullHashes(const TreeHasher& hasher);
+
+
+/* Implementation of a Sparse Merkle Tree.
+ *
+ * The design is inspired by the tree described in
+ * http://www.links.org/files/RevocationTransparency.pdf), but with some
+ * tweaks, most notably:
+ *   1) Leaf values are hashed before being incorporated into the tree.
+ *   2) Similar to the way it works in the CT MerkleTree, hashes are domain
+ *      separated by prefixing the preimage with \x00 for leaves, and \x01 for
+ *      internal nodes.
+ *
+ * These mean that level 2 nodes are of the form:
+ *      H(\x01||H(\0x00||valueL)||H(\0x00||valueR))
+ * and so on.
+ *
+ * Nodes are addressed by a Path, which is a bit-string of the same length as
+ * the output of the hashing fuction used.  This string describes a path down
+ * from the root to a leaf, with the 0-bits indicating the path takes the
+ * left-hand child branch, and 1-bits the right. e.g:
+ *        Root
+ *        /  \
+ *      0/    \1
+ *      /      \
+ *     i0      i3
+ *   0/ \1   0/  \1
+ *   /   \   /    \
+ *  l0  l1  l2    l3
+ *
+ *  The paths to the 4 leaves would then be:
+ *  l0: "00"
+ *  l1: "01"
+ *  l2: "10"
+ *  l3: "11"
+ *
+ * To help with memory consumption, leaves inserted into the tree are stored
+ * at the first unused node along their path.  An example is given below:
+ *
+ * * Empty tree:
+ *      Root
+ *
+ * * Add "10" = "hi":
+ * Since the tree is empty, the first bit of the added path is sufficient to
+ * identify a unique prefix, so the leaf is stored as the "1" entry
+ * immediately below the root.
+ *              Root
+ *                |
+ *                |_______1
+ *                       p:"10"
+ *                       v:"hi"
+ *
+ * * Add "11" = "to":
+ * The first bit of the added path is not enough to provide a unique
+ * prefix so the leaf node currently occupying the "1" node immediately below
+ * the root must be pushed down a level, resulting in:
+ *              Root
+ *                |
+ *                |_______1
+ *                        |
+ *                        |
+ *                  0_____|_____1
+ *                  |           |
+ *                p:"10"      p:"11"
+ *                v:"hi"      v:"to"
+ *
+ * (In the case where paths are longer and multiple bits of the prefix collide,
+ * the existing node is repeated pushed down a level until a unique prefix is
+ * found.)
+ *
+ * * Add "00" = "aa":
+ * The first bit of the added path is unique, and so the resulting tree is:
+ *              Root
+ *                |
+ *        0_______|_______1
+ *        |               |
+ *      p:"00"            |
+ *      v:"aa"      0_____|_____1
+ *                  |           |
+ *                p:"10"      p:"11"
+ *                v:"hi"      v:"to"
+ *
+ * * Calculating the root hash
+ * Calculating the root of the tree is similar to a regular MerkleTree, but is
+ * optimised by cribbing the value of "missing" nodes from a simple cache. This
+ * removes the need to calculate the vast majority of nodes from scratch.
+ *
+ * TODO(alcutter): LOTS!
+ *
+ * This class is thread-compatible, but not thread-safe.
+ */
+class SparseMerkleTree {
+ public:
+  static const int kDigestSizeBits = 256;
+
+  // Represents a path into the SparseMerkleTree.
+  // The MSB of the 0th entry in the path specifies the path from the root node
+  // of the tree, and so on until the LSB in the final byte specifies the leaf
+  // itself.
+  //
+  // i.e:
+  //   0th        1st     ...
+  // [76543210|76543210|76...|...|...0]
+  //  ||                             |_____LSB of path, identifies leaf at
+  //  lowest level in the tree
+  //  ||___________________________________Identifies 2nd level child node
+  //  |____________________________________Identifies 1st level child node
+  //
+  //  The reasoning behind this convention is that looked as a single
+  //  kDigestSizeBits sized word, the value of the path is then the same as
+  //  the index of the leaf node it identifies, this also has the advantage
+  //  that the paths are lexographically sortable.
+  typedef std::array<uint8_t, kDigestSizeBits / 8> Path;
+
+  // The constructor takes a pointer to some concrete hash function
+  // instantiation of the SerialHasher abstract class.
+  // Takes ownership of the hasher.
+  explicit SparseMerkleTree(SerialHasher* hasher);
+
+  // Length of a node (i.e., a hash), in bytes.
+  virtual size_t NodeSize() const {
+    return treehasher_.DigestSize();
+  };
+
+  // Return the leaf hash, but do not append the data to the tree.
+  virtual std::string LeafHash(const std::string& data) const {
+    return treehasher_.HashLeaf(data);
+  }
+
+  // Add a new leaf to the hash tree. Stores the hash of the leaf data in the
+  // tree structure, does not store the data itself.
+  //
+  // @param data Binary input blob
+  // @param path Binary path of node to set.
+  virtual void SetLeaf(const Path& path, const std::string& data);
+
+  // Get the current root of the tree.
+  // Update the root to reflect the current shape of the tree,
+  // and return the tree digest.
+  //
+  // Returns the hash of an empty string if the tree has no leaves
+  // (and hence, no root).
+  virtual std::string CurrentRoot();
+
+  // Get the Merkle path from the leaf at |path| to the current root.
+  //
+  // Returns a vector of node hashes, ordered by levels from leaf to root.
+  // The first element is the sibling of the leaf hash, and the last element
+  // is one below the root.
+  // Returns an empty vector if the tree is not large enough
+  // or the leaf index is 0.
+  //
+  // @param path the path of the leaf whose inclusion proof to return.
+  std::vector<std::string> InclusionProof(const Path& path);
+
+  std::string Dump() const;
+
+ private:
+  // WARNING WARNING WARNING
+  // 64 < 256 !
+  // WARNING WARNING WARNING
+  // TODO(alcutter): BIGNUM probably.
+  typedef uint64_t IndexType;
+
+  struct TreeNode {
+    TreeNode(const std::string& hash) : type_(INTERNAL), hash_(hash) {
+    }
+
+    TreeNode(const Path& path, const std::string& leaf_hash)
+        : type_(LEAF), path_(new Path(path)), hash_(leaf_hash) {
+    }
+
+    std::string DebugString() const;
+
+    enum { INTERNAL, LEAF } type_;
+    std::unique_ptr<Path> path_;
+    std::string hash_;
+  };
+
+  std::string CalculateSubtreeHash(size_t depth, IndexType index);
+
+  void DumpTree(std::ostream* os, size_t depth, IndexType index) const;
+
+  // Get the |index|-th node at level |level|. Indexing starts at 0;
+  // caller is responsible for ensuring tree is sufficiently up to date.
+  std::string Node(size_t level, size_t index) const;
+
+  // Maybe add a new tree level.
+  void EnsureHaveLevel(size_t n);
+
+  TreeHasher treehasher_;
+  const std::vector<std::string>* const null_hashes_;
+  // TODO(alcutter): investigate other structures
+  std::vector<std::unordered_map<IndexType, TreeNode>> tree_;
+  std::string root_hash_;
+};
+
+
+// Pretty print a Path
+std::ostream& operator<<(std::ostream& out,
+                         const SparseMerkleTree::Path& path);
+
+
+// Creates a Path from the bits passed in.
+inline SparseMerkleTree::Path PathFromBytes(const std::string& bytes) {
+  SparseMerkleTree::Path path;
+  // Path size must be a multiple of 8 for now.
+  CHECK_EQ(bytes.size(), path.size());
+
+  std::copy(bytes.begin(), bytes.end(), path.begin());
+  return path;
+}
+
+
+// Extracts the |n|th most significant bit from |path|
+inline int PathBit(const SparseMerkleTree::Path& path, size_t bit) {
+  CHECK_LT(bit, path.size() * 8);
+  return (path[bit / 8] & (1 << (7 - bit % 8))) == 0 ? 0 : 1;
+}
+
+
+struct PathHasher {
+  size_t operator()(const SparseMerkleTree::Path& p) const {
+    return std::hash<std::string>()(
+        std::string(reinterpret_cast<const char*>(p.data()), p.size()));
+  }
+};
+
+
+#endif  // CERT_TRANS_MERKLETREE_SPARSE_MERKLE_TREE_H
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/sparse_merkle_tree_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/sparse_merkle_tree_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/sparse_merkle_tree_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/sparse_merkle_tree_test.cc	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,353 @@
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <openssl/bn.h>
+#include <sys/resource.h>
+#include <algorithm>
+#include <map>
+#include <random>
+#include <string>
+
+#include "merkletree/sparse_merkle_tree.h"
+#include "util/openssl_scoped_types.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+namespace {
+
+using cert_trans::ScopedBIGNUM;
+using std::fill;
+using std::lower_bound;
+using std::map;
+using std::mt19937;
+using std::ostringstream;
+using std::pair;
+using std::random_device;
+using std::reverse;
+using std::string;
+using std::to_string;
+using std::unique_ptr;
+using std::vector;
+using util::ToBase64;
+
+
+const char kEmptyRootHashB64[] =
+    "xmifEIEqCYCXbZUz2Dh1KCFmFZVn7DUVVxbBQTr1PWo=";
+
+
+struct KeyComp {
+  const BIGNUM* AsBN(const ScopedBIGNUM& a) const {
+    return a.get();
+  }
+
+  const BIGNUM* AsBN(const BIGNUM* a) const {
+    return a;
+  }
+
+  const BIGNUM* AsBN(const pair<ScopedBIGNUM, string>& a) const {
+    return a.first.get();
+  }
+};
+
+
+struct KeyEq : public KeyComp {
+  template <class A, class B>
+  bool operator()(const A& a, const B& b) const {
+    return BN_cmp(AsBN(a), AsBN(b)) == 0;
+  }
+};
+
+
+struct KeyLess : public KeyComp {
+  template <class A, class B>
+  bool operator()(const A& a, const B& b) const {
+    return BN_cmp(AsBN(a), AsBN(b)) < 0;
+  }
+};
+
+
+typedef vector<pair<ScopedBIGNUM, string>> ValueList;
+
+pair<ScopedBIGNUM, string> Value(uint64_t n, const string& v) {
+  pair<ScopedBIGNUM, string> ret;
+  ret.second = v;
+  ret.first.reset(BN_new());
+  BN_set_word(ret.first.get(), n);
+  return ret;
+}
+
+// Implements (more-or-less) the reference python code given in the
+// revocation transparency paper for calculating the root-hash of a sparse
+// tree with a given set of leaf nodes.
+class Reference {
+ public:
+  Reference(SerialHasher* hasher)
+      : tree_hasher_(unique_ptr<SerialHasher>(CHECK_NOTNULL(hasher))),
+        hStarEmptyCache_{tree_hasher_.HashLeaf("")} {
+  }
+
+  // Calculates the root hash of a sparse merkle tree of depth |n|, containing
+  // the leaf values in |values|.
+  string HStar2(size_t n, ValueList* values) {
+    // values should be sorted
+    std::sort(values->begin(), values->end(), KeyLess());
+    // and without dupes
+    values->erase(std::unique(values->begin(), values->end(), KeyEq()),
+                  values->end());
+    // Sounds a lot like a map to me, but I've left it as a list because:
+    // a) it's just reference code, and
+    // b) I want it to be as similar as possible to the code in the paper.
+
+    ScopedBIGNUM offset(BN_new());
+    BN_zero(offset.get());
+    const string ret(
+        HStar2b(n, *values, values->begin(), values->end(), offset.get()));
+    return ret;
+  }
+
+
+ private:
+  // Calculates & caches the 'null' node at depth |n|
+  string HStarEmpty(size_t n) {
+    if (hStarEmptyCache_.size() <= n) {
+      const string t(
+          tree_hasher_.HashChildren(HStarEmpty(n - 1), HStarEmpty(n - 1)));
+      CHECK_EQ(n, hStarEmptyCache_.size());
+      hStarEmptyCache_.push_back(t);
+    }
+    CHECK_LT(n, hStarEmptyCache_.size());
+    return hStarEmptyCache_[n];
+  }
+
+  // Calculates an internal subtree.
+  string HStar2b(size_t n, const ValueList& values,
+                 ValueList::const_iterator lo, ValueList::const_iterator hi,
+                 BIGNUM* offset) {
+    if (n == 0) {
+      if (lo == hi) {
+        // DIFF: return the null leaf hash, rather than "0" as in the paper.
+        return hStarEmptyCache_[0];
+      }
+      CHECK_EQ(1, hi - lo);
+      // DIFF: return H(\x00||value) rather than "1" as in the paper.
+      return tree_hasher_.HashLeaf(lo->second);
+    }
+    if (lo == hi) {
+      return HStarEmpty(n);
+    }
+
+    // DIFF: use BIGNUM, 'cos we'll get to values of O(1 << 256) here (!)
+    ScopedBIGNUM split(BN_new());
+    CHECK_EQ(1, BN_set_word(split.get(), 1));
+    CHECK_EQ(1, BN_lshift(split.get(), split.get(), n - 1));
+    CHECK_EQ(1, BN_add(split.get(), split.get(), offset));
+
+    auto i(lower_bound(lo, hi, split, KeyLess()));
+    const string ret(
+        tree_hasher_.HashChildren(HStar2b(n - 1, values, lo, i, offset),
+                                  HStar2b(n - 1, values, i, hi, split.get())));
+    return ret;
+  }
+
+  TreeHasher tree_hasher_;
+  vector<string> hStarEmptyCache_;
+};
+
+
+class SparseMerkleTreeTest : public testing::Test {
+ public:
+  SparseMerkleTreeTest()
+      : tree_hasher_(unique_ptr<Sha256Hasher>(new Sha256Hasher)),
+        tree_(new Sha256Hasher),
+        rand_(1234) {
+  }
+
+ protected:
+  // Returns a Path with the high 64 bits set to |high|
+  SparseMerkleTree::Path PathHigh(uint64_t high) {
+    SparseMerkleTree::Path ret;
+    ret.fill(0);
+    for (size_t i(0); i < 8; ++i) {
+      ret[7 - i] = high & 0xff;
+      high >>= 8;
+    }
+    return ret;
+  }
+
+  // Returns a Path with the low 64 bits set to |high|
+  SparseMerkleTree::Path PathLow(uint64_t low) {
+    SparseMerkleTree::Path ret;
+    ret.fill(0);
+    for (size_t i(0); i < 8; ++i) {
+      ret[ret.size() - 1 - i] = low & 0xff;
+      low >>= 8;
+    }
+    return ret;
+  }
+
+  // Returns a random Path.
+  SparseMerkleTree::Path RandomPath() {
+    SparseMerkleTree::Path ret;
+    for (SparseMerkleTree::Path::size_type i(0); i < ret.size(); ++i) {
+      ret[i] = rand_() & 0xff;
+    }
+    return ret;
+  }
+
+  SparseMerkleTree::Path PathFromString(const string& s) {
+    SparseMerkleTree::Path ret;
+    CHECK_LE(s.size(), ret.size());
+    fill(copy(s.begin(), s.end(), ret.begin()), ret.end(), 0);
+    return ret;
+  }
+
+  TreeHasher tree_hasher_;
+  SparseMerkleTree tree_;
+  mt19937 rand_;
+};
+
+
+TEST_F(SparseMerkleTreeTest, PathBitAndPathStreamOperatorAgree) {
+  ostringstream os;
+  const SparseMerkleTree::Path p(RandomPath());
+  os << p;
+  string b;
+  for (size_t i(0); i < SparseMerkleTree::kDigestSizeBits; ++i) {
+    b += PathBit(p, i) == 0 ? '0' : '1';
+  }
+  EXPECT_EQ(os.str(), b);
+}
+
+
+TEST_F(SparseMerkleTreeTest, ReferenceEmptyTreeRootKAT) {
+  Reference ref(new Sha256Hasher);
+  ValueList empty_values;
+  EXPECT_EQ(kEmptyRootHashB64, ToBase64(ref.HStar2(256, &empty_values)));
+}
+
+
+TEST_F(SparseMerkleTreeTest, EmptyTreeRootKAT) {
+  tree_.CurrentRoot();
+  EXPECT_EQ(kEmptyRootHashB64, ToBase64(tree_.CurrentRoot()));
+}
+
+
+TEST_F(SparseMerkleTreeTest, SimpleTest) {
+  Reference ref(new Sha256Hasher);
+  ValueList values;
+  for (auto r : vector<uint64_t>{1, 5, 10}) {
+    const string value(to_string(r));
+    values.emplace_back(Value(r, value));
+    SparseMerkleTree::Path p(PathLow(r));
+    tree_.SetLeaf(p, value);
+  }
+  const string ref_root(
+      ref.HStar2(SparseMerkleTree::kDigestSizeBits, &values));
+  const string smt_root(tree_.CurrentRoot());
+  EXPECT_EQ(ToBase64(ref_root), ToBase64(smt_root));
+}
+
+
+TEST_F(SparseMerkleTreeTest, RandomReferenceTest) {
+  Reference ref(new Sha256Hasher);
+  ValueList values;
+  LOG(INFO) << "Setup";
+  for (int i(0); i < 10000; ++i) {
+    uint64_t r(rand_() + i);
+    const string value(to_string(r));
+    values.emplace_back(Value(r, value));
+    const SparseMerkleTree::Path p(PathLow(r));
+    tree_.SetLeaf(p, value);
+  }
+  LOG(INFO) << "Calculating SMT Root";
+  const string smt_root(tree_.CurrentRoot());
+  LOG(INFO) << "Calculating Reference Root";
+  const string ref_root(ref.HStar2(256, &values));
+  LOG(INFO) << "Comparing";
+  EXPECT_EQ(ToBase64(ref_root), ToBase64(smt_root));
+}
+
+
+TEST_F(SparseMerkleTreeTest, DISABLED_RefMemTest) {
+  Reference ref(new Sha256Hasher);
+  ValueList values;
+
+  struct rusage ru;
+  getrusage(RUSAGE_SELF, &ru);
+  long max_rss_before = ru.ru_maxrss;
+  uint64_t time_before = util::TimeInMilliseconds();
+  LOG(INFO) << "Setup";
+
+  for (int i(0); i < 10000000; ++i) {
+    uint64_t r(rand_() + i);
+    const string value(to_string(r));
+    values.emplace_back(Value(r, value));
+  }
+  LOG(INFO) << "Calculating Root";
+  const string ref_root(ref.HStar2(256, &values));
+  LOG(INFO) << "Done";
+
+  uint64_t time_after = util::TimeInMilliseconds();
+  getrusage(RUSAGE_SELF, &ru);
+  LOG(INFO) << "Peak RSS delta (as reported by getrusage()) was "
+            << ru.ru_maxrss - max_rss_before << " kB";
+  LOG(INFO) << "Elapsed time: " << time_after - time_before << " ms";
+}
+
+
+TEST_F(SparseMerkleTreeTest, DISABLED_SMTMemTest) {
+  struct rusage ru;
+  getrusage(RUSAGE_SELF, &ru);
+  long max_rss_before = ru.ru_maxrss;
+  uint64_t time_before = util::TimeInMilliseconds();
+  LOG(INFO) << "Setup";
+
+  for (int i(0); i < 10000000; ++i) {
+    uint64_t r(rand_() + i);
+    const string value(to_string(r));
+    const SparseMerkleTree::Path p(PathLow(r));
+    tree_.SetLeaf(p, value);
+  }
+  LOG(INFO) << "Calculating Root";
+  const string smt_root(tree_.CurrentRoot());
+  LOG(INFO) << "Done";
+
+  uint64_t time_after = util::TimeInMilliseconds();
+  getrusage(RUSAGE_SELF, &ru);
+  LOG(INFO) << "Peak RSS delta (as reported by getrusage()) was "
+            << ru.ru_maxrss - max_rss_before << " kB";
+  LOG(INFO) << "Elapsed time: " << time_after - time_before << " ms";
+}
+
+
+TEST_F(SparseMerkleTreeTest, TestSetLeaf) {
+  tree_.CurrentRoot();
+  LOG(INFO) << "Tree@0:";
+  LOG(INFO) << tree_.Dump();
+
+  tree_.SetLeaf(PathFromString("one"), "one");
+  tree_.CurrentRoot();
+  LOG(INFO) << "Tree@1:";
+  LOG(INFO) << tree_.Dump();
+
+  tree_.SetLeaf(PathFromString("two"), "two");
+  tree_.CurrentRoot();
+  LOG(INFO) << "Tree@2:";
+  LOG(INFO) << tree_.Dump();
+
+  tree_.SetLeaf(PathFromString("three"), "three");
+  tree_.CurrentRoot();
+  LOG(INFO) << "Tree@3:";
+  LOG(INFO) << tree_.Dump();
+}
+
+
+// TODO(alcutter): Lots and lots more tests.
+
+
+}  // namespace
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/tree_hasher.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/tree_hasher.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/tree_hasher.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/tree_hasher.cc	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,46 @@
+#include "merkletree/tree_hasher.h"
+
+#include <assert.h>
+
+#include "merkletree/serial_hasher.h"
+
+using std::lock_guard;
+using std::move;
+using std::mutex;
+using std::string;
+using std::unique_ptr;
+
+namespace {
+
+const char kLeafPrefix('\x00');
+const char kNodePrefix('\x01');
+
+std::string EmptyHash(SerialHasher* hasher) {
+  hasher->Reset();
+  return hasher->Final();
+}
+
+}  // namespace
+
+TreeHasher::TreeHasher(unique_ptr<SerialHasher> hasher)
+    : hasher_(move(hasher)), empty_hash_(EmptyHash(hasher_.get())) {
+  assert(hasher_);
+}
+
+string TreeHasher::HashLeaf(const string& data) const {
+  lock_guard<mutex> lock(lock_);
+  hasher_->Reset();
+  hasher_->Update(string(1, kLeafPrefix));
+  hasher_->Update(data);
+  return hasher_->Final();
+}
+
+string TreeHasher::HashChildren(const string& left_child,
+                                const string& right_child) const {
+  lock_guard<mutex> lock(lock_);
+  hasher_->Reset();
+  hasher_->Update(string(1, kNodePrefix));
+  hasher_->Update(left_child);
+  hasher_->Update(right_child);
+  return hasher_->Final();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/tree_hasher.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/tree_hasher.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/tree_hasher.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/tree_hasher.h	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,41 @@
+#ifndef CERT_TRANS_MERKLETREE_TREE_HASHER_H_
+#define CERT_TRANS_MERKLETREE_TREE_HASHER_H_
+
+#include <stddef.h>
+#include <memory>
+#include <mutex>
+#include <string>
+
+#include "base/macros.h"
+#include "merkletree/serial_hasher.h"
+
+class TreeHasher {
+ public:
+  TreeHasher(std::unique_ptr<SerialHasher> hasher);
+
+  size_t DigestSize() const {
+    return hasher_->DigestSize();
+  }
+
+  const std::string& HashEmpty() const {
+    return empty_hash_;
+  }
+
+  std::string HashLeaf(const std::string& data) const;
+
+  // Accepts arbitrary strings as children. When hashing digests, it
+  // is the responsibility of the caller to ensure the inputs are of
+  // correct size.
+  std::string HashChildren(const std::string& left_child,
+                           const std::string& right_child) const;
+
+ private:
+  mutable std::mutex lock_;
+  const std::unique_ptr<SerialHasher> hasher_;
+  // The pre-computed hash of an empty tree.
+  const std::string empty_hash_;
+
+  DISALLOW_COPY_AND_ASSIGN(TreeHasher);
+};
+
+#endif  // CERT_TRANS_MERKLETREE_TREE_HASHER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/tree_hasher_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/tree_hasher_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/tree_hasher_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/tree_hasher_test.cc	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,160 @@
+#include <gtest/gtest.h>
+#include <stddef.h>
+#include <string>
+
+#include "merkletree/serial_hasher.h"
+#include "merkletree/tree_hasher.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+namespace {
+
+using std::string;
+using std::unique_ptr;
+
+typedef struct {
+  size_t input_length;
+  const char* input;
+  const char* output;
+} LeafTestVector;
+
+// Inputs and outputs are of fixed digest size.
+typedef struct {
+  const char* left;
+  const char* right;
+  const char* output;
+} NodeTestVector;
+
+const char sha256_empty_hash[] =
+    "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855";
+
+LeafTestVector sha256_leaves[] = {
+    {0, "",
+     "6e340b9cffb37a989ca544e6bb780a2c78901d3fb33738768511a30617afa01d"},
+    {1, "00",
+     "96a296d224f285c67bee93c30f8a309157f0daa35dc5b87e410b78630a09cfc7"},
+
+    {16, "101112131415161718191a1b1c1d1e1f",
+     "3bfb960453ebaebf33727da7a1f4db38acc051d381b6da20d6d4e88f0eabfd7a"},
+    {0, NULL, NULL}};
+
+NodeTestVector sha256_nodes[] = {
+    {"000102030405060708090a0b0c0d0e0f101112131415161718191a1b1c1d1e1f",
+     "202122232425262728292a2b2c2d2e2f303132333435363738393a3b3c3d3e3f",
+     "1a378704c17da31e2d05b6d121c2bb2c7d76f6ee6fa8f983e596c2d034963c57"},
+    {NULL, NULL, NULL}};
+
+typedef struct {
+  const char* empty_hash;
+  LeafTestVector* leaves;
+  NodeTestVector* nodes;
+} TestVector;
+
+TestVector test_sha256 = {sha256_empty_hash, sha256_leaves, sha256_nodes};
+
+// A slightly shorter notation for constructing binary blobs from test vectors.
+#define S(t, n) util::BinaryString(string((t), (2 * n)))
+// The reverse
+#define H(t) util::HexString(t)
+
+template <class T>
+TestVector* TestVectors();
+
+template <>
+TestVector* TestVectors<Sha256Hasher>() {
+  return &test_sha256;
+}
+
+template <class T>
+class TreeHasherTest : public ::testing::Test {
+ protected:
+  TreeHasher tree_hasher_;
+  TestVector* test_vectors_;
+  TreeHasherTest()
+      : tree_hasher_(unique_ptr<T>(new T)), test_vectors_(TestVectors<T>()) {
+  }
+};
+
+typedef ::testing::Types<Sha256Hasher> Hashers;
+
+TYPED_TEST_CASE(TreeHasherTest, Hashers);
+
+// TreeHashers are collision resistant when used correctly, i.e.,
+// when HashChildren() is called on the (fixed-length) outputs of HashLeaf().
+TYPED_TEST(TreeHasherTest, CollisionTest) {
+  string leaf1_digest, leaf2_digest, node1_digest, node2_digest;
+
+  const size_t digestsize = this->tree_hasher_.DigestSize();
+
+  // Check that the empty hash is not the same as the hash of an empty leaf.
+  leaf1_digest = this->tree_hasher_.HashEmpty();
+  EXPECT_EQ(leaf1_digest.size(), digestsize);
+
+  leaf2_digest = this->tree_hasher_.HashLeaf(string());
+  EXPECT_EQ(leaf2_digest.size(), digestsize);
+
+  EXPECT_NE(H(leaf1_digest), H(leaf2_digest));
+
+  // Check that different leaves hash to different digests.
+  const char hello[] = "Hello";
+  const char world[] = "World";
+  string leaf1(hello, 5);
+  string leaf2(world, 5);
+  leaf1_digest = this->tree_hasher_.HashLeaf(leaf1);
+  EXPECT_EQ(leaf1_digest.size(), digestsize);
+
+  leaf2_digest = this->tree_hasher_.HashLeaf(leaf2);
+  EXPECT_EQ(leaf2_digest.size(), digestsize);
+
+  EXPECT_NE(H(leaf1_digest), H(leaf2_digest));
+
+  // Compute an intermediate node digest.
+  node1_digest = this->tree_hasher_.HashChildren(leaf1_digest, leaf2_digest);
+  EXPECT_EQ(node1_digest.size(), digestsize);
+
+  // Check that this is not the same as a leaf hash of their concatenation.
+  node2_digest = this->tree_hasher_.HashLeaf(leaf1_digest + leaf2_digest);
+  EXPECT_EQ(node2_digest.size(), digestsize);
+
+  EXPECT_NE(H(node1_digest), H(node2_digest));
+
+  // Swap the order of nodes and check that the hash is different.
+  node2_digest = this->tree_hasher_.HashChildren(leaf2_digest, leaf1_digest);
+  EXPECT_EQ(node2_digest.size(), digestsize);
+
+  EXPECT_NE(H(node1_digest), H(node2_digest));
+}
+
+TYPED_TEST(TreeHasherTest, TestVectors) {
+  // The empty hash
+  string digest = this->tree_hasher_.HashEmpty();
+  EXPECT_STREQ(this->test_vectors_->empty_hash, H(digest).c_str());
+
+  // Leaf hashes
+  for (size_t i = 0; this->test_vectors_->leaves[i].input != NULL; ++i) {
+    digest = this->tree_hasher_.HashLeaf(
+        S(this->test_vectors_->leaves[i].input,
+          this->test_vectors_->leaves[i].input_length));
+    EXPECT_STREQ(this->test_vectors_->leaves[i].output, H(digest).c_str());
+  }
+
+  // Node hashes
+  for (size_t i = 0; this->test_vectors_->nodes[i].left != NULL; ++i) {
+    digest =
+        this->tree_hasher_.HashChildren(S(this->test_vectors_->nodes[i].left,
+                                          this->tree_hasher_.DigestSize()),
+                                        S(this->test_vectors_->nodes[i].right,
+                                          this->tree_hasher_.DigestSize()));
+    EXPECT_STREQ(this->test_vectors_->nodes[i].output, H(digest).c_str());
+  }
+}
+
+#undef S
+#undef H
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/verifiable_map.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/verifiable_map.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/verifiable_map.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/verifiable_map.cc	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,50 @@
+#include <array>
+#include <string>
+
+#include "merkletree/verifiable_map.h"
+
+
+using std::string;
+using std::unique_ptr;
+using std::vector;
+using util::Status;
+using util::StatusOr;
+
+
+namespace cert_trans {
+
+
+VerifiableMap::VerifiableMap(SerialHasher* hasher)
+    : hasher_model_(CHECK_NOTNULL(hasher)->Create()), merkle_tree_(hasher) {
+}
+
+
+void VerifiableMap::Set(const string& key, const string& value) {
+  const SparseMerkleTree::Path path(PathFromKey(key));
+  merkle_tree_.SetLeaf(path, value);
+  values_[path] = value;
+}
+
+
+StatusOr<string> VerifiableMap::Get(const string& key) const {
+  const SparseMerkleTree::Path path(PathFromKey(key));
+  const auto it(values_.find(path));
+  if (it == values_.end()) {
+    return Status(util::error::NOT_FOUND, "No such entry.");
+  }
+  return it->second;
+}
+
+
+vector<string> VerifiableMap::InclusionProof(const string& key) {
+  return merkle_tree_.InclusionProof(PathFromKey(key));
+}
+
+
+SparseMerkleTree::Path VerifiableMap::PathFromKey(const string& key) const {
+  unique_ptr<SerialHasher> h(hasher_model_->Create());
+  h->Update(key);
+  return PathFromBytes(h->Final());
+}
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/verifiable_map.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/verifiable_map.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/verifiable_map.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/verifiable_map.h	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,45 @@
+#ifndef CERT_TRANS_MERKLETREE_VERIFIABLE_MAP_H_
+#define CERT_TRANS_MERKLETREE_VERIFIABLE_MAP_H_
+
+#include <string>
+#include <unordered_map>
+#include <vector>
+
+#include "base/macros.h"
+#include "merkletree/sparse_merkle_tree.h"
+#include "util/statusor.h"
+
+namespace cert_trans {
+
+
+// Implements a Verifiable Map using a SparseMerkleTree and hashmap.
+class VerifiableMap {
+ public:
+  VerifiableMap(SerialHasher* hasher);
+
+  std::string CurrentRoot() {
+    return merkle_tree_.CurrentRoot();
+  }
+
+  void Set(const std::string& key, const std::string& value);
+
+  util::StatusOr<std::string> Get(const std::string& key) const;
+
+  std::vector<std::string> InclusionProof(const std::string& key);
+
+ private:
+  SparseMerkleTree::Path PathFromKey(const std::string& key) const;
+
+  std::unique_ptr<SerialHasher> hasher_model_;
+  SparseMerkleTree merkle_tree_;
+
+  // TODO(alcutter): allow arbitrary stores here.
+  std::unordered_map<SparseMerkleTree::Path, std::string, PathHasher> values_;
+
+  DISALLOW_COPY_AND_ASSIGN(VerifiableMap);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_MERKLETREE_VERIFIABLE_MAP_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/verifiable_map_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/verifiable_map_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/merkletree/verifiable_map_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/merkletree/verifiable_map_test.cc	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,60 @@
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <string>
+
+#include "merkletree/verifiable_map.h"
+#include "util/status_test_util.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+
+namespace cert_trans {
+namespace {
+
+using std::array;
+using std::string;
+using std::unique_ptr;
+using util::StatusOr;
+using util::testing::StatusIs;
+using util::ToBase64;
+
+
+class VerifiableMapTest : public testing::Test {
+ public:
+  VerifiableMapTest() : map_(new Sha256Hasher()) {
+  }
+
+ protected:
+  VerifiableMap map_;
+};
+
+
+TEST_F(VerifiableMapTest, TestGetNotFound) {
+  const string kKey("unknown_key");
+
+  const StatusOr<string> retrieved(map_.Get(kKey));
+  EXPECT_THAT(retrieved.status(), StatusIs(util::error::NOT_FOUND));
+}
+
+TEST_F(VerifiableMapTest, TestSetGet) {
+  const string kKey("key");
+  const string kValue("value");
+  map_.Set(kKey, kValue);
+
+  const StatusOr<string> retrieved(map_.Get(kKey));
+  EXPECT_OK(retrieved);
+  EXPECT_EQ(kValue, retrieved.ValueOrDie());
+}
+
+
+// TODO(alcutter): Lots and lots more tests.
+
+
+}  // namespace
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/counter.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/counter.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/counter.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/counter.h	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,93 @@
+#ifndef CERT_TRANS_MONITORING_COUNTER_H_
+#define CERT_TRANS_MONITORING_COUNTER_H_
+
+
+#include <gflags/gflags.h>
+#include <memory>
+#include <mutex>
+#include <string>
+
+#include "base/macros.h"
+#include "monitoring/labelled_values.h"
+#include "monitoring/metric.h"
+
+namespace cert_trans {
+
+// A metric which can only increase (e.g. total_requests_served).
+template <class... LabelTypes>
+class Counter : public Metric {
+ public:
+  static Counter<LabelTypes...>* New(
+      const std::string& name,
+      const typename NameType<LabelTypes>::name&... label_names,
+      const std::string& help);
+
+  void Increment(const LabelTypes&... labels);
+
+  void IncrementBy(const LabelTypes&... labels, double amount);
+
+  double Get(const LabelTypes&... labels) const;
+
+  std::map<std::vector<std::string>, Metric::TimestampedValue> CurrentValues()
+      const override;
+
+ private:
+  Counter(const std::string& name,
+          const typename NameType<LabelTypes>::name&... label_names,
+          const std::string& help);
+
+  LabelledValues<LabelTypes...> values_;
+
+  DISALLOW_COPY_AND_ASSIGN(Counter);
+};
+
+
+// static
+template <class... LabelTypes>
+Counter<LabelTypes...>* Counter<LabelTypes...>::New(
+    const std::string& name,
+    const typename NameType<LabelTypes>::name&... label_names,
+    const std::string& help) {
+  return new Counter(name, label_names..., help);
+}
+
+
+template <class... LabelTypes>
+Counter<LabelTypes...>::Counter(
+    const std::string& name,
+    const typename NameType<LabelTypes>::name&... label_names,
+    const std::string& help)
+    : Metric(COUNTER, name, {label_names...}, help),
+      values_(name, label_names...) {
+}
+
+
+template <class... LabelTypes>
+void Counter<LabelTypes...>::Increment(const LabelTypes&... labels) {
+  values_.Increment(labels...);
+}
+
+
+template <class... LabelTypes>
+void Counter<LabelTypes...>::IncrementBy(const LabelTypes&... labels,
+                                         double amount) {
+  values_.IncrementBy(labels..., amount);
+}
+
+
+template <class... LabelTypes>
+double Counter<LabelTypes...>::Get(const LabelTypes&... labels) const {
+  return values_.Get(labels...);
+}
+
+
+template <class... LabelTypes>
+std::map<std::vector<std::string>, Metric::TimestampedValue>
+Counter<LabelTypes...>::CurrentValues() const {
+  return values_.CurrentValues();
+}
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_MONITORING_COUNTER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/counter_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/counter_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/counter_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/counter_test.cc	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,100 @@
+#include "monitoring/monitoring.h"
+
+#include <glog/logging.h>
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <memory>
+
+#include "util/testing.h"
+
+namespace cert_trans {
+
+using std::string;
+using std::vector;
+using testing::ElementsAre;
+
+class CounterTest : public ::testing::Test {
+ protected:
+  template <class... LabelTypes>
+  const string& GetName(const Metric& m) {
+    return m.Name();
+  }
+
+  template <class... LabelTypes>
+  const vector<string>& GetLabelNames(const Metric& m) {
+    return m.LabelNames();
+  }
+
+  template <class... LabelTypes>
+  const string& GetHelp(const Metric& m) {
+    return m.Help();
+  }
+};
+
+
+TEST_F(CounterTest, TestCounterName) {
+  std::unique_ptr<Counter<>> counter(Counter<>::New("name", "help"));
+  EXPECT_EQ("name", GetName(*counter));
+}
+
+
+TEST_F(CounterTest, TestCounterLabelNamesEmpty) {
+  std::unique_ptr<Counter<>> counter(Counter<>::New("name", "help"));
+  EXPECT_TRUE(GetLabelNames(*counter).empty());
+}
+
+
+TEST_F(CounterTest, TestCounterLabelNames) {
+  std::unique_ptr<Counter<string, string, int>> counter(
+      Counter<string, string, int>::New("name", "one", "two", "three",
+                                        "help"));
+  EXPECT_THAT(GetLabelNames(*counter), ElementsAre("one", "two", "three"));
+}
+
+
+TEST_F(CounterTest, TestCounterHelp) {
+  std::unique_ptr<Counter<>> counter(Counter<>::New("name", "help"));
+  EXPECT_EQ("help", GetHelp(*counter));
+}
+
+
+TEST_F(CounterTest, TestCounter) {
+  std::unique_ptr<Counter<>> counter(Counter<>::New("name", "help"));
+  counter->Increment();
+  EXPECT_EQ(1, counter->Get());
+}
+
+
+TEST_F(CounterTest, TestCounterWithLabels) {
+  std::unique_ptr<Counter<std::string, int>> counter(
+      Counter<std::string, int>::New("name", "a string", "an int", "help"));
+  counter->Increment("hi", 1);
+  EXPECT_EQ(1, counter->Get("hi", 1));
+}
+
+
+TEST_F(CounterTest, TestCounterWithLabelsMultiValues) {
+  std::unique_ptr<Counter<std::string, int>> counter(
+      Counter<std::string, int>::New("name", "a string", "an int", "help"));
+  EXPECT_EQ(0, counter->Get("alpha", 1));
+  EXPECT_EQ(0, counter->Get("alpha", 2));
+  EXPECT_EQ(0, counter->Get("beta", 1));
+  EXPECT_EQ(0, counter->Get("beta", 2));
+  counter->Increment("alpha", 1);
+  counter->IncrementBy("alpha", 2, 2);
+  counter->IncrementBy("beta", 1, 3);
+  counter->IncrementBy("beta", 2, 4);
+  EXPECT_EQ(1, counter->Get("alpha", 1));
+  EXPECT_EQ(2, counter->Get("alpha", 2));
+  EXPECT_EQ(3, counter->Get("beta", 1));
+  EXPECT_EQ(4, counter->Get("beta", 2));
+}
+
+
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/event_metric.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/event_metric.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/event_metric.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/event_metric.h	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,67 @@
+#ifndef CERT_TRANS_MONITORING_EVENT_METRIC_H_
+#define CERT_TRANS_MONITORING_EVENT_METRIC_H_
+
+#include <memory>
+#include <mutex>
+#include <string>
+
+#include "base/macros.h"
+#include "monitoring/counter.h"
+#include "monitoring/monitoring.h"
+
+namespace cert_trans {
+
+// A helper class for monitoring counter-type values for which it's interesting
+// to also have the number of times the counter has been updated (e.g. anything
+// for which you may want to calculate an average increase per event etc.)
+//
+// This class creates two Counter metrics, one called "|base_name|_overall_sum"
+// which contains the sum of all events broken down by labels, and another
+// called "|base_name|_count" which contains the number of measurements taken,
+// also broken down by labels.
+template <class... LabelTypes>
+class EventMetric {
+ public:
+  EventMetric(const std::string& base_name,
+              const typename NameType<LabelTypes>::name&... label_names,
+              const std::string& help);
+
+  // Records an increment of |amount| specified by |labels|.
+  // This increments the "|base_name|_overall_sum" metric by |amount|, and
+  // increments the "|base_name|_count" metric by 1.
+  void RecordEvent(const LabelTypes&... labels, double amount);
+
+ private:
+  std::mutex mutex_;
+  std::unique_ptr<Counter<LabelTypes...>> totals_;
+  std::unique_ptr<Counter<LabelTypes...>> counts_;
+
+  DISALLOW_COPY_AND_ASSIGN(EventMetric);
+};
+
+
+template <class... LabelTypes>
+EventMetric<LabelTypes...>::EventMetric(
+    const std::string& base_name,
+    const typename NameType<LabelTypes>::name&... label_names,
+    const std::string& help)
+    : totals_(Counter<LabelTypes...>::New(base_name + "_overall_sum",
+                                          label_names..., help)),
+      counts_(Counter<LabelTypes...>::New(base_name + "_count", label_names...,
+                                          help + " (count)")) {
+}
+
+
+template <class... LabelTypes>
+void EventMetric<LabelTypes...>::RecordEvent(const LabelTypes&... labels,
+                                             double amount) {
+  std::lock_guard<std::mutex> lock(mutex_);
+  totals_->IncrementBy(labels..., amount);
+  counts_->Increment(labels...);
+}
+
+
+}  // namespace cert_trans
+
+
+#endif  // CERT_TRANS_MONITORING_EVENT_METRIC_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/gauge.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/gauge.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/gauge.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/gauge.h	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,85 @@
+#ifndef CERT_TRANS_MONITORING_GAUGE_H_
+#define CERT_TRANS_MONITORING_GAUGE_H_
+
+#include <chrono>
+#include <mutex>
+#include <string>
+
+#include "base/macros.h"
+#include "monitoring/labelled_values.h"
+#include "monitoring/metric.h"
+
+
+namespace cert_trans {
+
+// A metric whose values can go down as well as up (e.g. memory usage.)
+template <class... LabelTypes>
+class Gauge : public Metric {
+ public:
+  static Gauge<LabelTypes...>* New(
+      const std::string& name,
+      const typename NameType<LabelTypes>::name&... label_names,
+      const std::string& help);
+
+  double Get(const LabelTypes&...) const;
+
+  void Set(const LabelTypes&... labels, double value);
+
+  // TODO(alcutter): Not over the moon about having this here.
+  std::map<std::vector<std::string>, Metric::TimestampedValue> CurrentValues()
+      const override;
+
+ private:
+  Gauge(const std::string& name,
+        const typename NameType<LabelTypes>::name&... label_names,
+        const std::string& help);
+
+  LabelledValues<LabelTypes...> values_;
+
+  DISALLOW_COPY_AND_ASSIGN(Gauge);
+};
+
+
+// static
+template <class... LabelTypes>
+Gauge<LabelTypes...>* Gauge<LabelTypes...>::New(
+    const std::string& name,
+    const typename NameType<LabelTypes>::name&... label_names,
+    const std::string& help) {
+  return new Gauge(name, label_names..., help);
+}
+
+
+template <class... LabelTypes>
+Gauge<LabelTypes...>::Gauge(
+    const std::string& name,
+    const typename NameType<LabelTypes>::name&... label_names,
+    const std::string& help)
+    : Metric(GAUGE, name, {label_names...}, help),
+      values_(name, label_names...) {
+}
+
+
+template <class... LabelTypes>
+double Gauge<LabelTypes...>::Get(const LabelTypes&... labels) const {
+  return values_.Get(labels...);
+}
+
+
+template <class... LabelTypes>
+void Gauge<LabelTypes...>::Set(const LabelTypes&... labels, double value) {
+  values_.Set(labels..., value);
+}
+
+
+template <class... LabelTypes>
+std::map<std::vector<std::string>, Metric::TimestampedValue>
+Gauge<LabelTypes...>::CurrentValues() const {
+  return values_.CurrentValues();
+}
+
+
+}  // namespace cert_trans
+
+
+#endif  // CERT_TRANS_MONITORING_GAUGE_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/gauge_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/gauge_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/gauge_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/gauge_test.cc	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,105 @@
+#include "monitoring/monitoring.h"
+
+#include <glog/logging.h>
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <memory>
+
+#include "util/testing.h"
+
+namespace cert_trans {
+
+using std::string;
+using std::vector;
+using testing::ElementsAre;
+
+class GaugeTest : public ::testing::Test {
+ protected:
+  template <class... LabelTypes>
+  const string& GetName(const Metric& m) {
+    return m.Name();
+  }
+
+  template <class... LabelTypes>
+  const vector<string>& GetLabelNames(const Metric& m) {
+    return m.LabelNames();
+  }
+
+  template <class... LabelTypes>
+  string GetHelp(const Metric& m) {
+    return m.Help();
+  }
+};
+
+
+TEST_F(GaugeTest, TestGaugeName) {
+  std::unique_ptr<Gauge<>> gauge(Gauge<>::New("name", "help"));
+  EXPECT_EQ("name", GetName(*gauge));
+}
+
+
+TEST_F(GaugeTest, TestGaugeLabelNamesEmpty) {
+  std::unique_ptr<Gauge<>> gauge(Gauge<>::New("name", "help"));
+  EXPECT_TRUE(GetLabelNames(*gauge).empty());
+}
+
+
+TEST_F(GaugeTest, TestGaugeLabelNames) {
+  std::unique_ptr<Gauge<string, string, int>> gauge(
+      Gauge<string, string, int>::New("name", "one", "two", "three", "help"));
+  EXPECT_THAT(GetLabelNames(*gauge), ElementsAre("one", "two", "three"));
+}
+
+
+TEST_F(GaugeTest, TestGaugeHelp) {
+  std::unique_ptr<Gauge<>> gauge(Gauge<>::New("name", "help"));
+  EXPECT_EQ("help", GetHelp(*gauge));
+}
+
+
+TEST_F(GaugeTest, TestGauge) {
+  std::unique_ptr<Gauge<>> gauge(Gauge<>::New("name", "help"));
+  EXPECT_EQ(0, gauge->Get());
+  gauge->Set(15);
+  EXPECT_EQ(15, gauge->Get());
+  gauge->Set(1);
+  EXPECT_EQ(1, gauge->Get());
+}
+
+
+TEST_F(GaugeTest, TestGaugeWithLabels) {
+  std::unique_ptr<Gauge<std::string, int>> gauge(
+      Gauge<std::string, int>::New("name", "a string", "an int", "help"));
+  EXPECT_EQ(0, gauge->Get("hi", 1));
+  gauge->Set("hi", 1, 100);
+  EXPECT_EQ(100, gauge->Get("hi", 1));
+  gauge->Set("hi", 1, 1);
+  EXPECT_EQ(1, gauge->Get("hi", 1));
+}
+
+
+TEST_F(GaugeTest, TestGaugeWithLabelsMultiValues) {
+  std::unique_ptr<Gauge<std::string, int>> gauge(
+      Gauge<std::string, int>::New("name", "a string", "an int", "help"));
+  EXPECT_EQ(0, gauge->Get("alpha", 1));
+  EXPECT_EQ(0, gauge->Get("alpha", 2));
+  EXPECT_EQ(0, gauge->Get("beta", 1));
+  EXPECT_EQ(0, gauge->Get("beta", 2));
+  gauge->Set("alpha", 1, 100);
+  gauge->Set("alpha", 2, 200);
+  gauge->Set("beta", 1, 300);
+  gauge->Set("beta", 2, 400);
+  EXPECT_EQ(100, gauge->Get("alpha", 1));
+  EXPECT_EQ(200, gauge->Get("alpha", 2));
+  EXPECT_EQ(300, gauge->Get("beta", 1));
+  EXPECT_EQ(400, gauge->Get("beta", 2));
+}
+
+
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/gcm/exporter.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/gcm/exporter.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/gcm/exporter.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/gcm/exporter.cc	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,325 @@
+#include "monitoring/gcm/exporter.h"
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <sstream>
+
+#include "monitoring/monitoring.h"
+#include "monitoring/registry.h"
+#include "net/url.h"
+#include "util/json_wrapper.h"
+#include "util/sync_task.h"
+
+DEFINE_string(google_compute_monitoring_base_url, "", "GCM base URL.");
+DEFINE_int32(google_compute_monitoring_push_interval_seconds, 15,
+             "Seconds between pushing metric values to GCM.");
+DEFINE_string(google_compute_metadata_url,
+              "http://metadata/computeMetadata/v1/instance/service-accounts",
+              "URL of GCE metadata server.");
+DEFINE_string(google_compute_monitoring_service_account, "default",
+              "Which GCE service account to use for pushing metrics.");
+DEFINE_int32(google_compute_monitoring_credentials_refresh_interval_minutes,
+             30,
+             "Interval between refreshing the auth credentials to write to "
+             "GCM.");
+DEFINE_int32(google_compute_monitoring_retry_delay_seconds, 5,
+             "Seconds between retrying failed GCM requests.");
+
+
+namespace cert_trans {
+
+using std::bind;
+using std::chrono::minutes;
+using std::chrono::seconds;
+using std::chrono::system_clock;
+using std::make_pair;
+using std::mutex;
+using std::ostringstream;
+using std::placeholders::_1;
+using std::string;
+using std::thread;
+using std::unique_lock;
+using std::unique_ptr;
+using util::Executor;
+using util::SyncTask;
+using util::Task;
+
+Counter<>* num_gcm_create_metric_failures =
+    Counter<>::New("num_gcm_create_metricpush_failures",
+                   "Number of failures to create metric metadata in GCM.");
+
+Counter<>* num_gcm_push_failures =
+    Counter<>::New("num_gcm_push_failures",
+                   "Number of failures to push metric data to GCM.");
+
+Counter<>* num_gcm_token_fetch_failures =
+    Counter<>::New("num_gcm_token_fetch_failures",
+                   "Number of failures to fetch GCM auth token");
+
+namespace {
+
+
+// Label and Metric -name prefix.
+const char kCloudPrefix[] = "custom.cloudmonitoring.googleapis.com/ct/";
+
+
+inline std::string RFC3339Time(const system_clock::time_point& when) {
+  const std::time_t now_c(system_clock::to_time_t(when));
+  char buf[256];
+  CHECK(std::strftime(buf, sizeof(buf), "%FT%T.00Z", std::localtime(&now_c)));
+  return buf;
+}
+
+
+}  // namespace
+
+
+GCMExporter::GCMExporter(const string& instance_name, UrlFetcher* fetcher,
+                         Executor* executor)
+    : instance_name_(instance_name),
+      fetcher_(CHECK_NOTNULL(fetcher)),
+      executor_(CHECK_NOTNULL(executor)),
+      task_(executor_),
+      metrics_created_(false) {
+  executor_->Add(bind(&GCMExporter::PushMetrics, this));
+}
+
+
+GCMExporter::~GCMExporter() {
+  task_.task()->Cancel();
+  task_.Wait();
+}
+
+
+void GCMExporter::RefreshCredentials() {
+  VLOG(1) << "Refreshing GCM credentials...";
+  UrlFetcher::Request req(
+      (URL(FLAGS_google_compute_metadata_url + "/" +
+           FLAGS_google_compute_monitoring_service_account + "/token")));
+  req.headers.insert(make_pair("Metadata-Flavor", "Google"));
+
+  UrlFetcher::Response* const resp(new UrlFetcher::Response);
+  fetcher_->Fetch(req, resp, task_.task()->AddChild(
+                                 bind(&GCMExporter::RefreshCredentialsDone,
+                                      this, resp, _1)));
+}
+
+
+void GCMExporter::RefreshCredentialsDone(UrlFetcher::Response* resp,
+                                         Task* task) {
+  unique_ptr<UrlFetcher::Response> resp_deleter(resp);
+  if (!task->status().ok() || resp->status_code != 200) {
+    LOG(WARNING) << "Failed to refresh GCM credentials, status: "
+                 << task->status() << ", response code: " << resp->status_code;
+    num_gcm_token_fetch_failures->Increment();
+    executor_->Delay(
+        seconds(FLAGS_google_compute_monitoring_retry_delay_seconds),
+        task_.task()->AddChild(bind(&GCMExporter::RefreshCredentials, this)));
+    return;
+  }
+  token_refreshed_at_ = system_clock::now();
+
+  JsonObject reply(resp->body);
+  CHECK(reply.Ok()) << "Failed to parse metadata JSON:\n" << resp->body;
+  JsonString bearer(reply, "access_token");
+  CHECK(bearer.Ok());
+  bearer_token_ = bearer.Value();
+
+  VLOG(1) << "GCM credentials refreshed";
+
+  PushMetrics();
+}
+
+
+namespace {
+
+
+void AddLabelDescription(const string& key, const string& desc,
+                         JsonArray* labels) {
+  JsonObject label;
+  label.Add("key", kCloudPrefix + key);
+  label.Add("description", desc);
+  CHECK_NOTNULL(labels)->Add(&label);
+}
+
+
+}  // namespace
+
+
+void GCMExporter::CreateMetrics() {
+  const std::set<const Metric*> metrics(Registry::Instance()->GetMetrics());
+  for (auto& m : metrics) {
+    CHECK_NOTNULL(m);
+
+    // See
+    // https://cloud.google.com/monitoring/v2beta2/metricDescriptors#resource
+    // for a description of the structure we're building here.
+
+    JsonArray labels;
+    AddLabelDescription("instance",
+                        "Instance from which the sample originates.", &labels);
+    for (const auto& label : m->LabelNames()) {
+      AddLabelDescription(label, label, &labels);
+    }
+
+    JsonObject desc;
+    switch (m->Type()) {
+      case Metric::COUNTER:
+        // only gauge type metrics are supported for custom metrics currently:
+        // https://cloud.google.com/monitoring/api/metrics#metric-types
+        desc.Add("metricType", "gauge");
+        break;
+      case Metric::GAUGE:
+        desc.Add("metricType", "gauge");
+        break;
+      default:
+        LOG(FATAL) << "Unknown type: " << m->Type();
+    }
+    desc.Add("valueType", "double");
+
+    JsonObject metric;
+    metric.Add("name", kCloudPrefix + m->Name());
+    metric.Add("description", m->Help());
+    metric.Add("labels", labels);
+    metric.Add("typeDescriptor", desc);
+
+    do {
+      UrlFetcher::Request req((URL(FLAGS_google_compute_monitoring_base_url +
+                                   "/metricDescriptors")));
+      req.verb = UrlFetcher::Verb::POST;
+      req.headers.insert(make_pair("Content-Type", "application/json"));
+      req.headers.insert(
+          make_pair("Authorization", "Bearer " + bearer_token_));
+      req.body = metric.ToString();
+
+      UrlFetcher::Response resp;
+      SyncTask task(executor_);
+      VLOG(1) << "Creating metric m.Name()...";
+      VLOG(2) << req.body;
+      fetcher_->Fetch(req, &resp, task.task());
+      task.Wait();
+      if (!task.status().ok() || resp.status_code != 200) {
+        LOG(WARNING) << "Failed to create/update metric metadata; status: "
+                     << task.status()
+                     << ", response_code: " << resp.status_code;
+        num_gcm_create_metric_failures->Increment();
+        // TODO(alcutter): consider breaking this up into separate child tasks.
+        sleep(FLAGS_google_compute_monitoring_retry_delay_seconds);
+        continue;
+      }
+      VLOG(1) << "Metrics Created.";
+      VLOG(2) << resp.body;
+      break;
+    } while (true);
+  }
+  metrics_created_ = true;
+}
+
+
+namespace {
+
+
+void AddLabel(const string& key, const string& value, JsonObject* labels) {
+  CHECK_NOTNULL(labels)->Add((kCloudPrefix + key).c_str(), value);
+}
+
+
+}  // namespace
+
+
+void GCMExporter::PushMetrics() {
+  if (task_.task()->CancelRequested()) {
+    task_.task()->Return(util::Status::CANCELLED);
+    return;
+  }
+
+  if (system_clock::now() - token_refreshed_at_ >
+      minutes(
+          FLAGS_google_compute_monitoring_credentials_refresh_interval_minutes)) {
+    // If necessary, asynchronously refresh credentials, and then call this
+    // method again when done.
+    RefreshCredentials();
+    return;
+  }
+
+  if (!metrics_created_) {
+    CreateMetrics();
+  }
+
+  // Build up the JSON write request into this object:
+  JsonObject metric_write;
+  metric_write.Add("kind", "cloudmonitoring#writeTimeseriesRequest");
+
+  JsonObject common_labels;
+  AddLabel("instance", instance_name_, &common_labels);
+  metric_write.Add("commonLabels", common_labels);
+
+  const std::set<const Metric*> metrics(Registry::Instance()->GetMetrics());
+  JsonArray timeseries;
+  for (auto& m : metrics) {
+    CHECK_NOTNULL(m);
+    for (auto& p : m->CurrentValues()) {
+      JsonObject labels;
+      for (size_t i(0); i < p.first.size(); ++i) {
+        AddLabel(m->LabelName(i), p.first[i], &labels);
+      }
+
+      JsonObject desc;
+      desc.Add("labels", labels);
+      desc.Add("metric", kCloudPrefix + m->Name());
+
+      JsonObject ts;
+      ts.Add("timeseriesDesc", desc);
+
+      JsonObject point;
+      // According to
+      // https://cloud.google.com/monitoring/v2beta2/timeseries/write
+      // GAUGE types should have a zero size timerange here
+      // Which implies we need to use the current time rather than the time the
+      // value was set because there's a [short ~5m] horizon over which GCM
+      // won't accept samples.
+      const auto now(system_clock::now());
+      point.Add("start", RFC3339Time(now));
+      point.Add("end", RFC3339Time(now));
+      point.Add("doubleValue", p.second.second);
+      ts.Add("point", point);
+
+      timeseries.Add(&ts);
+    }
+  }
+  metric_write.Add("timeseries", timeseries);
+
+  UrlFetcher::Request req(
+      (URL(FLAGS_google_compute_monitoring_base_url + "/timeseries:write")));
+  req.verb = UrlFetcher::Verb::POST;
+  req.headers.insert(make_pair("Content-Type", "application/json"));
+  req.headers.insert(make_pair("Authorization", "Bearer " + bearer_token_));
+  req.body = metric_write.ToString();
+
+  UrlFetcher::Response* resp(new UrlFetcher::Response);
+  VLOG(1) << "Pushing metrics...";
+  VLOG(2) << req.body;
+  fetcher_->Fetch(req, resp,
+                  task_.task()->AddChild(
+                      bind(&GCMExporter::PushMetricsDone, this, resp, _1)));
+}
+
+
+void GCMExporter::PushMetricsDone(UrlFetcher::Response* resp, Task* task) {
+  unique_ptr<UrlFetcher::Response> resp_deleter(resp);
+  if (!task->status().ok() || resp->status_code != 200) {
+    num_gcm_push_failures->Increment();
+    LOG(WARNING) << "Failed to push metrics to GCM, status: " << task->status()
+                 << ", reponse code: " << resp->status_code;
+  } else {
+    VLOG(1) << "Metrics pushed.";
+    VLOG(2) << resp->body;
+  }
+
+  executor_->Delay(
+      seconds(FLAGS_google_compute_monitoring_push_interval_seconds),
+      task_.task()->AddChild(bind(&GCMExporter::PushMetrics, this)));
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/gcm/exporter.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/gcm/exporter.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/gcm/exporter.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/gcm/exporter.h	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,45 @@
+#ifndef CERT_TRANS_MONITORING_GCM_EXPORTER_H_
+#define CERT_TRANS_MONITORING_GCM_EXPORTER_H_
+
+#include <chrono>
+#include <condition_variable>
+#include <memory>
+#include <thread>
+
+#include "net/url_fetcher.h"
+#include "util/executor.h"
+#include "util/sync_task.h"
+
+namespace cert_trans {
+
+
+class GCMExporter {
+ public:
+  GCMExporter(const std::string& instance_name, UrlFetcher* fetcher,
+              util::Executor* executor);
+  ~GCMExporter();
+
+ private:
+  void RefreshCredentials();
+  void RefreshCredentialsDone(UrlFetcher::Response* resp, util::Task* task);
+
+  void CreateMetrics();
+
+  void PushMetrics();
+  void PushMetricsDone(UrlFetcher::Response* resp, util::Task* task);
+
+  const std::string instance_name_;
+  UrlFetcher* const fetcher_;
+  util::Executor* const executor_;
+  util::SyncTask task_;
+  bool metrics_created_;
+  std::chrono::system_clock::time_point token_refreshed_at_;
+  std::string bearer_token_;
+
+  friend class GCMExporterTest;
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_MONITORING_GCM_EXPORTER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/gcm/exporter_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/gcm/exporter_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/gcm/exporter_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/gcm/exporter_test.cc	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,387 @@
+#include "monitoring/gcm/exporter.h"
+
+#include <glog/logging.h>
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <memory>
+
+#include "monitoring/monitoring.h"
+#include "net/mock_url_fetcher.h"
+#include "util/json_wrapper.h"
+#include "util/testing.h"
+#include "util/thread_pool.h"
+
+DECLARE_string(google_compute_metadata_url);
+DECLARE_string(google_compute_monitoring_base_url);
+DECLARE_int32(google_compute_monitoring_push_interval_seconds);
+DECLARE_string(google_compute_monitoring_service_account);
+DECLARE_int32(google_compute_monitoring_retry_delay_seconds);
+
+namespace cert_trans {
+
+const char kBaseUrl[] = "http://example.com/metrics";
+const char kMetadataUrl[] = "http://example.com/metadata";
+const int kPushInterval = 1;
+const char kServiceAccount[] = "default";
+
+const char kCredentialsJson[] =
+    "{\n"
+    "  \"access_token\":\"token\",\n"
+    "  \"expires_in\":3599,\n"
+    "  \"token_type\":\"Bearer\"\n"
+    "}";
+
+
+using std::bind;
+using std::chrono::seconds;
+using std::make_pair;
+using std::placeholders::_1;
+using std::placeholders::_2;
+using std::placeholders::_3;
+using std::string;
+using std::vector;
+using testing::_;
+using testing::AllOf;
+using testing::DoAll;
+using testing::ElementsAre;
+using testing::HasSubstr;
+using testing::InSequence;
+using testing::Invoke;
+using testing::InvokeWithoutArgs;
+using testing::IsEmpty;
+using util::Status;
+using util::SyncTask;
+using util::Task;
+
+namespace {
+
+
+void HandleFetch(Status status, int status_code,
+                 const UrlFetcher::Headers& headers, const string& body,
+                 const UrlFetcher::Request& req, UrlFetcher::Response* resp,
+                 Task* task) {
+  resp->status_code = status_code;
+  resp->headers = headers;
+  resp->body = body;
+  if (!req.body.empty()) {
+    // It should be valid JSON
+    JsonObject request(req.body);
+    CHECK(request.Ok());
+  }
+  task->Return(status);
+}
+
+
+}  // namespace
+
+
+class GCMExporterTest : public ::testing::Test {
+ public:
+  GCMExporterTest()
+      : metrics_url_(string(kBaseUrl) + "/metricDescriptors"),
+        push_url_(string(kBaseUrl) + "/timeseries:write"),
+        pool_(2) {
+    FLAGS_google_compute_monitoring_base_url = kBaseUrl;
+    FLAGS_google_compute_monitoring_push_interval_seconds = kPushInterval;
+    FLAGS_google_compute_metadata_url = kMetadataUrl;
+    FLAGS_google_compute_monitoring_service_account = kServiceAccount;
+
+    ON_CALL(fetcher_, Fetch(_, _, _))
+        .WillByDefault(Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                                   UrlFetcher::Headers{}, "", _1, _2, _3)));
+  }
+
+ protected:
+  string GetBearerToken(const GCMExporter& e) {
+    return e.bearer_token_;
+  }
+
+  bool HasFetchedToken(const GCMExporter& e) {
+    return e.token_refreshed_at_.time_since_epoch() > seconds(0);
+  }
+
+  const string metrics_url_;
+  const string push_url_;
+  ThreadPool pool_;
+  MockUrlFetcher fetcher_;
+};
+
+
+TEST_F(GCMExporterTest, TestCredentials) {
+  EXPECT_CALL(
+      fetcher_,
+      Fetch(IsUrlFetchRequest(
+                UrlFetcher::Verb::GET,
+                URL(string(kMetadataUrl) + "/" + kServiceAccount + "/token"),
+                UrlFetcher::Headers{make_pair("Metadata-Flavor", "Google")},
+                ""),
+            _, _))
+      .WillRepeatedly(
+          Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                      UrlFetcher::Headers{}, kCredentialsJson, _1, _2, _3)));
+  EXPECT_CALL(
+      fetcher_,
+      Fetch(IsUrlFetchRequest(
+                UrlFetcher::Verb::GET,
+                URL(string(kMetadataUrl) + "/" + kServiceAccount + "/token"),
+                UrlFetcher::Headers{make_pair("Metadata-Flavor", "Google")},
+                ""),
+            _, _))
+      .WillRepeatedly(
+          Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                      UrlFetcher::Headers{}, kCredentialsJson, _1, _2, _3)));
+  EXPECT_CALL(fetcher_,
+              Fetch(IsUrlFetchRequest(
+                        UrlFetcher::Verb::POST, URL(metrics_url_),
+                        UrlFetcher::Headers{
+                            make_pair("Content-Type", "application/json"),
+                            make_pair("Authorization", "Bearer token")},
+                        _),
+                    _, _))
+      .WillRepeatedly(Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                                  UrlFetcher::Headers{}, "", _1, _2, _3)));
+  EXPECT_CALL(fetcher_,
+              Fetch(IsUrlFetchRequest(
+                        UrlFetcher::Verb::POST, URL(push_url_),
+                        UrlFetcher::Headers{
+                            make_pair("Content-Type", "application/json"),
+                            make_pair("Authorization", "Bearer token")},
+                        _),
+                    _, _))
+      .WillRepeatedly(Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                                  UrlFetcher::Headers{}, "", _1, _2, _3)));
+  GCMExporter exporter("instance", &fetcher_, &pool_);
+  while (!HasFetchedToken(exporter)) {
+    sleep(1);
+  }
+  EXPECT_EQ("token", GetBearerToken(exporter));
+}
+
+TEST_F(GCMExporterTest, TestRetriesFetchingCredentials) {
+  FLAGS_google_compute_monitoring_retry_delay_seconds = 1;
+  EXPECT_CALL(
+      fetcher_,
+      Fetch(IsUrlFetchRequest(
+                UrlFetcher::Verb::GET,
+                URL(string(kMetadataUrl) + "/" + kServiceAccount + "/token"),
+                UrlFetcher::Headers{make_pair("Metadata-Flavor", "Google")},
+                ""),
+            _, _))
+      .WillRepeatedly(
+          Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                      UrlFetcher::Headers{}, kCredentialsJson, _1, _2, _3)));
+  {
+    InSequence s;
+    // fails to talk to GCM
+    EXPECT_CALL(
+        fetcher_,
+        Fetch(IsUrlFetchRequest(
+                  UrlFetcher::Verb::GET,
+                  URL(string(kMetadataUrl) + "/" + kServiceAccount + "/token"),
+                  UrlFetcher::Headers{make_pair("Metadata-Flavor", "Google")},
+                  ""),
+              _, _))
+        .WillOnce(Invoke(bind(&HandleFetch, util::Status::UNKNOWN, 0,
+                              UrlFetcher::Headers{}, "", _1, _2, _3)));
+    // GCM returns a 500
+    EXPECT_CALL(
+        fetcher_,
+        Fetch(IsUrlFetchRequest(
+                  UrlFetcher::Verb::GET,
+                  URL(string(kMetadataUrl) + "/" + kServiceAccount + "/token"),
+                  UrlFetcher::Headers{make_pair("Metadata-Flavor", "Google")},
+                  ""),
+              _, _))
+        .WillOnce(Invoke(bind(&HandleFetch, util::Status::OK, 500,
+                              UrlFetcher::Headers{}, "", _1, _2, _3)));
+    // Ok, all good now
+    EXPECT_CALL(
+        fetcher_,
+        Fetch(IsUrlFetchRequest(
+                  UrlFetcher::Verb::GET,
+                  URL(string(kMetadataUrl) + "/" + kServiceAccount + "/token"),
+                  UrlFetcher::Headers{make_pair("Metadata-Flavor", "Google")},
+                  ""),
+              _, _))
+        .WillRepeatedly(
+            Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                        UrlFetcher::Headers{}, kCredentialsJson, _1, _2, _3)));
+  }
+
+  EXPECT_CALL(fetcher_,
+              Fetch(IsUrlFetchRequest(
+                        UrlFetcher::Verb::POST, URL(metrics_url_),
+                        UrlFetcher::Headers{
+                            make_pair("Content-Type", "application/json"),
+                            make_pair("Authorization", "Bearer token")},
+                        _),
+                    _, _))
+      .WillRepeatedly(Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                                  UrlFetcher::Headers{}, "", _1, _2, _3)));
+  EXPECT_CALL(fetcher_,
+              Fetch(IsUrlFetchRequest(
+                        UrlFetcher::Verb::POST, URL(push_url_),
+                        UrlFetcher::Headers{
+                            make_pair("Content-Type", "application/json"),
+                            make_pair("Authorization", "Bearer token")},
+                        _),
+                    _, _))
+      .WillRepeatedly(Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                                  UrlFetcher::Headers{}, "", _1, _2, _3)));
+  GCMExporter exporter("instance", &fetcher_, &pool_);
+  while (!HasFetchedToken(exporter)) {
+    sleep(1);
+  }
+  EXPECT_EQ("token", GetBearerToken(exporter));
+}
+
+
+// TODO(alcutter): Add some more detailed tests on exactly what gets sent.
+TEST_F(GCMExporterTest, TestPushesMetrics) {
+  std::unique_ptr<Counter<>> one(Counter<>::New("one", "help1"));
+  one->Increment();
+  std::unique_ptr<Gauge<>> two(Gauge<>::New("two", "help2"));
+  two->Set(2);
+
+  SyncTask sync(&pool_);
+
+  EXPECT_CALL(
+      fetcher_,
+      Fetch(IsUrlFetchRequest(
+                UrlFetcher::Verb::GET,
+                URL(string(kMetadataUrl) + "/" + kServiceAccount + "/token"),
+                UrlFetcher::Headers{make_pair("Metadata-Flavor", "Google")},
+                ""),
+            _, _))
+      .WillRepeatedly(
+          Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                      UrlFetcher::Headers{}, kCredentialsJson, _1, _2, _3)));
+  EXPECT_CALL(fetcher_,
+              Fetch(IsUrlFetchRequest(
+                        UrlFetcher::Verb::POST, URL(string(metrics_url_)),
+                        UrlFetcher::Headers{
+                            make_pair("Content-Type", "application/json"),
+                            make_pair("Authorization", "Bearer token")},
+                        _),
+                    _, _))
+      .WillRepeatedly(Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                                  UrlFetcher::Headers{}, "", _1, _2, _3)));
+  {
+    InSequence s;
+    EXPECT_CALL(fetcher_,
+                Fetch(IsUrlFetchRequest(
+                          UrlFetcher::Verb::POST, URL(push_url_),
+                          UrlFetcher::Headers{
+                              make_pair("Content-Type", "application/json"),
+                              make_pair("Authorization", "Bearer token")},
+                          AllOf(HasSubstr("one"), HasSubstr("two"))),
+                      _, _))
+        .WillOnce(Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                              UrlFetcher::Headers{}, "", _1, _2, _3)));
+    EXPECT_CALL(fetcher_,
+                Fetch(IsUrlFetchRequest(
+                          UrlFetcher::Verb::POST, URL(push_url_),
+                          UrlFetcher::Headers{
+                              make_pair("Content-Type", "application/json"),
+                              make_pair("Authorization", "Bearer token")},
+                          AllOf(HasSubstr("one"), HasSubstr("two"))),
+                      _, _))
+        .WillOnce(DoAll(InvokeWithoutArgs([&sync] { sync.task()->Return(); }),
+                        Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                                    UrlFetcher::Headers{}, "", _1, _2, _3))));
+  }
+  GCMExporter exporter("instance", &fetcher_, &pool_);
+  sync.Wait();
+}
+
+
+TEST_F(GCMExporterTest, TestRetriesWhenPushingMetricsFails) {
+  std::unique_ptr<Counter<>> one(Counter<>::New("one", "help1"));
+  one->Increment();
+  std::unique_ptr<Gauge<>> two(Gauge<>::New("two", "help2"));
+  two->Set(2);
+
+  SyncTask sync(&pool_);
+
+  EXPECT_CALL(
+      fetcher_,
+      Fetch(IsUrlFetchRequest(
+                UrlFetcher::Verb::GET,
+                URL(string(kMetadataUrl) + "/" + kServiceAccount + "/token"),
+                UrlFetcher::Headers{make_pair("Metadata-Flavor", "Google")},
+                ""),
+            _, _))
+      .WillRepeatedly(
+          Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                      UrlFetcher::Headers{}, kCredentialsJson, _1, _2, _3)));
+  EXPECT_CALL(fetcher_,
+              Fetch(IsUrlFetchRequest(
+                        UrlFetcher::Verb::POST, URL(string(metrics_url_)),
+                        UrlFetcher::Headers{
+                            make_pair("Content-Type", "application/json"),
+                            make_pair("Authorization", "Bearer token")},
+                        _),
+                    _, _))
+      .WillRepeatedly(Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                                  UrlFetcher::Headers{}, "", _1, _2, _3)));
+
+  {
+    InSequence s;
+    // Can't talk to GCM
+    EXPECT_CALL(fetcher_,
+                Fetch(IsUrlFetchRequest(
+                          UrlFetcher::Verb::POST, URL(push_url_),
+                          UrlFetcher::Headers{
+                              make_pair("Content-Type", "application/json"),
+                              make_pair("Authorization", "Bearer token")},
+                          AllOf(HasSubstr("one"), HasSubstr("two"))),
+                      _, _))
+        .WillOnce(Invoke(bind(&HandleFetch, util::Status::UNKNOWN, 0,
+                              UrlFetcher::Headers{}, "", _1, _2, _3)));
+    // GCM says boom
+    EXPECT_CALL(fetcher_,
+                Fetch(IsUrlFetchRequest(
+                          UrlFetcher::Verb::POST, URL(push_url_),
+                          UrlFetcher::Headers{
+                              make_pair("Content-Type", "application/json"),
+                              make_pair("Authorization", "Bearer token")},
+                          AllOf(HasSubstr("one"), HasSubstr("two"))),
+                      _, _))
+        .WillOnce(Invoke(bind(&HandleFetch, util::Status::OK, 500,
+                              UrlFetcher::Headers{}, "", _1, _2, _3)));
+    // OK!
+    EXPECT_CALL(fetcher_,
+                Fetch(IsUrlFetchRequest(
+                          UrlFetcher::Verb::POST, URL(push_url_),
+                          UrlFetcher::Headers{
+                              make_pair("Content-Type", "application/json"),
+                              make_pair("Authorization", "Bearer token")},
+                          AllOf(HasSubstr("one"), HasSubstr("two"))),
+                      _, _))
+        .WillOnce(Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                              UrlFetcher::Headers{}, "", _1, _2, _3)));
+    // trigger test exit next time around
+    EXPECT_CALL(fetcher_,
+                Fetch(IsUrlFetchRequest(
+                          UrlFetcher::Verb::POST, URL(push_url_),
+                          UrlFetcher::Headers{
+                              make_pair("Content-Type", "application/json"),
+                              make_pair("Authorization", "Bearer token")},
+                          AllOf(HasSubstr("one"), HasSubstr("two"))),
+                      _, _))
+        .WillOnce(DoAll(InvokeWithoutArgs([&sync] { sync.task()->Return(); }),
+                        Invoke(bind(&HandleFetch, util::Status::OK, 200,
+                                    UrlFetcher::Headers{}, "", _1, _2, _3))));
+  }
+  GCMExporter exporter("instance", &fetcher_, &pool_);
+  sync.Wait();
+}
+
+
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/labelled_values.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/labelled_values.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/labelled_values.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/labelled_values.h	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,139 @@
+#ifndef CERT_TRANS_MONITORING_LABELLED_VALUES_H_
+#define CERT_TRANS_MONITORING_LABELLED_VALUES_H_
+
+#include <glog/logging.h>
+#include <chrono>
+#include <map>
+#include <mutex>
+
+#include "monitoring/metric.h"
+
+namespace cert_trans {
+
+
+template <class... LabelTypes>
+class LabelledValues {
+ public:
+  LabelledValues(const std::string& name,
+                 const typename NameType<LabelTypes>::name&... label_names);
+
+  double Get(const LabelTypes&...) const;
+
+  void Set(const LabelTypes&... labels, double value);
+
+  void Increment(const LabelTypes&...);
+
+  void IncrementBy(const LabelTypes&..., double value);
+
+  std::map<std::vector<std::string>, Metric::TimestampedValue> CurrentValues()
+      const;
+
+ private:
+  const std::string name_;
+  const std::vector<std::string> label_names_;
+  mutable std::mutex mutex_;
+  std::map<std::tuple<LabelTypes...>,
+           std::pair<std::chrono::system_clock::time_point, double>> values_;
+
+  DISALLOW_COPY_AND_ASSIGN(LabelledValues);
+};
+
+
+namespace {
+
+
+template <std::size_t>
+struct i__ {};
+
+
+template <class Tuple>
+void label_values(const Tuple&, std::vector<std::string>*, i__<0>) {
+}
+
+
+template <class Tuple, size_t Pos>
+void label_values(const Tuple& t, std::vector<std::string>* values, i__<Pos>) {
+  std::ostringstream oss;
+  oss << std::get<std::tuple_size<Tuple>::value - Pos>(t);
+  CHECK_NOTNULL(values)->push_back(oss.str());
+  label_values(t, values, i__<Pos - 1>());
+}
+
+
+template <class... Types>
+std::vector<std::string> label_values(const std::tuple<Types...>& t) {
+  std::vector<std::string> ret;
+  label_values(t, &ret, i__<sizeof...(Types)>());
+  return ret;
+}
+
+
+}  // namespace
+
+
+template <class... LabelTypes>
+LabelledValues<LabelTypes...>::LabelledValues(
+    const std::string& name,
+    const typename NameType<LabelTypes>::name&... label_names)
+    : name_(name), label_names_{label_names...} {
+}
+
+
+template <class... LabelTypes>
+double LabelledValues<LabelTypes...>::Get(const LabelTypes&... labels) const {
+  std::lock_guard<std::mutex> lock(mutex_);
+  const std::tuple<LabelTypes...> key(labels...);
+  const auto it(values_.find(key));
+  if (it == values_.end()) {
+    return 0;
+  }
+  return it->second.second;
+}
+
+
+template <class... LabelTypes>
+void LabelledValues<LabelTypes...>::Set(const LabelTypes&... labels,
+                                        double value) {
+  std::lock_guard<std::mutex> lock(mutex_);
+  values_[std::tuple<LabelTypes...>(labels...)] =
+      make_pair(std::chrono::system_clock::now(), value);
+}
+
+
+template <class... LabelTypes>
+void LabelledValues<LabelTypes...>::Increment(const LabelTypes&... labels) {
+  IncrementBy(labels..., 1);
+}
+
+
+template <class... LabelTypes>
+void LabelledValues<LabelTypes...>::IncrementBy(const LabelTypes&... labels,
+                                                double amount) {
+  std::lock_guard<std::mutex> lock(mutex_);
+  const std::tuple<LabelTypes...> key(labels...);
+  const auto it(values_.find(key));
+  if (it == values_.end()) {
+    values_[key] = make_pair(std::chrono::system_clock::now(), amount);
+    return;
+  }
+  values_[key] = make_pair(std::chrono::system_clock::now(),
+                           values_[key].second + amount);
+}
+
+
+template <class... LabelTypes>
+std::map<std::vector<std::string>, Metric::TimestampedValue>
+LabelledValues<LabelTypes...>::CurrentValues() const {
+  std::lock_guard<std::mutex> lock(mutex_);
+  std::map<std::vector<std::string>, Metric::TimestampedValue> ret;
+
+  for (const auto& v : values_) {
+    ret[label_values(v.first)] = v.second;
+  }
+  return ret;
+}
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_MONITORING_LABELLED_VALUES_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/latency.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/latency.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/latency.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/latency.h	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,132 @@
+#ifndef CERT_TRANS_MONITORING_LATENCY_H_
+#define CERT_TRANS_MONITORING_LATENCY_H_
+
+#include <string>
+
+#include "base/macros.h"
+#include "monitoring/counter.h"
+#include "monitoring/event_metric.h"
+#include "monitoring/monitoring.h"
+
+namespace cert_trans {
+
+class ScopedLatency;
+
+
+// A helper class for monitoring latency.
+// This class creates two Counter metrics, one called "|base_name|_overall_sum"
+// which contains the sum of all latencies broken down by labels, and another
+// called "|base_name|_count" which contains the number of latency measurements
+// taken, also broken down by labels.
+//
+// To actually measure latency, you can either call RecordLatency() directly
+// with a latency sample, or use the ScopedLatency() method to return an object
+// which will automatically add a latency measurement consisting of the
+// duration between the call to ScopedLatency() and the destruction of the
+// returned object.
+//
+// The |TimeUnit| template parameter is used to specify the unit of the values
+// added to the counter, e.g. specifying std::chrono::milliseconds will
+// duration_cast all recorded latencies to milliseconds before adding to the
+// total count.
+//
+// |LabelTypes...| works as in the Counter<> and Gauge<> templates.
+//
+// Example usage:
+//
+//   static Latency<std::chrono::milliseconds, std::string> latency_by_name(
+//      "latency_by_name", "name");
+//   ...
+//
+//   void DoStuffForName(const string& name) {
+//     // This will record the latency of this method for each different |name|
+//     ScopedLatency latency(latency_by_name.ScopedLatency(name));
+//     ...
+//     // do stuff
+//     ...
+//   }
+//
+//   // Here's an example where there's no one scope so can't easily use the
+//   // ScopedLatency helper.
+//   void FinishedDoingStuffCallback(const string& name,
+//                                   const steady_clock::time_point started_at)
+//                                   {
+//      latency_by_name.RecordLatency(name, steady_clock::now() - started_at);
+//   }
+template <class TimeUnit, class... LabelTypes>
+class Latency {
+ public:
+  Latency(const std::string& base_name,
+          const typename NameType<LabelTypes>::name&... label_names,
+          const std::string& help);
+
+  void RecordLatency(const LabelTypes&... labels,
+                     std::chrono::duration<double> latency);
+
+  ScopedLatency GetScopedLatency(const LabelTypes&... labels);
+
+ private:
+  EventMetric<LabelTypes...> metric_;
+
+  DISALLOW_COPY_AND_ASSIGN(Latency);
+};
+
+
+// Helper class to automatically calculate and record latency.
+// Measures the duration between its construction and destruction times, and
+// automatically registers that with the Latency<> class which created it.
+class ScopedLatency {
+ public:
+  ScopedLatency(ScopedLatency&& other) = default;
+
+  ~ScopedLatency() {
+    record_latency_(std::chrono::steady_clock::now() - start_);
+  }
+
+ private:
+  ScopedLatency(
+      const std::function<void(std::chrono::duration<double>)>& record_latency)
+      : record_latency_(record_latency),
+        start_(std::chrono::steady_clock::now()) {
+  }
+
+  const std::function<void(std::chrono::duration<double>)> record_latency_;
+  const std::chrono::steady_clock::time_point start_;
+
+  template <class TimeUnit, class... LabelTypes>
+  friend class Latency;
+
+  DISALLOW_COPY_AND_ASSIGN(ScopedLatency);
+};
+
+
+template <class TimeUnit, class... LabelTypes>
+Latency<TimeUnit, LabelTypes...>::Latency(
+    const std::string& base_name,
+    const typename NameType<LabelTypes>::name&... label_names,
+    const std::string& help)
+    : metric_(base_name, label_names..., help) {
+}
+
+
+template <class TimeUnit, class... LabelTypes>
+void Latency<TimeUnit, LabelTypes...>::RecordLatency(
+    const LabelTypes&... labels, std::chrono::duration<double> latency) {
+  metric_.RecordEvent(labels...,
+                      std::chrono::duration_cast<TimeUnit>(latency).count());
+}
+
+
+template <class TimeUnit, class... LabelTypes>
+ScopedLatency Latency<TimeUnit, LabelTypes...>::GetScopedLatency(
+    const LabelTypes&... labels) {
+  return cert_trans::ScopedLatency(
+      std::bind(&Latency<TimeUnit, LabelTypes...>::RecordLatency, this,
+                labels..., std::placeholders::_1));
+}
+
+
+}  // namespace cert_trans
+
+
+#endif  // CERT_TRANS_MONITORING_LATENCY_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/metric.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/metric.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/metric.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/metric.h	2017-01-15 10:56:31.044591151 +0100
@@ -0,0 +1,92 @@
+#ifndef CERT_TRANS_MONITORING_METRIC_H_
+#define CERT_TRANS_MONITORING_METRIC_H_
+
+#include <map>
+#include <ostream>
+#include <set>
+#include <string>
+#include <vector>
+
+#include "base/macros.h"
+#include "monitoring/registry.h"
+
+namespace cert_trans {
+
+// As pointless as this looks, it's crucial in order to be able to specify that
+// we want as many |name| typed args as there are LabelTypes... in the Metric
+// class below.
+template <class... F>
+struct NameType {
+  typedef const std::string& name;
+};
+
+
+// Base class for all metric types
+class Metric {
+ public:
+  typedef std::pair<std::chrono::system_clock::time_point, double>
+      TimestampedValue;
+
+  enum Type {
+    COUNTER,
+    GAUGE,
+  };
+
+  Type Type() const {
+    return type_;
+  }
+
+  // Returns the name of this metric
+  const std::string& Name() const {
+    return name_;
+  }
+
+  // Returns the name of each of the labels this metric has, in the same order
+  // as the LabelTypes were specified.
+  const std::vector<std::string>& LabelNames() const {
+    return label_names_;
+  }
+
+  // Returns the i'th label name.
+  const std::string& LabelName(size_t i) const {
+    return label_names_[i];
+  }
+
+  // Returns the help string associated with this metric.
+  const std::string& Help() const {
+    return help_;
+  }
+
+  bool operator<(const Metric& rhs) const {
+    return name_ < rhs.name_;
+  }
+
+  // TODO(alcutter): Not over the moon about having this here, but it'll do for
+  // now.
+  virtual std::map<std::vector<std::string>, TimestampedValue> CurrentValues()
+      const = 0;
+
+ protected:
+  Metric(enum Type type, const std::string& name,
+         const std::vector<std::string>& label_names, const std::string& help)
+      : type_(type), name_(name), label_names_(label_names), help_(help) {
+    Registry::Instance()->AddMetric(this);
+  }
+
+  virtual ~Metric() = default;
+
+ private:
+  const enum Type type_;
+  const std::string name_;
+  const std::vector<std::string> label_names_;
+  const std::string help_;
+
+  friend class CounterTest;
+  friend class GaugeTest;
+
+  DISALLOW_COPY_AND_ASSIGN(Metric);
+};
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_MONITORING_METRIC_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/monitoring.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/monitoring.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/monitoring.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/monitoring.cc	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,6 @@
+#include <gflags/gflags.h>
+
+#include "monitoring/monitoring.h"
+
+DEFINE_string(monitoring, "prometheus",
+              "Which monitoring system to use, one of: prometheus, gcm");
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/monitoring.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/monitoring.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/monitoring.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/monitoring.h	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,21 @@
+#ifndef CERT_TRANS_MONITORING_MONITORING_H_
+#define CERT_TRANS_MONITORING_MONITORING_H_
+
+#include <gflags/gflags.h>
+
+#include "monitoring/counter.h"
+#include "monitoring/gauge.h"
+
+DECLARE_string(monitoring);
+
+namespace cert_trans {
+
+
+const char kPrometheus[] = "prometheus";
+const char kGcm[] = "gcm";
+
+
+}  // namespace cert_trans
+
+
+#endif  // CERT_TRANS_MONITORING_MONITORING_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/prometheus/exporter.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/prometheus/exporter.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/prometheus/exporter.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/prometheus/exporter.cc	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,107 @@
+#include "monitoring/prometheus/exporter.h"
+#include "monitoring/metric.h"
+#include "monitoring/prometheus/metrics.pb.h"
+#include "monitoring/registry.h"
+
+using std::chrono::duration_cast;
+using std::chrono::milliseconds;
+using std::map;
+using std::set;
+using std::string;
+using std::vector;
+
+namespace cert_trans {
+namespace {
+
+void AddLabelTypes(::io::prometheus::client::Metric* metric,
+                   const std::vector<std::string>& names,
+                   const std::vector<std::string>& values) {
+  CHECK_NOTNULL(metric);
+  CHECK_EQ(names.size(), values.size());
+  for (size_t i(0); i < names.size(); ++i) {
+    ::io::prometheus::client::LabelPair* label_pair(metric->add_label());
+    label_pair->set_name(names[i]);
+    label_pair->set_value(values[i]);
+  }
+}
+
+
+::io::prometheus::client::MetricFamily PopulateMetricFamily(
+    const Metric& metric) {
+  ::io::prometheus::client::MetricFamily family;
+  family.set_name(metric.Name());
+  family.set_help(metric.Help());
+  switch (metric.Type()) {
+    case Metric::COUNTER:
+      family.set_type(io::prometheus::client::MetricType::COUNTER);
+      break;
+    case Metric::GAUGE:
+      family.set_type(io::prometheus::client::MetricType::GAUGE);
+      break;
+    default:
+      LOG(FATAL) << "Unknown metric type: " << metric.Type();
+  }
+  const map<vector<string>, Metric::TimestampedValue> values(
+      metric.CurrentValues());
+  const vector<string> label_names(metric.LabelNames());
+  for (auto it(values.begin()); it != values.end(); ++it) {
+    io::prometheus::client::Metric* m(family.add_metric());
+    AddLabelTypes(m, label_names, it->first);
+    m->set_timestamp_ms(
+        duration_cast<milliseconds>(it->second.first.time_since_epoch())
+            .count());
+    switch (metric.Type()) {
+      case Metric::COUNTER:
+        m->mutable_counter()->set_value(it->second.second);
+        break;
+      case Metric::GAUGE:
+        m->mutable_gauge()->set_value(it->second.second);
+        break;
+      default:
+        LOG(FATAL) << "Unknown metric type: " << metric.Type();
+    }
+  }
+
+  return family;
+}
+
+
+}  // namespace
+
+void ExportMetricsToPrometheus(std::ostream* os) {
+  const set<const Metric*> metrics(Registry::Instance()->GetMetrics());
+
+  for (auto it(metrics.begin()); it != metrics.end(); ++it) {
+    const ::io::prometheus::client::MetricFamily family(
+        PopulateMetricFamily(**it));
+    CHECK(WriteDelimitedToOstream(family, os));
+  }
+}
+
+
+void ExportMetricsToHtml(std::ostream* os) {
+  const set<const Metric*> metrics(Registry::Instance()->GetMetrics());
+  *os << "<html>\n"
+      << "<body>\n"
+      << "  <h1>Metrics</h1>\n";
+
+  *os << "<table>\n";
+  bool bg_flip(false);
+  for (const auto* m : metrics) {
+    *os << "<tr><td style='background-color:#"
+        << (bg_flip ? "bbffbb" : "eeffee") << "'><code>\n";
+    bg_flip = !bg_flip;
+
+    const ::io::prometheus::client::MetricFamily family(
+        PopulateMetricFamily(*m));
+    *os << family.DebugString();
+
+    *os << "\n</code></td></tr>\n";
+  }
+  *os << "</table>\n"
+      << "</body>\n"
+      << "</html>\n";
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/prometheus/exporter.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/prometheus/exporter.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/prometheus/exporter.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/prometheus/exporter.h	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,18 @@
+#ifndef CERT_TRANS_MONITORING_PROMETHEUS_H_
+#define CERT_TRANS_MONITORING_PROMETHEUS_H_
+
+#include <glog/logging.h>
+
+#include "util/protobuf_util.h"
+
+namespace cert_trans {
+
+void ExportMetricsToPrometheus(std::ostream* os);
+
+
+void ExportMetricsToHtml(std::ostream* os);
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_MONITORING_PROMETHEUS_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/prometheus/metrics.proto src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/prometheus/metrics.proto
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/prometheus/metrics.proto	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/prometheus/metrics.proto	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,82 @@
+// Copyright 2013 Prometheus Team
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+syntax = "proto2";
+
+package io.prometheus.client;
+option java_package = "io.prometheus.client";
+
+message LabelPair {
+  optional string name = 1;
+  optional string value = 2;
+}
+
+enum MetricType {
+  COUNTER = 0;
+  GAUGE = 1;
+  SUMMARY = 2;
+  UNTYPED = 3;
+  HISTOGRAM = 4;
+}
+
+message Gauge {
+  optional double value = 1;
+}
+
+message Counter {
+  optional double value = 1;
+}
+
+message Quantile {
+  optional double quantile = 1;
+  optional double value = 2;
+}
+
+message Summary {
+  optional uint64 sample_count = 1;
+  optional double sample_sum = 2;
+  repeated Quantile quantile = 3;
+}
+
+message Untyped {
+  optional double value = 1;
+}
+
+message Histogram {
+  optional uint64 sample_count = 1;
+  optional double sample_sum = 2;
+  repeated Bucket bucket = 3;  // Ordered in increasing order of upper_bound,
+                               // +Inf bucket is optional.
+}
+
+message Bucket {
+  optional uint64 cumulative_count = 1;  // Cumulative in increasing order.
+  optional double upper_bound = 2;       // Inclusive.
+}
+
+message Metric {
+  repeated LabelPair label = 1;
+  optional Gauge gauge = 2;
+  optional Counter counter = 3;
+  optional Summary summary = 4;
+  optional Untyped untyped = 5;
+  optional Histogram histogram = 7;
+  optional int64 timestamp_ms = 6;
+}
+
+message MetricFamily {
+  optional string name = 1;
+  optional string help = 2;
+  optional MetricType type = 3;
+  repeated Metric metric = 4;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/registry.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/registry.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/registry.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/registry.cc	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,39 @@
+#include "monitoring/registry.h"
+#include "monitoring/metric.h"
+
+using std::lock_guard;
+using std::mutex;
+using std::set;
+
+namespace cert_trans {
+
+using std::lock_guard;
+using std::mutex;
+using std::set;
+
+// static
+Registry* Registry::Instance() {
+  static Registry* registry(new Registry);
+  return registry;
+}
+
+
+void Registry::AddMetric(const Metric* metric) {
+  lock_guard<mutex> lock(mutex_);
+  metrics_.insert(metric);
+}
+
+
+void Registry::ResetForTestingOnly() {
+  lock_guard<mutex> lock(mutex_);
+  metrics_.clear();
+}
+
+
+set<const Metric*> Registry::GetMetrics() const {
+  lock_guard<mutex> lock(mutex_);
+  return set<const Metric*>(metrics_);
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/registry.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/registry.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/registry.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/registry.h	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,43 @@
+#ifndef CERT_TRANS_MONITORING_REGISTRY_H_
+#define CERT_TRANS_MONITORING_REGISTRY_H_
+
+#include <mutex>
+#include <set>
+#include <sstream>
+
+#include "base/macros.h"
+
+namespace cert_trans {
+class Metric;
+
+
+class Registry {
+ public:
+  static Registry* Instance();
+
+  // Registers a new Metric to be exported.
+  // |metric| must remain valid for at least the lifetime of this object
+  void AddMetric(const Metric* metric);
+
+  // Resets the registry, removing all references to added Metric objects.
+  // This method is only for use in testing.
+  void ResetForTestingOnly();
+
+  // Returns the set of currently known metrics.
+  std::set<const Metric*> GetMetrics() const;
+
+ private:
+  Registry() = default;
+
+  mutable std::mutex mutex_;
+  std::set<const Metric*> metrics_;
+
+  friend class RegistryTest;
+
+  DISALLOW_COPY_AND_ASSIGN(Registry);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_MONITORING_REGISTRY_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/registry_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/registry_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/monitoring/registry_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/monitoring/registry_test.cc	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,51 @@
+#include "monitoring/registry.h"
+
+#include <glog/logging.h>
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <memory>
+#include <sstream>
+
+#include "monitoring/monitoring.h"
+#include "util/testing.h"
+
+namespace cert_trans {
+
+using std::ostringstream;
+using std::string;
+using std::unique_ptr;
+using std::set;
+using testing::AllOf;
+using testing::AnyOf;
+using testing::Contains;
+
+
+class RegistryTest : public ::testing::Test {
+ public:
+  void TearDown() {
+    Registry::Instance()->ResetForTestingOnly();
+  }
+
+ protected:
+  const set<const Metric*>& GetMetrics() {
+    return Registry::Instance()->metrics_;
+  }
+};
+
+
+TEST_F(RegistryTest, TestAddMetric) {
+  unique_ptr<Counter<>> counter(Counter<>::New("name", "help"));
+  unique_ptr<Gauge<>> gauge(Gauge<>::New("name", "help"));
+  EXPECT_EQ(static_cast<size_t>(2), GetMetrics().size());
+  EXPECT_THAT(GetMetrics(),
+              AllOf(Contains(counter.get()), Contains(gauge.get())));
+}
+
+
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/connection_pool.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/connection_pool.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/connection_pool.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/connection_pool.cc	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,541 @@
+#include "net/connection_pool.h"
+
+#include <event2/event.h>
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <chrono>
+
+#include "monitoring/monitoring.h"
+#include "util/openssl_util.h"
+
+extern "C" {
+#include "third_party/curl/hostcheck.h"
+#include "third_party/isec_partners/openssl_hostname_validation.h"
+}  // extern "C"
+
+
+using std::bind;
+using std::chrono::duration_cast;
+using std::chrono::seconds;
+using std::chrono::system_clock;
+using std::lock_guard;
+using std::make_pair;
+using std::map;
+using std::move;
+using std::mutex;
+using std::pair;
+using std::placeholders::_1;
+using std::placeholders::_2;
+using std::string;
+using std::to_string;
+using std::unique_lock;
+using std::unique_ptr;
+using std::shared_ptr;
+using util::ClearOpenSSLErrors;
+using util::DumpOpenSSLErrorStack;
+
+DEFINE_int32(
+    connection_read_timeout_seconds, 60,
+    "Connection read timeout in seconds, only applies while willing to read.");
+DEFINE_int32(connection_write_timeout_seconds, 60,
+             "Connection write timeout in seconds, only applies while willing "
+             "to write.");
+DEFINE_int32(
+    connection_pool_max_unused_age_seconds, 60 * 5,
+    "When there are more than --url_fetcher_max_conn_per_host_port "
+    "connections per host:port pair, any unused for at least this long will "
+    "be removed.");
+DEFINE_string(trusted_root_certs, "",
+              "Location of trusted CA root certs for outgoing SSL "
+              "connections.");
+DEFINE_int32(url_fetcher_max_conn_per_host_port, 4,
+             "maximum number of URL fetcher connections per host:port");
+
+DEFINE_string(tls_client_minimum_protocol, "tlsv12",
+              "Minimum acceptable TLS "
+              "version protocol (tlsv1, tlsv11, tlsv12)");
+
+DEFINE_string(
+    tls_client_ciphers,
+    "ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:"
+    "ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:"
+    "DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:"
+    "ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:"
+    "ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:"
+    "ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:"
+    "DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:"
+    "DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:"
+    "!aNULL:!eNULL:!EXPORT:!DES:!RC4:!3DES:!MD5:!PSK",
+    "List of ciphers the client will accept, default is the Mozilla 'Modern "
+    "compatibility' recommended list.");
+
+
+namespace cert_trans {
+namespace internal {
+
+
+const int kZeroMillis = 0;
+
+
+static Gauge<string>* connections_per_host_port(
+    Gauge<string>::New("connections_per_host_port", "host_port",
+                       "Number of cached connections port host:port"));
+
+
+namespace {
+
+
+int GetSSLConnectionIndex() {
+  static const int ssl_connection_index(
+      SSL_get_ex_new_index(0, nullptr, nullptr, nullptr, nullptr));
+  return ssl_connection_index;
+}
+
+
+string HostPortString(const HostPortPair& pair) {
+  return pair.first + ":" + to_string(pair.second);
+}
+
+
+}  // namespace
+
+
+// This class wraps the evhtp_connection_t* and associated data which need to
+// hang around for at least the lifetime that structure.
+class EvConnection {
+ public:
+  // Called by OpenSSL to verify the hostname presented in the server cert.
+  static int SSLVerifyCallback(int preverify_ok, X509_STORE_CTX* x509_ctx);
+
+  // Called by libevhtp when it detects some kind of error with the connection.
+  static evhtp_res ConnectionErrorHook(evhtp_connection_t* conn,
+                                       evhtp_error_flags errtype, void* arg);
+
+  // Called by libevhtp once it's finished with the connection and is about to
+  // delete it.
+  static evhtp_res ConnectionFinishedHook(evhtp_connection_t* conn, void* arg);
+
+  EvConnection(evhtp_connection_t* conn, HostPortPair&& other_end)
+      : ev_conn_(CHECK_NOTNULL(conn)),
+        other_end_(move(other_end)),
+        errored_(false) {
+    if (ev_conn_->ssl) {
+      SSL_set_ex_data(ev_conn_->ssl, GetSSLConnectionIndex(),
+                      static_cast<void*>(this));
+      SSL_set_tlsext_host_name(ev_conn_->ssl, other_end_.first.c_str());
+    }
+  }
+
+  evhtp_connection_t* connection() const {
+    return ev_conn_;
+  }
+
+  const HostPortPair& other_end() const {
+    return other_end_;
+  }
+
+  void SetErrored() {
+    lock_guard<mutex> lock(lock_);
+    errored_ = true;
+  }
+
+  bool GetErrored() const {
+    lock_guard<mutex> lock(lock_);
+    return errored_;
+  }
+
+ private:
+  // We never really own this, evhtp does, as it likes to remind us.
+  evhtp_connection_t* ev_conn_;
+  const HostPortPair other_end_;
+
+  mutable std::mutex lock_;
+  bool errored_;
+};
+
+
+// static
+int EvConnection::SSLVerifyCallback(const int preverify_ok,
+                                    X509_STORE_CTX* x509_ctx) {
+  CHECK_NOTNULL(x509_ctx);
+  X509* const server_cert(
+      CHECK_NOTNULL(X509_STORE_CTX_get_current_cert(x509_ctx)));
+
+  if (preverify_ok == 0) {
+    const int err(X509_STORE_CTX_get_error(x509_ctx));
+    char buf[256];
+    X509_NAME_oneline(X509_get_subject_name(server_cert), buf, 256);
+
+    LOG(WARNING) << "OpenSSL failed to verify cert for " << buf << ": "
+                 << X509_verify_cert_error_string(err);
+    return preverify_ok;
+  }
+
+  // Only do extra checks (i.e. hostname matching) for the end-entity cert.
+  const int depth(X509_STORE_CTX_get_error_depth(x509_ctx));
+  if (depth > 0) {
+    return preverify_ok;
+  }
+
+  const SSL* const ssl(static_cast<SSL*>(CHECK_NOTNULL(
+      X509_STORE_CTX_get_ex_data(x509_ctx,
+                                 SSL_get_ex_data_X509_STORE_CTX_idx()))));
+  const EvConnection* const connection(
+      CHECK_NOTNULL(static_cast<const EvConnection*>(
+          SSL_get_ex_data(ssl, GetSSLConnectionIndex()))));
+
+  const HostnameValidationResult hostname_valid(
+      validate_hostname(connection->other_end_.first.c_str(), server_cert));
+  if (hostname_valid != MatchFound) {
+    string error;
+    switch (hostname_valid) {
+      case MatchFound:
+        LOG(FATAL) << "Shouldn't get here.";
+        break;
+      case MatchNotFound:
+        error = "certificate doesn't match hostname";
+        break;
+      case NoSANPresent:
+        // I don't think we should ever see this, should be handled inside
+        // validate_hostname()
+        error = "no SAN present";
+        break;
+      case MalformedCertificate:
+        error = "certificate is malformed";
+        break;
+      case Error:
+        error = "unknown error";
+        break;
+    }
+    if (connection->ev_conn_->request) {
+      connection->ev_conn_->request->status = kSSLErrorStatus;
+    }
+#pragma clang diagnostic push
+#pragma clang diagnostic ignored "-Wunknown-pragmas"
+#pragma clang diagnostic ignored "-Wunused-local-typedef"
+    LOG_EVERY_N(WARNING, 100)
+        << "Failed to validate SSL certificate: " << error << " : "
+        << DumpOpenSSLErrorStack();
+#pragma clang diagnostic pop
+    ClearOpenSSLErrors();
+    return 0;
+  }
+  return 1;
+}
+
+
+ConnectionPool::Connection::Connection(const shared_ptr<EvConnection>& conn)
+    : connection_(conn) {
+}
+
+
+evhtp_connection_t* ConnectionPool::Connection::connection() const {
+  return connection_->connection();
+}
+
+
+bool ConnectionPool::Connection::GetErrored() const {
+  return connection_->GetErrored();
+}
+
+
+const HostPortPair& ConnectionPool::Connection::other_end() const {
+  return connection_->other_end();
+}
+
+
+namespace {
+
+// No SSLv2 or SSLv3, thanks.
+const int kSslOpMinVersionTls1 = SSL_OP_NO_SSLv2 | SSL_OP_NO_SSLv3;
+const int kSslOpMinVersionTls11 = kSslOpMinVersionTls1 | SSL_OP_NO_TLSv1;
+const int kSslOpMinVersionTls12 = kSslOpMinVersionTls11 | SSL_OP_NO_TLSv1_1;
+
+
+// Create an SSL_CTX which permits the TLS versions specified by flags.
+// SSLv2 and SSLv3 are never supported.
+SSL_CTX* CreateSSLCTXFromFlags() {
+  SSL_CTX* ctx(SSL_CTX_new(SSLv23_client_method()));
+  CHECK_NOTNULL(ctx);
+
+  LOG(WARNING) << "Setting client minimum TLS protocol to "
+               << FLAGS_tls_client_minimum_protocol;
+
+  if (FLAGS_tls_client_minimum_protocol == "tlsv1") {
+    SSL_CTX_set_options(ctx, kSslOpMinVersionTls1);
+  } else if (FLAGS_tls_client_minimum_protocol == "tlsv11") {
+    SSL_CTX_set_options(ctx, kSslOpMinVersionTls11);
+  } else if (FLAGS_tls_client_minimum_protocol == "tlsv12") {
+    SSL_CTX_set_options(ctx, kSslOpMinVersionTls12);
+  } else {
+    LOG(FATAL) << "Unrecognised TLS version: "
+               << FLAGS_tls_client_minimum_protocol;
+  }
+
+  CHECK_EQ(1, SSL_CTX_set_cipher_list(ctx, FLAGS_tls_client_ciphers.c_str()));
+
+  return ctx;
+}
+
+
+}  // namespace
+
+
+ConnectionPool::ConnectionPool(libevent::Base* base)
+    : base_(CHECK_NOTNULL(base)),
+      cleanup_scheduled_(false),
+      ssl_ctx_(CreateSSLCTXFromFlags(), SSL_CTX_free) {
+  CHECK(ssl_ctx_) << "could not build SSL context: "
+                  << DumpOpenSSLErrorStack();
+
+  // Try to load trusted root certificates.
+  if (FLAGS_trusted_root_certs == "") {
+    LOG(INFO) << "Loading openssl default trusted root certificates...";
+    if (SSL_CTX_set_default_verify_paths(ssl_ctx_.get()) != 1) {
+      DumpOpenSSLErrorStack();
+      LOG(FATAL) << "Couldn't load openssl default trusted root certificates.";
+    }
+  } else {
+    LOG(INFO) << "Loading trusted root certificates from: "
+              << FLAGS_trusted_root_certs << " ...";
+    if (SSL_CTX_load_verify_locations(ssl_ctx_.get(),
+                                      FLAGS_trusted_root_certs.c_str(),
+                                      nullptr) != 1) {
+      DumpOpenSSLErrorStack();
+      LOG(FATAL) << "Couldn't load trusted root certificates: "
+                 << FLAGS_trusted_root_certs;
+    }
+  }
+
+  SSL_CTX_set_verify(ssl_ctx_.get(), SSL_VERIFY_PEER,
+                     EvConnection::SSLVerifyCallback);
+}
+
+
+namespace {
+
+
+string ErrorFlagDescription(const evhtp_error_flags flags) {
+  return string(flags & BEV_EVENT_READING ? " READING" : "") +
+         (flags & BEV_EVENT_WRITING ? " WRITING" : "") +
+         (flags & BEV_EVENT_EOF ? " EOF" : "") +
+         (flags & BEV_EVENT_ERROR ? " ERROR" : "") +
+         (flags & BEV_EVENT_TIMEOUT ? " TIMEOUT" : "") +
+         (flags & BEV_EVENT_CONNECTED ? " CONNECTED" : "");
+}
+
+
+}  // namespace
+
+
+// static
+evhtp_res EvConnection::ConnectionErrorHook(evhtp_connection_t* conn,
+                                            evhtp_error_flags flags,
+                                            void* arg) {
+  CHECK_NOTNULL(conn);
+  CHECK_NOTNULL(arg);
+  CHECK(libevent::Base::OnEventThread());
+  EvConnection* const c(static_cast<EvConnection*>(arg));
+  LOG(WARNING) << "Releasing errored connection to " << c->other_end_.first
+               << ":" << c->other_end_.second;
+
+  CHECK_EQ(conn, c->ev_conn_);
+  c->SetErrored();
+
+  // Need to let the client know their request has failed, seems evhtp doesn't
+  // do that by default so we'll call the request done callback here.
+  if (conn->request) {
+    // If someone hasn't already modified the default status, set it to a
+    // generic "something went wrong" value here:
+    if (conn->request->status == 200) {
+      bool log_error(true);
+      if (flags == BEV_EVENT_EOF) {
+        // not actually an error, we just read up to the EOF, probably the
+        // server didn't send a Content-Length header.
+        log_error = false;
+      } else if (flags & BEV_EVENT_TIMEOUT) {
+        conn->request->status = kTimeout;
+      } else {
+        conn->request->status = kUnknownErrorStatus;
+      }
+      if (log_error) {
+        const string error_str(
+            evutil_socket_error_to_string(evutil_socket_geterror(conn->sock)));
+        LOG(WARNING) << "error flag (0x" << std::hex << static_cast<int>(flags)
+                     << "):" << ErrorFlagDescription(flags) << " : "
+                     << error_str;
+      }
+    } else {
+      LOG(WARNING) << "status already set to " << conn->request->status;
+    }
+    // The callback is going to Put() the Connection back, which will release
+    // the underlying connection, and then delete the Connection wrapper when
+    // it's determined that it's bad.
+    conn->request->cb(conn->request, conn->request->cbarg);
+    conn->request = nullptr;
+  }
+  return EVHTP_RES_OK;
+}
+
+
+// static
+evhtp_res EvConnection::ConnectionFinishedHook(evhtp_connection_t* conn,
+                                               void* arg) {
+  CHECK_NOTNULL(conn);
+  CHECK_NOTNULL(arg);
+  CHECK(libevent::Base::OnEventThread());
+  // libevhtp has finished with this connection so we can release the
+  // shared_ptr we had to keep it around until now.
+  unique_ptr<shared_ptr<EvConnection>> const c(
+      static_cast<shared_ptr<EvConnection>*>(arg));
+  VLOG(1) << "Finished connection to " << (*c)->other_end_.first << ":"
+          << (*c)->other_end_.second;
+  // The underlying evhtp_connection_t is about to be freed, make sure nobody
+  // can hurt themselves via a dangling pointer.
+  (*c)->ev_conn_ = nullptr;
+  return EVHTP_RES_OK;
+}
+
+
+// static
+void ConnectionPool::RemoveDeadConnectionsFromDeque(
+    const unique_lock<mutex>& lock,
+    std::deque<ConnectionPool::TimestampedConnection>* deque) {
+  CHECK(lock.owns_lock());
+  CHECK(deque);
+
+  // Do a sweep and remove any dead connections
+  for (auto deque_it(deque->begin()); deque_it != deque->end();) {
+    CHECK(deque_it->second);
+    if (!deque_it->second->connection()) {
+      VLOG(1) << "Removing dead connection to "
+              << deque_it->second->other_end().first << ":"
+              << deque_it->second->other_end().second;
+      deque_it = deque->erase(deque_it);
+      continue;
+    }
+    ++deque_it;
+  }
+}
+
+
+unique_ptr<ConnectionPool::Connection> ConnectionPool::Get(const URL& url) {
+  CHECK(url.Protocol() == "http" || url.Protocol() == "https");
+  const uint16_t default_port(url.Protocol() == "https" ? 443 : 80);
+  HostPortPair key(url.Host(), url.Port() != 0 ? url.Port() : default_port);
+  unique_lock<mutex> lock(lock_);
+
+  auto it(conns_.find(key));
+
+  if (it != conns_.end() && !it->second.empty()) {
+    RemoveDeadConnectionsFromDeque(lock, &it->second);
+  }
+
+  if (it == conns_.end() || it->second.empty()) {
+    VLOG(1) << "new evhtp_connection for " << key.first << ":" << key.second;
+    // This EvConnection has a slightly complicated lifetime; it needs to hang
+    // around until libevhtp/libevent have entirely finished with the
+    // evhtp_connection_t it references, and for at least as long as the life
+    // of the Connection we return from this method.
+    //
+    // This is accomplished through the use of a couple of shared_ptrs;
+    // this one, which goes inside the returned Connection object, and another
+    // created further below which gets passed in to the
+    // ConnectionFinishedHook.
+    auto conn(std::make_shared<EvConnection>(
+        url.Protocol() == "https"
+            ? base_->HttpsConnectionNew(key.first, key.second, ssl_ctx_.get())
+            : base_->HttpConnectionNew(key.first, key.second),
+        move(key)));
+    unique_ptr<ConnectionPool::Connection> handle(new Connection(conn));
+    struct timeval read_timeout = {FLAGS_connection_read_timeout_seconds,
+                                   kZeroMillis};
+    struct timeval write_timeout = {FLAGS_connection_write_timeout_seconds,
+                                    kZeroMillis};
+    evhtp_connection_set_timeouts(handle->connection(), &read_timeout,
+                                  &write_timeout);
+    evhtp_set_hook(&handle->connection()->hooks, evhtp_hook_on_conn_error,
+                   reinterpret_cast<evhtp_hook>(
+                       EvConnection::ConnectionErrorHook),
+                   reinterpret_cast<void*>(conn.get()));
+    evhtp_set_hook(
+        &handle->connection()->hooks, evhtp_hook_on_connection_fini,
+        reinterpret_cast<evhtp_hook>(EvConnection::ConnectionFinishedHook),
+        // We'll hold on to another shared_ptr to the Connection
+        // until evhtp tells us that it's finished with the cnxn.
+        reinterpret_cast<void*>(new shared_ptr<EvConnection>(conn)));
+    return handle;
+  }
+
+  VLOG(1) << "cached evhtp_connection for " << key.first << ":" << key.second;
+  unique_ptr<ConnectionPool::Connection> retval(
+      move(it->second.back().second));
+  it->second.pop_back();
+  CHECK_NOTNULL(retval->connection());
+
+  return retval;
+}
+
+
+void ConnectionPool::Put(unique_ptr<ConnectionPool::Connection> handle) {
+  if (!handle) {
+    VLOG(1) << "returned null Connection";
+    return;
+  }
+
+  if (!handle->connection()) {
+    VLOG(1) << "returned dead Connection";
+    handle.reset();
+    return;
+  }
+
+  if (handle->GetErrored()) {
+    VLOG(1) << "returned errored Connection";
+    handle.reset();
+    return;
+  }
+
+  const HostPortPair& key(handle->other_end());
+  VLOG(1) << "returned Connection for " << key.first << ":" << key.second;
+  lock_guard<mutex> lock(lock_);
+  auto& entry(conns_[key]);
+
+  CHECK_GE(FLAGS_url_fetcher_max_conn_per_host_port, 0);
+  entry.emplace_back(make_pair(system_clock::now(), move(handle)));
+  const string hostport(HostPortString(key));
+  VLOG(1) << "ConnectionPool for " << hostport << " size : " << entry.size();
+  connections_per_host_port->Set(hostport, entry.size());
+  if (!cleanup_scheduled_ &&
+      entry.size() >
+          static_cast<uint>(FLAGS_url_fetcher_max_conn_per_host_port)) {
+    cleanup_scheduled_ = true;
+    base_->Add(bind(&ConnectionPool::Cleanup, this));
+  }
+}
+
+
+void ConnectionPool::Cleanup() {
+  unique_lock<mutex> lock(lock_);
+  cleanup_scheduled_ = false;
+  const system_clock::time_point cutoff(
+      system_clock::now() -
+      seconds(FLAGS_connection_pool_max_unused_age_seconds));
+
+  // conns_ is a std::map<HostPortPair, std::deque<TimestampedConnection>>
+  for (auto& entry : conns_) {
+    RemoveDeadConnectionsFromDeque(lock, &entry.second);
+    while (entry.second.front().first < cutoff &&
+           entry.second.size() >
+               static_cast<uint>(FLAGS_url_fetcher_max_conn_per_host_port)) {
+      entry.second.pop_front();
+    }
+    const string hostport(HostPortString(entry.first));
+    VLOG(1) << "ConnectionPool for " << hostport
+            << " size : " << entry.second.size();
+    connections_per_host_port->Set(hostport, entry.second.size());
+  }
+}
+
+
+}  // namespace internal
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/connection_pool.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/connection_pool.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/connection_pool.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/connection_pool.h	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,94 @@
+#ifndef CERT_TRANS_NET_CONNECTION_POOL_H_
+#define CERT_TRANS_NET_CONNECTION_POOL_H_
+
+#include <openssl/ssl.h>
+#include <stdint.h>
+#include <deque>
+#include <map>
+#include <memory>
+#include <mutex>
+#include <string>
+
+#include "base/macros.h"
+#include "net/url.h"
+#include "util/libevent_wrapper.h"
+
+namespace cert_trans {
+
+
+// Status code for when something went wrong with the connection.
+const int kUnknownErrorStatus = 0;
+
+// Status code for when there was an error with the SSL negotiation.
+const int kSSLErrorStatus = 1;
+
+// Status code for when the connection timed-out.
+const int kTimeout = 2;
+
+
+namespace internal {
+
+
+struct evhtp_connection_deleter {
+  void operator()(evhtp_connection_t* con) const {
+    evhtp_connection_free(con);
+  }
+};
+
+
+typedef std::pair<std::string, uint16_t> HostPortPair;
+class EvConnection;
+
+
+class ConnectionPool {
+ public:
+  class Connection {
+   public:
+    Connection(const std::shared_ptr<EvConnection>& evc);
+
+    evhtp_connection_t* connection() const;
+
+    const HostPortPair& other_end() const;
+
+    bool GetErrored() const;
+
+   private:
+    std::shared_ptr<EvConnection> connection_;
+    friend class ConnectionPool;
+
+    DISALLOW_COPY_AND_ASSIGN(Connection);
+  };
+
+  ConnectionPool(libevent::Base* base);
+
+  std::unique_ptr<Connection> Get(const URL& url);
+  void Put(std::unique_ptr<Connection> conn);
+
+ private:
+  typedef std::pair<std::chrono::system_clock::time_point,
+                    std::unique_ptr<Connection>> TimestampedConnection;
+
+  static void RemoveDeadConnectionsFromDeque(
+      const std::unique_lock<std::mutex>& lock,
+      std::deque<TimestampedConnection>* deque);
+
+  void Cleanup();
+
+  libevent::Base* const base_;
+
+  std::mutex lock_;
+  // We get and put connections from the back of the deque, and when
+  // there are too many, we prune them from the front (LIFO).
+  std::map<HostPortPair, std::deque<TimestampedConnection>> conns_;
+  bool cleanup_scheduled_;
+
+  std::unique_ptr<evhtp_ssl_ctx_t, void (*)(evhtp_ssl_ctx_t*)> ssl_ctx_;
+
+  DISALLOW_COPY_AND_ASSIGN(ConnectionPool);
+};
+
+
+}  // namespace internal
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_NET_CONNECTION_POOL_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/mock_url_fetcher.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/mock_url_fetcher.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/mock_url_fetcher.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/mock_url_fetcher.h	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,34 @@
+#ifndef CERT_TRANS_NET_MOCK_URL_FETCHER_H_
+#define CERT_TRANS_NET_MOCK_URL_FETCHER_H_
+
+#include <gmock/gmock.h>
+
+#include "net/url_fetcher.h"
+
+namespace cert_trans {
+
+
+class MockUrlFetcher : public UrlFetcher {
+ public:
+  MOCK_METHOD3(Fetch,
+               void(const Request& req, Response* resp, util::Task* task));
+};
+
+
+inline testing::Matcher<const UrlFetcher::Request&> IsUrlFetchRequest(
+    const testing::Matcher<UrlFetcher::Verb>& verb,
+    const testing::Matcher<URL>& url,
+    const testing::Matcher<UrlFetcher::Headers>& headers,
+    const testing::Matcher<std::string>& body) {
+  // TODO(pphaneuf): We should make our own matcher with an output
+  // that is easier to read, and also support form submissions.
+  return testing::AllOf(testing::Field(&UrlFetcher::Request::verb, verb),
+                        testing::Field(&UrlFetcher::Request::url, url),
+                        testing::Field(&UrlFetcher::Request::headers, headers),
+                        testing::Field(&UrlFetcher::Request::body, body));
+}
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_NET_MOCK_URL_FETCHER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/url.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/url.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/url.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/url.cc	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,67 @@
+#include "net/url.h"
+
+#include <event2/http.h>
+#include <glog/logging.h>
+#include <memory>
+
+using std::string;
+using std::unique_ptr;
+
+namespace cert_trans {
+
+namespace {
+
+
+void StringFromCharPtr(string* out, const char* in) {
+  if (in) {
+    *out = in;
+  }
+}
+
+
+}  // namespace
+
+
+URL::URL(const string& url) {
+  VLOG(1) << "parsing URL: " << url;
+
+  unique_ptr<evhttp_uri, void (*)(evhttp_uri*)> uri(
+      evhttp_uri_parse(url.c_str()), &evhttp_uri_free);
+
+  if (!uri) {
+    LOG(FATAL) << "URL invalid: " << url;
+  }
+
+  const int port(evhttp_uri_get_port(uri.get()));
+  port_ = port > 0 && port <= UINT16_MAX ? port : 0;
+
+  StringFromCharPtr(&protocol_, evhttp_uri_get_scheme(uri.get()));
+  StringFromCharPtr(&host_, evhttp_uri_get_host(uri.get()));
+  StringFromCharPtr(&path_, evhttp_uri_get_path(uri.get()));
+  StringFromCharPtr(&query_, evhttp_uri_get_query(uri.get()));
+}
+
+
+string URL::PathQuery() const {
+  string retval(path_);
+
+  if (!query_.empty()) {
+    retval.append("?");
+    retval.append(query_);
+  }
+
+  return retval;
+}
+
+
+std::ostream& operator<<(std::ostream& out, const URL& url) {
+  out << url.Protocol() << "://" << url.Host();
+  if (url.Port() > 0) {
+    out << ":" << url.Port();
+  }
+  out << url.PathQuery();
+  return out;
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/url_fetcher.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/url_fetcher.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/url_fetcher.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/url_fetcher.cc	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,337 @@
+#include "net/url_fetcher.h"
+
+#include <event2/buffer.h>
+#include <event2/keyvalq_struct.h>
+#include <evhtp.h>
+#include <glog/logging.h>
+#include <htparse.h>
+
+#include "net/connection_pool.h"
+#include "util/thread_pool.h"
+
+using cert_trans::internal::ConnectionPool;
+using std::bind;
+using std::endl;
+using std::make_pair;
+using std::move;
+using std::ostream;
+using std::string;
+using std::to_string;
+using std::unique_ptr;
+using util::Status;
+using util::Task;
+using util::TaskHold;
+
+namespace cert_trans {
+
+
+struct UrlFetcher::Impl {
+  Impl(libevent::Base* base, ThreadPool* thread_pool)
+      : base_(CHECK_NOTNULL(base)),
+        thread_pool_(CHECK_NOTNULL(thread_pool)),
+        pool_(base_) {
+  }
+
+  libevent::Base* const base_;
+  ThreadPool* const thread_pool_;
+  internal::ConnectionPool pool_;
+};
+
+
+namespace {
+
+
+htp_method VerbToCmdType(UrlFetcher::Verb verb) {
+  switch (verb) {
+    case UrlFetcher::Verb::GET:
+      return htp_method_GET;
+
+    case UrlFetcher::Verb::POST:
+      return htp_method_POST;
+
+    case UrlFetcher::Verb::PUT:
+      return htp_method_PUT;
+
+    case UrlFetcher::Verb::DELETE:
+      return htp_method_DELETE;
+  }
+
+  LOG(FATAL) << "unknown UrlFetcher::Verb: " << static_cast<int>(verb);
+}
+
+
+struct State {
+  State(libevent::Base* base, ConnectionPool* pool,
+        const UrlFetcher::Request& request, UrlFetcher::Response* response,
+        Task* task);
+
+  ~State() {
+    CHECK(!conn_) << "request state object still had a connection at cleanup?";
+  }
+
+  void MakeRequest();
+
+  // The following methods must only be called on the libevent
+  // dispatch thread.
+  void RunRequest();
+  void RequestDone(evhtp_request_t* req);
+
+  libevent::Base* const base_;
+  ConnectionPool* const pool_;
+  const UrlFetcher::Request request_;
+  UrlFetcher::Response* const response_;
+  Task* const task_;
+
+  unique_ptr<ConnectionPool::Connection> conn_;
+};
+
+
+void RequestCallback(evhtp_request_t* req, void* userdata) {
+  static_cast<State*>(CHECK_NOTNULL(userdata))->RequestDone(req);
+}
+
+
+UrlFetcher::Request NormaliseRequest(UrlFetcher::Request req) {
+  if (req.url.Path().empty()) {
+    req.url.SetPath("/");
+  }
+
+  if (req.headers.find("Host") == req.headers.end()) {
+    req.headers.insert(make_pair("Host", req.url.Host()));
+  }
+
+  return req;
+}
+
+
+State::State(libevent::Base* base, ConnectionPool* pool,
+             const UrlFetcher::Request& request,
+             UrlFetcher::Response* response, Task* task)
+    : base_(CHECK_NOTNULL(base)),
+      pool_(CHECK_NOTNULL(pool)),
+      request_(NormaliseRequest(request)),
+      response_(CHECK_NOTNULL(response)),
+      task_(CHECK_NOTNULL(task)) {
+  if (request_.url.Protocol() != "http" &&
+      request_.url.Protocol() != "https") {
+    VLOG(1) << "unsupported protocol: " << request_.url.Protocol();
+    task_->Return(Status(util::error::INVALID_ARGUMENT,
+                         "UrlFetcher: unsupported protocol: " +
+                             request_.url.Protocol()));
+    return;
+  }
+}
+
+
+void State::MakeRequest() {
+  CHECK(!libevent::Base::OnEventThread());
+  conn_ = pool_->Get(request_.url);
+  base_->Add(bind(&State::RunRequest, this));
+}
+
+
+void State::RunRequest() {
+  CHECK(libevent::Base::OnEventThread());
+  evhtp_request_t* const http_req(
+      CHECK_NOTNULL(evhtp_request_new(&RequestCallback, this)));
+  if (!request_.body.empty() &&
+      request_.headers.find("Content-Length") == request_.headers.end()) {
+    evhtp_headers_add_header(
+        http_req->headers_out,
+        evhtp_header_new("Content-Length",
+                         to_string(request_.body.size()).c_str(), 1, 1));
+  }
+  for (const auto& header : request_.headers) {
+    evhtp_headers_add_header(http_req->headers_out,
+                             evhtp_header_new(header.first.c_str(),
+                                              header.second.c_str(), 1, 1));
+  }
+
+  if (!conn_->connection() || conn_->GetErrored()) {
+    conn_.reset();
+    task_->Return(Status(util::error::UNAVAILABLE, "connection failed."));
+    return;
+  }
+
+  const htp_method verb(VerbToCmdType(request_.verb));
+  VLOG(1) << "evhtp_make_request(" << conn_.get()->connection() << ", "
+          << http_req << ", " << verb << ", \"" << request_.url.PathQuery()
+          << "\")";
+  VLOG(2) << request_;
+  if (evhtp_make_request(conn_->connection(), http_req, verb,
+                         request_.url.PathQuery().c_str()) != 0) {
+    VLOG(1) << "evhtp_make_request error";
+    // Put back the connection, RequestDone is not going to get
+    // called.
+    pool_->Put(move(conn_));
+    task_->Return(Status(util::error::INTERNAL, "evhtp_make_request error"));
+    return;
+  }
+
+  // evhtp_make_request doesn't know anything about the body, so we send it
+  // outselves here:
+  if (!request_.body.empty()) {
+    if (evbuffer_add_reference(bufferevent_get_output(
+                                   conn_->connection()->bev),
+                               request_.body.data(), request_.body.size(),
+                               nullptr, nullptr) != 0) {
+      VLOG(1) << "error when adding the request body";
+      task_->Return(
+          Status(util::error::INTERNAL, "could not set the request body"));
+      return;
+    }
+  }
+}
+
+
+struct evhtp_request_deleter {
+  void operator()(evhtp_request_t* r) const {
+    evhtp_request_free(r);
+  }
+};
+
+
+void State::RequestDone(evhtp_request_t* req) {
+  CHECK(libevent::Base::OnEventThread());
+  CHECK(conn_);
+  this->pool_->Put(move(conn_));
+  unique_ptr<evhtp_request_t, evhtp_request_deleter> req_deleter(req);
+
+  if (!req) {
+    // TODO(pphaneuf): The dreaded null request... These are fairly
+    // fatal things, like protocol parse errors, but could also be a
+    // connection timeout. I think we should do retries in this case,
+    // with a deadline of our own? At least, then, it would be easier
+    // to distinguish between an obscure error, or a more common
+    // timeout.
+    VLOG(1) << "RequestCallback received a null request";
+    task_->Return(Status::UNKNOWN);
+    return;
+  }
+
+  // Use evhtp_request_status, as req->status is not set correctly. Related to https://github.com/ellzey/libevhtp/issues/78
+  response_->status_code = evhtp_request_status(req);
+  if (response_->status_code < 100) {
+    util::Status status;
+    switch (response_->status_code) {
+      case kTimeout:
+        status =
+            Status(util::error::DEADLINE_EXCEEDED, "connection timed out");
+        break;
+      case kSSLErrorStatus:
+        // There was a problem communicating with the remote host.
+        status = Status(util::error::UNAVAILABLE, "SSL connection failed");
+        break;
+      case kUnknownErrorStatus:
+        status = Status(util::error::UNAVAILABLE, "connection failed");
+        break;
+      default:
+        LOG(WARNING) << "Unknown status code encountered: "
+                     << response_->status_code;
+        status =
+            Status(util::error::UNKNOWN, "unknown status code encountered");
+    }
+    task_->Return(status);
+    return;
+  }
+
+  response_->headers.clear();
+  for (evhtp_kv_s* ptr = req->headers_in->tqh_first; ptr;
+       ptr = ptr->next.tqe_next) {
+    response_->headers.insert(make_pair(ptr->key, ptr->val));
+  }
+
+  const size_t body_length(evbuffer_get_length(req->buffer_in));
+  string body(reinterpret_cast<const char*>(
+                  evbuffer_pullup(req->buffer_in, body_length)),
+              body_length);
+  response_->body.swap(body);
+
+  VLOG(2) << *response_;
+
+  task_->Return();
+}
+
+
+}  // namespace
+
+
+// Needs to be defined where Impl is also defined.
+UrlFetcher::UrlFetcher() {
+}
+
+
+UrlFetcher::UrlFetcher(libevent::Base* base, ThreadPool* thread_pool)
+    : impl_(new Impl(CHECK_NOTNULL(base), CHECK_NOTNULL(thread_pool))) {
+}
+
+
+// Needs to be defined where Impl is also defined.
+UrlFetcher::~UrlFetcher() {
+}
+
+
+void UrlFetcher::Fetch(const Request& req, Response* resp, Task* task) {
+  TaskHold hold(task);
+
+  State* const state(new State(impl_->base_, &impl_->pool_, req, resp, task));
+  task->DeleteWhenDone(state);
+
+  // Run State::MakeRequest() on the task's executor because it may
+  // block doing DNS resolution etc.
+  // TODO(alcutter): this can go back to being put straight on the event Base
+  // once evhtp supports creating SSL connections to a DNS name.
+  impl_->thread_pool_->Add(bind(&State::MakeRequest, state));
+}
+
+
+ostream& operator<<(ostream& output, const UrlFetcher::Response& resp) {
+  output << "status_code: " << resp.status_code << endl << "headers {" << endl;
+  for (const auto& header : resp.headers) {
+    output << "  " << header.first << ": " << header.second << endl;
+  }
+  output << "}" << endl << "body: <<EOF" << endl << resp.body << "EOF" << endl;
+
+  return output;
+}
+
+
+ostream& operator<<(ostream& output, const UrlFetcher::Request& req) {
+  output << "verb: " << req.verb << endl
+         << "url: " << req.url << endl
+         << "headers: " << req.headers << endl
+         << "body: <<EOF" << endl
+         << req.body << "EOF" << endl;
+  return output;
+}
+
+
+ostream& operator<<(ostream& os, const UrlFetcher::Verb& verb) {
+  switch (verb) {
+    case UrlFetcher::Verb::GET:
+      os << "GET";
+      break;
+    case UrlFetcher::Verb::POST:
+      os << "POST";
+      break;
+    case UrlFetcher::Verb::PUT:
+      os << "PUT";
+      break;
+    case UrlFetcher::Verb::DELETE:
+      os << "DELETE";
+      break;
+  }
+  return os;
+}
+
+
+ostream& operator<<(ostream& os, const UrlFetcher::Headers& headers) {
+  os << "{" << endl;
+  for (const auto& h : headers) {
+    os << "  " << h.first << ": " << h.second << endl;
+  }
+  return os << "}";
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/url_fetcher.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/url_fetcher.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/url_fetcher.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/url_fetcher.h	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,87 @@
+#ifndef CERT_TRANS_NET_URL_FETCHER_H_
+#define CERT_TRANS_NET_URL_FETCHER_H_
+
+#include <chrono>
+#include <map>
+#include <memory>
+#include <ostream>
+#include <string>
+
+#include "base/macros.h"
+#include "net/url.h"
+#include "util/compare.h"
+#include "util/task.h"
+
+namespace cert_trans {
+
+namespace libevent {
+class Base;
+}
+
+class ThreadPool;
+
+
+class UrlFetcher {
+ public:
+  typedef std::multimap<std::string, std::string, ci_less<std::string>>
+      Headers;
+
+  enum class Verb {
+    GET,
+    POST,
+    PUT,
+    DELETE,
+  };
+
+  struct Request {
+    Request() : verb(Verb::GET) {
+    }
+    Request(const URL& input_url) : verb(Verb::GET), url(input_url) {
+    }
+
+    Verb verb;
+    URL url;
+    Headers headers;
+    std::string body;
+  };
+
+  struct Response {
+    Response() : status_code(0) {
+    }
+
+    int status_code;
+    Headers headers;
+    std::string body;
+  };
+
+  UrlFetcher(libevent::Base* base, ThreadPool* thread_pool);
+  virtual ~UrlFetcher();
+
+  // If the status on the task is not OK, the response will be in an
+  // undefined state. If it is OK, it only means that the transaction
+  // with the remote server went correctly, you should still check
+  // Response::status_code.
+  virtual void Fetch(const Request& req, Response* resp, util::Task* task);
+
+ protected:
+  UrlFetcher();
+
+ private:
+  struct Impl;
+  const std::unique_ptr<Impl> impl_;
+
+  DISALLOW_COPY_AND_ASSIGN(UrlFetcher);
+};
+
+
+std::ostream& operator<<(std::ostream& output, const UrlFetcher::Request& req);
+std::ostream& operator<<(std::ostream& output,
+                         const UrlFetcher::Response& resp);
+::std::ostream& operator<<(::std::ostream& os,
+                           const UrlFetcher::Headers& headers);
+::std::ostream& operator<<(::std::ostream& os, const UrlFetcher::Verb& verb);
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_NET_URL_FETCHER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/url_fetcher_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/url_fetcher_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/url_fetcher_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/url_fetcher_test.cc	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,387 @@
+#include "config.h"
+
+#include <arpa/inet.h>
+#ifdef HAVE_ARPA_NAMESER_H
+#include <arpa/nameser.h> /* DNS HEADER struct */
+#endif
+#include <fcntl.h>
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <csignal>
+#ifdef HAVE_NETDB_H
+#include <netdb.h>
+#endif
+#include <netdb.h>
+#ifdef HAVE_NETINET_IN_H
+#include <netinet/in.h> /* inet_ functions / structs */
+#endif
+#ifdef HAVE_SYS_TYPES_H
+#include <sys/types.h>
+#endif
+#include <stdlib.h>
+#include <sys/stat.h>
+#include <sys/wait.h>
+#include <unistd.h>
+#ifdef HAVE_VFORK_H
+#include <vfork.h>
+#endif
+
+#include "net/connection_pool.h"
+#include "net/url_fetcher.h"
+#include "util/libevent_wrapper.h"
+#include "util/status_test_util.h"
+#include "util/sync_task.h"
+#include "util/testing.h"
+#include "util/thread_pool.h"
+
+DECLARE_int32(connection_read_timeout_seconds);
+DECLARE_int32(connection_write_timeout_seconds);
+DECLARE_string(trusted_root_certs);
+
+namespace cert_trans {
+
+using std::make_shared;
+using std::shared_ptr;
+using std::string;
+using std::to_string;
+using std::unique_ptr;
+using util::SyncTask;
+using util::testing::StatusIs;
+
+DEFINE_string(cert_dir, "test/testdata/urlfetcher_test_certs",
+              "Directory containing the test certs.");
+
+
+const uint16_t kLocalHostPort = 4433;
+const uint16_t kNonLocalHostPort = 4434;
+const uint16_t kStarExampleComPort = 4435;
+const uint16_t kBinkyExampleComPort = 4436;
+const uint16_t kExampleComPort = 4437;
+const uint16_t k127_0_0_1Port = 4438;
+const uint16_t kHangPort = 4439;
+
+
+namespace {
+
+
+class LocalhostResolver : public libevent::Base::Resolver {
+ public:
+  string Resolve(const std::string& name) override {
+    return "127.0.0.1";
+  }
+};
+
+
+pid_t RunOpenSSLServer(uint16_t port, const std::string& cert_file,
+                       const std::string& key_file,
+                       const std::string& mode = "-www") {
+#ifdef HAVE_WORKING_VFORK
+  pid_t pid(vfork());
+#else
+  pid_t pid(fork());
+#endif
+
+  if (pid == -1) {
+    LOG(INFO) << "fork() failed: " << pid;
+  } else if (pid == 0) {
+    const string port_str(to_string(port));
+    const string cert_str(FLAGS_cert_dir + "/" + cert_file);
+    const string key_str(FLAGS_cert_dir + "/" + key_file);
+    const char* argv[]{"openssl",    "s_server",
+                       "-accept",    port_str.c_str(),
+                       "-cert",      cert_str.c_str(),
+                       "-key",       key_str.c_str(),
+                       mode.c_str(), 0L};
+    execvp(argv[0], const_cast<char**>(argv));
+  }
+  return pid;
+}
+
+
+}  // namespace
+
+
+class UrlFetcherTest : public ::testing::Test {
+ public:
+  UrlFetcherTest()
+      : base_(make_shared<libevent::Base>(
+            unique_ptr<libevent::Base::Resolver>(new LocalhostResolver))),
+        event_pump_(base_),
+        pool_() {
+    FLAGS_trusted_root_certs = FLAGS_cert_dir + "/ca-cert.pem";
+    fetcher_.reset(new UrlFetcher(base_.get(), &pool_));
+  }
+
+ protected:
+  shared_ptr<libevent::Base> base_;
+  shared_ptr<UrlFetcher> fetcher_;
+  libevent::EventPumpThread event_pump_;
+  ThreadPool pool_;
+};
+
+
+TEST_F(UrlFetcherTest, TestCertMatchesHost) {
+  UrlFetcher::Request req(
+      URL("https://localhost:" + to_string(kLocalHostPort)));
+  UrlFetcher::Response resp;
+
+  SyncTask task(&pool_);
+  fetcher_->Fetch(req, &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task.status());
+  EXPECT_EQ(200, resp.status_code);
+}
+
+
+TEST_F(UrlFetcherTest, TestCertDoesNotMatchHost) {
+  UrlFetcher::Request req(
+      URL("https://localhost:" + to_string(kNonLocalHostPort)));
+  UrlFetcher::Response resp;
+
+  SyncTask task(&pool_);
+  fetcher_->Fetch(req, &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::UNAVAILABLE));
+  EXPECT_EQ(kSSLErrorStatus, resp.status_code);
+}
+
+
+TEST_F(UrlFetcherTest, TestNotListening) {
+  UrlFetcher::Request req(URL("https://localhost:63544"));
+  UrlFetcher::Response resp;
+
+  SyncTask task(&pool_);
+  fetcher_->Fetch(req, &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::UNAVAILABLE));
+  EXPECT_EQ(kUnknownErrorStatus, resp.status_code);
+}
+
+
+TEST_F(UrlFetcherTest, TestStarMatchesSubdomain) {
+  UrlFetcher::Request req(
+      URL("https://donkey.example.com:" + to_string(kStarExampleComPort)));
+  UrlFetcher::Response resp;
+
+  SyncTask task(&pool_);
+  fetcher_->Fetch(req, &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task.status());
+  EXPECT_EQ(200, resp.status_code);
+}
+
+
+TEST_F(UrlFetcherTest, TestStarDoesNotMatcheIncorrectParentDomain) {
+  UrlFetcher::Request req(
+      URL("https://donkey.9600.org:" + to_string(kStarExampleComPort)));
+  UrlFetcher::Response resp;
+
+  SyncTask task(&pool_);
+  fetcher_->Fetch(req, &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::UNAVAILABLE));
+  EXPECT_EQ(kSSLErrorStatus, resp.status_code);
+}
+
+
+TEST_F(UrlFetcherTest, TestSubdomainMatches) {
+  UrlFetcher::Request req(
+      URL("https://binky.example.com:" + to_string(kBinkyExampleComPort)));
+  UrlFetcher::Response resp;
+
+  SyncTask task(&pool_);
+  fetcher_->Fetch(req, &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task.status());
+  EXPECT_EQ(200, resp.status_code);
+}
+
+
+TEST_F(UrlFetcherTest, TestSubdomainDoesNotMatchIncorrectParentDomain) {
+  UrlFetcher::Request req(
+      URL("https://binky.9600.org:" + to_string(kBinkyExampleComPort)));
+  UrlFetcher::Response resp;
+
+  SyncTask task(&pool_);
+  fetcher_->Fetch(req, &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::UNAVAILABLE));
+  EXPECT_EQ(kSSLErrorStatus, resp.status_code);
+}
+
+
+TEST_F(UrlFetcherTest, TestSubstringSubjectDoesNotMatch) {
+  UrlFetcher::Request req(
+      URL("https://superexample.com:" + to_string(kExampleComPort)));
+  UrlFetcher::Response resp;
+
+  SyncTask task(&pool_);
+  fetcher_->Fetch(req, &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::UNAVAILABLE));
+  EXPECT_EQ(kSSLErrorStatus, resp.status_code);
+}
+
+
+TEST_F(UrlFetcherTest, TestSuperstringSubjectDoesNotMatch) {
+  UrlFetcher::Request req(
+      URL("https://xample.com:" + to_string(kExampleComPort)));
+  UrlFetcher::Response resp;
+
+  SyncTask task(&pool_);
+  fetcher_->Fetch(req, &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::UNAVAILABLE));
+  EXPECT_EQ(kSSLErrorStatus, resp.status_code);
+}
+
+
+TEST_F(UrlFetcherTest, TestSubstringHostDoesNotMatch) {
+  UrlFetcher::Request req(URL("https://exampl:" + to_string(kExampleComPort)));
+  UrlFetcher::Response resp;
+
+  SyncTask task(&pool_);
+  fetcher_->Fetch(req, &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::UNAVAILABLE));
+  EXPECT_EQ(kSSLErrorStatus, resp.status_code);
+}
+
+
+TEST_F(UrlFetcherTest, TestIpMatches) {
+  UrlFetcher::Request req(
+      URL("https://127.0.0.1:" + to_string(k127_0_0_1Port)));
+  UrlFetcher::Response resp;
+
+  SyncTask task(&pool_);
+  fetcher_->Fetch(req, &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task.status());
+  EXPECT_EQ(200, resp.status_code);
+}
+
+
+TEST_F(UrlFetcherTest, TestWrongIpDoesNotMatch) {
+  UrlFetcher::Request req(URL("https://1.2.3.4:" + to_string(k127_0_0_1Port)));
+  UrlFetcher::Response resp;
+
+  SyncTask task(&pool_);
+  fetcher_->Fetch(req, &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::UNAVAILABLE));
+  EXPECT_EQ(kSSLErrorStatus, resp.status_code);
+}
+
+
+TEST_F(UrlFetcherTest, TestTimeout) {
+  UrlFetcher::Request req(URL("http://localhost:" + to_string(kHangPort)));
+  UrlFetcher::Response resp;
+
+  FLAGS_connection_read_timeout_seconds = 1;
+  FLAGS_connection_write_timeout_seconds = 1;
+
+  SyncTask task(&pool_);
+  fetcher_->Fetch(req, &resp, task.task());
+  task.Wait();
+
+  EXPECT_THAT(task.status(), StatusIs(util::error::DEADLINE_EXCEEDED));
+  EXPECT_EQ(kTimeout, resp.status_code);
+}
+
+
+}  // namespace cert_trans
+
+
+namespace {
+
+
+pid_t localhost_pid(0);
+pid_t nonlocalhost_pid(0);
+pid_t star_example_com_pid(0);
+pid_t binky_example_com_pid(0);
+pid_t example_com_pid(0);
+pid_t ip_address_pid(0);
+
+
+void KillAllOpenSSLServers() {
+  kill(localhost_pid, SIGTERM);
+  kill(nonlocalhost_pid, SIGTERM);
+  kill(star_example_com_pid, SIGTERM);
+  kill(binky_example_com_pid, SIGTERM);
+  kill(example_com_pid, SIGTERM);
+  kill(ip_address_pid, SIGTERM);
+  waitpid(localhost_pid, nullptr, 0);
+  waitpid(nonlocalhost_pid, nullptr, 0);
+  waitpid(star_example_com_pid, nullptr, 0);
+  waitpid(binky_example_com_pid, nullptr, 0);
+  waitpid(example_com_pid, nullptr, 0);
+  waitpid(ip_address_pid, nullptr, 0);
+}
+
+
+}  // namespace
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  OpenSSL_add_all_algorithms();
+  ERR_load_BIO_strings();
+  ERR_load_crypto_strings();
+  SSL_load_error_strings();
+  SSL_library_init();
+
+  signal(SIGPIPE, SIG_IGN);
+
+  int hang_fd(socket(AF_INET, SOCK_STREAM, 0));
+  CHECK_NE(-1, hang_fd);
+  CHECK_NE(-1, fcntl(hang_fd, F_SETFL, O_NONBLOCK));
+  struct sockaddr_in hang_addr;
+  bzero((char*)&hang_addr, sizeof(hang_addr));
+  hang_addr.sin_family = AF_INET;
+// Prefer to use INADDR_LOOPBACK if available as it avoids the firewall
+// triggering on some platforms if we bind a non-local address.
+#ifdef HAVE_INADDR_LOOPBACK
+  hang_addr.sin_addr.s_addr = htonl(INADDR_LOOPBACK);
+#else
+  hang_addr.sin_addr.s_addr = htonl(INADDR_ANY);
+#endif
+  hang_addr.sin_port = htons(cert_trans::kHangPort);
+  CHECK_EQ(0, bind(hang_fd, reinterpret_cast<struct sockaddr*>(&hang_addr),
+                   sizeof(hang_addr)))
+      << strerror(errno);
+  CHECK_EQ(0, listen(hang_fd, 10));
+  struct sockaddr_in other_addr;
+  socklen_t other_size;
+  accept(hang_fd, reinterpret_cast<struct sockaddr*>(&other_addr),
+         &other_size);
+
+  localhost_pid =
+      cert_trans::RunOpenSSLServer(cert_trans::kLocalHostPort,
+                                   "localhost-cert.pem", "localhost-key.pem");
+  nonlocalhost_pid =
+      cert_trans::RunOpenSSLServer(cert_trans::kNonLocalHostPort,
+                                   "not-localhost-cert.pem",
+                                   "not-localhost-key.pem");
+  star_example_com_pid =
+      cert_trans::RunOpenSSLServer(cert_trans::kStarExampleComPort,
+                                   "star_example_com-cert.pem",
+                                   "star_example_com-key.pem");
+  binky_example_com_pid =
+      cert_trans::RunOpenSSLServer(cert_trans::kBinkyExampleComPort,
+                                   "binky_example_com-cert.pem",
+                                   "binky_example_com-key.pem");
+  example_com_pid = cert_trans::RunOpenSSLServer(cert_trans::kExampleComPort,
+                                                 "example_com-cert.pem",
+                                                 "example_com-key.pem");
+  ip_address_pid =
+      cert_trans::RunOpenSSLServer(cert_trans::k127_0_0_1Port,
+                                   "127_0_0_1-cert.pem", "127_0_0_1-key.pem");
+
+  sleep(1);
+
+  const int ret(RUN_ALL_TESTS());
+  KillAllOpenSSLServers();
+  close(hang_fd);
+  return ret;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/url.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/url.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/net/url.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/net/url.h	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,85 @@
+#ifndef CERT_TRANS_NET_URL_H_
+#define CERT_TRANS_NET_URL_H_
+
+#include <stdint.h>
+#include <ostream>
+#include <string>
+
+namespace cert_trans {
+
+
+class URL {
+ public:
+  URL() : port_(0) {
+  }
+
+  explicit URL(const std::string& url);
+
+  const std::string& Protocol() const {
+    return protocol_;
+  }
+
+  const std::string& Host() const {
+    return host_;
+  }
+
+  uint16_t Port() const {
+    return port_;
+  }
+
+  const std::string& Path() const {
+    return path_;
+  }
+
+  const std::string& Query() const {
+    return query_;
+  }
+
+  std::string PathQuery() const;
+
+  void SetProtocol(const std::string& protocol) {
+    protocol_ = protocol;
+  }
+
+  void SetHost(const std::string& host) {
+    host_ = host;
+  }
+
+  void SetPort(uint16_t port) {
+    port_ = port;
+  }
+
+  void SetPath(const std::string& path) {
+    path_ = path;
+  }
+
+  void SetQuery(const std::string& query) {
+    query_ = query;
+  }
+
+  bool operator<(const URL& rhs) const {
+    return protocol_ < rhs.protocol_ && host_ < rhs.host_ &&
+           port_ < rhs.port_ && path_ < rhs.path_ && query_ < rhs.query_;
+  }
+
+  bool operator==(const URL& rhs) const {
+    return protocol_ == rhs.protocol_ && host_ == rhs.host_ &&
+           port_ == rhs.port_ && path_ == rhs.path_ && query_ == rhs.query_;
+  }
+
+ private:
+  std::string protocol_;
+  std::string host_;
+  uint16_t port_;
+  std::string path_;
+  std::string query_;
+};
+
+
+// For testing and debugging.
+std::ostream& operator<<(std::ostream& out, const URL& url);
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_NET_URL_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/cert_serializer.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/cert_serializer.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/cert_serializer.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/cert_serializer.cc	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,668 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "proto/cert_serializer.h"
+
+#include <glog/logging.h>
+#include <math.h>
+#include <string>
+
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+
+using cert_trans::serialization::SerializeResult;
+using cert_trans::serialization::DeserializeResult;
+using cert_trans::serialization::WriteFixedBytes;
+using cert_trans::serialization::WriteList;
+using cert_trans::serialization::WriteUint;
+using cert_trans::serialization::WriteVarBytes;
+using ct::DigitallySigned;
+using ct::LogEntry;
+using ct::LogEntryType_IsValid;
+using ct::MerkleTreeLeaf;
+using ct::PrecertChainEntry;
+using ct::SignedCertificateTimestamp;
+using ct::SignedCertificateTimestampList;
+using ct::SthExtension;
+using ct::SctExtension;
+using ct::X509ChainEntry;
+using google::protobuf::RepeatedPtrField;
+using std::string;
+
+
+const size_t kMaxCertificateLength = (1 << 24) - 1;
+const size_t kMaxCertificateChainLength = (1 << 24) - 1;
+
+
+SerializeResult CheckCertificateFormat(const string& cert) {
+  if (cert.empty()) {
+    return SerializeResult::EMPTY_CERTIFICATE;
+  }
+  if (cert.size() > kMaxCertificateLength) {
+    return SerializeResult::CERTIFICATE_TOO_LONG;
+  }
+  return SerializeResult::OK;
+}
+
+
+string CertV1LeafData(const LogEntry& entry) {
+  switch (entry.type()) {
+    // TODO(mhs): Because there is no X509_ENTRY_V2 we have to assume that
+    // whichever of the cert fields is set defines the entry type. In other
+    // words this is V2 if it has a CertInfo. Might be possible
+    // to pass the type when the code that calls this is updated for V2.
+    case ct::X509_ENTRY:
+      CHECK(!entry.x509_entry().has_cert_info())
+          << "Attempting to use a V1 serializer with a V2 LogEntry.";
+      CHECK(entry.x509_entry().has_leaf_certificate())
+          << "Missing leaf certificate";
+      return entry.x509_entry().leaf_certificate();
+    case ct::PRECERT_ENTRY:
+      CHECK(!entry.x509_entry().has_cert_info())
+          << "Attempting to use a V1 serializer with a V2 LogEntry.";
+      CHECK(entry.precert_entry().pre_cert().has_tbs_certificate())
+          << "Missing tbs certificate.";
+      return entry.precert_entry().pre_cert().tbs_certificate();
+    default:
+      break;
+  }
+  LOG(FATAL) << "Invalid entry type " << entry.type();
+}
+
+
+SerializeResult SerializeV1CertSCTSignatureInput(uint64_t timestamp,
+                                                 const string& certificate,
+                                                 const string& extensions,
+                                                 string* result) {
+  SerializeResult res = CheckCertificateFormat(certificate);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  res = CheckExtensionsFormat(extensions);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  WriteUint(ct::V1, Serializer::kVersionLengthInBytes, result);
+  WriteUint(ct::CERTIFICATE_TIMESTAMP, Serializer::kSignatureTypeLengthInBytes,
+            result);
+  WriteUint(timestamp, Serializer::kTimestampLengthInBytes, result);
+  WriteUint(ct::X509_ENTRY, Serializer::kLogEntryTypeLengthInBytes, result);
+  WriteVarBytes(certificate, kMaxCertificateLength, result);
+  WriteVarBytes(extensions, Serializer::kMaxExtensionsLength, result);
+  return SerializeResult::OK;
+}
+
+
+SerializeResult SerializeV1PrecertSCTSignatureInput(
+    uint64_t timestamp, const string& issuer_key_hash,
+    const string& tbs_certificate, const string& extensions, string* result) {
+  SerializeResult res = CheckCertificateFormat(tbs_certificate);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  res = CheckKeyHashFormat(issuer_key_hash);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  res = CheckExtensionsFormat(extensions);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  result->clear();
+  WriteUint(ct::V1, Serializer::kVersionLengthInBytes, result);
+  WriteUint(ct::CERTIFICATE_TIMESTAMP, Serializer::kSignatureTypeLengthInBytes,
+            result);
+  WriteUint(timestamp, Serializer::kTimestampLengthInBytes, result);
+  WriteUint(ct::PRECERT_ENTRY, Serializer::kLogEntryTypeLengthInBytes, result);
+  WriteFixedBytes(issuer_key_hash, result);
+  WriteVarBytes(tbs_certificate, kMaxCertificateLength, result);
+  WriteVarBytes(extensions, Serializer::kMaxExtensionsLength, result);
+  return SerializeResult::OK;
+}
+
+
+SerializeResult SerializeV1SCTSignatureInput(
+    const SignedCertificateTimestamp& sct, const LogEntry& entry,
+    string* result) {
+  if (sct.version() != ct::V1) {
+    return SerializeResult::UNSUPPORTED_VERSION;
+  }
+  result->clear();
+  switch (entry.type()) {
+    case ct::X509_ENTRY:
+      return SerializeV1CertSCTSignatureInput(
+          sct.timestamp(), entry.x509_entry().leaf_certificate(),
+          sct.extensions(), result);
+    case ct::PRECERT_ENTRY:
+      return SerializeV1PrecertSCTSignatureInput(
+          sct.timestamp(), entry.precert_entry().pre_cert().issuer_key_hash(),
+          entry.precert_entry().pre_cert().tbs_certificate(), sct.extensions(),
+          result);
+    default:
+      return SerializeResult::INVALID_ENTRY_TYPE;
+  }
+}
+
+
+SerializeResult SerializeV1CertSCTMerkleTreeLeaf(uint64_t timestamp,
+                                                 const string& certificate,
+                                                 const string& extensions,
+                                                 string* result) {
+  SerializeResult res = CheckCertificateFormat(certificate);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  res = CheckExtensionsFormat(extensions);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  result->clear();
+  WriteUint(ct::V1, Serializer::kVersionLengthInBytes, result);
+  WriteUint(ct::TIMESTAMPED_ENTRY, Serializer::kMerkleLeafTypeLengthInBytes,
+            result);
+  WriteUint(timestamp, Serializer::kTimestampLengthInBytes, result);
+  WriteUint(ct::X509_ENTRY, Serializer::kLogEntryTypeLengthInBytes, result);
+  WriteVarBytes(certificate, kMaxCertificateLength, result);
+  WriteVarBytes(extensions, Serializer::kMaxExtensionsLength, result);
+  return SerializeResult::OK;
+}
+
+
+SerializeResult SerializeV1PrecertSCTMerkleTreeLeaf(
+    uint64_t timestamp, const string& issuer_key_hash,
+    const string& tbs_certificate, const string& extensions, string* result) {
+  SerializeResult res = CheckCertificateFormat(tbs_certificate);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  res = CheckKeyHashFormat(issuer_key_hash);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  res = CheckExtensionsFormat(extensions);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  result->clear();
+  WriteUint(ct::V1, Serializer::kVersionLengthInBytes, result);
+  WriteUint(ct::TIMESTAMPED_ENTRY, Serializer::kMerkleLeafTypeLengthInBytes,
+            result);
+  WriteUint(timestamp, Serializer::kTimestampLengthInBytes, result);
+  WriteUint(ct::PRECERT_ENTRY, Serializer::kLogEntryTypeLengthInBytes, result);
+  WriteFixedBytes(issuer_key_hash, result);
+  WriteVarBytes(tbs_certificate, kMaxCertificateLength, result);
+  WriteVarBytes(extensions, Serializer::kMaxExtensionsLength, result);
+  return SerializeResult::OK;
+}
+
+
+SerializeResult SerializeV1SCTMerkleTreeLeaf(
+    const ct::SignedCertificateTimestamp& sct, const ct::LogEntry& entry,
+    string* result) {
+  if (sct.version() != ct::V1) {
+    return SerializeResult::UNSUPPORTED_VERSION;
+  }
+  result->clear();
+  switch (entry.type()) {
+    case ct::X509_ENTRY:
+      return SerializeV1CertSCTMerkleTreeLeaf(
+          sct.timestamp(), entry.x509_entry().leaf_certificate(),
+          sct.extensions(), result);
+    case ct::PRECERT_ENTRY:
+      return SerializeV1PrecertSCTMerkleTreeLeaf(
+          sct.timestamp(), entry.precert_entry().pre_cert().issuer_key_hash(),
+          entry.precert_entry().pre_cert().tbs_certificate(), sct.extensions(),
+          result);
+    default:
+      break;
+  }
+  return SerializeResult::INVALID_ENTRY_TYPE;
+}
+
+
+DeserializeResult DeserializeV1SCTMerkleTreeLeaf(TLSDeserializer* des,
+                                                 MerkleTreeLeaf* leaf) {
+  CHECK_NOTNULL(des);
+  CHECK_NOTNULL(leaf);
+
+  unsigned int version;
+  if (!des->ReadUint(Serializer::kVersionLengthInBytes, &version)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+
+  if (version != ct::V1) {
+    return DeserializeResult::UNSUPPORTED_VERSION;
+  }
+  leaf->set_version(ct::V1);
+
+  unsigned int type;
+  if (!des->ReadUint(Serializer::kMerkleLeafTypeLengthInBytes, &type)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+  if (type != ct::TIMESTAMPED_ENTRY) {
+    return DeserializeResult::UNKNOWN_LEAF_TYPE;
+  }
+  leaf->set_type(ct::TIMESTAMPED_ENTRY);
+
+  ct::TimestampedEntry* const entry = leaf->mutable_timestamped_entry();
+
+  uint64_t timestamp;
+  if (!des->ReadUint(Serializer::kTimestampLengthInBytes, &timestamp)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+  entry->set_timestamp(timestamp);
+
+  unsigned int entry_type;
+  if (!des->ReadUint(Serializer::kLogEntryTypeLengthInBytes, &entry_type)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+
+  CHECK(LogEntryType_IsValid(entry_type));
+  entry->set_entry_type(static_cast<ct::LogEntryType>(entry_type));
+
+  switch (entry_type) {
+    case ct::X509_ENTRY: {
+      string x509;
+      if (!des->ReadVarBytes(kMaxCertificateLength, &x509)) {
+        return DeserializeResult::INPUT_TOO_SHORT;
+      }
+      entry->mutable_signed_entry()->set_x509(x509);
+      return ReadExtensionsV1(des, entry);
+    }
+
+    case ct::PRECERT_ENTRY: {
+      string issuer_key_hash;
+      if (!des->ReadFixedBytes(32, &issuer_key_hash)) {
+        return DeserializeResult::INPUT_TOO_SHORT;
+      }
+      entry->mutable_signed_entry()->mutable_precert()->set_issuer_key_hash(
+          issuer_key_hash);
+      string tbs_certificate;
+      if (!des->ReadVarBytes(kMaxCertificateLength, &tbs_certificate)) {
+        return DeserializeResult::INPUT_TOO_SHORT;
+      }
+      entry->mutable_signed_entry()->mutable_precert()->set_tbs_certificate(
+          tbs_certificate);
+      return ReadExtensionsV1(des, entry);
+    }
+  }
+
+  LOG(FATAL) << "entry_type: " << entry_type;
+  return DeserializeResult::UNKNOWN_LOGENTRY_TYPE;
+}
+
+
+// ----------------- V2 cert stuff ------------------------
+
+string CertV2LeafData(const LogEntry& entry) {
+  switch (entry.type()) {
+    // TODO(mhs): Because there is no X509_ENTRY_V2 we have to assume that
+    // whichever of the cert fields is set defines the entry type. In other
+    // words this is V2 if it has a CertInfo. Might be possible
+    // to pass the type when the code that calls this is updated for V2.
+    case ct::X509_ENTRY:
+      CHECK(!entry.x509_entry().has_leaf_certificate());
+      CHECK(entry.x509_entry().has_cert_info());
+      CHECK(entry.x509_entry().cert_info().has_tbs_certificate())
+          << "Missing V2 leaf certificate";
+      return entry.x509_entry().cert_info().tbs_certificate();
+    case ct::PRECERT_ENTRY_V2:
+      // Must not have both v1 and v2 entries set
+      CHECK(!entry.precert_entry().has_pre_cert());
+      CHECK(entry.precert_entry().cert_info().has_tbs_certificate())
+          << "Missing tbs certificate (V2)";
+      return entry.precert_entry().cert_info().tbs_certificate();
+    default:
+      break;
+  }
+  LOG(FATAL) << "Invalid entry type " << entry.type();
+}
+
+
+// static
+SerializeResult SerializeV2CertSCTSignatureInput(
+    uint64_t timestamp, const string& issuer_key_hash,
+    const string& tbs_certificate,
+    const RepeatedPtrField<ct::SctExtension>& sct_extension, string* result) {
+  SerializeResult res = CheckCertificateFormat(tbs_certificate);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  res = CheckSctExtensionsFormat(sct_extension);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  result->clear();
+  WriteUint(ct::V2, Serializer::kVersionLengthInBytes, result);
+  WriteUint(ct::CERTIFICATE_TIMESTAMP, Serializer::kSignatureTypeLengthInBytes,
+            result);
+  WriteUint(timestamp, Serializer::kTimestampLengthInBytes, result);
+  WriteUint(ct::X509_ENTRY, Serializer::kLogEntryTypeLengthInBytes, result);
+  WriteFixedBytes(issuer_key_hash, result);
+  WriteVarBytes(tbs_certificate, kMaxCertificateLength, result);
+  WriteSctExtension(sct_extension, result);
+  return SerializeResult::OK;
+}
+
+
+// static
+SerializeResult SerializeV2PrecertSCTSignatureInput(
+    uint64_t timestamp, const string& issuer_key_hash,
+    const string& tbs_certificate,
+    const RepeatedPtrField<ct::SctExtension>& sct_extension, string* result) {
+  SerializeResult res = CheckCertificateFormat(tbs_certificate);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  res = CheckSctExtensionsFormat(sct_extension);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  result->clear();
+  WriteUint(ct::V2, Serializer::kVersionLengthInBytes, result);
+  WriteUint(ct::CERTIFICATE_TIMESTAMP, Serializer::kSignatureTypeLengthInBytes,
+            result);
+  WriteUint(timestamp, Serializer::kTimestampLengthInBytes, result);
+  WriteUint(ct::PRECERT_ENTRY_V2, Serializer::kLogEntryTypeLengthInBytes,
+            result);
+  WriteFixedBytes(issuer_key_hash, result);
+  WriteVarBytes(tbs_certificate, kMaxCertificateLength, result);
+  WriteSctExtension(sct_extension, result);
+  return SerializeResult::OK;
+}
+
+// static
+SerializeResult SerializeV2SCTSignatureInput(
+    const SignedCertificateTimestamp& sct, const LogEntry& entry,
+    string* result) {
+  if (sct.version() != ct::V2) {
+    return SerializeResult::UNSUPPORTED_VERSION;
+  }
+  result->clear();
+  switch (entry.type()) {
+    case ct::X509_ENTRY:
+      return SerializeV2CertSCTSignatureInput(
+          sct.timestamp(), entry.x509_entry().cert_info().issuer_key_hash(),
+          entry.x509_entry().cert_info().tbs_certificate(),
+          sct.sct_extension(), result);
+    case ct::PRECERT_ENTRY_V2:
+      return SerializeV2PrecertSCTSignatureInput(
+          sct.timestamp(), entry.precert_entry().cert_info().issuer_key_hash(),
+          entry.precert_entry().cert_info().tbs_certificate(),
+          sct.sct_extension(), result);
+    default:
+      break;
+  }
+  return SerializeResult::INVALID_ENTRY_TYPE;
+}
+
+
+SerializeResult SerializeV2CertSCTMerkleTreeLeaf(
+    uint64_t timestamp, const string& issuer_key_hash,
+    const string& tbs_certificate,
+    const RepeatedPtrField<SctExtension>& sct_extension, string* result) {
+  SerializeResult res = CheckCertificateFormat(tbs_certificate);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  res = CheckSctExtensionsFormat(sct_extension);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  result->clear();
+  WriteUint(ct::V2, Serializer::kVersionLengthInBytes, result);
+  WriteUint(ct::TIMESTAMPED_ENTRY, Serializer::kMerkleLeafTypeLengthInBytes,
+            result);
+  WriteUint(timestamp, Serializer::kTimestampLengthInBytes, result);
+  WriteUint(ct::X509_ENTRY, Serializer::kLogEntryTypeLengthInBytes, result);
+  WriteFixedBytes(issuer_key_hash, result);
+  WriteVarBytes(tbs_certificate, kMaxCertificateLength, result);
+  WriteSctExtension(sct_extension, result);
+  return SerializeResult::OK;
+}
+
+
+SerializeResult SerializeV2PrecertSCTMerkleTreeLeaf(
+    uint64_t timestamp, const string& issuer_key_hash,
+    const string& tbs_certificate,
+    const google::protobuf::RepeatedPtrField<ct::SctExtension>& sct_extension,
+    string* result) {
+  SerializeResult res = CheckCertificateFormat(tbs_certificate);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  res = CheckKeyHashFormat(issuer_key_hash);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  res = CheckSctExtensionsFormat(sct_extension);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  result->clear();
+  WriteUint(ct::V2, Serializer::kVersionLengthInBytes, result);
+  WriteUint(ct::TIMESTAMPED_ENTRY, Serializer::kMerkleLeafTypeLengthInBytes,
+            result);
+  WriteUint(timestamp, Serializer::kTimestampLengthInBytes, result);
+  WriteUint(ct::PRECERT_ENTRY_V2, Serializer::kLogEntryTypeLengthInBytes,
+            result);
+  WriteFixedBytes(issuer_key_hash, result);
+  WriteVarBytes(tbs_certificate, kMaxCertificateLength, result);
+  WriteSctExtension(sct_extension, result);
+  return SerializeResult::OK;
+}
+
+
+SerializeResult SerializeV2SCTMerkleTreeLeaf(
+    const ct::SignedCertificateTimestamp& sct, const ct::LogEntry& entry,
+    string* result) {
+  CHECK_EQ(ct::V2, sct.version());
+  result->clear();
+  switch (entry.type()) {
+    case ct::X509_ENTRY:
+      return SerializeV2CertSCTMerkleTreeLeaf(
+          sct.timestamp(), entry.x509_entry().cert_info().issuer_key_hash(),
+          entry.x509_entry().cert_info().tbs_certificate(),
+          sct.sct_extension(), result);
+    case ct::PRECERT_ENTRY_V2:
+      return SerializeV2PrecertSCTMerkleTreeLeaf(
+          sct.timestamp(), entry.precert_entry().cert_info().issuer_key_hash(),
+          entry.precert_entry().cert_info().tbs_certificate(),
+          sct.sct_extension(), result);
+    default:
+      break;
+  }
+  return SerializeResult::INVALID_ENTRY_TYPE;
+}
+
+
+DeserializeResult DeserializeV2SCTMerkleTreeLeaf(TLSDeserializer* des,
+                                                 MerkleTreeLeaf* leaf) {
+  CHECK_NOTNULL(des);
+  CHECK_NOTNULL(leaf);
+
+  unsigned int version;
+  if (!des->ReadUint(Serializer::kVersionLengthInBytes, &version)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+
+  if (version != ct::V2) {
+    return DeserializeResult::UNSUPPORTED_VERSION;
+  }
+  leaf->set_version(ct::V2);
+
+  unsigned int type;
+  if (!des->ReadUint(Serializer::kMerkleLeafTypeLengthInBytes, &type)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+  if (type != ct::TIMESTAMPED_ENTRY) {
+    return DeserializeResult::UNKNOWN_LEAF_TYPE;
+  }
+  leaf->set_type(ct::TIMESTAMPED_ENTRY);
+
+  ct::TimestampedEntry* const entry = leaf->mutable_timestamped_entry();
+
+  uint64_t timestamp;
+  if (!des->ReadUint(Serializer::kTimestampLengthInBytes, &timestamp)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+  entry->set_timestamp(timestamp);
+
+  unsigned int entry_type;
+  if (!des->ReadUint(Serializer::kLogEntryTypeLengthInBytes, &entry_type)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+
+  CHECK(LogEntryType_IsValid(entry_type));
+  entry->set_entry_type(static_cast<ct::LogEntryType>(entry_type));
+
+  switch (entry_type) {
+    // In V2 both X509 and Precert entries use CertInfo
+    case ct::X509_ENTRY:
+    case ct::PRECERT_ENTRY_V2: {
+      string issuer_key_hash;
+      if (!des->ReadFixedBytes(32, &issuer_key_hash)) {
+        return DeserializeResult::INPUT_TOO_SHORT;
+      }
+      entry->mutable_signed_entry()->mutable_cert_info()->set_issuer_key_hash(
+          issuer_key_hash);
+      string tbs_certificate;
+      if (!des->ReadVarBytes(kMaxCertificateLength, &tbs_certificate)) {
+        return DeserializeResult::INPUT_TOO_SHORT;
+      }
+      entry->mutable_signed_entry()->mutable_cert_info()->set_tbs_certificate(
+          tbs_certificate);
+      // TODO(eranm): This is wrong, V2 Extensions should be read using
+      // ReadSctExtensions
+      return ReadExtensionsV1(des, entry);
+    }
+
+    case ct::UNKNOWN_ENTRY_TYPE: {
+      // handled below.
+      break;
+    }
+  }
+  LOG(FATAL) << "entry_type: " << entry_type;
+  return DeserializeResult::UNKNOWN_LOGENTRY_TYPE;
+}
+
+
+void ConfigureSerializerForV1CT() {
+  Serializer::ConfigureV1(CertV1LeafData, SerializeV1SCTSignatureInput,
+                          SerializeV1SCTMerkleTreeLeaf);
+  Deserializer::Configure(DeserializeV1SCTMerkleTreeLeaf);
+}
+
+
+void ConfigureSerializerForV2CT() {
+  Serializer::ConfigureV2(CertV2LeafData, SerializeV2SCTSignatureInput,
+                          SerializeV2SCTMerkleTreeLeaf);
+  Deserializer::Configure(DeserializeV2SCTMerkleTreeLeaf);
+}
+
+
+SerializeResult SerializeX509Chain(const ct::X509ChainEntry& entry,
+                                   std::string* result) {
+  return SerializeX509ChainV1(entry.certificate_chain(), result);
+}
+
+
+SerializeResult SerializeX509ChainV1(const repeated_string& certificate_chain,
+                                     std::string* result) {
+  return Serializer::SerializeList(certificate_chain, kMaxCertificateLength,
+                                   kMaxCertificateChainLength, result);
+}
+
+
+SerializeResult SerializePrecertChainEntry(const ct::PrecertChainEntry& entry,
+                                           std::string* result) {
+  return SerializePrecertChainEntry(entry.pre_certificate(),
+                                    entry.precertificate_chain(), result);
+}
+
+
+SerializeResult SerializePrecertChainEntry(
+    const std::string& pre_certificate,
+    const repeated_string& precertificate_chain, std::string* result) {
+  if (pre_certificate.size() > kMaxCertificateLength) {
+    return SerializeResult::CERTIFICATE_TOO_LONG;
+  }
+  if (pre_certificate.empty()) {
+    return SerializeResult::EMPTY_CERTIFICATE;
+  }
+
+  result->clear();
+  WriteVarBytes(pre_certificate, kMaxCertificateLength, result);
+
+  SerializeResult res = WriteList(precertificate_chain, kMaxCertificateLength,
+                                  kMaxCertificateChainLength, result);
+  if (res != SerializeResult::OK) {
+    result->clear();
+    return res;
+  }
+  return SerializeResult::OK;
+}
+
+
+SerializeResult SerializeV1SignedCertEntryWithType(
+    const std::string& leaf_certificate, std::string* result) {
+  SerializeResult res = CheckCertificateFormat(leaf_certificate);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  result->clear();
+  WriteUint(ct::X509_ENTRY, Serializer::kLogEntryTypeLengthInBytes, result);
+  WriteVarBytes(leaf_certificate, kMaxCertificateLength, result);
+  return SerializeResult::OK;
+}
+
+
+SerializeResult SerializeV1SignedPrecertEntryWithType(
+    const std::string& issuer_key_hash, const std::string& tbs_certificate,
+    std::string* result) {
+  SerializeResult res = CheckCertificateFormat(tbs_certificate);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  res = CheckKeyHashFormat(issuer_key_hash);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  result->clear();
+  WriteUint(ct::PRECERT_ENTRY, Serializer::kLogEntryTypeLengthInBytes, result);
+  WriteFixedBytes(issuer_key_hash, result);
+  WriteVarBytes(tbs_certificate, kMaxCertificateLength, result);
+  return SerializeResult::OK;
+}
+
+
+// static
+DeserializeResult DeserializeX509Chain(const std::string& in,
+                                       X509ChainEntry* x509_chain_entry) {
+  // Empty list is ok.
+  x509_chain_entry->clear_certificate_chain();
+  return Deserializer::DeserializeList(
+      in, kMaxCertificateChainLength, kMaxCertificateLength,
+      x509_chain_entry->mutable_certificate_chain());
+}
+
+
+// static
+DeserializeResult DeserializePrecertChainEntry(
+    const std::string& in, ct::PrecertChainEntry* precert_chain_entry) {
+  TLSDeserializer deserializer(in);
+  if (!deserializer.ReadVarBytes(
+          kMaxCertificateLength,
+          precert_chain_entry->mutable_pre_certificate())) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+  precert_chain_entry->clear_precertificate_chain();
+  DeserializeResult res = deserializer.ReadList(
+      kMaxCertificateChainLength, kMaxCertificateLength,
+      precert_chain_entry->mutable_precertificate_chain());
+  if (res != DeserializeResult::OK) {
+    return res;
+  }
+  if (!deserializer.ReachedEnd()) {
+    return DeserializeResult::INPUT_TOO_LONG;
+  }
+  return DeserializeResult::OK;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/cert_serializer.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/cert_serializer.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/cert_serializer.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/cert_serializer.h	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,92 @@
+/* -*- mode: c++; indent-tabs-mode: nil -*- */
+#ifndef CERT_TRANS_PROTO_CERT_SERIALIZER_H_
+#define CERT_TRANS_PROTO_CERT_SERIALIZER_H_
+
+#include <glog/logging.h>
+#include <google/protobuf/repeated_field.h>
+#include <stdint.h>
+#include <string>
+
+#include "base/macros.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+
+
+void ConfigureSerializerForV1CT();
+void ConfigureSerializerForV2CT();
+
+// NB This serializes the certificate_chain component of the X509 chain only.
+// Needed for the GetEntries flow.
+cert_trans::serialization::SerializeResult SerializeX509Chain(
+    const ct::X509ChainEntry& entry, std::string* result);
+
+cert_trans::serialization::SerializeResult SerializeX509ChainV1(
+    const repeated_string& certificate_chain, std::string* result);
+
+cert_trans::serialization::SerializeResult SerializePrecertChainEntry(
+    const ct::PrecertChainEntry& entry, std::string* result);
+
+cert_trans::serialization::SerializeResult SerializePrecertChainEntry(
+    const std::string& pre_certificate,
+    const repeated_string& precertificate_chain, std::string* result);
+
+// These two functions are depended on externally.
+cert_trans::serialization::SerializeResult SerializeV1SignedCertEntryWithType(
+    const std::string& leaf_certificate, std::string* result);
+
+cert_trans::serialization::SerializeResult
+SerializeV1SignedPrecertEntryWithType(const std::string& issuer_key_hash,
+                                      const std::string& tbs_certificate,
+                                      std::string* result);
+
+cert_trans::serialization::DeserializeResult DeserializeX509Chain(
+    const std::string& in, ct::X509ChainEntry* x509_chain_entry);
+
+cert_trans::serialization::DeserializeResult DeserializePrecertChainEntry(
+    const std::string& in, ct::PrecertChainEntry* precert_chain_entry);
+
+// Test helpers
+//
+cert_trans::serialization::SerializeResult SerializeV1CertSCTMerkleTreeLeaf(
+    uint64_t timestamp, const std::string& certificate,
+    const std::string& extensions, std::string* result);
+
+cert_trans::serialization::SerializeResult SerializeV1PrecertSCTMerkleTreeLeaf(
+    uint64_t timestamp, const std::string& issuer_key_hash,
+    const std::string& tbs_certificate, const std::string& extensions,
+    std::string* result);
+
+cert_trans::serialization::SerializeResult SerializeV2CertSCTMerkleTreeLeaf(
+    uint64_t timestamp, const std::string& issuer_key_hash,
+    const std::string& tbs_certificate,
+    const google::protobuf::RepeatedPtrField<ct::SctExtension>& sct_extension,
+    std::string* result);
+
+cert_trans::serialization::SerializeResult SerializeV2PrecertSCTMerkleTreeLeaf(
+    uint64_t timestamp, const std::string& issuer_key_hash,
+    const std::string& tbs_certificate,
+    const google::protobuf::RepeatedPtrField<ct::SctExtension>& sct_extension,
+    std::string* result);
+
+cert_trans::serialization::SerializeResult SerializeV2CertSCTSignatureInput(
+    uint64_t timestamp, const std::string& issuer_key_hash,
+    const std::string& tbs_certificate,
+    const google::protobuf::RepeatedPtrField<ct::SctExtension>& sct_extension,
+    std::string* result);
+
+cert_trans::serialization::SerializeResult SerializeV1CertSCTSignatureInput(
+    uint64_t timestamp, const std::string& certificate,
+    const std::string& extensions, std::string* result);
+
+cert_trans::serialization::SerializeResult SerializeV1PrecertSCTSignatureInput(
+    uint64_t timestamp, const std::string& issuer_key_hash,
+    const std::string& tbs_certificate, const std::string& extensions,
+    std::string* result);
+
+cert_trans::serialization::SerializeResult SerializeV2PrecertSCTSignatureInput(
+    uint64_t timestamp, const std::string& issuer_key_hash,
+    const std::string& tbs_certificate,
+    const google::protobuf::RepeatedPtrField<ct::SctExtension>& sct_extension,
+    std::string* result);
+
+#endif  // CERT_TRANS_PROTO_CERT_SERIALIZER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/serializer.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/serializer.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/serializer.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/serializer.cc	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,654 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "proto/serializer.h"
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <math.h>
+#include <string>
+
+#include "proto/ct.pb.h"
+
+using cert_trans::serialization::internal::PrefixLength;
+using cert_trans::serialization::SerializeResult;
+using cert_trans::serialization::DeserializeResult;
+using cert_trans::serialization::WriteDigitallySigned;
+using cert_trans::serialization::WriteFixedBytes;
+using cert_trans::serialization::WriteUint;
+using cert_trans::serialization::WriteVarBytes;
+using cert_trans::serialization::constants::kMaxSignatureLength;
+using cert_trans::serialization::constants::kHashAlgorithmLengthInBytes;
+using cert_trans::serialization::constants::kSigAlgorithmLengthInBytes;
+using ct::DigitallySigned;
+using ct::DigitallySigned_HashAlgorithm_IsValid;
+using ct::DigitallySigned_SignatureAlgorithm_IsValid;
+using ct::LogEntry;
+using ct::MerkleTreeLeaf;
+using ct::PrecertChainEntry;
+using ct::SignedCertificateTimestamp;
+using ct::SignedCertificateTimestampList;
+using ct::SthExtension;
+using ct::SctExtension;
+using ct::Version_IsValid;
+using ct::X509ChainEntry;
+using google::protobuf::RepeatedPtrField;
+using std::function;
+using std::string;
+
+const size_t Serializer::kMaxV2ExtensionType = (1 << 16) - 1;
+const size_t Serializer::kMaxV2ExtensionsCount = (1 << 16) - 2;
+const size_t Serializer::kMaxExtensionsLength = (1 << 16) - 1;
+const size_t Serializer::kMaxSerializedSCTLength = (1 << 16) - 1;
+const size_t Serializer::kMaxSCTListLength = (1 << 16) - 1;
+
+const size_t Serializer::kLogEntryTypeLengthInBytes = 2;
+const size_t Serializer::kSignatureTypeLengthInBytes = 1;
+const size_t Serializer::kVersionLengthInBytes = 1;
+const size_t Serializer::kKeyIDLengthInBytes = 32;
+const size_t Serializer::kMerkleLeafTypeLengthInBytes = 1;
+const size_t Serializer::kKeyHashLengthInBytes = 32;
+const size_t Serializer::kTimestampLengthInBytes = 8;
+
+DEFINE_bool(allow_reconfigure_serializer_test_only, false,
+            "Allow tests to reconfigure the serializer multiple times.");
+
+// TODO(pphaneuf): This is just to avoid causing diff churn while
+// refactoring. Functions for internal use only should be put together
+// in an anonymous namespace.
+SerializeResult CheckSthExtensionsFormat(
+    const repeated_sth_extension& extension);
+
+
+namespace {
+
+
+function<string(const ct::LogEntry&)> leaf_data;
+
+function<SerializeResult(const ct::SignedCertificateTimestamp& sct,
+                         const ct::LogEntry& entry, std::string* result)>
+    serialize_sct_sig_input;
+
+function<SerializeResult(const ct::SignedCertificateTimestamp& sct,
+                         const ct::LogEntry& entry, std::string* result)>
+    serialize_sct_merkle_leaf;
+
+function<SerializeResult(uint64_t timestamp, int64_t tree_size,
+                         const std::string& root_hash, std::string* result)>
+    serialize_sth_sig_input_v1;
+
+function<SerializeResult(uint64_t timestamp, int64_t tree_size,
+                         const std::string& root_hash,
+                         const repeated_sth_extension& sth_extension,
+                         const std::string& log_id, std::string* result)>
+    serialize_sth_sig_input_v2;
+
+function<DeserializeResult(TLSDeserializer* d, ct::MerkleTreeLeaf* leaf)>
+    read_merkle_tree_leaf;
+
+
+}  // namespace
+
+
+// static
+string Serializer::LeafData(const LogEntry& entry) {
+  CHECK(leaf_data);
+  return leaf_data(entry);
+}
+
+
+// static
+SerializeResult Serializer::SerializeV1STHSignatureInput(
+    uint64_t timestamp, int64_t tree_size, const string& root_hash,
+    string* result) {
+  CHECK(result);
+  // result will be cleared by SerializeV1STHSignatureInput
+  CHECK(serialize_sth_sig_input_v1);
+  return serialize_sth_sig_input_v1(timestamp, tree_size, root_hash, result);
+}
+
+
+static SerializeResult SerializeV1STHSignatureInput(uint64_t timestamp,
+                                                    int64_t tree_size,
+                                                    const string& root_hash,
+                                                    string* result) {
+  CHECK_GE(tree_size, 0);
+  result->clear();
+  if (root_hash.size() != 32)
+    return SerializeResult::INVALID_HASH_LENGTH;
+  WriteUint(ct::V1, Serializer::kVersionLengthInBytes, result);
+  WriteUint(ct::TREE_HEAD, Serializer::kSignatureTypeLengthInBytes, result);
+  WriteUint(timestamp, Serializer::kTimestampLengthInBytes, result);
+  WriteUint(tree_size, 8, result);
+  WriteFixedBytes(root_hash, result);
+  return SerializeResult::OK;
+}
+
+
+// static
+SerializeResult Serializer::SerializeV2STHSignatureInput(
+    uint64_t timestamp, int64_t tree_size, const string& root_hash,
+    const repeated_sth_extension& sth_extension, const string& log_id,
+    string* result) {
+  CHECK(result);
+  CHECK(serialize_sth_sig_input_v2);
+  return serialize_sth_sig_input_v2(timestamp, tree_size, root_hash,
+                                     sth_extension, log_id, result);
+}
+
+
+static SerializeResult SerializeV2STHSignatureInput(
+    uint64_t timestamp, int64_t tree_size, const string& root_hash,
+    const RepeatedPtrField<SthExtension>& sth_extension, const string& log_id,
+    string* result) {
+  CHECK_GE(tree_size, 0);
+  result->clear();
+  if (root_hash.size() != 32) {
+    return SerializeResult::INVALID_HASH_LENGTH;
+  }
+  SerializeResult res = CheckSthExtensionsFormat(sth_extension);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  if (log_id.size() != Serializer::kKeyIDLengthInBytes) {
+    return SerializeResult::INVALID_KEYID_LENGTH;
+  }
+
+  WriteUint(ct::V2, Serializer::kVersionLengthInBytes, result);
+  WriteUint(ct::TREE_HEAD, Serializer::kSignatureTypeLengthInBytes, result);
+  // TODO(eranm): This is wrong, V2 Log IDs are OIDs.
+  WriteFixedBytes(log_id, result);
+  WriteUint(timestamp, Serializer::kTimestampLengthInBytes, result);
+  WriteUint(tree_size, 8, result);
+  WriteFixedBytes(root_hash, result);
+  // V2 STH can have multiple extensions
+  WriteUint(sth_extension.size(), 2, result);
+  for (auto it = sth_extension.begin(); it != sth_extension.end(); ++it) {
+    WriteUint(it->sth_extension_type(), 2, result);
+    WriteVarBytes(it->sth_extension_data(), Serializer::kMaxExtensionsLength,
+                  result);
+  }
+
+  return SerializeResult::OK;
+}
+
+
+// static
+SerializeResult Serializer::SerializeSTHSignatureInput(
+    const ct::SignedTreeHead& sth, std::string* result) {
+  CHECK(result);
+  // result will be cleared by
+  // SerializeV1STHSignatureInput or SerializeV2STHSignatureInput
+  // TODO(alcutter): this should know whether it's V1 or V2 from the
+  // Configure()
+  switch (sth.version()) {
+    case ct::V1:
+      return SerializeV1STHSignatureInput(sth.timestamp(), sth.tree_size(),
+                                          sth.sha256_root_hash(), result);
+    case ct::V2:
+      return SerializeV2STHSignatureInput(sth.timestamp(), sth.tree_size(),
+                                          sth.sha256_root_hash(),
+                                          sth.sth_extension(),
+                                          sth.id().key_id(), result);
+    default:
+      break;
+  }
+  return SerializeResult::UNSUPPORTED_VERSION;
+}
+
+
+// static
+SerializeResult Serializer::SerializeSCTMerkleTreeLeaf(
+    const ct::SignedCertificateTimestamp& sct, const ct::LogEntry& entry,
+    std::string* result) {
+  CHECK(result);
+  CHECK(serialize_sct_merkle_leaf);
+  return serialize_sct_merkle_leaf(sct, entry, result);
+}
+
+
+// static
+SerializeResult Serializer::SerializeSCTSignatureInput(
+    const SignedCertificateTimestamp& sct, const LogEntry& entry,
+    string* result) {
+  CHECK(result);
+  CHECK(serialize_sct_sig_input);
+  return serialize_sct_sig_input(sct, entry, result);
+}
+
+SerializeResult WriteSCTV1(const SignedCertificateTimestamp& sct,
+                           std::string* output) {
+  CHECK(sct.version() == ct::V1);
+  // output is cleared by SerializeSCT
+  SerializeResult res = CheckExtensionsFormat(sct.extensions());
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  if (sct.id().key_id().size() != Serializer::kKeyIDLengthInBytes) {
+    return SerializeResult::INVALID_KEYID_LENGTH;
+  }
+  WriteUint(sct.version(), Serializer::kVersionLengthInBytes, output);
+  WriteFixedBytes(sct.id().key_id(), output);
+  WriteUint(sct.timestamp(), Serializer::kTimestampLengthInBytes, output);
+  WriteVarBytes(sct.extensions(), Serializer::kMaxExtensionsLength, output);
+  return WriteDigitallySigned(sct.signature(), output);
+}
+
+void WriteSctExtension(const RepeatedPtrField<SctExtension>& extension,
+                       std::string* output) {
+  WriteUint(extension.size(), 2, output);
+  for (auto it = extension.begin(); it != extension.end(); ++it) {
+    WriteUint(it->sct_extension_type(), 2, output);
+    WriteVarBytes(it->sct_extension_data(), Serializer::kMaxExtensionsLength,
+                  output);
+  }
+}
+
+SerializeResult WriteSCTV2(const SignedCertificateTimestamp& sct,
+                           std::string* output) {
+  CHECK(sct.version() == ct::V2);
+  // output is cleared by SerializeSCT
+  SerializeResult res = CheckSctExtensionsFormat(sct.sct_extension());
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  if (sct.id().key_id().size() != Serializer::kKeyIDLengthInBytes) {
+    return SerializeResult::INVALID_KEYID_LENGTH;
+  }
+  WriteUint(sct.version(), Serializer::kVersionLengthInBytes, output);
+  WriteFixedBytes(sct.id().key_id(), output);
+  WriteUint(sct.timestamp(), Serializer::kTimestampLengthInBytes, output);
+  // V2 SCT can have a number of extensions. They must be ordered by type
+  // but we already checked that above.
+  WriteSctExtension(sct.sct_extension(), output);
+  return WriteDigitallySigned(sct.signature(), output);
+}
+
+// static
+SerializeResult Serializer::SerializeSCT(const SignedCertificateTimestamp& sct,
+                                         string* result) {
+  SerializeResult res = SerializeResult::UNSUPPORTED_VERSION;
+
+  result->clear();
+  switch (sct.version()) {
+    case ct::V1:
+      res = WriteSCTV1(sct, result);
+      break;
+    case ct::V2:
+      res = WriteSCTV2(sct, result);
+      break;
+    default:
+      res = SerializeResult::UNSUPPORTED_VERSION;
+  }
+  if (res != SerializeResult::OK) {
+    result->clear();
+    return res;
+  }
+  return SerializeResult::OK;
+}
+
+// static
+SerializeResult Serializer::SerializeSCTList(
+    const SignedCertificateTimestampList& sct_list, string* result) {
+  if (sct_list.sct_list_size() == 0) {
+    return SerializeResult::EMPTY_LIST;
+  }
+  return SerializeList(sct_list.sct_list(),
+                       Serializer::kMaxSerializedSCTLength,
+                       Serializer::kMaxSCTListLength, result);
+}
+
+// static
+SerializeResult Serializer::SerializeDigitallySigned(
+    const DigitallySigned& sig, string* result) {
+  result->clear();
+  return WriteDigitallySigned(sig, result);
+}
+
+// static
+SerializeResult Serializer::SerializeList(const repeated_string& in,
+                                          size_t max_elem_length,
+                                          size_t max_total_length,
+                                          string* result) {
+  std::string output;
+  SerializeResult res =
+      cert_trans::serialization::WriteList(in, max_elem_length,
+                                           max_total_length, &output);
+  if (res != SerializeResult::OK)
+    return res;
+  result->assign(output);
+  return SerializeResult::OK;
+}
+
+SerializeResult CheckKeyHashFormat(const string& key_hash) {
+  if (key_hash.size() != Serializer::kKeyHashLengthInBytes)
+    return SerializeResult::INVALID_HASH_LENGTH;
+  return SerializeResult::OK;
+}
+
+
+SerializeResult CheckExtensionsFormat(const string& extensions) {
+  if (extensions.size() > Serializer::kMaxExtensionsLength)
+    return SerializeResult::EXTENSIONS_TOO_LONG;
+  return SerializeResult::OK;
+}
+
+
+// Checks the (v2) STH extensions are correct. The RFC defines that there can
+// be up to 65534 of them and each one can contain up to 65535 bytes.
+// They must be in ascending order of extension type.
+SerializeResult CheckSthExtensionsFormat(
+    const repeated_sth_extension& extension) {
+  if (extension.size() > static_cast<int>(Serializer::kMaxV2ExtensionsCount)) {
+    return SerializeResult::EXTENSIONS_TOO_LONG;
+  }
+
+  uint32_t last_type_seen = 0;
+
+  for (auto it = extension.begin(); it != extension.end(); ++it) {
+    if (it->sth_extension_type() > Serializer::kMaxV2ExtensionType) {
+      return SerializeResult::INVALID_ENTRY_TYPE;
+    }
+
+    if (it->sth_extension_data().size() > Serializer::kMaxExtensionsLength) {
+      return SerializeResult::EXTENSIONS_TOO_LONG;
+    }
+
+    if (it->sth_extension_type() < last_type_seen) {
+      // It's out of order - reject
+      return SerializeResult::EXTENSIONS_NOT_ORDERED;
+    }
+
+    last_type_seen = it->sth_extension_type();
+  }
+
+  return SerializeResult::OK;
+}
+
+
+// Checks the (v2) SCT extensions are correct. The RFC defines that there can
+// be up to 65534 of them and each one can contain up to 65535 bytes. They
+// must be in ascending order of extension type
+SerializeResult CheckSctExtensionsFormat(
+    const RepeatedPtrField<SctExtension>& extension) {
+  if (extension.size() > static_cast<int>(Serializer::kMaxV2ExtensionsCount)) {
+    return SerializeResult::EXTENSIONS_TOO_LONG;
+  }
+
+  uint32_t last_type_seen = 0;
+
+  for (auto it = extension.begin(); it != extension.end(); ++it) {
+    if (it->sct_extension_data().size() > Serializer::kMaxExtensionsLength) {
+      return SerializeResult::EXTENSIONS_TOO_LONG;
+    }
+
+    if (it->sct_extension_type() > Serializer::kMaxV2ExtensionType) {
+      return SerializeResult::INVALID_ENTRY_TYPE;
+    }
+
+    if (it->sct_extension_type() < last_type_seen) {
+      // It's out of order - reject
+      return SerializeResult::EXTENSIONS_NOT_ORDERED;
+    }
+
+    last_type_seen = it->sct_extension_type();
+  }
+
+  return SerializeResult::OK;
+}
+
+
+namespace {
+
+DeserializeResult ReadSCTV1(TLSDeserializer* deserializer,
+                            SignedCertificateTimestamp* sct) {
+  sct->set_version(ct::V1);
+  if (!deserializer->ReadFixedBytes(Serializer::kKeyIDLengthInBytes,
+                                    sct->mutable_id()->mutable_key_id())) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+  // V1 encoding.
+  uint64_t timestamp = 0;
+  if (!deserializer->ReadUint(Serializer::kTimestampLengthInBytes,
+                              &timestamp)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+  sct->set_timestamp(timestamp);
+  string extensions;
+  if (!deserializer->ReadVarBytes(Serializer::kMaxExtensionsLength,
+                                  &extensions)) {
+    // In theory, could also be an invalid length prefix, but not if
+    // length limits follow byte boundaries.
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+  return deserializer->ReadDigitallySigned(sct->mutable_signature());
+}
+
+const size_t kV2ExtensionCountLengthInBytes = 2;
+const size_t kV2ExtensionTypeLengthInBytes = 2;
+
+DeserializeResult ReadSctExtension(TLSDeserializer* deserializer,
+                                   RepeatedPtrField<SctExtension>* extension) {
+  uint32_t ext_count;
+  if (!deserializer->ReadUint(kV2ExtensionCountLengthInBytes, &ext_count)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+
+  if (ext_count > Serializer::kMaxV2ExtensionsCount) {
+    return DeserializeResult::EXTENSIONS_TOO_LONG;
+  }
+
+  for (uint32_t ext = 0; ext < ext_count; ++ext) {
+    uint32_t ext_type;
+    if (!deserializer->ReadUint(kV2ExtensionTypeLengthInBytes, &ext_type)) {
+      return DeserializeResult::INPUT_TOO_SHORT;
+    }
+
+    string ext_data;
+    if (!deserializer->ReadVarBytes(Serializer::kMaxExtensionsLength,
+                                    &ext_data)) {
+      return DeserializeResult::INPUT_TOO_SHORT;
+    }
+
+    SctExtension* new_ext = extension->Add();
+    new_ext->set_sct_extension_type(ext_type);
+    new_ext->set_sct_extension_data(ext_data);
+  }
+
+  // This makes sure they're correctly ordered (See RFC section 5.3)
+  return CheckSctExtensionsFormat(*extension) == SerializeResult::OK
+             ? DeserializeResult::OK
+             : DeserializeResult::EXTENSIONS_NOT_ORDERED;
+}
+
+DeserializeResult ReadSCTV2(TLSDeserializer* deserializer,
+                            SignedCertificateTimestamp* sct) {
+  sct->set_version(ct::V2);
+  if (!deserializer->ReadFixedBytes(Serializer::kKeyIDLengthInBytes,
+                                    sct->mutable_id()->mutable_key_id())) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+  // V2 encoding.
+  uint64_t timestamp = 0;
+  if (!deserializer->ReadUint(Serializer::kTimestampLengthInBytes,
+                              &timestamp)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+  sct->set_timestamp(timestamp);
+  // Extensions are handled differently for V2
+  const DeserializeResult res =
+      ReadSctExtension(deserializer, sct->mutable_sct_extension());
+  if (res != DeserializeResult::OK) {
+    return res;
+  }
+  return deserializer->ReadDigitallySigned(sct->mutable_signature());
+}
+
+}  // namespace
+
+
+DeserializeResult ReadExtensionsV1(TLSDeserializer* deserializer,
+                                   ct::TimestampedEntry* entry) {
+  CHECK_NOTNULL(deserializer);
+  string extensions;
+  if (!deserializer->ReadVarBytes(Serializer::kMaxExtensionsLength,
+                                  &extensions)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+  CHECK_NOTNULL(entry)->set_extensions(extensions);
+  return DeserializeResult::OK;
+}
+
+
+DeserializeResult ReadSCT(TLSDeserializer* deserializer,
+                          SignedCertificateTimestamp* sct) {
+  int version;
+  if (!deserializer->ReadUint(Serializer::kVersionLengthInBytes, &version)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+  if (!Version_IsValid(version) || (version != ct::V1 && version != ct::V2)) {
+    return DeserializeResult::UNSUPPORTED_VERSION;
+  }
+
+  switch (version) {
+    case ct::V1:
+      return ReadSCTV1(deserializer, sct);
+      break;
+
+    case ct::V2:
+
+      return ReadSCTV2(deserializer, sct);
+      break;
+
+    default:
+      return DeserializeResult::UNSUPPORTED_VERSION;
+  }
+}
+
+
+// static
+DeserializeResult Deserializer::DeserializeSCT(
+    const string& in, SignedCertificateTimestamp* sct) {
+  TLSDeserializer deserializer(in);
+  DeserializeResult res = ReadSCT(&deserializer, sct);
+  if (res != DeserializeResult::OK) {
+    return res;
+  }
+  if (!deserializer.ReachedEnd()) {
+    return DeserializeResult::INPUT_TOO_LONG;
+  }
+  return DeserializeResult::OK;
+}
+
+
+// static
+DeserializeResult Deserializer::DeserializeSCTList(
+    const string& in, SignedCertificateTimestampList* sct_list) {
+  sct_list->clear_sct_list();
+  DeserializeResult res = DeserializeList(in, Serializer::kMaxSCTListLength,
+                                          Serializer::kMaxSerializedSCTLength,
+                                          sct_list->mutable_sct_list());
+  if (res != DeserializeResult::OK)
+    return res;
+  if (sct_list->sct_list_size() == 0)
+    return DeserializeResult::EMPTY_LIST;
+  return DeserializeResult::OK;
+}
+
+
+// static
+DeserializeResult Deserializer::DeserializeDigitallySigned(
+    const string& in, DigitallySigned* sig) {
+  TLSDeserializer deserializer(in);
+  DeserializeResult res = deserializer.ReadDigitallySigned(sig);
+  if (res != DeserializeResult::OK)
+    return res;
+  if (!deserializer.ReachedEnd())
+    return DeserializeResult::INPUT_TOO_LONG;
+  return DeserializeResult::OK;
+}
+
+
+
+// static
+DeserializeResult Deserializer::DeserializeList(const string& in,
+                                                size_t max_total_length,
+                                                size_t max_elem_length,
+                                                repeated_string* out) {
+  TLSDeserializer deserializer(in);
+  DeserializeResult res =
+      deserializer.ReadList(max_total_length, max_elem_length, out);
+  if (res != DeserializeResult::OK)
+    return res;
+  if (!deserializer.ReachedEnd())
+    return DeserializeResult::INPUT_TOO_LONG;
+  return DeserializeResult::OK;
+}
+
+
+
+DeserializeResult Deserializer::DeserializeMerkleTreeLeaf(
+    const std::string& in, ct::MerkleTreeLeaf* leaf) {
+  TLSDeserializer des(in);
+
+  DeserializeResult ret = read_merkle_tree_leaf(&des, leaf);
+  if (ret != DeserializeResult::OK) {
+    return ret;
+  }
+
+  if (!des.ReachedEnd()) {
+    return DeserializeResult::INPUT_TOO_LONG;
+  }
+
+  return DeserializeResult::OK;
+}
+
+
+// static
+void Serializer::ConfigureV1(
+    const function<string(const ct::LogEntry&)>& leaf_data_func,
+    const function<SerializeResult(
+        const ct::SignedCertificateTimestamp& sct, const ct::LogEntry& entry,
+        std::string* result)>& serialize_sct_sig_input_func,
+    const function<SerializeResult(
+        const ct::SignedCertificateTimestamp& sct, const ct::LogEntry& entry,
+        std::string* result)>& serialize_sct_merkle_leaf_func) {
+  CHECK(FLAGS_allow_reconfigure_serializer_test_only ||
+        (!leaf_data&& !serialize_sct_sig_input &&
+         !serialize_sct_merkle_leaf))
+      << "Serializer already configured";
+  leaf_data = leaf_data_func;
+  serialize_sct_sig_input = serialize_sct_sig_input_func;
+  serialize_sct_merkle_leaf = serialize_sct_merkle_leaf_func;
+  serialize_sth_sig_input_v1 = ::SerializeV1STHSignatureInput;
+}
+
+
+// static
+void Serializer::ConfigureV2(
+    const function<string(const ct::LogEntry&)>& leaf_data_func,
+    const function<SerializeResult(
+        const ct::SignedCertificateTimestamp& sct, const ct::LogEntry& entry,
+        std::string* result)>& serialize_sct_sig_input_func,
+    const function<SerializeResult(
+        const ct::SignedCertificateTimestamp& sct, const ct::LogEntry& entry,
+        std::string* result)>& serialize_sct_merkle_leaf_func) {
+  CHECK(FLAGS_allow_reconfigure_serializer_test_only ||
+        (!leaf_data && !serialize_sct_sig_input &&
+         !serialize_sct_merkle_leaf))
+      << "Serializer already configured";
+  leaf_data = leaf_data_func;
+  serialize_sct_sig_input = serialize_sct_sig_input_func;
+  serialize_sct_merkle_leaf = serialize_sct_merkle_leaf_func;
+  serialize_sth_sig_input_v2 = ::SerializeV2STHSignatureInput;
+}
+
+
+// static
+void Deserializer::Configure(
+    const function<DeserializeResult(TLSDeserializer* d,
+                                     ct::MerkleTreeLeaf* leaf)>&
+        read_merkle_tree_leaf_func) {
+  CHECK(FLAGS_allow_reconfigure_serializer_test_only ||
+        !read_merkle_tree_leaf)
+      << "Deserializer already configured";
+  read_merkle_tree_leaf = read_merkle_tree_leaf_func;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/serializer.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/serializer.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/serializer.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/serializer.h	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,180 @@
+#ifndef CERT_TRANS_PROTO_SERIALIZER_H_
+#define CERT_TRANS_PROTO_SERIALIZER_H_
+
+#include <glog/logging.h>
+#include <google/protobuf/repeated_field.h>
+#include <stdint.h>
+#include <functional>
+#include <string>
+
+#include "base/macros.h"
+#include "proto/ct.pb.h"
+#include "proto/tls_encoding.h"
+
+typedef google::protobuf::RepeatedPtrField<ct::SthExtension>
+    repeated_sth_extension;
+typedef google::protobuf::RepeatedPtrField<ct::SctExtension>
+    repeated_sct_extension;
+
+cert_trans::serialization::SerializeResult CheckExtensionsFormat(
+    const std::string& extensions);
+cert_trans::serialization::SerializeResult CheckKeyHashFormat(
+    const std::string& key_hash);
+cert_trans::serialization::SerializeResult CheckSctExtensionsFormat(
+    const repeated_sct_extension& extension);
+
+void WriteSctExtension(const repeated_sct_extension& extension,
+                       std::string* output);
+
+cert_trans::serialization::DeserializeResult ReadExtensionsV1(
+    TLSDeserializer* deserializer, ct::TimestampedEntry* entry);
+
+cert_trans::serialization::DeserializeResult ReadSCT(
+    TLSDeserializer* deserializer, ct::SignedCertificateTimestamp* sct);
+
+cert_trans::serialization::DeserializeResult ReadMerkleTreeLeaf(
+    TLSDeserializer* deserializer, ct::MerkleTreeLeaf* leaf);
+
+// A utility class for writing protocol buffer fields in canonical TLS style.
+class Serializer {
+ public:
+  static const size_t kMaxV2ExtensionType;
+  static const size_t kMaxV2ExtensionsCount;
+  static const size_t kMaxExtensionsLength;
+  static const size_t kMaxSerializedSCTLength;
+  static const size_t kMaxSCTListLength;
+
+  static const size_t kLogEntryTypeLengthInBytes;
+  static const size_t kSignatureTypeLengthInBytes;
+  static const size_t kVersionLengthInBytes;
+  // Log Key ID
+  static const size_t kKeyIDLengthInBytes;
+  static const size_t kMerkleLeafTypeLengthInBytes;
+  // Public key hash from cert
+  static const size_t kKeyHashLengthInBytes;
+  static const size_t kTimestampLengthInBytes;
+
+  // API
+  // TODO(alcutter): typedef these function<> bits
+  static void ConfigureV1(
+      const std::function<std::string(const ct::LogEntry&)>& leaf_data,
+      const std::function<cert_trans::serialization::SerializeResult(
+          const ct::SignedCertificateTimestamp& sct, const ct::LogEntry& entry,
+          std::string* result)>& serialize_sct_sig_input,
+      const std::function<cert_trans::serialization::SerializeResult(
+          const ct::SignedCertificateTimestamp& sct, const ct::LogEntry& entry,
+          std::string* result)>& serialize_sct_merkle_leaf);
+
+  static void ConfigureV2(
+      const std::function<std::string(const ct::LogEntry&)>& leaf_data,
+      const std::function<cert_trans::serialization::SerializeResult(
+          const ct::SignedCertificateTimestamp& sct, const ct::LogEntry& entry,
+          std::string* result)>& serialize_sct_sig_input,
+      const std::function<cert_trans::serialization::SerializeResult(
+          const ct::SignedCertificateTimestamp& sct, const ct::LogEntry& entry,
+          std::string* result)>& serialize_sct_merkle_leaf);
+
+  static std::string LeafData(const ct::LogEntry& entry);
+
+  static cert_trans::serialization::SerializeResult SerializeSTHSignatureInput(
+      const ct::SignedTreeHead& sth, std::string* result);
+
+  static cert_trans::serialization::SerializeResult SerializeSCTMerkleTreeLeaf(
+      const ct::SignedCertificateTimestamp& sct, const ct::LogEntry& entry,
+      std::string* result);
+
+  static cert_trans::serialization::SerializeResult SerializeSCTSignatureInput(
+      const ct::SignedCertificateTimestamp& sct, const ct::LogEntry& entry,
+      std::string* result);
+
+  static cert_trans::serialization::SerializeResult
+  SerializeV1STHSignatureInput(uint64_t timestamp, int64_t tree_size,
+                               const std::string& root_hash,
+                               std::string* result);
+
+  static cert_trans::serialization::SerializeResult
+  SerializeV2STHSignatureInput(uint64_t timestamp, int64_t tree_size,
+                               const std::string& root_hash,
+                               const repeated_sth_extension& sth_extension,
+                               const std::string& log_id, std::string* result);
+
+
+  // Random utils
+  static cert_trans::serialization::SerializeResult SerializeList(
+      const repeated_string& in, size_t max_elem_length,
+      size_t max_total_length, std::string* result);
+
+  static cert_trans::serialization::SerializeResult SerializeSCT(
+      const ct::SignedCertificateTimestamp& sct, std::string* result);
+
+  static cert_trans::serialization::SerializeResult SerializeSCTList(
+      const ct::SignedCertificateTimestampList& sct_list, std::string* result);
+
+  static cert_trans::serialization::SerializeResult SerializeDigitallySigned(
+      const ct::DigitallySigned& sig, std::string* result);
+
+  // TODO(ekasper): tests for these!
+  template <class T>
+  static std::string SerializeUint(T in, size_t bytes = sizeof(T)) {
+    std::string out;
+    cert_trans::serialization::WriteUint(in, bytes, &out);
+    return out;
+  }
+
+ private:
+  // This class is mostly a namespace for static methods.
+  // TODO(pphaneuf): Make this into normal functions in a namespace.
+  Serializer() = delete;
+};
+
+
+class Deserializer {
+ public:
+  static void Configure(
+      const std::function<cert_trans::serialization::DeserializeResult(
+          TLSDeserializer* d, ct::MerkleTreeLeaf* leaf)>&
+          read_merkle_tree_leaf_body);
+
+  static cert_trans::serialization::DeserializeResult DeserializeSCT(
+      const std::string& in, ct::SignedCertificateTimestamp* sct);
+
+  static cert_trans::serialization::DeserializeResult DeserializeSCTList(
+      const std::string& in, ct::SignedCertificateTimestampList* sct_list);
+
+  static cert_trans::serialization::DeserializeResult
+  DeserializeDigitallySigned(const std::string& in, ct::DigitallySigned* sig);
+
+  // FIXME(ekasper): for simplicity these reject if the list has empty
+  // elements (all our use cases are like this) but they should take in
+  // an arbitrary min bound instead.
+  static cert_trans::serialization::DeserializeResult DeserializeList(
+      const std::string& in, size_t max_total_length, size_t max_elem_length,
+      repeated_string* out);
+
+  static cert_trans::serialization::DeserializeResult
+  DeserializeMerkleTreeLeaf(const std::string& in, ct::MerkleTreeLeaf* leaf);
+
+  // TODO(pphaneuf): Maybe the users of this should just use
+  // TLSDeserializer directly?
+  template <class T>
+  static cert_trans::serialization::DeserializeResult DeserializeUint(
+      const std::string& in, size_t bytes, T* result) {
+    TLSDeserializer deserializer(in);
+    bool res = deserializer.ReadUint(bytes, result);
+    if (!res)
+      return cert_trans::serialization::DeserializeResult::INPUT_TOO_SHORT;
+    if (!deserializer.ReachedEnd())
+      return cert_trans::serialization::DeserializeResult::INPUT_TOO_LONG;
+    return cert_trans::serialization::DeserializeResult::OK;
+  }
+
+ private:
+  // This class is mostly a namespace for static methods.
+  // TODO(pphaneuf): Make this into normal functions in a namespace.
+  Deserializer() = delete;
+
+  // This should never do anything, but just in case...
+  DISALLOW_COPY_AND_ASSIGN(Deserializer);
+};
+
+#endif  // CERT_TRANS_PROTO_SERIALIZER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_test.cc	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,1572 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <google/protobuf/repeated_field.h>
+#include <gtest/gtest.h>
+#include <string>
+
+#include "proto/cert_serializer.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+DECLARE_bool(allow_reconfigure_serializer_test_only);
+
+namespace {
+
+using cert_trans::serialization::SerializeResult;
+using cert_trans::serialization::DeserializeResult;
+using ct::DigitallySigned;
+using ct::LogEntry;
+using ct::LogEntryType;
+using ct::MerkleTreeLeaf;
+using ct::PrecertChainEntry;
+using ct::SignedCertificateTimestamp;
+using ct::SignedCertificateTimestampList;
+using ct::SctExtension;
+using ct::SignedTreeHead;
+using ct::SthExtension;
+using ct::Version;
+using ct::X509ChainEntry;
+using google::protobuf::RepeatedPtrField;
+using std::string;
+
+// A slightly shorter notation for constructing binary blobs from test vectors.
+string B(const string& hexstring) {
+  return util::BinaryString(hexstring);
+}
+
+// The reverse.
+string H(const string& byte_string) {
+  return util::HexString(byte_string);
+}
+
+// This string must be 32 bytes long to be a valid log id
+static const char* kDUMMY_LOG_ID = "iamapublickeyshatwofivesixdigest";
+
+const char kDefaultSCTSignatureHexString[] =
+    // hash algo, sig algo, 2 bytes
+    "0403"
+    // signature length, 2 bytes
+    "0009"
+    // signature, 9 bytes
+    "7369676e6174757265";
+
+const char kDefaultSCTHexString[] =
+    // version, 1 byte
+    "00"
+    // keyid, 32 bytes
+    "69616d617075626c69636b657973686174776f66697665736978646967657374"
+    // timestamp, 8 bytes
+    "00000000000004d2"
+    // extensions length, 2 bytes
+    "0000"
+    // extensions, 0 bytes
+    // hash algo, sig algo, 2 bytes
+    "0403"
+    // signature length, 2 bytes
+    "0009"
+    // signature, 9 bytes
+    "7369676e6174757265";
+
+const char kDefaultSCTHexStringV2[] =
+    // version, 1 byte
+    "01"
+    // keyid, 32 bytes
+    "69616d617075626c69636b657973686174776f66697665736978646967657374"
+    // timestamp, 8 bytes
+    "00000000000004d2"
+    // extensions length, 2 bytes
+    "0000"
+    // extensions, 0 bytes
+    // hash algo, sig algo, 2 bytes
+    "0403"
+    // signature length, 2 bytes
+    "0009"
+    // signature, 9 bytes
+    "7369676e6174757265";
+
+const char kDefaultSCTHexStringV2Extensions[] =
+    // version, 1 byte
+    "01"
+    // keyid, 32 bytes
+    "69616d617075626c69636b657973686174776f66697665736978646967657374"
+    // timestamp, 8 bytes
+    "00000000000004d2"
+    // extensions count 2 bytes
+    "0002"
+    // extension 1 type
+    "002a"
+    // extension 1 data length
+    "0009"
+    // extension 1 data "dontpanic"
+    "646f6e7470616e6963"
+    // extension 2 type
+    "0472"
+    // extension 2 data length
+    "0003"
+    // extension 2 data "thx"
+    "746878"
+    // hash algo, sig algo, 2 bytes
+    "0403"
+    // signature length, 2 bytes
+    "0009"
+    // signature, 9 bytes
+    "7369676e6174757265";
+
+const char kDefaultSCTListHexString[] =
+    // list length prefix
+    "003a"
+    // first (and only) SCT length prefix
+    "0038"
+    // the SCT
+    "0069616d617075626c69636b657973686174776f666976657369786469676573740000000"
+    "0000004d20000040300097369676e6174757265";
+
+const char kDefaultCertSCTSignedHexString[] =
+    // version, 1 byte
+    "00"
+    // signature type, 1 byte
+    "00"
+    // timestamp, 8 bytes
+    "00000000000004d2"
+    // entry type, 2 bytes
+    "0000"
+    // leaf certificate length, 3 bytes
+    "00000b"
+    // leaf certificate, 11 bytes
+    "6365727469666963617465"
+    // extensions length, 2 bytes
+    "0000";
+    // extensions, 0 bytes
+
+const char kDefaultCertSCTSignedHexStringExtensions[] =
+    // version, 1 byte
+    "00"
+    // signature type, 1 byte
+    "00"
+    // timestamp, 8 bytes
+    "00000000000004d2"
+    // entry type, 2 bytes
+    "0000"
+    // leaf certificate length, 3 bytes
+    "00000b"
+    // leaf certificate, 11 bytes
+    "6365727469666963617465"
+    // extensions length, 2 bytes
+    "0005"
+    // extension data "hello"
+    "68656c6c6f";
+
+const char kDefaultCertSCTSignedHexStringV2[] =
+    // version, 1 byte
+    "01"
+    // signature type, 1 byte
+    "00"
+    // timestamp, 8 bytes
+    "00000000000004d2"
+    // entry type, 2 bytes
+    "0000"
+    // keyid, 32 bytes
+    "69616d617075626c69636b657973686174776f66697665736978646967657374"
+    // leaf certificate length, 3 bytes
+    "00000c"
+    // leaf certificate, 12 bytes
+    "636572746966696361746532"
+    // extensions length, 2 bytes
+    "0000";
+    // extensions, 0 bytes
+
+const char kDefaultCertSCTSignedHexStringV2Extensions[] =
+    // version, 1 byte
+    "01"
+    // signature type, 1 byte
+    "00"
+    // timestamp, 8 bytes
+    "00000000000004d2"
+    // entry type, 2 bytes
+    "0000"
+    // keyid, 32 bytes
+    "69616d617075626c69636b657973686174776f66697665736978646967657374"
+    // leaf certificate length, 3 bytes
+    "00000c"
+    // leaf certificate, 12 bytes
+    "636572746966696361746532"
+    // extensions count 2 bytes
+    "0002"
+    // extension 1 type
+    "002a"
+    // extension 1 data length
+    "0009"
+    // extension 1 data "dontpanic"
+    "646f6e7470616e6963"
+    // extension 2 type
+    "0472"
+    // extension 2 data length
+    "0003"
+    // extension 2 data "thx"
+    "746878";
+
+const char kDefaultSignedCertEntryWithTypeHexString[] =
+    // entry type, 2 bytes
+    "0000"
+    // leaf certificate length, 3 bytes
+    "00000b"
+    // leaf certificate, 11 bytes
+    "6365727469666963617465";
+
+const char kDefaultSignedPrecertEntryWithTypeHexString[] =
+    // entry type, 2 bytes
+    "0001"
+    // issuer key hash, 32 bytes
+    "69616d617075626c69636b657973686174776f66697665736978646967657374"
+    // tbs certificate length, 3 bytes
+    "000003"
+    // tbs certificate, 3 bytes
+    "746273";
+
+const char kDefaultPrecertSCTSignedHexString[] =
+    // version, 1 byte
+    "00"
+    // signature type, 1 byte
+    "00"
+    // timestamp, 8 bytes
+    "00000000000004d2"
+    // entry type, 2 bytes (PRECERT)
+    "0001"
+    // issuer key hash, 32 bytes
+    "69616d617075626c69636b657973686174776f66697665736978646967657374"
+    // tbs certificate length, 3 bytes
+    "000003"
+    // tbs certificate, 3 bytes
+    "746273"
+    // extensions length, 2 bytes
+    "0000";
+    // extensions, 0 bytes
+
+const char kDefaultPrecertSCTSignedHexStringV2[] =
+    // version, 1 byte
+    "01"
+    // signature type, 1 byte
+    "00"
+    // timestamp, 8 bytes
+    "00000000000004d2"
+    // entry type, 2 bytes (PRECERT_V2)
+    "0002"
+    // issuer key hash, 32 bytes
+    "69616d617075626c69636b657973686174776f66697665736978646967657374"
+    // certificate length, 4 bytes
+    "000004"
+    // certificate, 4 bytes
+    "74627332"
+    // extensions length, 2 bytes
+    "0000";
+    // extensions, 0 bytes
+
+const char kDefaultCertSCTLeafHexString[] =
+    // version, 1 byte
+    "00"
+    // leaf type, 1 byte
+    "00"
+    // timestamp, 8 bytes
+    "00000000000004d2"
+    // entry type, 2 bytes
+    "0000"
+    // leaf certificate length, 3 bytes
+    "00000b"
+    // leaf certificate, 11 bytes
+    "6365727469666963617465"
+    // extensions length, 2 bytes
+    "0000";
+    // extensions, 0 bytes
+
+const char kDefaultCertSCTLeafHexStringV2[] =
+    // version, 1 byte
+    "01"
+    // leaf type, 1 byte
+    "00"
+    // timestamp, 8 bytes
+    "00000000000004d2"
+    // entry type, 2 bytes
+    "0000"
+    // issuer key hash, 32 bytes
+    "69616d617075626c69636b657973686174776f66697665736978646967657374"
+    // leaf certificate length, 3 bytes
+    "00000c"
+    // leaf certificate, 12 bytes
+    "636572746966696361746532"
+    // extensions length, 2 bytes
+    "0000";
+    // extensions, 0 bytes
+
+const char kDefaultCertSCTLeafHexStringV2Extensions[] =
+    // version, 1 byte
+    "01"
+    // leaf type, 1 byte
+    "00"
+    // timestamp, 8 bytes
+    "00000000000004d2"
+    // entry type, 2 bytes
+    "0000"
+    // issuer key hash, 32 bytes
+    "69616d617075626c69636b657973686174776f66697665736978646967657374"
+    // leaf certificate length, 3 bytes
+    "00000c"
+    // leaf certificate, 12 bytes
+    "636572746966696361746532"
+    // extensions count 2 bytes
+    "0002"
+    // extension 1 type
+    "002a"
+    // extension 1 data length
+    "0009"
+    // extension 1 data "dontpanic"
+    "646f6e7470616e6963"
+    // extension 2 type
+    "0472"
+    // extension 2 data length
+    "0003"
+    // extension 2 data "thx"
+    "746878";
+
+const char kDefaultPrecertSCTLeafHexString[] =
+    // version, 1 byte
+    "00"
+    // leaf type, 1 byte
+    "00"
+    // timestamp, 8 bytes
+    "00000000000004d2"
+    // entry type, 2 bytes (PRECERT)
+    "0001"
+    // issuer key hash, 32 bytes
+    "69616d617075626c69636b657973686174776f66697665736978646967657374"
+    // tbs certificate length, 3 bytes
+    "000003"
+    // leaf certificate, 3 bytes
+    "746273"
+    // extensions length, 2 bytes
+    "0000";
+    // extensions, 0 bytes
+
+const char kDefaultPrecertSCTLeafHexStringV2[] =
+    // version, 1 byte
+    "01"
+    // leaf type, 1 byte
+    "00"
+    // timestamp, 8 bytes
+    "00000000000004d2"
+    // entry type, 2 bytes (PRECERT_V2)
+    "0002"
+    // issuer key hash, 32 bytes
+    "69616d617075626c69636b657973686174776f66697665736978646967657374"
+    // tbs certificate length, 4 bytes
+    "000004"
+    // leaf certificate, 4 bytes
+    "74627332"
+    // extensions length, 2 bytes
+    "0000";
+    // extensions, 0 bytes
+
+const char kDefaultSTHSignedHexString[] =
+    // version, 1 byte
+    "00"
+    // signature type, 1 byte
+    "01"
+    // timestamp, 8 bytes
+    "0000000000000929"
+    // tree size, 8 bytes
+    "0000000000000006"
+    // root hash, 32 bytes
+    "696d757374626565786163746c7974686972747974776f62797465736c6f6e67";
+
+const char kDefaultSTHSignedHexStringV2[] =
+    // version, 1 byte
+    "01"
+    // signature type, 1 byte
+    "01"
+    // keyid, 32 bytes
+    "69616d617075626c69636b657973686174776f66697665736978646967657374"
+    // timestamp, 8 bytes
+    "0000000000000929"
+    // tree size, 8 bytes
+    "0000000000000006"
+    // root hash, 32 bytes
+    "696d757374626565786163746c7974686972747974776f62797465736c6f6e67"
+    // extensions length 2 bytes, no extension data
+    "0000";
+
+const char kDefaultSTHSignedHexStringV2Extensions[] =
+    // version, 1 byte
+    "01"
+    // signature type, 1 byte
+    "01"
+    // keyid, 32 bytes
+    "69616d617075626c69636b657973686174776f66697665736978646967657374"
+    // timestamp, 8 bytes
+    "0000000000000929"
+    // tree size, 8 bytes
+    "0000000000000006"
+    // root hash, 32 bytes
+    "696d757374626565786163746c7974686972747974776f62797465736c6f6e67"
+    // extensions count 2 bytes
+    "0002"
+    // extension 1 type
+    "002a"
+    // extension 1 data length
+    "0009"
+    // extension 1 data "dontpanic"
+    "646f6e7470616e6963"
+    // extension 2 type
+    "0472"
+    // extension 2 data length
+    "0003"
+    // extension 2 data "thx"
+    "746878";
+
+// TODO(ekasper): switch to real data here, too.
+class SerializerTest : public ::testing::Test {
+ protected:
+  SerializerTest()
+      : cert_entry_(),
+        cert_entry_v2_(),
+        precert_entry_(),
+        precert_entry_v2_(),
+        sct_(),
+        sct_v2_(),
+        sct_v2_ext_(),
+        sct_v2_ext_badorder_(),
+        sct_list_(),
+        sct_list_v2_(),
+        sth_(),
+        sth_v2_(),
+        sth_v2_ext_(),
+        sth_v2_ext_badorder_() {
+    cert_entry_.set_type(ct::X509_ENTRY);
+    cert_entry_.mutable_x509_entry()->set_leaf_certificate("certificate");
+
+    cert_entry_v2_.set_type(ct::X509_ENTRY);
+    cert_entry_v2_.mutable_x509_entry()
+        ->mutable_cert_info()
+        ->set_tbs_certificate("certificate2");
+    cert_entry_v2_.mutable_x509_entry()
+        ->mutable_cert_info()
+        ->set_issuer_key_hash(kDUMMY_LOG_ID);
+
+    precert_entry_.set_type(ct::PRECERT_ENTRY);
+    precert_entry_.mutable_precert_entry()->set_pre_certificate("precert");
+    precert_entry_.mutable_precert_entry()
+        ->mutable_pre_cert()
+        ->set_issuer_key_hash(kDUMMY_LOG_ID);
+    precert_entry_.mutable_precert_entry()
+        ->mutable_pre_cert()
+        ->set_tbs_certificate("tbs");
+
+    precert_entry_v2_.set_type(ct::PRECERT_ENTRY_V2);
+    precert_entry_v2_.mutable_precert_entry()->set_pre_certificate("precert2");
+    precert_entry_v2_.mutable_precert_entry()
+        ->mutable_cert_info()
+        ->set_issuer_key_hash(kDUMMY_LOG_ID);
+    precert_entry_v2_.mutable_precert_entry()
+        ->mutable_cert_info()
+        ->set_tbs_certificate("tbs2");
+
+    sct_.set_version(ct::V1);
+    sct_.mutable_id()->set_key_id(kDUMMY_LOG_ID);
+    sct_.set_timestamp(1234);
+    sct_.mutable_signature()->set_hash_algorithm(DigitallySigned::SHA256);
+    sct_.mutable_signature()->set_sig_algorithm(DigitallySigned::ECDSA);
+    sct_.mutable_signature()->set_signature("signature");
+    sct_list_.add_sct_list(B(kDefaultSCTHexString));
+
+    sct_v2_.set_version(ct::V2);
+    sct_v2_.mutable_id()->set_key_id(kDUMMY_LOG_ID);
+    sct_v2_.set_timestamp(1234);
+    sct_v2_.mutable_signature()->set_hash_algorithm(DigitallySigned::SHA256);
+    sct_v2_.mutable_signature()->set_sig_algorithm(DigitallySigned::ECDSA);
+    sct_v2_.mutable_signature()->set_signature("signature");
+    sct_list_v2_.add_sct_list(B(kDefaultSCTHexStringV2));
+
+    // create a v2 sct with extensions
+    sct_v2_ext_ = sct_v2_;
+    SctExtension* const sct_ext1 = sct_v2_ext_.add_sct_extension();
+    sct_ext1->set_sct_extension_type(42);
+    sct_ext1->set_sct_extension_data("dontpanic");
+
+    SctExtension* const sct_ext2 = sct_v2_ext_.add_sct_extension();
+    sct_ext2->set_sct_extension_type(1138);
+    sct_ext2->set_sct_extension_data("thx");
+
+    // create a v2 sct with extensions out of order and hence invalid
+    sct_v2_ext_badorder_ = sct_v2_;
+    SctExtension* const sct_ext1_bad =
+        sct_v2_ext_badorder_.add_sct_extension();
+    sct_ext1_bad->set_sct_extension_type(1138);
+    sct_ext1_bad->set_sct_extension_data("thx");
+
+    SctExtension* const sct_ext2_bad =
+        sct_v2_ext_badorder_.add_sct_extension();
+    sct_ext2_bad->set_sct_extension_type(42);
+    sct_ext2_bad->set_sct_extension_data("dontpanic");
+
+    sth_.set_version(ct::V1);
+    sth_.mutable_id()->set_key_id(kDUMMY_LOG_ID);
+    sth_.set_timestamp(2345);
+    sth_.set_tree_size(6);
+    sth_.set_sha256_root_hash("imustbeexactlythirtytwobyteslong");
+    sth_.mutable_signature()->set_hash_algorithm(DigitallySigned::SHA256);
+    sth_.mutable_signature()->set_sig_algorithm(DigitallySigned::ECDSA);
+    sth_.mutable_signature()->set_signature("tree_signature");
+
+    sth_v2_.set_version(ct::V2);
+    sth_v2_.mutable_id()->set_key_id(kDUMMY_LOG_ID);
+    sth_v2_.set_timestamp(2345);
+    sth_v2_.set_tree_size(6);
+    sth_v2_.set_sha256_root_hash("imustbeexactlythirtytwobyteslong");
+    sth_v2_.mutable_signature()->set_hash_algorithm(DigitallySigned::SHA256);
+    sth_v2_.mutable_signature()->set_sig_algorithm(DigitallySigned::ECDSA);
+    sth_v2_.mutable_signature()->set_signature("tree_signature");
+
+    sth_v2_ext_ = sth_v2_;  // basically the same but with added extensions
+    SthExtension* const sth_ext1 = sth_v2_ext_.add_sth_extension();
+    sth_ext1->set_sth_extension_type(42);
+    sth_ext1->set_sth_extension_data("dontpanic");
+
+    SthExtension* const sth_ext2 = sth_v2_ext_.add_sth_extension();
+    sth_ext2->set_sth_extension_type(1138);
+    sth_ext2->set_sth_extension_data("thx");
+
+    // This sth has extensions out of order (invalid)
+    sth_v2_ext_badorder_ = sth_v2_;
+    SthExtension* const sth_ext1_bad_order =
+        sth_v2_ext_badorder_.add_sth_extension();
+    sth_ext1_bad_order->set_sth_extension_type(1138);
+    sth_ext1_bad_order->set_sth_extension_data("thx");
+
+    SthExtension* const sth_ext2_bad_order =
+        sth_v2_ext_badorder_.add_sth_extension();
+    sth_ext2_bad_order->set_sth_extension_type(42);
+    sth_ext2_bad_order->set_sth_extension_data("dontpanic");
+  }
+
+  const LogEntry& DefaultCertEntry() const {
+    return cert_entry_;
+  }
+
+  const LogEntry& DefaultCertEntryV2() const {
+    return cert_entry_v2_;
+  }
+
+  const LogEntry& DefaultPrecertEntry() const {
+    return precert_entry_;
+  }
+
+  const LogEntry& DefaultPrecertEntryV2() const {
+    return precert_entry_v2_;
+  }
+
+  uint64_t DefaultSCTTimestamp() const {
+    return sct_.timestamp();
+  }
+
+  string DefaultCertificate() const {
+    return cert_entry_.x509_entry().leaf_certificate();
+  }
+
+  string DefaultCertificateV2() const {
+    return cert_entry_v2_.x509_entry().cert_info().tbs_certificate();
+  }
+
+  string DefaultIssuerKeyHash() const {
+    return precert_entry_.precert_entry().pre_cert().issuer_key_hash();
+  }
+
+  string DefaultTbsCertificate() const {
+    return precert_entry_.precert_entry().pre_cert().tbs_certificate();
+  }
+
+  string DefaultTbsCertificateV2() const {
+    return precert_entry_v2_.precert_entry().cert_info().tbs_certificate();
+  }
+
+  string DefaultExtensions() const {
+    return string();
+  }
+
+  const RepeatedPtrField<SthExtension>& DefaultSthExtensions() const {
+    return sth_v2_.sth_extension();
+  }
+
+  const SignedCertificateTimestamp& DefaultSCT() const {
+    return sct_;
+  }
+
+  const SignedCertificateTimestamp& DefaultSCTV2() const {
+    return sct_v2_;
+  }
+
+  const SignedCertificateTimestamp& DefaultSCTV2Ext() const {
+    return sct_v2_ext_;
+  }
+
+  const RepeatedPtrField<SctExtension>& DefaultSctExtensions() const {
+    return sct_v2_.sct_extension();
+  }
+
+  const SignedCertificateTimestamp& DefaultSCTV2ExtBadOrder() const {
+    return sct_v2_ext_badorder_;
+  }
+
+  const SignedCertificateTimestampList& DefaultSCTList() const {
+    return sct_list_;
+  }
+
+  const SignedCertificateTimestampList& DefaultSCTListV2() const {
+    return sct_list_v2_;
+  }
+
+  uint64_t DefaultSTHTimestamp() const {
+    return sth_.timestamp();
+  }
+
+  int64_t DefaultTreeSize() const {
+    CHECK_GE(sth_.tree_size(), 0);
+    return sth_.tree_size();
+  }
+
+  string DefaultRootHash() const {
+    return sth_.sha256_root_hash();
+  }
+
+  const SignedTreeHead& DefaultSTH() const {
+    return sth_;
+  }
+
+  const SignedTreeHead& DefaultSTHV2() const {
+    return sth_v2_;
+  }
+
+  const SignedTreeHead& DefaultSTHV2Ext() const {
+    return sth_v2_ext_;
+  }
+
+  const SignedTreeHead& DefaultSTHV2ExtBadOrder() const {
+    return sth_v2_ext_badorder_;
+  }
+
+  const DigitallySigned& DefaultSCTSignature() const {
+    return sct_.signature();
+  }
+
+  const DigitallySigned& DefaultSTHSignature() const {
+    return sth_.signature();
+  }
+
+  static void CompareDS(const DigitallySigned& ds,
+                        const DigitallySigned& ds2) {
+    EXPECT_EQ(ds.hash_algorithm(), ds2.hash_algorithm());
+    EXPECT_EQ(ds.sig_algorithm(), ds2.sig_algorithm());
+    EXPECT_EQ(H(ds.signature()), H(ds2.signature()));
+  }
+
+  static void CompareSCT(const SignedCertificateTimestamp& sct,
+                         const SignedCertificateTimestamp& sct2) {
+    EXPECT_EQ(sct.version(), sct2.version());
+    EXPECT_EQ(sct.id().key_id(), sct2.id().key_id());
+    EXPECT_EQ(sct.timestamp(), sct2.timestamp());
+    CompareDS(sct.signature(), sct2.signature());
+  }
+
+ private:
+  LogEntry cert_entry_;
+  LogEntry cert_entry_v2_;
+  LogEntry precert_entry_;
+  LogEntry precert_entry_v2_;
+  SignedCertificateTimestamp sct_;
+  SignedCertificateTimestamp sct_v2_;
+  SignedCertificateTimestamp sct_v2_ext_;
+  SignedCertificateTimestamp sct_v2_ext_badorder_;
+  SignedCertificateTimestampList sct_list_;
+  SignedCertificateTimestampList sct_list_v2_;
+  SignedTreeHead sth_;
+  SignedTreeHead sth_v2_;
+  SignedTreeHead sth_v2_ext_;
+  SignedTreeHead sth_v2_ext_badorder_;
+};
+
+
+class SerializerTestV1 : public SerializerTest {
+ public:
+  void SetUp() {
+    FLAGS_allow_reconfigure_serializer_test_only = true;
+    ConfigureSerializerForV1CT();
+  }
+};
+
+
+class SerializerTestV2 : public SerializerTest {
+ public:
+  void SetUp() {
+    FLAGS_allow_reconfigure_serializer_test_only = true;
+    ConfigureSerializerForV2CT();
+  }
+};
+
+
+TEST_F(SerializerTestV1, SerializeDigitallySignedKatTest) {
+  string result;
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeDigitallySigned(DefaultSCTSignature(),
+                                                 &result));
+  EXPECT_EQ(string(kDefaultSCTSignatureHexString), H(result));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTKatTest) {
+  string result;
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCT(DefaultSCT(), &result));
+  EXPECT_EQ(string(kDefaultSCTHexString), H(result));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTListKatTest) {
+  string result;
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCTList(DefaultSCTList(), &result));
+  EXPECT_EQ(string(kDefaultSCTListHexString), H(result));
+}
+
+TEST_F(SerializerTestV1, DeserializeSCTListKatTest) {
+  SignedCertificateTimestampList sct_list;
+  EXPECT_EQ(DeserializeResult::OK,
+            Deserializer::DeserializeSCTList(B(kDefaultSCTListHexString),
+                                             &sct_list));
+  EXPECT_EQ(1, sct_list.sct_list_size());
+  EXPECT_EQ(string(kDefaultSCTHexString), H(sct_list.sct_list(0)));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTSignatureInputKatTestV1) {
+  string cert_result, precert_result;
+  EXPECT_EQ(SerializeResult::OK,
+            SerializeV1CertSCTSignatureInput(DefaultSCTTimestamp(),
+                                             DefaultCertificate(),
+                                             DefaultExtensions(),
+                                             &cert_result));
+  EXPECT_EQ(string(kDefaultCertSCTSignedHexString), H(cert_result));
+
+  EXPECT_EQ(SerializeResult::OK,
+            SerializeV1PrecertSCTSignatureInput(DefaultSCTTimestamp(),
+                                                DefaultIssuerKeyHash(),
+                                                DefaultTbsCertificate(),
+                                                DefaultExtensions(),
+                                                &precert_result));
+  EXPECT_EQ(string(kDefaultPrecertSCTSignedHexString), H(precert_result));
+
+  EXPECT_NE(cert_result, precert_result);
+
+  cert_result.clear();
+  precert_result.clear();
+
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCTSignatureInput(DefaultSCT(),
+                                                   DefaultCertEntry(),
+                                                   &cert_result));
+  EXPECT_EQ(string(kDefaultCertSCTSignedHexString), H(cert_result));
+
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCTSignatureInput(DefaultSCT(),
+                                                   DefaultPrecertEntry(),
+                                                   &precert_result));
+  EXPECT_EQ(string(kDefaultPrecertSCTSignedHexString), H(precert_result));
+}
+
+TEST_F(SerializerTestV2, SerializeSCTSignatureInputKatTestV2) {
+  string cert_result, precert_result;
+  EXPECT_EQ(SerializeResult::OK,
+            SerializeV2CertSCTSignatureInput(
+                DefaultSCTTimestamp(), DefaultIssuerKeyHash(),
+                DefaultCertificateV2(), DefaultSctExtensions(), &cert_result));
+  EXPECT_EQ(string(kDefaultCertSCTSignedHexStringV2), H(cert_result));
+
+  EXPECT_EQ(SerializeResult::OK,
+            SerializeV2PrecertSCTSignatureInput(DefaultSCTTimestamp(),
+                                                DefaultIssuerKeyHash(),
+                                                DefaultTbsCertificateV2(),
+                                                DefaultSctExtensions(),
+                                                &precert_result));
+  EXPECT_EQ(string(kDefaultPrecertSCTSignedHexStringV2), H(precert_result));
+
+  EXPECT_NE(cert_result, precert_result);
+
+  cert_result.clear();
+  precert_result.clear();
+
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCTSignatureInput(DefaultSCTV2(),
+                                                   DefaultCertEntryV2(),
+                                                   &cert_result));
+  EXPECT_EQ(string(kDefaultCertSCTSignedHexStringV2), H(cert_result));
+
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCTSignatureInput(DefaultSCTV2(),
+                                                   DefaultPrecertEntryV2(),
+                                                   &precert_result));
+  EXPECT_EQ(string(kDefaultPrecertSCTSignedHexStringV2), H(precert_result));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTMerkleTreeLeafKatTestV1) {
+  string cert_result, precert_result;
+  EXPECT_EQ(SerializeResult::OK,
+            SerializeV1CertSCTMerkleTreeLeaf(DefaultSCTTimestamp(),
+                                             DefaultCertificate(),
+                                             DefaultExtensions(),
+                                             &cert_result));
+  EXPECT_EQ(string(kDefaultCertSCTLeafHexString), H(cert_result));
+
+  EXPECT_EQ(SerializeResult::OK,
+            SerializeV1PrecertSCTMerkleTreeLeaf(DefaultSCTTimestamp(),
+                                                DefaultIssuerKeyHash(),
+                                                DefaultTbsCertificate(),
+                                                DefaultExtensions(),
+                                                &precert_result));
+  EXPECT_EQ(string(kDefaultPrecertSCTLeafHexString), H(precert_result));
+
+  EXPECT_NE(cert_result, precert_result);
+
+  cert_result.clear();
+  precert_result.clear();
+
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCTMerkleTreeLeaf(DefaultSCT(),
+                                                   DefaultCertEntry(),
+                                                   &cert_result));
+  EXPECT_EQ(string(kDefaultCertSCTLeafHexString), H(cert_result));
+
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCTMerkleTreeLeaf(DefaultSCT(),
+                                                   DefaultPrecertEntry(),
+                                                   &precert_result));
+  EXPECT_EQ(string(kDefaultPrecertSCTLeafHexString), H(precert_result));
+}
+
+TEST_F(SerializerTestV2, SerializeSCTMerkleTreeLeafKatTestV2) {
+  string cert_result, precert_result;
+  EXPECT_EQ(SerializeResult::OK,
+            SerializeV2CertSCTMerkleTreeLeaf(
+                DefaultSCTTimestamp(), DefaultIssuerKeyHash(),
+                DefaultCertificateV2(), DefaultSctExtensions(), &cert_result));
+  EXPECT_EQ(string(kDefaultCertSCTLeafHexStringV2), H(cert_result));
+
+  EXPECT_EQ(SerializeResult::OK,
+            SerializeV2PrecertSCTMerkleTreeLeaf(DefaultSCTTimestamp(),
+                                                DefaultIssuerKeyHash(),
+                                                DefaultTbsCertificateV2(),
+                                                DefaultSctExtensions(),
+                                                &precert_result));
+  EXPECT_EQ(string(kDefaultPrecertSCTLeafHexStringV2), H(precert_result));
+
+  EXPECT_NE(cert_result, precert_result);
+
+  cert_result.clear();
+  precert_result.clear();
+
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCTMerkleTreeLeaf(DefaultSCTV2(),
+                                                   DefaultCertEntryV2(),
+                                                   &cert_result));
+  EXPECT_EQ(string(kDefaultCertSCTLeafHexStringV2), H(cert_result));
+
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCTMerkleTreeLeaf(DefaultSCTV2(),
+                                                   DefaultPrecertEntryV2(),
+                                                   &precert_result));
+  EXPECT_EQ(string(kDefaultPrecertSCTLeafHexStringV2), H(precert_result));
+}
+
+TEST_F(SerializerTestV1, DeserializeMerkleTreeLeafKATV1Cert) {
+  MerkleTreeLeaf leaf;
+  EXPECT_EQ(DeserializeResult::OK,
+            Deserializer::DeserializeMerkleTreeLeaf(
+                B(kDefaultCertSCTLeafHexString), &leaf));
+  EXPECT_EQ(leaf.version(), ct::V1);
+  EXPECT_EQ(leaf.type(), ct::TIMESTAMPED_ENTRY);
+  EXPECT_EQ(leaf.timestamped_entry().timestamp(), DefaultSCTTimestamp());
+  EXPECT_EQ(leaf.timestamped_entry().entry_type(), ct::X509_ENTRY);
+  EXPECT_EQ(leaf.timestamped_entry().signed_entry().x509(),
+            DefaultCertEntry().x509_entry().leaf_certificate());
+  EXPECT_FALSE(leaf.timestamped_entry().signed_entry().has_precert());
+}
+
+TEST_F(SerializerTestV1, DeserializeMerkleTreeLeafKATV1Precert) {
+  MerkleTreeLeaf leaf;
+  EXPECT_EQ(DeserializeResult::OK,
+            Deserializer::DeserializeMerkleTreeLeaf(
+                B(kDefaultPrecertSCTLeafHexString), &leaf));
+  EXPECT_EQ(leaf.version(), ct::V1);
+  EXPECT_EQ(leaf.type(), ct::TIMESTAMPED_ENTRY);
+  EXPECT_EQ(leaf.timestamped_entry().timestamp(), DefaultSCTTimestamp());
+  EXPECT_EQ(leaf.timestamped_entry().entry_type(), ct::PRECERT_ENTRY);
+  EXPECT_FALSE(leaf.timestamped_entry().signed_entry().has_x509());
+  EXPECT_EQ(
+      leaf.timestamped_entry().signed_entry().precert().issuer_key_hash(),
+      DefaultIssuerKeyHash());
+  EXPECT_EQ(
+      leaf.timestamped_entry().signed_entry().precert().tbs_certificate(),
+      DefaultTbsCertificate());
+}
+
+TEST_F(SerializerTestV2, DeserializeMerkleTreeLeafKATV2Cert) {
+  MerkleTreeLeaf leaf;
+  EXPECT_EQ(DeserializeResult::OK,
+            Deserializer::DeserializeMerkleTreeLeaf(
+                B(kDefaultCertSCTLeafHexStringV2), &leaf));
+  EXPECT_EQ(leaf.version(), ct::V2);
+  EXPECT_EQ(leaf.type(), ct::TIMESTAMPED_ENTRY);
+  EXPECT_EQ(leaf.timestamped_entry().timestamp(), DefaultSCTTimestamp());
+  EXPECT_EQ(leaf.timestamped_entry().entry_type(), ct::X509_ENTRY);
+  EXPECT_EQ(
+      leaf.timestamped_entry().signed_entry().cert_info().tbs_certificate(),
+      DefaultCertEntryV2().x509_entry().cert_info().tbs_certificate());
+  EXPECT_EQ(
+      leaf.timestamped_entry().signed_entry().cert_info().issuer_key_hash(),
+      DefaultCertEntryV2().x509_entry().cert_info().issuer_key_hash());
+  EXPECT_FALSE(leaf.timestamped_entry().signed_entry().has_precert());
+}
+
+TEST_F(SerializerTestV2, DeserializeMerkleTreeLeafKATV2Precert) {
+  MerkleTreeLeaf leaf;
+  EXPECT_EQ(DeserializeResult::OK,
+            Deserializer::DeserializeMerkleTreeLeaf(
+                B(kDefaultPrecertSCTLeafHexStringV2), &leaf));
+  EXPECT_EQ(leaf.version(), ct::V2);
+  EXPECT_EQ(leaf.type(), ct::TIMESTAMPED_ENTRY);
+  EXPECT_EQ(leaf.timestamped_entry().timestamp(), DefaultSCTTimestamp());
+  EXPECT_EQ(leaf.timestamped_entry().entry_type(), ct::PRECERT_ENTRY_V2);
+  EXPECT_FALSE(leaf.timestamped_entry().signed_entry().has_x509());
+  EXPECT_EQ(
+      leaf.timestamped_entry().signed_entry().cert_info().issuer_key_hash(),
+      DefaultIssuerKeyHash());
+  EXPECT_EQ(
+      leaf.timestamped_entry().signed_entry().cert_info().tbs_certificate(),
+      DefaultTbsCertificateV2());
+}
+
+TEST_F(SerializerTestV1, DeserializeSCTKatTestV1) {
+  string token = B(kDefaultSCTHexString);
+  SignedCertificateTimestamp sct;
+  EXPECT_EQ(DeserializeResult::OK, Deserializer::DeserializeSCT(token, &sct));
+  CompareSCT(DefaultSCT(), sct);
+}
+
+TEST_F(SerializerTestV2, DeserializeSCTKatTestV2) {
+  string token = B(kDefaultSCTHexStringV2);
+  SignedCertificateTimestamp sct;
+  EXPECT_EQ(DeserializeResult::OK, Deserializer::DeserializeSCT(token, &sct));
+  CompareSCT(DefaultSCTV2(), sct);
+}
+
+TEST_F(SerializerTestV1, DeserializeDigitallySignedKatTest) {
+  string serialized_sig = B(kDefaultSCTSignatureHexString);
+  DigitallySigned signature;
+  EXPECT_EQ(DeserializeResult::OK,
+            Deserializer::DeserializeDigitallySigned(serialized_sig,
+                                                     &signature));
+  CompareDS(DefaultSCTSignature(), signature);
+}
+
+TEST_F(SerializerTestV1, SerializeDeserializeSCTChangeHashAlgorithm) {
+  SignedCertificateTimestamp sct(DefaultSCT());
+  sct.mutable_signature()->set_hash_algorithm(DigitallySigned::SHA224);
+
+  string result;
+  EXPECT_EQ(SerializeResult::OK, Serializer::SerializeSCT(sct, &result));
+
+  string default_result = string(kDefaultSCTHexString);
+  string new_result = H(result);
+  EXPECT_EQ(default_result.size(), new_result.size());
+  EXPECT_NE(default_result, new_result);
+
+  SignedCertificateTimestamp read_sct;
+  EXPECT_EQ(DeserializeResult::OK,
+            Deserializer::DeserializeSCT(result, &read_sct));
+  CompareSCT(read_sct, sct);
+}
+
+TEST_F(SerializerTestV1, SerializeDeserializeSCTChangeSignature) {
+  SignedCertificateTimestamp sct(DefaultSCT());
+  sct.mutable_signature()->set_signature("bazinga");
+
+  string result;
+  EXPECT_EQ(SerializeResult::OK, Serializer::SerializeSCT(sct, &result));
+  EXPECT_NE(string(kDefaultSCTHexString), H(result));
+
+  SignedCertificateTimestamp read_sct;
+  EXPECT_EQ(DeserializeResult::OK,
+            Deserializer::DeserializeSCT(result, &read_sct));
+  CompareSCT(read_sct, sct);
+}
+
+TEST_F(SerializerTestV1, SerializeSCTSignatureInputEmptyCertificate) {
+  string result;
+  EXPECT_EQ(SerializeResult::EMPTY_CERTIFICATE,
+            SerializeV1CertSCTSignatureInput(DefaultSCTTimestamp(), string(),
+                                             DefaultExtensions(), &result));
+
+  LogEntry entry(DefaultCertEntry());
+  entry.mutable_x509_entry()->clear_leaf_certificate();
+  EXPECT_EQ(SerializeResult::EMPTY_CERTIFICATE,
+            Serializer::SerializeSCTSignatureInput(DefaultSCT(), entry,
+                                                   &result));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTMerkleTreeLeafEmptyCertificate) {
+  string result;
+  EXPECT_EQ(SerializeResult::EMPTY_CERTIFICATE,
+            SerializeV1CertSCTMerkleTreeLeaf(DefaultSCTTimestamp(), string(),
+                                             DefaultExtensions(), &result));
+
+  LogEntry entry(DefaultCertEntry());
+  entry.mutable_x509_entry()->clear_leaf_certificate();
+  EXPECT_EQ(SerializeResult::EMPTY_CERTIFICATE,
+            Serializer::SerializeSCTMerkleTreeLeaf(DefaultSCT(), entry,
+                                                   &result));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTSignatureInputEmptyTbsCertificate) {
+  string result;
+  EXPECT_EQ(SerializeResult::EMPTY_CERTIFICATE,
+            SerializeV1PrecertSCTSignatureInput(DefaultSCTTimestamp(),
+                                                DefaultIssuerKeyHash(),
+                                                string(), DefaultExtensions(),
+                                                &result));
+
+  LogEntry entry(DefaultPrecertEntry());
+  entry.mutable_precert_entry()->mutable_pre_cert()->clear_tbs_certificate();
+  EXPECT_EQ(SerializeResult::EMPTY_CERTIFICATE,
+            Serializer::SerializeSCTSignatureInput(DefaultSCT(), entry,
+                                                   &result));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTMerkleTreeLeafEmptyTbsCertificate) {
+  string result;
+  EXPECT_EQ(SerializeResult::EMPTY_CERTIFICATE,
+            SerializeV1PrecertSCTMerkleTreeLeaf(DefaultSCTTimestamp(),
+                                                DefaultIssuerKeyHash(),
+                                                string(), DefaultExtensions(),
+                                                &result));
+
+  LogEntry entry(DefaultPrecertEntry());
+  entry.mutable_precert_entry()->mutable_pre_cert()->clear_tbs_certificate();
+  EXPECT_EQ(SerializeResult::EMPTY_CERTIFICATE,
+            Serializer::SerializeSCTMerkleTreeLeaf(DefaultSCT(), entry,
+                                                   &result));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTSignatureInputInvalidIssuerKeyHash) {
+  string result;
+  EXPECT_EQ(SerializeResult::INVALID_HASH_LENGTH,
+            SerializeV1PrecertSCTSignatureInput(DefaultSCTTimestamp(),
+                                                "hash" /* not 32 bytes */,
+                                                DefaultTbsCertificate(),
+                                                DefaultExtensions(), &result));
+
+  LogEntry entry(DefaultPrecertEntry());
+  entry.mutable_precert_entry()->mutable_pre_cert()->set_issuer_key_hash("sh");
+  EXPECT_EQ(SerializeResult::INVALID_HASH_LENGTH,
+            Serializer::SerializeSCTSignatureInput(DefaultSCT(), entry,
+                                                   &result));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTMerkleTreeLeafInvalidIssuerKeyHash) {
+  string result;
+  EXPECT_EQ(SerializeResult::INVALID_HASH_LENGTH,
+            SerializeV1PrecertSCTMerkleTreeLeaf(DefaultSCTTimestamp(),
+                                                "hash" /* not 32 bytes */,
+                                                DefaultTbsCertificate(),
+                                                DefaultExtensions(), &result));
+
+  LogEntry entry(DefaultPrecertEntry());
+  entry.mutable_precert_entry()->mutable_pre_cert()->set_issuer_key_hash("sh");
+  EXPECT_EQ(SerializeResult::INVALID_HASH_LENGTH,
+            Serializer::SerializeSCTMerkleTreeLeaf(DefaultSCT(), entry,
+                                                   &result));
+}
+
+TEST_F(SerializerTestV1, DeserializeSCTBadHashType) {
+  string token = B(kDefaultSCTHexString);
+  // Overwrite with a non-existent hash algorithm type.
+  token[43] = 0xff;
+
+  SignedCertificateTimestamp sct;
+  EXPECT_EQ(DeserializeResult::INVALID_HASH_ALGORITHM,
+            Deserializer::DeserializeSCT(token, &sct));
+}
+
+TEST_F(SerializerTestV1, DeserializeSCTBadSignatureType) {
+  string token = B(kDefaultSCTHexString);
+  // Overwrite with a non-existent signature algorithm type.
+  token[44] = 0xff;
+
+  SignedCertificateTimestamp sct;
+  EXPECT_EQ(DeserializeResult::INVALID_SIGNATURE_ALGORITHM,
+            Deserializer::DeserializeSCT(token, &sct));
+}
+
+TEST_F(SerializerTestV1, DeserializeSCTTooShort) {
+  string token = B(kDefaultSCTHexString);
+
+  for (size_t i = 0; i < token.size(); ++i) {
+    SignedCertificateTimestamp sct;
+    EXPECT_EQ(DeserializeResult::INPUT_TOO_SHORT,
+              Deserializer::DeserializeSCT(token.substr(0, i), &sct));
+  }
+}
+
+TEST_F(SerializerTestV1, DeserializeSCTTooLong) {
+  string token = B(kDefaultSCTHexString);
+  token.push_back(0x42);
+
+  SignedCertificateTimestamp sct;
+
+  // We can still read from the beginning of a longer string...
+  TLSDeserializer deserializer(token);
+  EXPECT_EQ(DeserializeResult::OK, ReadSCT(&deserializer, &sct));
+  EXPECT_FALSE(deserializer.ReachedEnd());
+  CompareSCT(DefaultSCT(), sct);
+
+  // ... but we can't deserialize.
+  EXPECT_EQ(DeserializeResult::INPUT_TOO_LONG,
+            Deserializer::DeserializeSCT(token, &sct));
+}
+
+TEST_F(SerializerTestV1, SerializeSTHSignatureInputKatTestV1) {
+  string result;
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSTHSignatureInput(DefaultSTH(), &result));
+  EXPECT_EQ(string(kDefaultSTHSignedHexString), H(result));
+
+  result.clear();
+  EXPECT_EQ(SerializeResult::OK, Serializer::SerializeV1STHSignatureInput(
+                                     DefaultSTHTimestamp(), DefaultTreeSize(),
+                                     DefaultRootHash(), &result));
+  EXPECT_EQ(string(kDefaultSTHSignedHexString), H(result));
+}
+
+TEST_F(SerializerTestV2, SerializeSTHSignatureInputKatTestV2) {
+  string result;
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSTHSignatureInput(DefaultSTHV2(), &result));
+  EXPECT_EQ(string(kDefaultSTHSignedHexStringV2), H(result));
+
+  result.clear();
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeV2STHSignatureInput(
+                DefaultSTHTimestamp(), DefaultTreeSize(), DefaultRootHash(),
+                DefaultSthExtensions(), kDUMMY_LOG_ID, &result));
+  EXPECT_EQ(string(kDefaultSTHSignedHexStringV2), H(result));
+}
+
+TEST_F(SerializerTestV2, SerializeSTHSignatureInputKatTestV2InvalidLogId) {
+  string result;
+  EXPECT_EQ(SerializeResult::INVALID_KEYID_LENGTH,
+            Serializer::SerializeV2STHSignatureInput(
+                DefaultSTHTimestamp(), DefaultTreeSize(), DefaultRootHash(),
+                DefaultSthExtensions(), "this isn't 32 bytes long", &result));
+}
+
+TEST_F(SerializerTestV2, SerializeSTHSignatureInputKatTestV2WithExtensions) {
+  string result;
+  SignedTreeHead sth(DefaultSTHV2Ext());
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSTHSignatureInput(sth, &result));
+  EXPECT_EQ(string(kDefaultSTHSignedHexStringV2Extensions), H(result));
+
+  result.clear();
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeV2STHSignatureInput(
+                DefaultSTHTimestamp(), DefaultTreeSize(), DefaultRootHash(),
+                DefaultSTHV2Ext().sth_extension(), kDUMMY_LOG_ID, &result));
+  EXPECT_EQ(string(kDefaultSTHSignedHexStringV2Extensions), H(result));
+}
+
+TEST_F(SerializerTestV1, SerializeSTHSignatureInputBadHashV1) {
+  SignedTreeHead sth(DefaultSTH());
+  sth.set_sha256_root_hash("thisisnotthirtytwobyteslong");
+  string result;
+  EXPECT_EQ(SerializeResult::INVALID_HASH_LENGTH,
+            Serializer::SerializeSTHSignatureInput(sth, &result));
+}
+
+TEST_F(SerializerTestV2, SerializeSTHSignatureInputBadHashV2) {
+  SignedTreeHead sth(DefaultSTHV2());
+  sth.set_sha256_root_hash("thisisnotthirtytwobyteslong");
+  string result;
+  EXPECT_EQ(SerializeResult::INVALID_HASH_LENGTH,
+            Serializer::SerializeSTHSignatureInput(sth, &result));
+}
+
+TEST_F(SerializerTestV2, SerializeSTHSignatureInputExtBadOrderV2) {
+  string result;
+  EXPECT_EQ(SerializeResult::EXTENSIONS_NOT_ORDERED,
+            Serializer::SerializeSTHSignatureInput(DefaultSTHV2ExtBadOrder(),
+                                                   &result));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTWithExtensionsTestV1) {
+  SignedCertificateTimestamp sct(DefaultSCT());
+  sct.set_extensions("hello");
+  string result;
+  EXPECT_EQ(SerializeResult::OK, Serializer::SerializeSCT(sct, &result));
+  EXPECT_NE(string(kDefaultSCTHexString), H(result));
+}
+
+TEST_F(SerializerTestV2, SerializeSCTWithExtensionsTestV2) {
+  SignedCertificateTimestamp sct(DefaultSCTV2Ext());
+  string result;
+  EXPECT_EQ(SerializeResult::OK, Serializer::SerializeSCT(sct, &result));
+  EXPECT_EQ(string(kDefaultSCTHexStringV2Extensions), H(result));
+}
+
+TEST_F(SerializerTestV2, SerializeSCTWithExtensionsTestV2BadOrder) {
+  SignedCertificateTimestamp sct(DefaultSCTV2ExtBadOrder());
+  string result;
+  EXPECT_EQ(SerializeResult::EXTENSIONS_NOT_ORDERED,
+            Serializer::SerializeSCT(sct, &result));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTSignatureInputWithExtensionsTestV1) {
+  string result;
+  EXPECT_EQ(SerializeResult::OK,
+            SerializeV1CertSCTSignatureInput(DefaultSCTTimestamp(),
+                                             DefaultCertificate(), "hello",
+                                             &result));
+  EXPECT_EQ(string(kDefaultCertSCTSignedHexStringExtensions), H(result));
+
+  result.clear();
+  SignedCertificateTimestamp sct(DefaultSCT());
+  sct.set_extensions("hello");
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCTSignatureInput(sct, DefaultCertEntry(),
+                                                   &result));
+  EXPECT_EQ(string(kDefaultCertSCTSignedHexStringExtensions), H(result));
+}
+
+TEST_F(SerializerTestV2, SerializeSCTSignatureInputWithExtensionsTestV2) {
+  string result;
+  EXPECT_EQ(SerializeResult::OK,
+            SerializeV2CertSCTSignatureInput(DefaultSCTTimestamp(),
+                                             DefaultIssuerKeyHash(),
+                                             DefaultCertificateV2(),
+                                             DefaultSCTV2Ext().sct_extension(),
+                                             &result));
+  EXPECT_EQ(string(kDefaultCertSCTSignedHexStringV2Extensions), H(result));
+
+  result.clear();
+  SignedCertificateTimestamp sct(DefaultSCTV2Ext());
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCTSignatureInput(sct, DefaultCertEntryV2(),
+                                                   &result));
+  EXPECT_EQ(string(kDefaultCertSCTSignedHexStringV2Extensions), H(result));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTMerkleTreeLeafWithExtensionsTestV1) {
+  string result;
+  EXPECT_EQ(SerializeResult::OK,
+            SerializeV1CertSCTMerkleTreeLeaf(DefaultSCTTimestamp(),
+                                             DefaultCertificate(), "hello",
+                                             &result));
+  EXPECT_NE(string(kDefaultCertSCTLeafHexString), H(result));
+
+  result.clear();
+  SignedCertificateTimestamp sct(DefaultSCT());
+  sct.set_extensions("hello");
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCTMerkleTreeLeaf(sct, DefaultCertEntry(),
+                                                   &result));
+  EXPECT_NE(string(kDefaultCertSCTLeafHexString), H(result));
+}
+
+TEST_F(SerializerTestV2, SerializeSCTMerkleTreeLeafWithExtensionsTestV2) {
+  string result;
+  EXPECT_EQ(SerializeResult::OK,
+            SerializeV2CertSCTMerkleTreeLeaf(DefaultSCTTimestamp(),
+                                             DefaultIssuerKeyHash(),
+                                             DefaultCertificateV2(),
+                                             DefaultSCTV2Ext().sct_extension(),
+                                             &result));
+  EXPECT_EQ(string(kDefaultCertSCTLeafHexStringV2Extensions), H(result));
+
+  result.clear();
+  SignedCertificateTimestamp sct(DefaultSCTV2Ext());
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCTMerkleTreeLeaf(sct, DefaultCertEntryV2(),
+                                                   &result));
+  EXPECT_EQ(string(kDefaultCertSCTLeafHexStringV2Extensions), H(result));
+}
+
+TEST_F(SerializerTestV1, SerializeDeserializeSCTAddExtensionsV1) {
+  SignedCertificateTimestamp sct(DefaultSCT());
+  sct.set_extensions("hello");
+
+  string result;
+  EXPECT_EQ(SerializeResult::OK, Serializer::SerializeSCT(sct, &result));
+
+  SignedCertificateTimestamp read_sct;
+  EXPECT_EQ(DeserializeResult::OK,
+            Deserializer::DeserializeSCT(result, &read_sct));
+  CompareSCT(sct, read_sct);
+}
+
+TEST_F(SerializerTestV2, SerializeDeserializeSCTAddExtensionsV2) {
+  SignedCertificateTimestamp sct(DefaultSCTV2Ext());
+
+  string result;
+  EXPECT_EQ(SerializeResult::OK, Serializer::SerializeSCT(sct, &result));
+
+  SignedCertificateTimestamp read_sct;
+  EXPECT_EQ(DeserializeResult::OK,
+            Deserializer::DeserializeSCT(result, &read_sct));
+  CompareSCT(sct, read_sct);
+}
+
+TEST_F(SerializerTestV1, SerializeSCTUnsupportedVersion) {
+  SignedCertificateTimestamp sct(DefaultSCT());
+  sct.set_version(ct::UNKNOWN_VERSION);
+
+  string result;
+  EXPECT_EQ(SerializeResult::UNSUPPORTED_VERSION,
+            Serializer::SerializeSCT(sct, &result));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTSignatureInputUnsupportedVersion) {
+  SignedCertificateTimestamp sct(DefaultSCT());
+  sct.set_version(ct::UNKNOWN_VERSION);
+
+  string result;
+  EXPECT_EQ(SerializeResult::UNSUPPORTED_VERSION,
+            Serializer::SerializeSCTSignatureInput(sct, DefaultCertEntry(),
+                                                   &result));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTMerkleTreeLeafUnsupportedVersion) {
+  SignedCertificateTimestamp sct(DefaultSCT());
+  sct.set_version(ct::UNKNOWN_VERSION);
+
+  string result;
+  EXPECT_EQ(SerializeResult::UNSUPPORTED_VERSION,
+            Serializer::SerializeSCTMerkleTreeLeaf(sct, DefaultCertEntry(),
+                                                   &result));
+}
+
+TEST_F(SerializerTestV1, SerializeSTHSignatureInputUnsupportedVersion) {
+  SignedTreeHead sth(DefaultSTH());
+  sth.set_version(ct::UNKNOWN_VERSION);
+
+  string result;
+  EXPECT_EQ(SerializeResult::UNSUPPORTED_VERSION,
+            Serializer::SerializeSTHSignatureInput(sth, &result));
+}
+
+TEST_F(SerializerTestV1, DeserializeSCTUnsupportedVersion) {
+  string token = B(kDefaultSCTHexString);
+  // Overwrite with a non-existent version.
+  token[0] = 0xff;
+
+  SignedCertificateTimestamp sct;
+  EXPECT_EQ(DeserializeResult::UNSUPPORTED_VERSION,
+            Deserializer::DeserializeSCT(token, &sct));
+}
+
+TEST_F(SerializerTestV1, SerializeEmptySCTList) {
+  SignedCertificateTimestampList sct_list;
+  string result;
+  EXPECT_EQ(SerializeResult::EMPTY_LIST,
+            Serializer::SerializeSCTList(sct_list, &result));
+}
+
+TEST_F(SerializerTestV1, DeserializeEmptySCTList) {
+  // Length prefix for an empty list.
+  string empty_hex = "0000";
+  SignedCertificateTimestampList sct_list;
+  string result;
+  EXPECT_EQ(DeserializeResult::EMPTY_LIST,
+            Deserializer::DeserializeSCTList(B(empty_hex), &sct_list));
+}
+
+TEST_F(SerializerTestV1, SerializeSCTListEmptySCTInList) {
+  SignedCertificateTimestampList sct_list;
+  sct_list.add_sct_list(B(kDefaultSCTHexString));
+  sct_list.add_sct_list(string());
+  string result;
+  EXPECT_EQ(SerializeResult::EMPTY_ELEM_IN_LIST,
+            Serializer::SerializeSCTList(sct_list, &result));
+}
+
+TEST_F(SerializerTestV1, DeserializeSCTListEmptySCTInList) {
+  // Length prefix for a list with an empty sct.
+  string empty_hex = "00020000";
+  SignedCertificateTimestampList sct_list;
+  string result;
+  EXPECT_EQ(DeserializeResult::EMPTY_ELEM_IN_LIST,
+            Deserializer::DeserializeSCTList(B(empty_hex), &sct_list));
+}
+
+TEST_F(SerializerTestV1, SerializeDeserializeMultiSCTList) {
+  SignedCertificateTimestampList sct_list;
+  sct_list.add_sct_list("hello");
+  sct_list.add_sct_list(B(kDefaultSCTHexString));
+  string result;
+  EXPECT_EQ(SerializeResult::OK,
+            Serializer::SerializeSCTList(sct_list, &result));
+  SignedCertificateTimestampList read_sct_list;
+  EXPECT_EQ(DeserializeResult::OK,
+            Deserializer::DeserializeSCTList(result, &read_sct_list));
+  EXPECT_EQ(2, read_sct_list.sct_list_size());
+  EXPECT_EQ("hello", read_sct_list.sct_list(0));
+  EXPECT_EQ(B(kDefaultSCTHexString), read_sct_list.sct_list(1));
+}
+
+TEST_F(SerializerTestV1, DeserializeSCTListTooLong) {
+  string sct_string(B(kDefaultSCTListHexString));
+  sct_string.push_back('x');
+  SignedCertificateTimestampList read_sct_list;
+  EXPECT_EQ(DeserializeResult::INPUT_TOO_LONG,
+            Deserializer::DeserializeSCTList(sct_string, &read_sct_list));
+}
+
+TEST_F(SerializerTestV1, DeserializeSCTListTooShort) {
+  string sct_string(B(kDefaultSCTListHexString));
+  string bad_string(sct_string.substr(0, sct_string.size() - 1));
+  SignedCertificateTimestampList read_sct_list;
+  EXPECT_EQ(DeserializeResult::INPUT_TOO_SHORT,
+            Deserializer::DeserializeSCTList(bad_string, &read_sct_list));
+}
+
+TEST_F(SerializerTestV1, DeserializeSCTListInvalidList) {
+  // 2 byte-list, length of the first element allegedly 1 bytes...
+  string invalid_hex = "00020001";
+  SignedCertificateTimestampList read_sct_list;
+  EXPECT_EQ(DeserializeResult::INVALID_LIST_ENCODING,
+            Deserializer::DeserializeSCTList(B(invalid_hex), &read_sct_list));
+}
+
+TEST_F(SerializerTestV1, SerializeDeserializeX509Chain) {
+  X509ChainEntry entry, read_entry;
+  entry.set_leaf_certificate("cert");
+  entry.add_certificate_chain("hello");
+  entry.add_certificate_chain("world");
+  string result;
+  EXPECT_EQ(SerializeResult::OK, SerializeX509Chain(entry, &result));
+  EXPECT_EQ(DeserializeResult::OK, DeserializeX509Chain(result, &read_entry));
+  // TODO(ekasper): proper KAT tests
+  EXPECT_EQ(2, read_entry.certificate_chain_size());
+  EXPECT_EQ("hello", read_entry.certificate_chain(0));
+  EXPECT_EQ("world", read_entry.certificate_chain(1));
+  // Leaf cert does not get written or read.
+  EXPECT_FALSE(read_entry.has_leaf_certificate());
+}
+
+TEST_F(SerializerTestV1, SerializeDeserializeX509Chain_EmptyChain) {
+  X509ChainEntry entry, read_entry;
+  string result;
+  EXPECT_EQ(SerializeResult::OK, SerializeX509Chain(entry, &result));
+  EXPECT_EQ(DeserializeResult::OK, DeserializeX509Chain(result, &read_entry));
+  EXPECT_EQ(0, read_entry.certificate_chain_size());
+}
+
+TEST_F(SerializerTestV1, SerializeDeserializeX509Chain_EmptyCert) {
+  X509ChainEntry entry, read_entry;
+  entry.add_certificate_chain("");
+
+  string result;
+  EXPECT_EQ(SerializeResult::EMPTY_ELEM_IN_LIST,
+            SerializeX509Chain(entry, &result));
+}
+
+TEST_F(SerializerTestV1, SerializeDeserializePrecertChainEntry) {
+  PrecertChainEntry entry, read_entry;
+  entry.set_pre_certificate("hello");
+  entry.add_precertificate_chain("world");
+  string result;
+  EXPECT_EQ(SerializeResult::OK, SerializePrecertChainEntry(entry, &result));
+  EXPECT_EQ(DeserializeResult::OK,
+            DeserializePrecertChainEntry(result, &read_entry));
+  // TODO(ekasper): proper KAT tests
+  EXPECT_EQ(1, read_entry.precertificate_chain_size());
+  EXPECT_EQ("hello", read_entry.pre_certificate());
+  EXPECT_EQ("world", read_entry.precertificate_chain(0));
+}
+
+TEST_F(SerializerTestV1, SerializeDeserializePrecertChainEntry_EmptyPrecert) {
+  PrecertChainEntry entry, read_entry;
+  entry.add_precertificate_chain("world");
+  string result;
+  EXPECT_EQ(SerializeResult::EMPTY_CERTIFICATE,
+            SerializePrecertChainEntry(entry, &result));
+}
+
+TEST_F(SerializerTestV1, SerializeDeserializePrecertChainEntry_EmptyChain) {
+  PrecertChainEntry entry, read_entry;
+  entry.set_pre_certificate("hello");
+  string result;
+  EXPECT_EQ(SerializeResult::OK, SerializePrecertChainEntry(entry, &result));
+  EXPECT_EQ(DeserializeResult::OK,
+            DeserializePrecertChainEntry(result, &read_entry));
+  EXPECT_EQ(0, read_entry.precertificate_chain_size());
+  EXPECT_EQ("hello", read_entry.pre_certificate());
+}
+
+TEST_F(SerializerTestV1,
+       SerializeDeserializePrecertChainEntry_EmptyChainCert) {
+  PrecertChainEntry entry, read_entry;
+  entry.set_pre_certificate("hello");
+  entry.add_precertificate_chain("");
+  string result;
+  EXPECT_EQ(SerializeResult::EMPTY_ELEM_IN_LIST,
+            SerializePrecertChainEntry(entry, &result));
+}
+
+TEST_F(SerializerTest, SerializeSCTSignedEntryWithType_KatTest) {
+  string cert_result, precert_result;
+  EXPECT_EQ(SerializeResult::OK,
+            SerializeV1SignedCertEntryWithType(DefaultCertificate(),
+                                               &cert_result));
+  EXPECT_EQ(string(kDefaultSignedCertEntryWithTypeHexString), H(cert_result));
+
+  EXPECT_EQ(SerializeResult::OK,
+            SerializeV1SignedPrecertEntryWithType(DefaultIssuerKeyHash(),
+                                                  DefaultTbsCertificate(),
+                                                  &precert_result));
+  EXPECT_EQ(string(kDefaultSignedPrecertEntryWithTypeHexString),
+            H(precert_result));
+
+  cert_result.clear();
+  precert_result.clear();
+}
+
+TEST_F(SerializerTest, SerializeSCTSignedEntryWithType_EmptyCertificate) {
+  string result;
+  EXPECT_EQ(SerializeResult::EMPTY_CERTIFICATE,
+            SerializeV1SignedCertEntryWithType(string(), &result));
+}
+
+TEST_F(SerializerTest, SerializeSCTSignedEntryWithType_EmptyTbsCertificate) {
+  string result;
+  EXPECT_EQ(SerializeResult::EMPTY_CERTIFICATE,
+            SerializeV1SignedPrecertEntryWithType(DefaultIssuerKeyHash(),
+                                                  string(), &result));
+}
+
+TEST_F(SerializerTest, SerializeSCTSignedEntryWithType_BadIssuerKeyHash) {
+  string result;
+  EXPECT_EQ(SerializeResult::INVALID_HASH_LENGTH,
+            SerializeV1SignedPrecertEntryWithType("bad",
+                                                  DefaultTbsCertificate(),
+                                                  &result));
+}
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_v2.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_v2.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_v2.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_v2.cc	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,117 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "proto/serializer_v2.h"
+
+#include <glog/logging.h>
+
+#include "util/status.h"
+#include "util/openssl_util.h"
+#include "util/openssl_scoped_types.h"
+
+#if defined(OPENSSL_IS_BORINGSSL)
+#include <openssl/asn1.h>
+#endif
+
+namespace rfc6962_bis {
+using util::StatusOr;
+using util::Status;
+using cert_trans::ScopedOpenSSLBytes;
+
+namespace {
+const char kDerOIDTag = 0x06;
+// OpenSSL documentation recommends 80, see the BUGS section in:
+// https://www.openssl.org/docs/manmaster/crypto/OBJ_obj2txt.html
+const size_t kTextOIDMaxSize = 80;
+}
+
+OID::OID() : oid_(nullptr) {
+}
+
+OID::OID(ASN1_OBJECT* oid) : oid_(oid) {
+  CHECK_NOTNULL(oid_);
+}
+
+OID::OID(const OID& other) : oid_(nullptr) {
+  if (other.oid_ != nullptr) {
+    oid_ = OBJ_dup(other.oid_);
+  }
+}
+
+OID::~OID() {
+  if (oid_ != nullptr) {
+    ASN1_OBJECT_free(oid_);
+  }
+}
+
+util::StatusOr<std::string> OID::ToTagMissingDER() const {
+  if(oid_ == nullptr) {
+    // Uninitialized.
+    return Status(util::error::INVALID_ARGUMENT,
+                  std::string("OID not initialized."));
+  }
+  int encoded_length = i2d_ASN1_OBJECT(oid_, NULL);
+  if (encoded_length <= 0) {
+    return Status(util::error::INVALID_ARGUMENT,
+                  std::string("Failed to encode OID: ") +
+                  util::DumpOpenSSLErrorStack());
+  }
+
+  ScopedOpenSSLBytes encoded_oid(
+      reinterpret_cast<uint8_t*>(OPENSSL_malloc(encoded_length)));
+  // i2d_ASN1_OBJECT will change the pointer, so have to use a temporary.
+  unsigned char* tmp_ptr = encoded_oid.get();
+  encoded_length = i2d_ASN1_OBJECT(oid_, &tmp_ptr);
+  if (encoded_length <= 0) {
+    return Status(util::error::INVALID_ARGUMENT,
+                  std::string("Failed to encode OID: ") +
+                  util::DumpOpenSSLErrorStack());
+  }
+
+  // If the first byte, the tag, does not indicate an OID, then OpenSSL was not
+  // used correctly.
+  CHECK_EQ(encoded_oid.get()[0], kDerOIDTag);
+  // Skip the tag byte.
+  std::string out(reinterpret_cast<char*>(encoded_oid.get() + 1), encoded_length - 1);
+  return std::move(out);
+}
+
+std::string OID::ToString() const {
+  if (oid_ == nullptr) {
+    return "";
+  }
+
+  char output_buffer[kTextOIDMaxSize];
+  int encoded_length = i2t_ASN1_OBJECT(output_buffer, kTextOIDMaxSize, oid_);
+
+  return std::string(output_buffer, encoded_length);
+}
+
+// static
+util::StatusOr<OID> OID::FromString(const std::string& oid_string) {
+  ASN1_OBJECT *oid = OBJ_txt2obj(oid_string.c_str(), 0);
+  if (oid == nullptr) {
+    return Status(util::error::INVALID_ARGUMENT,
+                  std::string("Bad OID: ") + oid_string + " "
+                  + util::DumpOpenSSLErrorStack());
+  }
+
+  return OID(oid);
+}
+
+// static
+util::StatusOr<OID> OID::FromTagMissingDER(
+    const std::string& missing_tag_oid_der) {
+  std::string oid_der = std::string(1, kDerOIDTag) + missing_tag_oid_der;
+  const unsigned char* data_ptr =
+      reinterpret_cast<const unsigned char*>(oid_der.data());
+
+  ASN1_OBJECT *oid = d2i_ASN1_OBJECT(NULL, &data_ptr, oid_der.size());
+
+  if (oid == nullptr) {
+    return Status(util::error::INVALID_ARGUMENT,
+                  std::string("Bad DER in OID: ") +
+                  util::DumpOpenSSLErrorStack());
+  }
+  return OID(oid);
+}
+
+}  // namespace rfc6962_bis
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_v2.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_v2.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_v2.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_v2.h	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,34 @@
+/* -*- mode: c++; indent-tabs-mode: nil -*- */
+#ifndef SERIALIZER_V2_H
+#define SERIALIZER_V2_H
+
+#include <string>
+
+#include <openssl/objects.h>
+
+#include "util/statusor.h"
+
+// RFC6962-bis (V2) stuff.
+namespace rfc6962_bis {
+class OID {
+ public:
+  static util::StatusOr<OID> FromString(const std::string& oid_string);
+  static util::StatusOr<OID> FromTagMissingDER(const std::string& der_oid);
+
+  OID();
+  OID(const OID& other);
+  ~OID();
+
+  util::StatusOr<std::string> ToTagMissingDER() const;
+  std::string ToString() const;
+
+ private:
+  // Takes ownership
+  OID(ASN1_OBJECT* oid);
+
+  ASN1_OBJECT *oid_;
+};
+
+}  // namespace rfc6962_bis
+
+#endif
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_v2_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_v2_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_v2_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/serializer_v2_test.cc	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,60 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <google/protobuf/repeated_field.h>
+#include <gtest/gtest.h>
+#include <string>
+
+#include "proto/cert_serializer.h"
+#include "proto/ct.pb.h"
+#include "proto/serializer_v2.h"
+#include "util/testing.h"
+#include "util/util.h"
+
+namespace {
+
+const char kOID[] = "1.2.3.4.5";
+const char kOIDTagMissingDERHex[] = "042a030405";
+
+using rfc6962_bis::OID;
+using std::string;
+
+class SerializerV2Test : public ::testing::Test {
+ public:
+  SerializerV2Test() {
+    oid_text_ = std::string(kOID);
+    oid_der_missing_tag_ = util::BinaryString(kOIDTagMissingDERHex);
+  }
+ protected:
+  string oid_text_;
+  string oid_der_missing_tag_;
+};
+
+TEST_F(SerializerV2Test, SerializesSimpleOID) {
+  util::StatusOr<OID> res = OID::FromString(oid_text_);
+  ASSERT_TRUE(res.ok());
+
+  string encoded_der = res.ValueOrDie().ToTagMissingDER().ValueOrDie();
+  EXPECT_EQ(oid_der_missing_tag_, encoded_der);
+}
+
+TEST_F(SerializerV2Test, FailsOnInvalidOID) {
+  string bad_oid("3.7.-12.b");
+
+  util::StatusOr<OID> res = OID::FromString(bad_oid);
+  ASSERT_FALSE(res.ok());
+}
+
+TEST_F(SerializerV2Test, CreatesFromTagMissingDER) {
+  util::StatusOr<OID> res = OID::FromTagMissingDER(oid_der_missing_tag_);
+
+  ASSERT_TRUE(res.ok());
+  EXPECT_EQ(oid_text_, res.ValueOrDie().ToString());
+}
+
+}  // namespace
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/tls_encoding.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/tls_encoding.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/tls_encoding.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/tls_encoding.cc	2017-01-15 10:56:31.045591151 +0100
@@ -0,0 +1,266 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "proto/tls_encoding.h"
+
+#include <math.h>
+#include <ostream>
+#include <string>
+
+using ct::DigitallySigned;
+
+namespace cert_trans {
+
+namespace serialization {
+
+namespace {
+
+SerializeResult CheckSignatureFormat(const DigitallySigned& sig) {
+  // This is just DCHECKED upon setting, so check again.
+  if (!DigitallySigned_HashAlgorithm_IsValid(sig.hash_algorithm()))
+    return SerializeResult::INVALID_HASH_ALGORITHM;
+  if (!DigitallySigned_SignatureAlgorithm_IsValid(sig.sig_algorithm()))
+    return SerializeResult::INVALID_SIGNATURE_ALGORITHM;
+  if (sig.signature().size() > constants::kMaxSignatureLength)
+    return SerializeResult::SIGNATURE_TOO_LONG;
+  return SerializeResult::OK;
+}
+
+size_t SerializedListLength(const repeated_string& in, size_t max_elem_length,
+                            size_t max_total_length) {
+  size_t elem_prefix_length = internal::PrefixLength(max_elem_length);
+  size_t total_length = 0;
+
+  for (int i = 0; i < in.size(); ++i) {
+    if (in.Get(i).size() > max_elem_length ||
+        max_total_length - total_length < elem_prefix_length ||
+        max_total_length - total_length - elem_prefix_length <
+            in.Get(i).size())
+      return 0;
+
+    total_length += elem_prefix_length + in.Get(i).size();
+  }
+
+  return total_length + internal::PrefixLength(max_total_length);
+}
+
+}  // namespace
+
+std::ostream& operator<<(std::ostream& stream, const SerializeResult& r) {
+  switch (r) {
+    case SerializeResult::OK:
+      return stream << "OK";
+    case SerializeResult::INVALID_ENTRY_TYPE:
+      return stream << "INVALID_ENTRY_TYPE";
+    case SerializeResult::EMPTY_CERTIFICATE:
+      return stream << "EMPTY_CERTIFICATE";
+    case SerializeResult::CERTIFICATE_TOO_LONG:
+      return stream << "CERTIFICATE_TOO_LONG";
+    case SerializeResult::CERTIFICATE_CHAIN_TOO_LONG:
+      return stream << "CERTIFICATE_CHAIN_TOO_LONG";
+    case SerializeResult::INVALID_HASH_ALGORITHM:
+      return stream << "INVALID_HASH_ALGORITHM";
+    case SerializeResult::INVALID_SIGNATURE_ALGORITHM:
+      return stream << "INVALID_SIGNATURE_ALGORITHM";
+    case SerializeResult::SIGNATURE_TOO_LONG:
+      return stream << "SIGNATURE_TOO_LONG";
+    case SerializeResult::INVALID_HASH_LENGTH:
+      return stream << "INVALID_HASH_LENGTH";
+    case SerializeResult::EMPTY_PRECERTIFICATE_CHAIN:
+      return stream << "EMPTY_PRECERTIFICATE_CHAIN";
+    case SerializeResult::UNSUPPORTED_VERSION:
+      return stream << "UNSUPPORTED_VERSION";
+    case SerializeResult::EXTENSIONS_TOO_LONG:
+      return stream << "EXTENSIONS_TOO_LONG";
+    case SerializeResult::INVALID_KEYID_LENGTH:
+      return stream << "INVALID_KEYID_LENGTH";
+    case SerializeResult::EMPTY_LIST:
+      return stream << "EMPTY_LIST";
+    case SerializeResult::EMPTY_ELEM_IN_LIST:
+      return stream << "EMPTY_ELEM_IN_LIST";
+    case SerializeResult::LIST_ELEM_TOO_LONG:
+      return stream << "LIST_ELEM_TOO_LONG";
+    case SerializeResult::LIST_TOO_LONG:
+      return stream << "LIST_TOO_LONG";
+    case SerializeResult::EXTENSIONS_NOT_ORDERED:
+      return stream << "EXTENSIONS_NOT_ORDERED";
+  }
+  return stream << "<unknown>";
+}
+
+std::ostream& operator<<(std::ostream& stream, const DeserializeResult& r) {
+  switch (r) {
+    case DeserializeResult::OK:
+      return stream << "OK";
+    case DeserializeResult::INPUT_TOO_SHORT:
+      return stream << "INPUT_TOO_SHORT";
+    case DeserializeResult::INVALID_HASH_ALGORITHM:
+      return stream << "INVALID_HASH_ALGORITHM";
+    case DeserializeResult::INVALID_SIGNATURE_ALGORITHM:
+      return stream << "INVALID_SIGNATURE_ALGORITHM";
+    case DeserializeResult::INPUT_TOO_LONG:
+      return stream << "INPUT_TOO_LONG";
+    case DeserializeResult::UNSUPPORTED_VERSION:
+      return stream << "UNSUPPORTED_VERSION";
+    case DeserializeResult::INVALID_LIST_ENCODING:
+      return stream << "INVALID_LIST_ENCODING";
+    case DeserializeResult::EMPTY_LIST:
+      return stream << "EMPTY_LIST";
+    case DeserializeResult::EMPTY_ELEM_IN_LIST:
+      return stream << "EMPTY_ELEM_IN_LIST";
+    case DeserializeResult::UNKNOWN_LEAF_TYPE:
+      return stream << "UNKNOWN_LEAF_TYPE";
+    case DeserializeResult::UNKNOWN_LOGENTRY_TYPE:
+      return stream << "UNKNOWN_LOGENTRY_TYPE";
+    case DeserializeResult::EXTENSIONS_TOO_LONG:
+      return stream << "EXTENSIONS_TOO_LONG";
+    case DeserializeResult::EXTENSIONS_NOT_ORDERED:
+      return stream << "EXTENSIONS_NOT_ORDERED";
+  }
+  return stream << "<unknown>";
+}
+
+void WriteFixedBytes(const std::string& in, std::string* output) {
+  output->append(in);
+}
+
+void WriteVarBytes(const std::string& in, size_t max_length,
+                   std::string* output) {
+  CHECK_LE(in.size(), max_length);
+
+  size_t prefix_length = internal::PrefixLength(max_length);
+  WriteUint(in.size(), prefix_length, output);
+  WriteFixedBytes(in, output);
+}
+
+SerializeResult WriteList(const repeated_string& in, size_t max_elem_length,
+                          size_t max_total_length, std::string* output) {
+  for (int i = 0; i < in.size(); ++i) {
+    if (in.Get(i).empty())
+      return SerializeResult::EMPTY_ELEM_IN_LIST;
+    if (in.Get(i).size() > max_elem_length)
+      return SerializeResult::LIST_ELEM_TOO_LONG;
+  }
+  size_t length = SerializedListLength(in, max_elem_length, max_total_length);
+  if (length == 0)
+    return SerializeResult::LIST_TOO_LONG;
+  size_t prefix_length = internal::PrefixLength(max_total_length);
+  CHECK_GE(length, prefix_length);
+
+  WriteUint(length - prefix_length, prefix_length, output);
+
+  for (int i = 0; i < in.size(); ++i)
+    WriteVarBytes(in.Get(i), max_elem_length, output);
+  return SerializeResult::OK;
+}
+
+SerializeResult WriteDigitallySigned(const DigitallySigned& sig,
+                                     std::string* output) {
+  SerializeResult res = CheckSignatureFormat(sig);
+  if (res != SerializeResult::OK)
+    return res;
+  WriteUint(sig.hash_algorithm(), constants::kHashAlgorithmLengthInBytes,
+            output);
+  WriteUint(sig.sig_algorithm(), constants::kSigAlgorithmLengthInBytes,
+            output);
+  WriteVarBytes(sig.signature(), constants::kMaxSignatureLength, output);
+  return SerializeResult::OK;
+}
+
+namespace internal {
+
+size_t PrefixLength(size_t max_length) {
+  CHECK_GT(max_length, 0U);
+  return ceil(log2(max_length) / float(8));
+}
+
+}  // namespace internal
+
+}  // namespace serialization
+
+}  // namespace cert_trans
+
+
+// TODO(pphaneuf): The following is outside of the namespace to ease
+// review, should be moved inside.
+
+
+using cert_trans::serialization::DeserializeResult;
+namespace constants = cert_trans::serialization::constants;
+
+
+TLSDeserializer::TLSDeserializer(const std::string& input)
+    : current_pos_(input.data()), bytes_remaining_(input.size()) {
+}
+
+
+bool TLSDeserializer::ReadFixedBytes(size_t bytes, std::string* result) {
+  if (bytes_remaining_ < bytes)
+    return false;
+  result->assign(current_pos_, bytes);
+  current_pos_ += bytes;
+  bytes_remaining_ -= bytes;
+  return true;
+}
+
+
+bool TLSDeserializer::ReadLengthPrefix(size_t max_length, size_t* result) {
+  size_t prefix_length = cert_trans::serialization::internal::PrefixLength(max_length);
+  size_t length;
+  if (!ReadUint(prefix_length, &length) || length > max_length)
+    return false;
+  *result = length;
+  return true;
+}
+
+
+bool TLSDeserializer::ReadVarBytes(size_t max_length, std::string* result) {
+  size_t length;
+  if (!ReadLengthPrefix(max_length, &length))
+    return false;
+  return ReadFixedBytes(length, result);
+}
+
+DeserializeResult TLSDeserializer::ReadList(size_t max_total_length,
+                                            size_t max_elem_length,
+                                            repeated_string* out) {
+  std::string serialized_list;
+  if (!ReadVarBytes(max_total_length, &serialized_list))
+    // TODO(ekasper): could also be a length that's too large, if
+    // length limits don't follow byte boundaries.
+    return DeserializeResult::INPUT_TOO_SHORT;
+  if (!ReachedEnd())
+    return DeserializeResult::INPUT_TOO_LONG;
+
+  TLSDeserializer list_reader(serialized_list);
+  while (!list_reader.ReachedEnd()) {
+    std::string elem;
+    if (!list_reader.ReadVarBytes(max_elem_length, &elem))
+      return DeserializeResult::INVALID_LIST_ENCODING;
+    if (elem.empty())
+      return DeserializeResult::EMPTY_ELEM_IN_LIST;
+    *(out->Add()) = elem;
+  }
+  return DeserializeResult::OK;
+}
+
+
+DeserializeResult TLSDeserializer::ReadDigitallySigned(DigitallySigned* sig) {
+  int hash_algo = -1, sig_algo = -1;
+  if (!ReadUint(constants::kHashAlgorithmLengthInBytes, &hash_algo))
+    return DeserializeResult::INPUT_TOO_SHORT;
+  if (!ct::DigitallySigned_HashAlgorithm_IsValid(hash_algo))
+    return DeserializeResult::INVALID_HASH_ALGORITHM;
+  if (!ReadUint(constants::kSigAlgorithmLengthInBytes, &sig_algo))
+    return DeserializeResult::INPUT_TOO_SHORT;
+  if (!ct::DigitallySigned_SignatureAlgorithm_IsValid(sig_algo))
+    return DeserializeResult::INVALID_SIGNATURE_ALGORITHM;
+
+  std::string sig_string;
+  if (!ReadVarBytes(constants::kMaxSignatureLength, &sig_string))
+    return DeserializeResult::INPUT_TOO_SHORT;
+  sig->set_hash_algorithm(
+      static_cast<DigitallySigned::HashAlgorithm>(hash_algo));
+  sig->set_sig_algorithm(
+      static_cast<DigitallySigned::SignatureAlgorithm>(sig_algo));
+  sig->set_signature(sig_string);
+  return DeserializeResult::OK;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/tls_encoding.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/tls_encoding.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/tls_encoding.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/tls_encoding.h	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,150 @@
+#ifndef CERT_TRANS_PROTO_TLS_ENCODING_H_
+#define CERT_TRANS_PROTO_TLS_ENCODING_H_
+
+#include <glog/logging.h>
+#include <string>
+
+#include "base/macros.h"
+#include "proto/ct.pb.h"
+
+typedef google::protobuf::RepeatedPtrField<std::string> repeated_string;
+
+namespace cert_trans {
+
+namespace serialization {
+
+// Serialization methods return OK on success,
+// or the first encountered error on failure.
+enum class SerializeResult {
+  OK,
+  INVALID_ENTRY_TYPE,
+  EMPTY_CERTIFICATE,
+  // TODO(alcutter): rename these to LEAFDATA_TOO_LONG or similar?
+  CERTIFICATE_TOO_LONG,
+  CERTIFICATE_CHAIN_TOO_LONG,
+  INVALID_HASH_ALGORITHM,
+  INVALID_SIGNATURE_ALGORITHM,
+  SIGNATURE_TOO_LONG,
+  INVALID_HASH_LENGTH,
+  EMPTY_PRECERTIFICATE_CHAIN,
+  UNSUPPORTED_VERSION,
+  EXTENSIONS_TOO_LONG,
+  INVALID_KEYID_LENGTH,
+  EMPTY_LIST,
+  EMPTY_ELEM_IN_LIST,
+  LIST_ELEM_TOO_LONG,
+  LIST_TOO_LONG,
+  EXTENSIONS_NOT_ORDERED,
+};
+
+std::ostream& operator<<(std::ostream& stream, const SerializeResult& r);
+
+enum class DeserializeResult {
+  OK,
+  INPUT_TOO_SHORT,
+  INVALID_HASH_ALGORITHM,
+  INVALID_SIGNATURE_ALGORITHM,
+  INPUT_TOO_LONG,
+  UNSUPPORTED_VERSION,
+  INVALID_LIST_ENCODING,
+  EMPTY_LIST,
+  EMPTY_ELEM_IN_LIST,
+  UNKNOWN_LEAF_TYPE,
+  UNKNOWN_LOGENTRY_TYPE,
+  EXTENSIONS_TOO_LONG,
+  EXTENSIONS_NOT_ORDERED,
+};
+
+std::ostream& operator<<(std::ostream& stream, const DeserializeResult& r);
+
+///////////////////////////////////////////////////////////////////////////////
+// Basic serialization functions.                                            //
+///////////////////////////////////////////////////////////////////////////////
+template <class T>
+void WriteUint(T in, size_t bytes, std::string* output) {
+  CHECK_LE(bytes, sizeof(in));
+  CHECK(bytes == sizeof(in) || in >> (bytes * 8) == 0);
+  for (; bytes > 0; --bytes)
+    output->push_back(((in & (static_cast<T>(0xff) << ((bytes - 1) * 8))) >>
+                       ((bytes - 1) * 8)));
+}
+
+// Fixed-length byte array.
+void WriteFixedBytes(const std::string& in, std::string* output);
+
+// Variable-length byte array.
+// Caller is responsible for checking |in| <= max_length
+// TODO(ekasper): could return a bool instead.
+void WriteVarBytes(const std::string& in, size_t max_length,
+                   std::string* output);
+
+SerializeResult WriteList(const repeated_string& in, size_t max_elem_length,
+                          size_t max_total_length, std::string* output);
+
+SerializeResult WriteDigitallySigned(const ct::DigitallySigned& sig,
+                                     std::string* output);
+
+namespace constants {
+static const size_t kMaxSignatureLength = (1 << 16) - 1;
+static const size_t kHashAlgorithmLengthInBytes = 1;
+static const size_t kSigAlgorithmLengthInBytes = 1;
+}  // namespace constants
+
+namespace internal {
+
+// Returns the number of bytes needed to store a value up to max_length.
+size_t PrefixLength(size_t max_length);
+
+}  // namespace internal
+
+}  // namespace serializer
+
+}  // namespace cert_trans
+
+class TLSDeserializer {
+ public:
+  // We do not make a copy, so input must remain valid.
+  // TODO(pphaneuf): And so we should take a string *, not a string &
+  // (which could be to a temporary, and not valid once the
+  // constructor returns).
+  explicit TLSDeserializer(const std::string& input);
+
+  bool ReadFixedBytes(size_t bytes, std::string* result);
+
+  bool ReadVarBytes(size_t max_length, std::string* result);
+
+  cert_trans::serialization::DeserializeResult ReadList(
+      size_t max_total_length, size_t max_elem_length, repeated_string* out);
+
+  cert_trans::serialization::DeserializeResult ReadDigitallySigned(
+      ct::DigitallySigned* sig);
+
+  bool ReachedEnd() const {
+    return bytes_remaining_ == 0;
+  }
+
+  template <class T>
+  bool ReadUint(size_t bytes, T* result) {
+    if (bytes_remaining_ < bytes)
+      return false;
+    T res = 0;
+    for (size_t i = 0; i < bytes; ++i) {
+      res = (res << 8) | static_cast<unsigned char>(*current_pos_);
+      ++current_pos_;
+    }
+
+    bytes_remaining_ -= bytes;
+    *result = res;
+    return true;
+  }
+
+ private:
+  bool ReadLengthPrefix(size_t max_length, size_t* result);
+  const char* current_pos_;
+  size_t bytes_remaining_;
+
+  DISALLOW_COPY_AND_ASSIGN(TLSDeserializer);
+};
+
+
+#endif
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/xjson_serializer.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/xjson_serializer.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/xjson_serializer.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/xjson_serializer.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,177 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "proto/xjson_serializer.h"
+
+#include <glog/logging.h>
+#include <math.h>
+#include <string>
+
+#include "proto/ct.pb.h"
+#include "proto/serializer.h"
+
+using cert_trans::serialization::SerializeResult;
+using cert_trans::serialization::DeserializeResult;
+using cert_trans::serialization::WriteDigitallySigned;
+using cert_trans::serialization::WriteFixedBytes;
+using cert_trans::serialization::WriteUint;
+using cert_trans::serialization::WriteVarBytes;
+using ct::DigitallySigned;
+using ct::DigitallySigned_HashAlgorithm_IsValid;
+using ct::DigitallySigned_SignatureAlgorithm_IsValid;
+using ct::LogEntry;
+using ct::LogEntryType_IsValid;
+using ct::MerkleTreeLeaf;
+using ct::SignedCertificateTimestamp;
+using ct::SignedCertificateTimestampList;
+using ct::SthExtension;
+using ct::SctExtension;
+using ct::Version_IsValid;
+using google::protobuf::RepeatedPtrField;
+using std::string;
+
+
+namespace {
+
+
+const size_t kMaxJsonLength = (1 << 24) - 1;
+
+
+SerializeResult CheckJsonFormat(const string& json) {
+  if (json.empty())
+    return SerializeResult::EMPTY_CERTIFICATE;
+  if (json.size() > kMaxJsonLength)
+    return SerializeResult::CERTIFICATE_TOO_LONG;
+  return SerializeResult::OK;
+}
+
+
+string V1LeafData(const LogEntry& entry) {
+  CHECK(entry.has_x_json_entry());
+  return entry.x_json_entry().json();
+}
+
+
+SerializeResult SerializeV1SCTSignatureInput(
+    const SignedCertificateTimestamp& sct, const LogEntry& entry,
+    string* result) {
+  CHECK_NOTNULL(result);
+  if (sct.version() != ct::V1) {
+    return SerializeResult::UNSUPPORTED_VERSION;
+  }
+  const string json(entry.x_json_entry().json());
+  SerializeResult res = CheckJsonFormat(json);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  const string extensions(sct.extensions());
+  res = CheckExtensionsFormat(extensions);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  result->clear();
+  WriteUint(ct::V1, Serializer::kVersionLengthInBytes, result);
+  WriteUint(ct::CERTIFICATE_TIMESTAMP, Serializer::kSignatureTypeLengthInBytes,
+            result);
+  WriteUint(sct.timestamp(), Serializer::kTimestampLengthInBytes, result);
+  WriteUint(ct::X_JSON_ENTRY, Serializer::kLogEntryTypeLengthInBytes, result);
+  WriteVarBytes(json, kMaxJsonLength, result);
+  WriteVarBytes(extensions, Serializer::kMaxExtensionsLength, result);
+  return SerializeResult::OK;
+}
+
+
+SerializeResult SerializeV1SCTMerkleTreeLeaf(
+    const ct::SignedCertificateTimestamp& sct, const ct::LogEntry& entry,
+    string* result) {
+  CHECK_NOTNULL(result);
+  if (sct.version() != ct::V1) {
+    return SerializeResult::UNSUPPORTED_VERSION;
+  }
+  const string json(entry.x_json_entry().json());
+  SerializeResult res = CheckJsonFormat(json);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  const string extensions(sct.extensions());
+  res = CheckExtensionsFormat(extensions);
+  if (res != SerializeResult::OK) {
+    return res;
+  }
+  result->clear();
+  WriteUint(ct::V1, Serializer::kVersionLengthInBytes, result);
+  WriteUint(ct::TIMESTAMPED_ENTRY, Serializer::kMerkleLeafTypeLengthInBytes,
+            result);
+  WriteUint(sct.timestamp(), Serializer::kTimestampLengthInBytes, result);
+  WriteUint(ct::X_JSON_ENTRY, Serializer::kLogEntryTypeLengthInBytes, result);
+  WriteVarBytes(json, kMaxJsonLength, result);
+  WriteVarBytes(extensions, Serializer::kMaxExtensionsLength, result);
+  return SerializeResult::OK;
+}
+
+
+DeserializeResult DeserializeV1SCTMerkleTreeLeaf(TLSDeserializer* des,
+                                                 MerkleTreeLeaf* leaf) {
+  CHECK_NOTNULL(des);
+  CHECK_NOTNULL(leaf);
+
+  unsigned int version;
+  if (!des->ReadUint(Serializer::kVersionLengthInBytes, &version)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+
+  if (version != ct::V1) {
+    return DeserializeResult::UNSUPPORTED_VERSION;
+  }
+  leaf->set_version(ct::V1);
+
+  unsigned int type;
+  if (!des->ReadUint(Serializer::kMerkleLeafTypeLengthInBytes, &type)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+  if (type != ct::TIMESTAMPED_ENTRY) {
+    return DeserializeResult::UNKNOWN_LEAF_TYPE;
+  }
+  leaf->set_type(ct::TIMESTAMPED_ENTRY);
+
+  ct::TimestampedEntry* const entry = leaf->mutable_timestamped_entry();
+
+  uint64_t timestamp;
+  if (!des->ReadUint(Serializer::kTimestampLengthInBytes, &timestamp)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+  entry->set_timestamp(timestamp);
+
+  unsigned int entry_type;
+  if (!des->ReadUint(Serializer::kLogEntryTypeLengthInBytes, &entry_type)) {
+    return DeserializeResult::INPUT_TOO_SHORT;
+  }
+
+  CHECK(LogEntryType_IsValid(entry_type));
+  entry->set_entry_type(static_cast<ct::LogEntryType>(entry_type));
+
+  switch (entry_type) {
+    case ct::X_JSON_ENTRY: {
+      string json;
+      if (!des->ReadVarBytes(kMaxJsonLength, &json)) {
+        return DeserializeResult::INPUT_TOO_SHORT;
+      }
+      entry->mutable_signed_entry()->set_json(json);
+      return ReadExtensionsV1(des, entry);
+    }
+
+    case ct::UNKNOWN_ENTRY_TYPE: {
+      // handled below.
+      break;
+    }
+  }
+  return DeserializeResult::UNKNOWN_LOGENTRY_TYPE;
+}
+
+
+}  // namespace
+
+
+void ConfigureSerializerForV1XJSON() {
+  Serializer::ConfigureV1(V1LeafData, SerializeV1SCTSignatureInput,
+                          SerializeV1SCTMerkleTreeLeaf);
+  Deserializer::Configure(DeserializeV1SCTMerkleTreeLeaf);
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/xjson_serializer.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/xjson_serializer.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/proto/xjson_serializer.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/proto/xjson_serializer.h	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,17 @@
+/* -*- mode: c++; indent-tabs-mode: nil -*- */
+#ifndef CERT_TRANS_PROTO_XJSON_SERIALIZER_H_
+#define CERT_TRANS_PROTO_XJSON_SERIALIZER_H_
+
+#include <glog/logging.h>
+#include <google/protobuf/repeated_field.h>
+#include <stdint.h>
+#include <string>
+
+#include "base/macros.h"
+#include "proto/ct.pb.h"
+
+
+void ConfigureSerializerForV1XJSON();
+
+
+#endif  // CERT_TRANS_PROTO_XJSON_SERIALIZER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,193 @@
+#include <functional>
+
+#include "log/frontend.h"
+#include "server/certificate_handler.h"
+#include "server/json_output.h"
+#include "util/json_wrapper.h"
+#include "util/status.h"
+#include "util/thread_pool.h"
+
+namespace cert_trans {
+
+using ct::LogEntry;
+using ct::SignedCertificateTimestamp;
+using std::bind;
+using std::make_shared;
+using std::move;
+using std::multimap;
+using std::placeholders::_1;
+using std::shared_ptr;
+using std::string;
+using std::unique_ptr;
+using util::Status;
+
+
+namespace {
+
+
+bool ExtractChain(libevent::Base* base, evhttp_request* req,
+                  CertChain* chain) {
+  if (evhttp_request_get_command(req) != EVHTTP_REQ_POST) {
+    SendJsonError(base, req, HTTP_BADMETHOD, "Method not allowed.");
+    return false;
+  }
+
+  // TODO(pphaneuf): Should we check that Content-Type says
+  // "application/json", as recommended by RFC4627?
+  JsonObject json_body(evhttp_request_get_input_buffer(req));
+  if (!json_body.Ok() || !json_body.IsType(json_type_object)) {
+    SendJsonError(base, req, HTTP_BADREQUEST,
+                  "Unable to parse provided JSON.");
+    return false;
+  }
+
+  JsonArray json_chain(json_body, "chain");
+  if (!json_chain.Ok()) {
+    SendJsonError(base, req, HTTP_BADREQUEST,
+                  "Unable to parse provided JSON.");
+    return false;
+  }
+
+  VLOG(2) << "ExtractChain chain:\n" << json_chain.DebugString();
+
+  for (int i = 0; i < json_chain.Length(); ++i) {
+    JsonString json_cert(json_chain, i);
+    if (!json_cert.Ok()) {
+      SendJsonError(base, req, HTTP_BADREQUEST,
+                    "Unable to parse provided JSON.");
+      return false;
+    }
+
+    unique_ptr<Cert> cert(Cert::FromDerString(json_cert.FromBase64()));
+    if (!cert) {
+      SendJsonError(base, req, HTTP_BADREQUEST,
+                    "Unable to parse provided chain.");
+      return false;
+    }
+
+    chain->AddCert(move(cert));
+  }
+
+  return true;
+}
+
+
+CertSubmissionHandler* MaybeCreateSubmissionHandler(
+    const CertChecker* checker) {
+  if (checker != nullptr) {
+    return new CertSubmissionHandler(checker);
+  }
+  return nullptr;
+}
+
+
+}  // namespace
+
+
+CertificateHttpHandler::CertificateHttpHandler(
+    LogLookup* log_lookup, const ReadOnlyDatabase* db,
+    const ClusterStateController* controller, const CertChecker* cert_checker,
+    Frontend* frontend, ThreadPool* pool, libevent::Base* event_base,
+    StalenessTracker* staleness_tracker)
+    : HttpHandler(log_lookup, db, controller, pool, event_base,
+                  staleness_tracker),
+      cert_checker_(cert_checker),
+      submission_handler_(MaybeCreateSubmissionHandler(cert_checker_)),
+      frontend_(frontend) {
+}
+
+
+void CertificateHttpHandler::AddHandlers(libevent::HttpServer* server) {
+  // TODO(alcutter): Support this for mirrors too
+  if (cert_checker_) {
+    // Don't really need to proxy this one, but may as well just to keep
+    // everything tidy:
+    AddProxyWrappedHandler(server, "/ct/v1/get-roots",
+                           bind(&CertificateHttpHandler::GetRoots, this, _1));
+  }
+  if (frontend_) {
+    // Proxy the add-* calls too, technically we could serve them, but a
+    // more up-to-date node will have a better chance of handling dupes
+    // correctly, rather than bloating the tree.
+    AddProxyWrappedHandler(server, "/ct/v1/add-chain",
+                           bind(&CertificateHttpHandler::AddChain, this, _1));
+    AddProxyWrappedHandler(server, "/ct/v1/add-pre-chain",
+                           bind(&CertificateHttpHandler::AddPreChain, this,
+                                _1));
+  }
+}
+
+
+void CertificateHttpHandler::GetRoots(evhttp_request* req) const {
+  if (evhttp_request_get_command(req) != EVHTTP_REQ_GET) {
+    return SendJsonError(event_base_, req, HTTP_BADMETHOD,
+                         "Method not allowed.");
+  }
+
+  JsonArray roots;
+  for (const auto& trusted_cert : cert_checker_->GetTrustedCertificates()) {
+    string cert;
+    if (trusted_cert.second->DerEncoding(&cert) != util::Status::OK) {
+      LOG(ERROR) << "Cert encoding failed";
+      return SendJsonError(event_base_, req, HTTP_INTERNAL,
+                           "Serialisation failed.");
+    }
+    roots.AddBase64(cert);
+  }
+
+  JsonObject json_reply;
+  json_reply.Add("certificates", roots);
+
+  SendJsonReply(event_base_, req, HTTP_OK, json_reply);
+}
+
+
+void CertificateHttpHandler::AddChain(evhttp_request* req) {
+  const shared_ptr<CertChain> chain(make_shared<CertChain>());
+  if (!ExtractChain(event_base_, req, chain.get())) {
+    return;
+  }
+
+  pool_->Add(
+      bind(&CertificateHttpHandler::BlockingAddChain, this, req, chain));
+}
+
+
+void CertificateHttpHandler::AddPreChain(evhttp_request* req) {
+  const shared_ptr<PreCertChain> chain(make_shared<PreCertChain>());
+  if (!ExtractChain(event_base_, req, chain.get())) {
+    return;
+  }
+
+  pool_->Add(
+      bind(&CertificateHttpHandler::BlockingAddPreChain, this, req, chain));
+}
+
+
+void CertificateHttpHandler::BlockingAddChain(
+    evhttp_request* req, const shared_ptr<CertChain>& chain) const {
+  SignedCertificateTimestamp sct;
+
+  LogEntry entry;
+  const Status status(frontend_->QueueProcessedEntry(
+      submission_handler_->ProcessX509Submission(chain.get(), &entry), entry,
+      &sct));
+
+  AddEntryReply(req, status, sct);
+}
+
+
+void CertificateHttpHandler::BlockingAddPreChain(
+    evhttp_request* req, const shared_ptr<PreCertChain>& chain) const {
+  SignedCertificateTimestamp sct;
+
+  LogEntry entry;
+  const Status status(frontend_->QueueProcessedEntry(
+      submission_handler_->ProcessPreCertSubmission(chain.get(), &entry),
+      entry, &sct));
+
+  AddEntryReply(req, status, sct);
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler.h	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,51 @@
+#ifndef CERT_TRANS_SERVER_CERTIFICATE_HANDLER_H_
+#define CERT_TRANS_SERVER_CERTIFICATE_HANDLER_H_
+
+#include "log/cert_submission_handler.h"
+#include "log/database.h"
+#include "log/logged_entry.h"
+#include "server/handler.h"
+#include "server/staleness_tracker.h"
+
+namespace cert_trans {
+
+
+class CertificateHttpHandler : public HttpHandler {
+ public:
+  // Does not take ownership of its parameters, which must outlive
+  // this instance. The |frontend| and |cert_checker| parameters can be NULL,
+  // in which case this server will not accept "add-chain" and "add-pre-chain"
+  // requests.
+  CertificateHttpHandler(LogLookup* log_lookup, const ReadOnlyDatabase* db,
+                         const ClusterStateController* controller,
+                         const CertChecker* cert_checker, Frontend* frontend,
+                         ThreadPool* pool, libevent::Base* event_base,
+                         StalenessTracker* staleness_tracker);
+
+  ~CertificateHttpHandler() = default;
+
+ protected:
+  void AddHandlers(libevent::HttpServer* server) override;
+
+ private:
+  const CertChecker* const cert_checker_;
+  const std::unique_ptr<CertSubmissionHandler> submission_handler_;
+  Frontend* const frontend_;
+
+  void GetRoots(evhttp_request* req) const;
+  void AddChain(evhttp_request* req);
+  void AddPreChain(evhttp_request* req);
+
+  void BlockingAddChain(evhttp_request* req,
+                        const std::shared_ptr<CertChain>& chain) const;
+  void BlockingAddPreChain(evhttp_request* req,
+                           const std::shared_ptr<PreCertChain>& chain) const;
+
+  DISALLOW_COPY_AND_ASSIGN(CertificateHttpHandler);
+};
+
+
+}  // namespace cert_trans
+
+
+#endif  // CERT_TRANS_SERVER_CERTIFICATE_HANDLER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler_v2.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler_v2.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler_v2.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler_v2.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,92 @@
+#include <functional>
+
+#include "log/frontend.h"
+#include "server/certificate_handler_v2.h"
+#include "server/json_output.h"
+#include "util/json_wrapper.h"
+#include "util/status.h"
+#include "util/thread_pool.h"
+
+namespace cert_trans {
+
+using ct::LogEntry;
+using ct::SignedCertificateTimestamp;
+using std::bind;
+using std::make_shared;
+using std::multimap;
+using std::placeholders::_1;
+using std::shared_ptr;
+using std::string;
+using std::unique_ptr;
+using util::Status;
+
+
+CertificateHttpHandlerV2::CertificateHttpHandlerV2(
+    LogLookup* log_lookup, const ReadOnlyDatabase* db,
+    const ClusterStateController* controller, const CertChecker* cert_checker,
+    Frontend* frontend, ThreadPool* pool, libevent::Base* event_base,
+    StalenessTracker* staleness_tracker)
+    : HttpHandlerV2(log_lookup, db, controller, pool, event_base,
+                    staleness_tracker),
+      cert_checker_(CHECK_NOTNULL(cert_checker)),
+      submission_handler_(cert_checker_),
+      frontend_(frontend) {
+}
+
+
+void CertificateHttpHandlerV2::AddHandlers(libevent::HttpServer* server) {
+  // TODO(alcutter): Support this for mirrors too
+  if (cert_checker_) {
+    // Don't really need to proxy this one, but may as well just to keep
+    // everything tidy:
+    AddProxyWrappedHandler(server, "/ct/v2/get-roots",
+                           bind(&CertificateHttpHandlerV2::GetRoots, this,
+                                _1));
+  }
+  if (frontend_) {
+    // Proxy the add-* calls too, technically we could serve them, but a
+    // more up-to-date node will have a better chance of handling dupes
+    // correctly, rather than bloating the tree.
+    AddProxyWrappedHandler(server, "/ct/v2/add-chain",
+                           bind(&CertificateHttpHandlerV2::AddChain, this,
+                                _1));
+    AddProxyWrappedHandler(server, "/ct/v2/add-pre-chain",
+                           bind(&CertificateHttpHandlerV2::AddPreChain, this,
+                                _1));
+  }
+}
+
+
+void CertificateHttpHandlerV2::GetRoots(evhttp_request* req) const {
+  return SendJsonError(event_base_, req, HTTP_NOTIMPLEMENTED,
+                       "Not yet implemented.");
+}
+
+
+void CertificateHttpHandlerV2::AddChain(evhttp_request* req) {
+  return SendJsonError(event_base_, req, HTTP_NOTIMPLEMENTED,
+                       "Not yet implemented.");
+}
+
+
+void CertificateHttpHandlerV2::AddPreChain(evhttp_request* req) {
+  return SendJsonError(event_base_, req, HTTP_NOTIMPLEMENTED,
+                       "Not yet implemented.");
+}
+
+
+void CertificateHttpHandlerV2::BlockingAddChain(
+    evhttp_request* req, const shared_ptr<CertChain>& chain) const {
+  return SendJsonError(event_base_, req, HTTP_NOTIMPLEMENTED,
+                       "Not yet implemented.");
+}
+
+
+void CertificateHttpHandlerV2::BlockingAddPreChain(
+    evhttp_request* req, const shared_ptr<PreCertChain>& chain) const {
+  return SendJsonError(event_base_, req, HTTP_NOTIMPLEMENTED,
+                       "Not yet implemented.");
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler_v2.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler_v2.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler_v2.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/certificate_handler_v2.h	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,51 @@
+#ifndef CERT_TRANS_SERVER_CERTIFICATE_HANDLER_V2_H_
+#define CERT_TRANS_SERVER_CERTIFICATE_HANDLER_V2_H_
+
+#include "log/cert_submission_handler.h"
+#include "log/database.h"
+#include "log/logged_entry.h"
+#include "server/handler_v2.h"
+#include "server/staleness_tracker.h"
+
+namespace cert_trans {
+
+
+class CertificateHttpHandlerV2 : public HttpHandlerV2 {
+ public:
+  // Does not take ownership of its parameters, which must outlive
+  // this instance. The |frontend| and |cert_checker| parameters can be NULL,
+  // in which case this server will not accept "add-chain" and "add-pre-chain"
+  // requests.
+  CertificateHttpHandlerV2(LogLookup* log_lookup, const ReadOnlyDatabase* db,
+                           const ClusterStateController* controller,
+                           const CertChecker* cert_checker, Frontend* frontend,
+                           ThreadPool* pool, libevent::Base* event_base,
+                           StalenessTracker* staleness_tracker);
+
+  ~CertificateHttpHandlerV2() = default;
+
+ protected:
+  void AddHandlers(libevent::HttpServer* server) override;
+
+ private:
+  const CertChecker* const cert_checker_;
+  const CertSubmissionHandler submission_handler_;
+  Frontend* const frontend_;
+
+  void GetRoots(evhttp_request* req) const;
+  void AddChain(evhttp_request* req);
+  void AddPreChain(evhttp_request* req);
+
+  void BlockingAddChain(evhttp_request* req,
+                        const std::shared_ptr<CertChain>& chain) const;
+  void BlockingAddPreChain(evhttp_request* req,
+                           const std::shared_ptr<PreCertChain>& chain) const;
+
+  DISALLOW_COPY_AND_ASSIGN(CertificateHttpHandlerV2);
+};
+
+
+}  // namespace cert_trans
+
+
+#endif  // CERT_TRANS_SERVER_CERTIFICATE_HANDLER_V2_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/ct-dns-server.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/ct-dns-server.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/ct-dns-server.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/ct-dns-server.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,289 @@
+#include <gflags/gflags.h>
+#include <ldns/ldns.h>
+#include <iostream>
+#include <sstream>
+#include <string>
+
+#include "log/log_lookup.h"
+#include "log/logged_entry.h"
+#include "log/sqlite_db.h"
+#include "proto/cert_serializer.h"
+#include "proto/ct.pb.h"
+#include "server/event.h"
+#include "util/init.h"
+#include "util/util.h"
+
+using cert_trans::LogLookup;
+using cert_trans::LoggedEntry;
+using cert_trans::SQLiteDB;
+using ct::SignedTreeHead;
+using google::RegisterFlagValidator;
+using std::string;
+using std::stringstream;
+
+DEFINE_int32(port, 0, "Server port");
+DEFINE_string(domain, "", "Domain");
+DEFINE_string(db, "", "Database for certificate and tree storage");
+
+// Basic sanity checks on flag values.
+static bool ValidatePort(const char*, int32_t port) {
+  return (port <= 0 || port > 65535);
+}
+
+static const bool port_dummy =
+    RegisterFlagValidator(&FLAGS_port, &ValidatePort);
+
+static bool NonEmptyString(const char*, const string& str) {
+  return !str.empty();
+}
+
+static const bool domain_dummy =
+    RegisterFlagValidator(&FLAGS_domain, &NonEmptyString);
+
+class CTUDPDNSServer : public UDPServer {
+ public:
+  CTUDPDNSServer(const string& domain, SQLiteDB* db, EventLoop* loop, int fd)
+      : UDPServer(loop, fd), domain_(domain), lookup_(db), db_(db) {
+  }
+
+  virtual void PacketRead(const sockaddr_in& from, const char* buf,
+                          size_t len) {
+    ldns_pkt* packet = NULL;
+
+    ldns_status ret = ldns_wire2pkt(&packet, (const uint8_t*)buf, len);
+    if (ret != LDNS_STATUS_OK) {
+      LOG(INFO) << "Bad DNS packet";
+      return;
+    }
+
+    // ldns_pkt_print(stdout, packet);
+
+    if (ldns_pkt_qr(packet) != 0) {
+      LOG(INFO) << "Packet is not a query";
+      return;
+    }
+
+    if (ldns_pkt_get_opcode(packet) != LDNS_PACKET_QUERY) {
+      LOG(INFO) << "Packet has bad opcode";
+      return;
+    }
+
+    ldns_pkt* answers = ldns_pkt_new();
+    ldns_pkt_set_id(answers, ldns_pkt_id(packet));
+    ldns_pkt_set_qr(answers, true);
+
+    ldns_rr_list* questions = ldns_pkt_question(packet);
+
+    ldns_pkt_safe_push_rr_list(answers, LDNS_SECTION_QUESTION,
+                               ldns_rr_list_clone(questions));
+
+    for (size_t n = 0; n < ldns_rr_list_rr_count(questions); ++n) {
+      ldns_rr* question = ldns_rr_list_rr(questions, n);
+
+      if (ldns_rr_get_type(question) != LDNS_RR_TYPE_TXT) {
+        LOG(INFO) << "Question is not TXT";
+        // FIXME(benl): set error response?
+        continue;
+      }
+
+      ldns_rdf* owner = ldns_rr_owner(question);
+      if (ldns_rdf_get_type(owner) != LDNS_RDF_TYPE_DNAME) {
+        LOG(INFO) << "Owner is not a dname";
+        continue;
+      }
+
+      ldns_buffer* dname = ldns_buffer_new(512);
+      if (ldns_rdf2buffer_str_dname(dname, owner) != LDNS_STATUS_OK) {
+        LOG(INFO) << "Can't decode owner";
+        continue;
+      }
+
+      char* owner_name_raw = ldns_buffer2str(dname);
+      std::string owner_name(owner_name_raw);
+      free(owner_name_raw);
+      owner_name_raw = NULL;
+      ldns_buffer_free(dname);
+      dname = NULL;
+
+      LOG(INFO) << "Question is TXT of " << owner_name;
+
+      if (owner_name.length() <= domain_.length() ||
+          owner_name.compare(owner_name.length() - domain_.length(),
+                             domain_.length(), domain_) != 0) {
+        LOG(INFO) << "Question is not for our domain";
+        continue;
+      }
+
+      std::string response = Response(
+          owner_name.substr(0, owner_name.length() - domain_.length() - 1));
+
+      ldns_rr* answer = ldns_rr_new();
+      ldns_rr_set_owner(answer, ldns_rdf_new_frm_str(LDNS_RDF_TYPE_DNAME,
+                                                     owner_name.c_str()));
+      ldns_rr_set_type(answer, LDNS_RR_TYPE_TXT);
+      ldns_rr_set_ttl(answer, 123);
+      ldns_rr_push_rdf(answer, ldns_rdf_new_frm_str(LDNS_RDF_TYPE_STR,
+                                                    response.c_str()));
+      ldns_pkt_safe_push_rr(answers, LDNS_SECTION_ANSWER, answer);
+    }
+    ldns_pkt_free(packet);
+
+    char* answer_str = ldns_pkt2str(answers);
+    LOG(INFO) << "Answer is " << answer_str;
+    free(answer_str);
+
+    uint8_t* wire_answer;
+    size_t answer_size;
+    if (ldns_pkt2wire(&wire_answer, answers, &answer_size) != LDNS_STATUS_OK) {
+      LOG(ERROR) << "Can't make wire answer";
+      return;
+    }
+    QueuePacket(from, wire_answer, answer_size);
+    free(wire_answer);
+    ldns_pkt_free(answers);
+  }
+
+ private:
+  string Response(string question) {
+    if (question == "sth")
+      return STH();
+
+    size_t dot = question.find_last_of('.');
+    if (dot == string::npos)
+      return question + " not understood";
+
+    string head = question.substr(0, dot);
+    string tail = question.substr(dot + 1);
+    LOG(INFO) << "head = " << head << ", tail = " << tail;
+    if (tail == "tree")
+      return Tree(head);
+    else if (tail == "hash")
+      return Hash(head);
+    else if (tail == "leafhash")
+      return LeafHash(head);
+
+    return question + " is the question.";
+  }
+
+  string LeafHash(const string& index_str) const {
+    int index = atoi(index_str.c_str());
+    LoggedEntry cert;
+    if (db_->LookupByIndex(index, &cert) != db_->LOOKUP_OK)
+      return "No such index";
+    return util::ToBase64(lookup_.LeafHash(cert));
+  }
+
+  string Hash(const string& hash) {
+    db_->ForceNotifySTH();
+
+    // FIXME: decode hash!
+    int64_t index;
+    if (lookup_.GetIndex(hash, &index) != lookup_.OK)
+      return "No such hash";
+
+    stringstream ss;
+    ss << index;
+    return ss.str();
+  }
+
+  string Tree(const string& question) {
+    size_t dot = question.find_first_of('.');
+    if (dot == string::npos)
+      return question + " not understood";
+
+    size_t dot2 = question.find_first_of('.', dot + 1);
+    if (dot2 == string::npos)
+      return question + " not understood";
+
+    string level = question.substr(0, dot);
+    string index = question.substr(dot + 1, dot2 - dot - 1);
+    string size = question.substr(dot2 + 1);
+
+    LOG(INFO) << "level = " << level << ", index = " << index
+              << ", size = " << size;
+
+    ct::ShortMerkleAuditProof proof;
+    if (lookup_.AuditProof(atoi(index.c_str()), atoi(size.c_str()), &proof) !=
+        lookup_.OK)
+      return "Lookup of node " + index + "." + size + " failed";
+
+    int l = atoi(level.c_str());
+    if (l < 0 || l >= proof.path_node_size())
+      return "Level " + level + " is out of range";
+
+    string b64 = util::ToBase64(proof.path_node(l));
+    return b64;
+  }
+
+  string STH() {
+    db_->ForceNotifySTH();
+
+    const SignedTreeHead& sth = lookup_.GetSTH();
+
+    std::string signature;
+    CHECK_EQ(Serializer::SerializeDigitallySigned(sth.signature(), &signature),
+             cert_trans::serialization::SerializeResult::OK);
+
+    stringstream ss;
+    ss << sth.tree_size() << '.' << sth.timestamp() << '.'
+       << util::ToBase64(sth.sha256_root_hash()) << '.'
+       << util::ToBase64(signature);
+
+    return ss.str();
+  }
+
+  string domain_;
+  LogLookup lookup_;
+  SQLiteDB* const db_;
+};
+
+class Keyboard : public Server {
+ public:
+  Keyboard(EventLoop* loop) : Server(loop, 0) {
+  }
+
+  void BytesRead(std::string* rbuffer) {
+    while (!rbuffer->empty()) {
+      ProcessKey(rbuffer->at(0));
+      rbuffer->erase(0, 1);
+    }
+  }
+
+ private:
+  void ProcessKey(char key) {
+    switch (key) {
+      case 'q':
+        loop()->Stop();
+        break;
+
+      case '\n':
+        break;
+
+      default:
+        std::cout << "Don't understand " << key << std::endl;
+        break;
+    }
+  }
+};
+
+int main(int argc, char* argv[]) {
+  util::InitCT(&argc, &argv);
+  ConfigureSerializerForV1CT();
+
+  // TODO(pphaneuf): This current *has* to be SQLite, because it
+  // depends on sharing the database with a ct-server that will
+  // populate it (which FileDB does not support).
+  SQLiteDB db(FLAGS_db);
+
+  EventLoop loop;
+
+  // Mostly so we can have a clean exit for valgrind etc.
+  Keyboard keyboard(&loop);
+
+  int dns_fd;
+  CHECK(Services::InitServer(&dns_fd, FLAGS_port, NULL, SOCK_DGRAM));
+  CTUDPDNSServer dns(FLAGS_domain, &db, &loop, dns_fd);
+
+  LOG(INFO) << "Server listening on port " << FLAGS_port;
+  loop.Forever();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/ct-dns-server-test.py src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/ct-dns-server-test.py
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/ct-dns-server-test.py	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/ct-dns-server-test.py	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,368 @@
+import base64
+import dns.resolver
+import dns.rdatatype
+import logging
+import math
+import os
+import random
+import shlex
+import signal
+import subprocess
+import sys
+import time
+
+NUMBER_OF_CERTS = 100
+
+basepath = os.path.dirname(sys.argv[0])
+
+sys.path.append(os.path.join(basepath, '../../python'))
+from ct.crypto import merkle
+from ct.proto import ct_pb2
+
+tmpdir = sys.argv[1]
+
+class CTDNSLookup:
+    def __init__(self, nameservers, port):
+        self.resolver = dns.resolver.Resolver(configure=False)
+        self.resolver.nameservers = nameservers
+        self.resolver.port = port
+
+    def Get(self, name):
+        answers = self.resolver.query(name, 'TXT')
+        assert answers.rdtype == dns.rdatatype.TXT
+        return answers
+
+    def GetOne(self, name):
+        answers = self.Get(name)
+        assert len(answers) == 1
+        txt = answers[0]
+        assert len(txt.strings) == 1
+        return txt.strings[0]
+
+    def GetSTH(self):
+        sth_str = self.GetOne('sth.example.com')
+        sth = ct_pb2.SignedTreeHead()
+        parts = str(sth_str).split('.')
+        sth.tree_size = int(parts[0])
+        sth.timestamp = int(parts[1])
+        sth.sha256_root_hash = base64.b64decode(parts[2])
+        #FIXME(benl): decompose signature into its parts
+        #sth.signature = base64.b64decode(parts[3])
+        return sth
+
+    def GetEntry(self, level, index, size):
+        return self.GetOne(str(level) + '.' + str(index) + '.' + str(size)
+                           + '.tree.example.com')
+
+    def GetLeafHash(self, index):
+        return self.GetOne(str(index) + '.leafhash.example.com')
+
+class DNSServerRunner:
+    def Run(self, cmd):
+        args = shlex.split(cmd)
+        self.proc = subprocess.Popen(args)
+
+def OpenSSL(*params):
+    logging.info("RUN: openssl " + str(params))
+    null = open("/dev/null")
+    subprocess.check_call(("openssl",) + params, stdout=null, stderr=null)
+
+class timeout:
+    def __init__(self, seconds, error_message='Timeout'):
+        self.seconds = seconds
+        self.error_message = error_message
+
+    def handle_timeout(self, signum, frame):
+        raise TimeoutError(self.error_message)
+
+    def __enter__(self):
+        signal.signal(signal.SIGALRM, self.handle_timeout)
+        signal.alarm(self.seconds)
+
+    def __exit__(self, type, value, traceback):
+        signal.alarm(0)
+
+class CTServer:
+    def __init__(self, cmd, base, ca):
+        self.cmd_ = cmd
+        self.base_ = base
+        self.ca_ = ca
+        self.GenerateKey()
+
+    def __del__(self):
+        self.proc.terminate()
+        self.proc.wait()
+
+    def PrivateKey(self):
+        return self.base_ + "-ct-server-private-key.pem"
+        
+    def PublicKey(self):
+        return self.base_ + "-ct-server-public-key.pem"
+
+    def Database(self):
+        return self.base_ + "-database.sqlite"
+
+    def GenerateKey(self):
+        OpenSSL("ecparam",
+                "-out", self.PrivateKey(),
+                "-name", "secp256r1",
+                "-genkey")
+        OpenSSL("ec",
+                "-in", self.PrivateKey(),
+                "-pubout",
+                "-out", self.PublicKey())
+
+    def URL(self):
+        return "http://localhost:9999/"
+
+    def Run(self):
+        cmd = (self.cmd_ + " -key " + self.PrivateKey() +
+               " -trusted_cert_file " + self.ca_.RootCertificate() +
+               " -sqlite_db " + self.Database() +
+               " -tree_signing_frequency_seconds 1" +
+               " -logtostderr")
+        logging.info("RUN: " + cmd)
+        args = shlex.split(cmd)
+        self.proc = subprocess.Popen(args, stdout=subprocess.PIPE)
+        with timeout(10):
+            while self.proc.stdout.readline() != "READY\n":
+                continue
+
+RootConfig = """[ req ]
+distinguished_name=req_distinguished_name
+prompt=no
+x509_extensions=v3_ca
+
+[ req_distinguished_name ]
+countryName=GB
+stateOrProvinceName=Wales
+localityName=Erw Wen
+0.organizationName=Certificate Transparency Test CA
+
+[ v3_ca ]
+subjectKeyIdentifier=hash
+authorityKeyIdentifier=keyid:always,issuer:always
+basicConstraints=CA:TRUE
+"""
+
+CAConfig = """[ ca ]
+default_ca = CA_default
+
+[ CA_default ]
+default_startdate = 120601000000Z
+default_enddate   = 220601000000Z
+default_md	  = sha1
+unique_subject	  = no
+email_in_dn	  = no
+policy	          = policy_default
+serial            = {serial}
+database          = {database}
+
+[ policy_default ]
+countryName	    = supplied
+organizationName    = supplied
+stateOrProvinceName = optional
+localityName	    = optional
+commonName          = optional
+"""
+
+RequestConfig = """[ req ]
+distinguished_name=req_distinguished_name
+prompt=no
+
+[ req_distinguished_name ]
+countryName=GB
+stateOrProvinceName=Wales
+localityName=Erw Wen
+0.organizationName={subject}
+
+# For the precert
+[ pre ]
+subjectKeyIdentifier=hash
+authorityKeyIdentifier=keyid:always,issuer:always
+basicConstraints=CA:FALSE
+1.3.6.1.4.1.11129.2.4.3=critical,ASN1:NULL
+
+# For the simple cert, without embedded proof extensions
+[ simple ]
+subjectKeyIdentifier=hash
+authorityKeyIdentifier=keyid:always,issuer:always
+basicConstraints=CA:FALSE
+
+# For the cert with an embedded proof
+[ embedded ]
+subjectKeyIdentifier=hash
+authorityKeyIdentifier=keyid:always,issuer:always
+basicConstraints=CA:FALSE
+"""
+
+def WriteFile(name, content):
+    with open(name, "w") as f:
+        f.write(content)
+
+class CA:
+    def __init__(self, base):
+        self.base_ = base
+
+        os.mkdir(self.Directory())
+        
+        open(self.Database(), "w")
+        WriteFile(self.Serial(), "0000000000000001")
+
+        WriteFile(self.RootConfig(), RootConfig)
+        ca_config = CAConfig.format(database = self.Database(),
+                                    serial = self.Serial())
+        WriteFile(self.CAConfig(), ca_config)
+
+        self.GenerateRootCertificate()
+
+        os.mkdir(self.IssuedCertificates())
+
+    def Directory(self):
+        """Where the CA does house-keeping"""
+        return self.base_ + "-housekeeping"
+
+    def Database(self):
+        return self.Directory() + "/database"
+
+    def Serial(self):
+        return self.Directory() + "/serial"
+
+    def RootConfig(self):
+        return self.base_ + "-root-config"
+
+    def CAConfig(self):
+        return self.base_ + "-ca-config"
+
+    def PrivateKey(self):
+        return self.base_ + "-private-key.pem"
+
+    def RootCertificate(self):
+        return self.base_ + "-cert.pem"
+
+    def TempFile(self, name):
+        return self.base_ + "-temp-" + name
+
+    def RequestConfig(self):
+        return self.TempFile("req-config")
+
+    def IssuedCertificates(self):
+        return self.base_ + "-issued"
+
+    def IssuedFile(self, name, subject):
+        return self.IssuedCertificates() + "/" + name + "-" + subject + ".pem"
+
+    def IssuedPrivateKey(self, subject):
+        return self.IssuedFile("private-key", subject)
+
+    def IssuedCertificate(self, subject):
+        return self.IssuedFile("certificate", subject)
+
+    def GenerateRootCertificate(self):
+        csr = self.TempFile("csr")
+        OpenSSL("req",
+                "-new",
+                "-newkey", "rsa:2048",
+                "-keyout", self.PrivateKey(),
+                "-out", csr,
+                "-config", self.RootConfig(),
+                "-nodes")
+        OpenSSL("ca",
+                "-in", csr,
+                "-selfsign",
+                "-keyfile", self.PrivateKey(),
+                "-config", self.CAConfig(),
+                "-extfile", self.RootConfig(),
+                "-extensions", "v3_ca",
+                "-outdir", self.Directory(),
+                "-out", self.RootCertificate(),
+                "-batch")
+
+    def CreateAndLogCert(self, ct_server, subject):
+        WriteFile(self.RequestConfig(), RequestConfig.format(subject=subject))
+        csr = self.TempFile("csr")
+        OpenSSL("req",
+                "-new",
+                "-newkey", "rsa:1024",
+                "-keyout", self.IssuedPrivateKey(subject),
+                "-out", csr,
+                "-config", self.RequestConfig(),
+                "-nodes")
+        OpenSSL("ca",
+                "-in", csr,
+                "-cert", self.RootCertificate(),
+                "-keyfile", self.PrivateKey(),
+                "-config", self.CAConfig(),
+                "-extfile", self.RequestConfig(),
+                "-extensions", "simple",
+                "-outdir", self.Directory(),
+                "-out", self.IssuedCertificate(subject),
+                "-batch")
+
+        # Reverse the order of these to show a bug in ct-server where
+        # it accepts the CA cert even though there's a redundant extra
+        # cert in the chain. At least, I think its a bug.
+        certs = (open(self.IssuedCertificate(subject)).read()
+                 + open(self.RootCertificate()).read())
+        chain_file = self.TempFile("chain")
+        WriteFile(chain_file, certs)
+        subprocess.check_call(("client/ct", "upload",
+                               "-ct_server_submission", chain_file,
+                               "-ct_server", ct_server.URL(),
+                               "-ct_server_public_key", ct_server.PublicKey(),
+                               "-ct_server_response_out", self.TempFile("sct")))
+
+logging.basicConfig(level="WARNING")
+
+# Set up our test CA
+ca = CA(tmpdir + "/ct-test-ca")
+
+# Run a CT server
+ct_cmd = basepath + "/ct-server"
+ct_server = CTServer(ct_cmd, tmpdir + "/ct-test", ca)
+ct_server.Run()
+
+# Add nn certs to the CT server
+for x in range(NUMBER_OF_CERTS):
+    ca.CreateAndLogCert(ct_server, "TestCertificate" + str(x))
+
+# Make sure server has had enough time to assimilate all certs
+time.sleep(2)
+
+# We'll need the DB for the DNS server
+db = ct_server.Database()
+# Kill the CT server (shared database access not currently supported)
+del ct_server
+
+# Now run the DNS server from the same database
+server_cmd = basepath + "/ct-dns-server --port=1111 --domain=example.com. --db=" + db
+runner = DNSServerRunner()
+runner.Run(server_cmd)
+
+# Get the STH
+lookup = CTDNSLookup(['127.0.0.1'], 1111)
+
+sth = lookup.GetSTH()
+logging.info("sth = " + str(sth))
+logging.info("size = " + str(sth.tree_size))
+
+assert sth.tree_size == NUMBER_OF_CERTS
+
+# test all the entries
+for index in range(NUMBER_OF_CERTS):
+    leaf_hash = lookup.GetLeafHash(index)
+    logging.info("index = " + str(index) + " hash = " + leaf_hash)
+
+    verifier = merkle.MerkleVerifier()
+    audit_path = []
+    for level in range(0, verifier.audit_path_length(index, sth.tree_size)):
+        hash = lookup.GetEntry(level, index, sth.tree_size)
+        logging.info("hash = " + hash)
+        audit_path.append(base64.b64decode(hash))
+
+    logging.info("path = " + str(map(base64.b64encode, audit_path)))
+
+    assert verifier.verify_leaf_hash_inclusion(base64.b64decode(leaf_hash),
+                                               index, audit_path, sth)
+
+print "DNS Server test passed"
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/ct-mirror.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/ct-mirror.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/ct-mirror.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/ct-mirror.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,393 @@
+/* -*- indent-tabs-mode: nil -*- */
+
+#include <event2/buffer.h>
+#include <event2/thread.h>
+#include <gflags/gflags.h>
+#include <openssl/crypto.h>
+#include <openssl/err.h>
+#include <signal.h>
+#include <unistd.h>
+#include <chrono>
+#include <csignal>
+#include <cstring>
+#include <functional>
+#include <iostream>
+#include <memory>
+#include <mutex>
+#include <string>
+#include <utility>
+
+#include "client/async_log_client.h"
+#include "config.h"
+#include "fetcher/continuous_fetcher.h"
+#include "fetcher/peer_group.h"
+#include "fetcher/remote_peer.h"
+#include "log/cluster_state_controller.h"
+#include "log/ct_extensions.h"
+#include "log/database.h"
+#include "log/etcd_consistent_store.h"
+#include "log/log_lookup.h"
+#include "log/strict_consistent_store.h"
+#include "merkletree/compact_merkle_tree.h"
+#include "merkletree/merkle_verifier.h"
+#include "monitoring/latency.h"
+#include "monitoring/monitoring.h"
+#include "monitoring/registry.h"
+#include "proto/cert_serializer.h"
+#include "server/certificate_handler.h"
+#include "server/json_output.h"
+#include "server/metrics.h"
+#include "server/proxy.h"
+#include "server/server.h"
+#include "server/server_helper.h"
+#include "util/etcd.h"
+#include "util/init.h"
+#include "util/libevent_wrapper.h"
+#include "util/masterelection.h"
+#include "util/periodic_closure.h"
+#include "util/read_key.h"
+#include "util/status.h"
+#include "util/thread_pool.h"
+#include "util/util.h"
+#include "util/uuid.h"
+
+DEFINE_int32(log_stats_frequency_seconds, 3600,
+             "Interval for logging summary statistics. Approximate: the "
+             "server will log statistics if in the beginning of its select "
+             "loop, at least this period has elapsed since the last log time. "
+             "Must be greater than 0.");
+DEFINE_int32(target_poll_frequency_seconds, 10,
+             "How often should the target log be polled for updates.");
+DEFINE_int32(num_http_server_threads, 16,
+             "Number of threads for servicing the incoming HTTP requests.");
+DEFINE_string(target_log_uri, "",
+              "URI of the log to mirror, or empty to disable mirroring.");
+DEFINE_string(
+    target_public_key, "",
+    "PEM-encoded server public key file of the log we're mirroring.");
+DEFINE_int32(local_sth_update_frequency_seconds, 30,
+             "Number of seconds between local checks for updated tree data.");
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::AsyncLogClient;
+using cert_trans::CertificateHttpHandler;
+using cert_trans::ClusterStateController;
+using cert_trans::ConsistentStore;
+using cert_trans::ContinuousFetcher;
+using cert_trans::Counter;
+using cert_trans::Database;
+using cert_trans::EtcdClient;
+using cert_trans::EtcdConsistentStore;
+using cert_trans::Gauge;
+using cert_trans::HttpHandler;
+using cert_trans::Latency;
+using cert_trans::LogLookup;
+using cert_trans::LoggedEntry;
+using cert_trans::MasterElection;
+using cert_trans::PeriodicClosure;
+using cert_trans::Proxy;
+using cert_trans::ReadPublicKey;
+using cert_trans::RemotePeer;
+using cert_trans::ScopedLatency;
+using cert_trans::Server;
+using cert_trans::StalenessTracker;
+using cert_trans::StrictConsistentStore;
+using cert_trans::ThreadPool;
+using cert_trans::Update;
+using cert_trans::UrlFetcher;
+using ct::ClusterNodeState;
+using ct::SignedTreeHead;
+using google::RegisterFlagValidator;
+using std::bind;
+using std::chrono::duration;
+using std::chrono::duration_cast;
+using std::chrono::milliseconds;
+using std::chrono::seconds;
+using std::chrono::steady_clock;
+using std::function;
+using std::lock_guard;
+using std::make_pair;
+using std::make_shared;
+using std::map;
+using std::mutex;
+using std::placeholders::_1;
+using std::shared_ptr;
+using std::string;
+using std::thread;
+using std::unique_ptr;
+using util::HexString;
+using util::StatusOr;
+using util::SyncTask;
+using util::Task;
+
+
+namespace {
+
+
+Gauge<>* latest_local_tree_size_gauge =
+    Gauge<>::New("latest_local_tree_size",
+                 "Size of latest locally available STH.");
+
+Counter<>* inconsistent_sths_received =
+    Counter<>::New("inconsistent_sths_received",
+                   "Number of STHs received from the mirror target whose root "
+                   "hash does not match the locally built tree.");
+
+
+// Basic sanity checks on flag values.
+static bool ValidateRead(const char* flagname, const string& path) {
+  if (access(path.c_str(), R_OK) != 0) {
+    std::cout << "Cannot access " << flagname << " at " << path << std::endl;
+    return false;
+  }
+  return true;
+}
+
+static const bool pubkey_dummy =
+    RegisterFlagValidator(&FLAGS_target_public_key, &ValidateRead);
+
+static bool ValidateIsPositive(const char* flagname, int value) {
+  if (value <= 0) {
+    std::cout << flagname << " must be greater than 0" << std::endl;
+    return false;
+  }
+  return true;
+}
+
+static const bool follow_dummy =
+    RegisterFlagValidator(&FLAGS_target_poll_frequency_seconds,
+                          &ValidateIsPositive);
+}  // namespace
+
+
+void STHUpdater(Database* db, ClusterStateController* cluster_state_controller,
+                mutex* queue_mutex, map<int64_t, ct::SignedTreeHead>* queue,
+                LogLookup* log_lookup, Task* task) {
+  CHECK_NOTNULL(db);
+  CHECK_NOTNULL(cluster_state_controller);
+  CHECK_NOTNULL(queue_mutex);
+  CHECK_NOTNULL(queue);
+  CHECK_NOTNULL(task);
+  CHECK_NOTNULL(log_lookup);
+
+  while (true) {
+    if (task->CancelRequested()) {
+      task->Return(util::Status::CANCELLED);
+    }
+
+    const int64_t local_size(db->TreeSize());
+    latest_local_tree_size_gauge->Set(local_size);
+
+    // log_lookup doesn't yet have the data for the new STHs integrated (that
+    // happens via a callback when the WriteTreeHead() method is called on the
+    // DB), so we'll used a compact tree to pre-validate the STH roots.
+    //
+    // We'll start with one based on the current state of our serving tree and
+    // update it to the STH sizes we're checking.
+    unique_ptr<CompactMerkleTree> new_tree(
+        log_lookup->GetCompactMerkleTree(new Sha256Hasher));
+
+    {
+      lock_guard<mutex> lock(*queue_mutex);
+      unique_ptr<Database::Iterator> entries(
+          db->ScanEntries(new_tree->LeafCount()));
+      while (!queue->empty() &&
+             queue->begin()->second.tree_size() <= local_size) {
+        const SignedTreeHead next_sth(queue->begin()->second);
+        queue->erase(queue->begin());
+
+        // First, if necessary, catch our local compact tree up to the
+        // candidate STH size:
+        {
+          LoggedEntry entry;
+          CHECK_LE(next_sth.tree_size(), local_size);
+          CHECK_GE(next_sth.tree_size(), 0);
+          const uint64_t next_sth_tree_size(
+              static_cast<uint64_t>(next_sth.tree_size()));
+          while (new_tree->LeafCount() < next_sth_tree_size) {
+            CHECK(entries->GetNextEntry(&entry));
+            CHECK(entry.has_sequence_number());
+            CHECK_GE(entry.sequence_number(), 0);
+            const uint64_t entry_sequence_number(
+                static_cast<uint64_t>(entry.sequence_number()));
+            CHECK_EQ(new_tree->LeafCount(), entry_sequence_number);
+            string serialized_leaf;
+            CHECK(entry.SerializeForLeaf(&serialized_leaf));
+            CHECK_EQ(entry_sequence_number + 1,
+                     new_tree->AddLeaf(serialized_leaf));
+          }
+        }
+
+        // If the candidate STH is historical, use the RootAtSnapshot() from
+        // our serving tree, otherwise use the root we just calculated with our
+        // compact tree.
+        const string local_root_at_snapshot(
+            next_sth.tree_size() > log_lookup->GetSTH().tree_size()
+                ? new_tree->CurrentRoot()
+                : log_lookup->RootAtSnapshot(next_sth.tree_size()));
+
+        if (next_sth.sha256_root_hash() != local_root_at_snapshot) {
+          LOG(WARNING) << "Received STH:\n" << next_sth.DebugString()
+                       << " whose root:\n"
+                       << HexString(next_sth.sha256_root_hash())
+                       << "\ndoes not match that of local tree at "
+                       << "corresponding snapshot:\n"
+                       << HexString(local_root_at_snapshot);
+          inconsistent_sths_received->Increment();
+          // TODO(alcutter): We should probably write these bad STHs out to a
+          // separate DB table for later analysis.
+          continue;
+        }
+        LOG(INFO) << "Can serve new STH of size " << next_sth.tree_size()
+                  << " locally";
+        cluster_state_controller->NewTreeHead(next_sth);
+      }
+    }
+
+    std::this_thread::sleep_for(
+        seconds(FLAGS_local_sth_update_frequency_seconds));
+  }
+}
+
+
+shared_ptr<RemotePeer> createTargetPeerFromFlags(
+    ThreadPool* pool, UrlFetcher* url_fetcher, EVP_PKEY* pubkey, Task* task,
+    function<void(const ct::SignedTreeHead&)> new_sth) {
+  if (FLAGS_target_log_uri.empty()) {
+    LOG(WARNING) << "Empty target_log_uri flag; mirroring DISABLED";
+    return shared_ptr<RemotePeer>();
+  }
+
+  return make_shared<RemotePeer>(
+      unique_ptr<AsyncLogClient>(new AsyncLogClient(CHECK_NOTNULL(pool),
+                                                    CHECK_NOTNULL(url_fetcher),
+                                                    FLAGS_target_log_uri)),
+      unique_ptr<LogVerifier>(new LogVerifier(
+          new LogSigVerifier(CHECK_NOTNULL(pubkey)),
+          new MerkleVerifier(unique_ptr<Sha256Hasher>(new Sha256Hasher)))),
+      new_sth, CHECK_NOTNULL(task)->AddChild(
+                   [](Task*) { LOG(INFO) << "RemotePeer exited."; }));
+}
+
+int main(int argc, char* argv[]) {
+  // Ignore various signals whilst we start up.
+  signal(SIGHUP, SIG_IGN);
+  signal(SIGINT, SIG_IGN);
+  signal(SIGTERM, SIG_IGN);
+
+  util::InitCT(&argc, &argv);
+  ConfigureSerializerForV1CT();
+
+  Server::StaticInit();
+
+  cert_trans::EnsureValidatorsRegistered();
+  const unique_ptr<Database> db(cert_trans::ProvideDatabase());
+  CHECK(db) << "No database instance created, check flag settings";
+
+  const bool stand_alone_mode(cert_trans::IsStandalone(false));
+  const shared_ptr<libevent::Base> event_base(make_shared<libevent::Base>());
+  ThreadPool internal_pool(8);
+  UrlFetcher url_fetcher(event_base.get(), &internal_pool);
+
+  const unique_ptr<EtcdClient> etcd_client(
+      cert_trans::ProvideEtcdClient(event_base.get(), &internal_pool,
+                                    &url_fetcher));
+
+  CHECK(!FLAGS_target_public_key.empty());
+  const StatusOr<EVP_PKEY*> pubkey(ReadPublicKey(FLAGS_target_public_key));
+  CHECK(pubkey.ok()) << "Failed to read target log's public key file: "
+                     << pubkey.status();
+
+  const LogVerifier log_verifier(new LogSigVerifier(pubkey.ValueOrDie()),
+                                 new MerkleVerifier(unique_ptr<Sha256Hasher>(
+                                     new Sha256Hasher)));
+
+  ThreadPool http_pool(FLAGS_num_http_server_threads);
+
+  Server server(event_base, &internal_pool, &http_pool, db.get(),
+                etcd_client.get(), &url_fetcher, &log_verifier);
+  server.Initialise(true /* is_mirror */);
+
+  unique_ptr<StalenessTracker> staleness_tracker(
+      new StalenessTracker(server.cluster_state_controller(), &internal_pool,
+                           event_base.get()));
+
+  CertificateHttpHandler handler(server.log_lookup(), db.get(),
+                                 server.cluster_state_controller(),
+                                 nullptr /* checker */, nullptr /* Frontend */,
+                                 &internal_pool, event_base.get(),
+                                 staleness_tracker.get());
+
+  // Connect the handler, proxy and server together
+  handler.SetProxy(server.proxy());
+  handler.Add(server.http_server());
+
+  if (stand_alone_mode) {
+    // Set up a simple single-node mirror environment for testing.
+    //
+    // Put a sensible single-node config into FakeEtcd. For a real clustered
+    // log
+    // we'd expect a ClusterConfig already to be present within etcd as part of
+    // the provisioning of the log.
+    //
+    // TODO(alcutter): Note that we're currently broken wrt to restarting the
+    // log server when there's data in the log.  It's a temporary thing though,
+    // so fear ye not.
+    ct::ClusterConfig config;
+    config.set_minimum_serving_nodes(1);
+    config.set_minimum_serving_fraction(1);
+    LOG(INFO) << "Setting default single-node ClusterConfig:\n"
+              << config.DebugString();
+    server.consistent_store()->SetClusterConfig(config);
+
+    // Since we're a single node cluster, we'll settle that we're the
+    // master here, so that we can populate the initial STH
+    // (StrictConsistentStore won't allow us to do so unless we're master.)
+    server.election()->StartElection();
+    server.election()->WaitToBecomeMaster();
+  }
+
+
+  ThreadPool pool(16);
+  SyncTask fetcher_task(&pool);
+
+  mutex queue_mutex;
+  map<int64_t, ct::SignedTreeHead> queue;
+
+  const function<void(const ct::SignedTreeHead&)> new_sth(
+      [&queue_mutex, &queue](const ct::SignedTreeHead& sth) {
+        lock_guard<mutex> lock(queue_mutex);
+        const auto it(queue.find(sth.tree_size()));
+        if (it != queue.end() && sth.timestamp() < it->second.timestamp()) {
+          LOG(WARNING) << "Received older STH:\nHad:\n"
+                       << it->second.DebugString() << "\nGot:\n"
+                       << sth.DebugString();
+          return;
+        }
+        queue.insert(make_pair(sth.tree_size(), sth));
+      });
+
+  const shared_ptr<RemotePeer> peer(
+      createTargetPeerFromFlags(&pool, &url_fetcher, pubkey.ValueOrDie(),
+                                fetcher_task.task(), new_sth));
+  if (peer) {
+    LOG(INFO) << "Adding remote peer for target log.";
+    server.continuous_fetcher()->AddPeer("target", peer);
+  }
+
+  server.WaitForReplication();
+
+  thread sth_updater(&STHUpdater, db.get(), server.cluster_state_controller(),
+                     &queue_mutex, &queue, server.log_lookup(),
+                     fetcher_task.task()->AddChild(
+                         [](Task*) { LOG(INFO) << "STHUpdater exited."; }));
+
+  server.Run();
+
+  fetcher_task.task()->Return();
+  fetcher_task.Wait();
+  sth_updater.join();
+
+  return 0;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/ct-mirror_v2.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/ct-mirror_v2.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/ct-mirror_v2.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/ct-mirror_v2.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,376 @@
+/* -*- indent-tabs-mode: nil -*- */
+
+#include <gflags/gflags.h>
+#include <signal.h>
+#include <unistd.h>
+#include <iostream>
+#include <string>
+#include <utility>
+
+#include "client/async_log_client.h"
+#include "config.h"
+#include "fetcher/continuous_fetcher.h"
+#include "fetcher/peer_group.h"
+#include "fetcher/remote_peer.h"
+#include "log/cluster_state_controller.h"
+#include "log/ct_extensions.h"
+#include "log/database.h"
+#include "log/etcd_consistent_store.h"
+#include "log/log_lookup.h"
+#include "log/strict_consistent_store.h"
+#include "merkletree/compact_merkle_tree.h"
+#include "merkletree/merkle_verifier.h"
+#include "monitoring/latency.h"
+#include "monitoring/monitoring.h"
+#include "monitoring/registry.h"
+#include "proto/cert_serializer.h"
+#include "server/certificate_handler_v2.h"
+#include "server/json_output.h"
+#include "server/metrics.h"
+#include "server/proxy.h"
+#include "server/server.h"
+#include "server/server_helper.h"
+#include "util/etcd.h"
+#include "util/init.h"
+#include "util/libevent_wrapper.h"
+#include "util/masterelection.h"
+#include "util/periodic_closure.h"
+#include "util/read_key.h"
+#include "util/status.h"
+#include "util/thread_pool.h"
+#include "util/util.h"
+#include "util/uuid.h"
+
+DEFINE_int32(log_stats_frequency_seconds, 3600,
+             "Interval for logging summary statistics. Approximate: the "
+             "server will log statistics if in the beginning of its select "
+             "loop, at least this period has elapsed since the last log time. "
+             "Must be greater than 0.");
+DEFINE_int32(target_poll_frequency_seconds, 10,
+             "How often should the target log be polled for updates.");
+DEFINE_int32(num_http_server_threads, 16,
+             "Number of threads for servicing the incoming HTTP requests.");
+DEFINE_string(target_log_uri, "http://ct.googleapis.com/pilot",
+              "URI of the log to mirror.");
+DEFINE_string(
+    target_public_key, "",
+    "PEM-encoded server public key file of the log we're mirroring.");
+DEFINE_int32(local_sth_update_frequency_seconds, 30,
+             "Number of seconds between local checks for updated tree data.");
+// TODO(mhs): Remove this flag when V2 is complete
+DEFINE_bool(i_know_v2_is_not_finished_yet, false,
+            "Set this to allow V2 server startup as the functionality "
+            "is not complete yet");
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::AsyncLogClient;
+using cert_trans::CertificateHttpHandlerV2;
+using cert_trans::ClusterStateController;
+using cert_trans::ConsistentStore;
+using cert_trans::ContinuousFetcher;
+using cert_trans::Counter;
+using cert_trans::Database;
+using cert_trans::EtcdClient;
+using cert_trans::EtcdConsistentStore;
+using cert_trans::Gauge;
+using cert_trans::Latency;
+using cert_trans::LogLookup;
+using cert_trans::LoggedEntry;
+using cert_trans::MasterElection;
+using cert_trans::PeriodicClosure;
+using cert_trans::Proxy;
+using cert_trans::ReadPublicKey;
+using cert_trans::RemotePeer;
+using cert_trans::ScopedLatency;
+using cert_trans::Server;
+using cert_trans::StalenessTracker;
+using cert_trans::StrictConsistentStore;
+using cert_trans::ThreadPool;
+using cert_trans::Update;
+using cert_trans::UrlFetcher;
+using ct::ClusterNodeState;
+using ct::SignedTreeHead;
+using google::RegisterFlagValidator;
+using std::bind;
+using std::chrono::duration;
+using std::chrono::duration_cast;
+using std::chrono::milliseconds;
+using std::chrono::seconds;
+using std::chrono::steady_clock;
+using std::function;
+using std::lock_guard;
+using std::make_pair;
+using std::make_shared;
+using std::map;
+using std::mutex;
+using std::placeholders::_1;
+using std::shared_ptr;
+using std::string;
+using std::thread;
+using std::unique_ptr;
+using util::HexString;
+using util::StatusOr;
+using util::SyncTask;
+using util::Task;
+
+
+namespace {
+
+
+Gauge<>* latest_local_tree_size_gauge =
+    Gauge<>::New("latest_local_tree_size",
+                 "Size of latest locally available STH.");
+
+Counter<>* inconsistent_sths_received =
+    Counter<>::New("inconsistent_sths_received",
+                   "Number of STHs received from the mirror target whose root "
+                   "hash does not match the locally built tree.");
+
+
+// Basic sanity checks on flag values.
+static bool ValidateRead(const char* flagname, const string& path) {
+  if (access(path.c_str(), R_OK) != 0) {
+    std::cout << "Cannot access " << flagname << " at " << path << std::endl;
+    return false;
+  }
+  return true;
+}
+
+static const bool pubkey_dummy =
+    RegisterFlagValidator(&FLAGS_target_public_key, &ValidateRead);
+
+static bool ValidateIsPositive(const char* flagname, int value) {
+  if (value <= 0) {
+    std::cout << flagname << " must be greater than 0" << std::endl;
+    return false;
+  }
+  return true;
+}
+
+static const bool follow_dummy =
+    RegisterFlagValidator(&FLAGS_target_poll_frequency_seconds,
+                          &ValidateIsPositive);
+}  // namespace
+
+
+void STHUpdater(Database* db, ClusterStateController* cluster_state_controller,
+                mutex* queue_mutex, map<int64_t, ct::SignedTreeHead>* queue,
+                LogLookup* log_lookup, Task* task) {
+  CHECK_NOTNULL(db);
+  CHECK_NOTNULL(cluster_state_controller);
+  CHECK_NOTNULL(queue_mutex);
+  CHECK_NOTNULL(queue);
+  CHECK_NOTNULL(task);
+  CHECK_NOTNULL(log_lookup);
+
+  while (true) {
+    if (task->CancelRequested()) {
+      task->Return(util::Status::CANCELLED);
+    }
+
+    const int64_t local_size(db->TreeSize());
+    latest_local_tree_size_gauge->Set(local_size);
+
+    // log_lookup doesn't yet have the data for the new STHs integrated (that
+    // happens via a callback when the WriteTreeHead() method is called on the
+    // DB), so we'll used a compact tree to pre-validate the STH roots.
+    //
+    // We'll start with one based on the current state of our serving tree and
+    // update it to the STH sizes we're checking.
+    unique_ptr<CompactMerkleTree> new_tree(
+        log_lookup->GetCompactMerkleTree(new Sha256Hasher));
+
+    {
+      lock_guard<mutex> lock(*queue_mutex);
+      unique_ptr<Database::Iterator> entries(
+          db->ScanEntries(new_tree->LeafCount()));
+      while (!queue->empty() &&
+             queue->begin()->second.tree_size() <= local_size) {
+        const SignedTreeHead next_sth(queue->begin()->second);
+        queue->erase(queue->begin());
+
+        // First, if necessary, catch our local compact tree up to the
+        // candidate STH size:
+        {
+          LoggedEntry entry;
+          CHECK_LE(next_sth.tree_size(), local_size);
+          CHECK_GE(next_sth.tree_size(), 0);
+          const uint64_t next_sth_tree_size(
+              static_cast<uint64_t>(next_sth.tree_size()));
+          while (new_tree->LeafCount() < next_sth_tree_size) {
+            CHECK(entries->GetNextEntry(&entry));
+            CHECK(entry.has_sequence_number());
+            CHECK_GE(entry.sequence_number(), 0);
+            const uint64_t entry_sequence_number(
+                static_cast<uint64_t>(entry.sequence_number()));
+            CHECK_EQ(new_tree->LeafCount(), entry_sequence_number);
+            string serialized_leaf;
+            CHECK(entry.SerializeForLeaf(&serialized_leaf));
+            CHECK_EQ(entry_sequence_number + 1,
+                     new_tree->AddLeaf(serialized_leaf));
+          }
+        }
+
+        // If the candidate STH is historical, use the RootAtSnapshot() from
+        // our serving tree, otherwise use the root we just calculated with our
+        // compact tree.
+        const string local_root_at_snapshot(
+            next_sth.tree_size() > log_lookup->GetSTH().tree_size()
+                ? new_tree->CurrentRoot()
+                : log_lookup->RootAtSnapshot(next_sth.tree_size()));
+
+        if (next_sth.sha256_root_hash() != local_root_at_snapshot) {
+          LOG(WARNING) << "Received STH:\n" << next_sth.DebugString()
+                       << " whose root:\n"
+                       << HexString(next_sth.sha256_root_hash())
+                       << "\ndoes not match that of local tree at "
+                       << "corresponding snapshot:\n"
+                       << HexString(local_root_at_snapshot);
+          inconsistent_sths_received->Increment();
+          // TODO(alcutter): We should probably write these bad STHs out to a
+          // separate DB table for later analysis.
+          continue;
+        }
+        LOG(INFO) << "Can serve new STH of size " << next_sth.tree_size()
+                  << " locally";
+        cluster_state_controller->NewTreeHead(next_sth);
+      }
+    }
+
+    std::this_thread::sleep_for(
+        seconds(FLAGS_local_sth_update_frequency_seconds));
+  }
+}
+
+
+int main(int argc, char* argv[]) {
+  // Ignore various signals whilst we start up.
+  signal(SIGHUP, SIG_IGN);
+  signal(SIGINT, SIG_IGN);
+  signal(SIGTERM, SIG_IGN);
+
+  ConfigureSerializerForV2CT();
+  util::InitCT(&argc, &argv);
+
+  if (!FLAGS_i_know_v2_is_not_finished_yet) {
+    LOG(FATAL)
+        << "You must set --i_know_v2_is_not_finished_yet to run a v2 server";
+  }
+
+  Server::StaticInit();
+
+  cert_trans::EnsureValidatorsRegistered();
+  const unique_ptr<Database> db(cert_trans::ProvideDatabase());
+  CHECK(db) << "No database instance created, check flag settings";
+
+  const bool stand_alone_mode(cert_trans::IsStandalone(false));
+  const shared_ptr<libevent::Base> event_base(make_shared<libevent::Base>());
+  ThreadPool internal_pool(8);
+  UrlFetcher url_fetcher(event_base.get(), &internal_pool);
+
+  const unique_ptr<EtcdClient> etcd_client(
+      cert_trans::ProvideEtcdClient(event_base.get(), &internal_pool,
+                                    &url_fetcher));
+
+  CHECK(!FLAGS_target_public_key.empty());
+  const StatusOr<EVP_PKEY*> pubkey(ReadPublicKey(FLAGS_target_public_key));
+  CHECK(pubkey.ok()) << "Failed to read target log's public key file: "
+                     << pubkey.status();
+
+  const LogVerifier log_verifier(new LogSigVerifier(pubkey.ValueOrDie()),
+                                 new MerkleVerifier(unique_ptr<Sha256Hasher>(
+                                     new Sha256Hasher)));
+
+  ThreadPool http_pool(FLAGS_num_http_server_threads);
+
+  Server server(event_base, &internal_pool, &http_pool, db.get(),
+                etcd_client.get(), &url_fetcher, &log_verifier);
+  server.Initialise(true /* is_mirror */);
+
+  unique_ptr<StalenessTracker> staleness_tracker(
+      new StalenessTracker(server.cluster_state_controller(), &internal_pool,
+                           event_base.get()));
+
+  CertificateHttpHandlerV2 handler(server.log_lookup(), db.get(),
+                                   server.cluster_state_controller(),
+                                   nullptr /* checker */,
+                                   nullptr /* Frontend */, &internal_pool,
+                                   event_base.get(), staleness_tracker.get());
+
+  // Connect the handler, proxy and server together
+  handler.SetProxy(server.proxy());
+  handler.Add(server.http_server());
+
+  if (stand_alone_mode) {
+    // Set up a simple single-node mirror environment for testing.
+    //
+    // Put a sensible single-node config into FakeEtcd. For a real clustered
+    // log
+    // we'd expect a ClusterConfig already to be present within etcd as part of
+    // the provisioning of the log.
+    //
+    // TODO(alcutter): Note that we're currently broken wrt to restarting the
+    // log server when there's data in the log.  It's a temporary thing though,
+    // so fear ye not.
+    ct::ClusterConfig config;
+    config.set_minimum_serving_nodes(1);
+    config.set_minimum_serving_fraction(1);
+    LOG(INFO) << "Setting default single-node ClusterConfig:\n"
+              << config.DebugString();
+    server.consistent_store()->SetClusterConfig(config);
+
+    // Since we're a single node cluster, we'll settle that we're the
+    // master here, so that we can populate the initial STH
+    // (StrictConsistentStore won't allow us to do so unless we're master.)
+    server.election()->StartElection();
+    server.election()->WaitToBecomeMaster();
+  }
+
+  CHECK(!FLAGS_target_log_uri.empty());
+
+  ThreadPool pool(16);
+  SyncTask fetcher_task(&pool);
+
+  mutex queue_mutex;
+  map<int64_t, ct::SignedTreeHead> queue;
+
+  const function<void(const ct::SignedTreeHead&)> new_sth(
+      [&queue_mutex, &queue](const ct::SignedTreeHead& sth) {
+        lock_guard<mutex> lock(queue_mutex);
+        const auto it(queue.find(sth.tree_size()));
+        if (it != queue.end() && sth.timestamp() < it->second.timestamp()) {
+          LOG(WARNING) << "Received older STH:\nHad:\n"
+                       << it->second.DebugString() << "\nGot:\n"
+                       << sth.DebugString();
+          return;
+        }
+        queue.insert(make_pair(sth.tree_size(), sth));
+      });
+
+  const shared_ptr<RemotePeer> peer(make_shared<RemotePeer>(
+      unique_ptr<AsyncLogClient>(
+          new AsyncLogClient(&pool, &url_fetcher, FLAGS_target_log_uri)),
+      unique_ptr<LogVerifier>(new LogVerifier(
+          new LogSigVerifier(pubkey.ValueOrDie()),
+          new MerkleVerifier(unique_ptr<Sha256Hasher>(new Sha256Hasher)))),
+      new_sth, fetcher_task.task()->AddChild(
+                   [](Task*) { LOG(INFO) << "RemotePeer exited."; })));
+
+  server.continuous_fetcher()->AddPeer("target", peer);
+
+  server.WaitForReplication();
+
+  thread sth_updater(&STHUpdater, db.get(), server.cluster_state_controller(),
+                     &queue_mutex, &queue, server.log_lookup(),
+                     fetcher_task.task()->AddChild(
+                         [](Task*) { LOG(INFO) << "STHUpdater exited."; }));
+
+  server.Run();
+
+  fetcher_task.task()->Return();
+  fetcher_task.Wait();
+  sth_updater.join();
+
+  return 0;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/ct-server.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/ct-server.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/ct-server.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/ct-server.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,216 @@
+/* -*- indent-tabs-mode: nil -*- */
+
+#include <gflags/gflags.h>
+#include <openssl/err.h>
+#include <signal.h>
+#include <stdlib.h>
+#include <unistd.h>
+#include <iostream>
+#include <string>
+
+#include "config.h"
+#include "log/cert_checker.h"
+#include "log/cert_submission_handler.h"
+#include "log/cluster_state_controller.h"
+#include "log/etcd_consistent_store.h"
+#include "log/frontend.h"
+#include "log/frontend_signer.h"
+#include "log/log_lookup.h"
+#include "log/log_signer.h"
+#include "log/log_verifier.h"
+#include "log/strict_consistent_store.h"
+#include "log/tree_signer.h"
+#include "merkletree/merkle_verifier.h"
+#include "proto/cert_serializer.h"
+#include "server/certificate_handler.h"
+#include "server/log_processes.h"
+#include "server/server.h"
+#include "server/server_helper.h"
+#include "server/staleness_tracker.h"
+#include "util/etcd.h"
+#include "util/init.h"
+#include "util/libevent_wrapper.h"
+#include "util/read_key.h"
+#include "util/status.h"
+#include "util/uuid.h"
+
+DEFINE_string(key, "", "PEM-encoded server private key file");
+DEFINE_string(trusted_cert_file, "",
+              "File for trusted CA certificates, in concatenated PEM format");
+DEFINE_double(guard_window_seconds, 60,
+              "Unsequenced entries newer than this "
+              "number of seconds will not be sequenced.");
+DEFINE_int32(num_http_server_threads, 16,
+             "Number of threads for servicing the incoming HTTP requests.");
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::CertChecker;
+using cert_trans::CertificateHttpHandler;
+using cert_trans::CleanUpEntries;
+using cert_trans::ClusterStateController;
+using cert_trans::ConsistentStore;
+using cert_trans::Database;
+using cert_trans::EtcdClient;
+using cert_trans::EtcdConsistentStore;
+using cert_trans::LoggedEntry;
+using cert_trans::ReadPrivateKey;
+using cert_trans::SequenceEntries;
+using cert_trans::Server;
+using cert_trans::SignMerkleTree;
+using cert_trans::StalenessTracker;
+using cert_trans::ThreadPool;
+using cert_trans::TreeSigner;
+using cert_trans::UrlFetcher;
+using ct::ClusterNodeState;
+using ct::SignedTreeHead;
+using google::RegisterFlagValidator;
+using std::bind;
+using std::function;
+using std::make_shared;
+using std::shared_ptr;
+using std::string;
+using std::thread;
+using std::unique_ptr;
+
+
+namespace {
+
+// Basic sanity checks on flag values.
+static bool ValidateRead(const char* flagname, const string& path) {
+  if (access(path.c_str(), R_OK) != 0) {
+    std::cout << "Cannot access " << flagname << " at " << path << std::endl;
+    return false;
+  }
+  return true;
+}
+
+static const bool key_dummy = RegisterFlagValidator(&FLAGS_key, &ValidateRead);
+
+static const bool cert_dummy =
+    RegisterFlagValidator(&FLAGS_trusted_cert_file, &ValidateRead);
+
+}  // namespace
+
+
+int main(int argc, char* argv[]) {
+  // Ignore various signals whilst we start up.
+  signal(SIGHUP, SIG_IGN);
+  signal(SIGINT, SIG_IGN);
+  signal(SIGTERM, SIG_IGN);
+
+  ConfigureSerializerForV1CT();
+  util::InitCT(&argc, &argv);
+
+  Server::StaticInit();
+
+  util::StatusOr<EVP_PKEY*> pkey(ReadPrivateKey(FLAGS_key));
+  CHECK_EQ(pkey.status(), util::Status::OK);
+  LogSigner log_signer(pkey.ValueOrDie());
+
+  CertChecker checker;
+  CHECK(checker.LoadTrustedCertificates(FLAGS_trusted_cert_file))
+      << "Could not load CA certs from " << FLAGS_trusted_cert_file;
+
+  cert_trans::EnsureValidatorsRegistered();
+  const unique_ptr<Database> db(cert_trans::ProvideDatabase());
+  CHECK(db) << "No database instance created, check flag settings";
+
+  shared_ptr<libevent::Base> event_base(make_shared<libevent::Base>());
+  ThreadPool internal_pool(8);
+  UrlFetcher url_fetcher(event_base.get(), &internal_pool);
+
+  const bool stand_alone_mode(cert_trans::IsStandalone(true));
+  LOG(INFO) << "Running in "
+            << (stand_alone_mode ? "STAND-ALONE" : "CLUSTERED") << " mode.";
+
+  unique_ptr<EtcdClient> etcd_client(
+      cert_trans::ProvideEtcdClient(event_base.get(), &internal_pool,
+                                    &url_fetcher));
+
+  const LogVerifier log_verifier(new LogSigVerifier(pkey.ValueOrDie()),
+                                 new MerkleVerifier(unique_ptr<Sha256Hasher>(
+                                     new Sha256Hasher)));
+
+  ThreadPool http_pool(FLAGS_num_http_server_threads);
+
+  Server server(event_base, &internal_pool, &http_pool, db.get(),
+                etcd_client.get(), &url_fetcher, &log_verifier);
+  server.Initialise(false /* is_mirror */);
+
+  Frontend frontend(
+      new FrontendSigner(db.get(), server.consistent_store(), &log_signer));
+  unique_ptr<StalenessTracker> staleness_tracker(
+      new StalenessTracker(server.cluster_state_controller(), &internal_pool,
+                           event_base.get()));
+  CertificateHttpHandler handler(server.log_lookup(), db.get(),
+                                 server.cluster_state_controller(), &checker,
+                                 &frontend, &internal_pool, event_base.get(),
+                                 staleness_tracker.get());
+
+  // Connect the handler, proxy and server together
+  handler.SetProxy(server.proxy());
+  handler.Add(server.http_server());
+
+  TreeSigner tree_signer(
+      std::chrono::duration<double>(FLAGS_guard_window_seconds), db.get(),
+      server.log_lookup()->GetCompactMerkleTree(new Sha256Hasher),
+      server.consistent_store(), &log_signer);
+
+  if (stand_alone_mode) {
+    // Set up a simple single-node environment.
+    //
+    // Put a sensible single-node config into FakeEtcd. For a real clustered
+    // log
+    // we'd expect a ClusterConfig already to be present within etcd as part of
+    // the provisioning of the log.
+    //
+    // TODO(alcutter): Note that we're currently broken wrt to restarting the
+    // log server when there's data in the log.  It's a temporary thing though,
+    // so fear ye not.
+    ct::ClusterConfig config;
+    config.set_minimum_serving_nodes(1);
+    config.set_minimum_serving_fraction(1);
+    LOG(INFO) << "Setting default single-node ClusterConfig:\n"
+              << config.DebugString();
+    server.consistent_store()->SetClusterConfig(config);
+
+    // Since we're a single node cluster, we'll settle that we're the
+    // master here, so that we can populate the initial STH
+    // (StrictConsistentStore won't allow us to do so unless we're master.)
+    server.election()->StartElection();
+    server.election()->WaitToBecomeMaster();
+
+    {
+      EtcdClient::Response resp;
+      util::SyncTask task(event_base.get());
+      etcd_client->Create("/root/sequence_mapping", "", &resp, task.task());
+      task.Wait();
+      CHECK_EQ(util::Status::OK, task.status());
+    }
+
+    // Do an initial signing run to get the initial STH, again this is
+    // temporary until we re-populate FakeEtcd from the DB.
+    CHECK_EQ(tree_signer.UpdateTree(), TreeSigner::OK);
+
+    // Need to boot-strap the Serving STH too because we consider it an error
+    // if it's not set, which in turn causes us to not attempt to become
+    // master:
+    server.consistent_store()->SetServingSTH(tree_signer.LatestSTH());
+  }
+
+  server.WaitForReplication();
+
+  // TODO(pphaneuf): We should be remaining in an "unhealthy state"
+  // (either not accepting any requests, or returning some internal
+  // server error) until we have an STH to serve.
+  const function<bool()> is_master(bind(&Server::IsMaster, &server));
+  thread sequencer(&SequenceEntries, &tree_signer, is_master);
+  thread cleanup(&CleanUpEntries, server.consistent_store(), is_master);
+  thread signer(&SignMerkleTree, &tree_signer, server.consistent_store(),
+                server.cluster_state_controller());
+
+  server.Run();
+
+  return 0;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/ct-server_v2.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/ct-server_v2.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/ct-server_v2.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/ct-server_v2.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,223 @@
+/* -*- indent-tabs-mode: nil -*- */
+
+#include <gflags/gflags.h>
+#include <signal.h>
+#include <unistd.h>
+#include <iostream>
+#include <string>
+
+#include "config.h"
+#include "log/cert_checker.h"
+#include "log/cert_submission_handler.h"
+#include "log/cluster_state_controller.h"
+#include "log/etcd_consistent_store.h"
+#include "log/frontend.h"
+#include "log/frontend_signer.h"
+#include "log/log_lookup.h"
+#include "log/log_signer.h"
+#include "log/log_verifier.h"
+#include "log/strict_consistent_store.h"
+#include "log/tree_signer.h"
+#include "merkletree/merkle_verifier.h"
+#include "proto/cert_serializer.h"
+#include "server/certificate_handler_v2.h"
+#include "server/log_processes.h"
+#include "server/server.h"
+#include "server/server_helper.h"
+#include "server/staleness_tracker.h"
+#include "util/etcd.h"
+#include "util/init.h"
+#include "util/libevent_wrapper.h"
+#include "util/read_key.h"
+#include "util/status.h"
+#include "util/uuid.h"
+
+DEFINE_string(key, "", "PEM-encoded server private key file");
+DEFINE_string(trusted_cert_file, "",
+              "File for trusted CA certificates, in concatenated PEM format");
+DEFINE_double(guard_window_seconds, 60,
+              "Unsequenced entries newer than this "
+              "number of seconds will not be sequenced.");
+DEFINE_int32(num_http_server_threads, 16,
+             "Number of threads for servicing the incoming HTTP requests.");
+// TODO(mhs): Remove this flag when V2 is complete
+DEFINE_bool(i_know_v2_is_not_finished_yet, false,
+            "Set this to allow V2 server startup as the functionality "
+            "is not complete yet");
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::CertChecker;
+using cert_trans::CertificateHttpHandlerV2;
+using cert_trans::CleanUpEntries;
+using cert_trans::ClusterStateController;
+using cert_trans::ConsistentStore;
+using cert_trans::Database;
+using cert_trans::EtcdClient;
+using cert_trans::EtcdConsistentStore;
+using cert_trans::LoggedEntry;
+using cert_trans::ReadPrivateKey;
+using cert_trans::SequenceEntries;
+using cert_trans::Server;
+using cert_trans::SignMerkleTree;
+using cert_trans::StalenessTracker;
+using cert_trans::ThreadPool;
+using cert_trans::TreeSigner;
+using cert_trans::UrlFetcher;
+using ct::ClusterNodeState;
+using ct::SignedTreeHead;
+using google::RegisterFlagValidator;
+using std::bind;
+using std::function;
+using std::make_shared;
+using std::shared_ptr;
+using std::string;
+using std::thread;
+using std::unique_ptr;
+
+
+namespace {
+
+// Basic sanity checks on flag values.
+static bool ValidateRead(const char* flagname, const string& path) {
+  if (access(path.c_str(), R_OK) != 0) {
+    std::cout << "Cannot access " << flagname << " at " << path << std::endl;
+    return false;
+  }
+  return true;
+}
+
+static const bool key_dummy = RegisterFlagValidator(&FLAGS_key, &ValidateRead);
+
+static const bool cert_dummy =
+    RegisterFlagValidator(&FLAGS_trusted_cert_file, &ValidateRead);
+
+}  // namespace
+
+
+int main(int argc, char* argv[]) {
+  // Ignore various signals whilst we start up.
+  signal(SIGHUP, SIG_IGN);
+  signal(SIGINT, SIG_IGN);
+  signal(SIGTERM, SIG_IGN);
+
+  ConfigureSerializerForV2CT();
+  util::InitCT(&argc, &argv);
+
+  if (!FLAGS_i_know_v2_is_not_finished_yet) {
+    LOG(FATAL)
+        << "You must set --i_know_v2_is_not_finished_yet to run a v2 server";
+  }
+
+  Server::StaticInit();
+
+  util::StatusOr<EVP_PKEY*> pkey(ReadPrivateKey(FLAGS_key));
+  CHECK_EQ(pkey.status(), util::Status::OK);
+  LogSigner log_signer(pkey.ValueOrDie());
+
+  CertChecker checker;
+  CHECK(checker.LoadTrustedCertificates(FLAGS_trusted_cert_file))
+      << "Could not load CA certs from " << FLAGS_trusted_cert_file;
+
+  cert_trans::EnsureValidatorsRegistered();
+  const unique_ptr<Database> db(cert_trans::ProvideDatabase());
+  CHECK(db) << "No database instance created, check flag settings";
+
+  shared_ptr<libevent::Base> event_base(make_shared<libevent::Base>());
+  ThreadPool internal_pool(8);
+  UrlFetcher url_fetcher(event_base.get(), &internal_pool);
+
+  const bool stand_alone_mode(cert_trans::IsStandalone(true));
+  LOG(INFO) << "Running in "
+            << (stand_alone_mode ? "STAND-ALONE" : "CLUSTERED") << " mode.";
+
+  unique_ptr<EtcdClient> etcd_client(
+      cert_trans::ProvideEtcdClient(event_base.get(), &internal_pool,
+                                    &url_fetcher));
+
+  const LogVerifier log_verifier(new LogSigVerifier(pkey.ValueOrDie()),
+                                 new MerkleVerifier(unique_ptr<Sha256Hasher>(
+                                     new Sha256Hasher)));
+
+  ThreadPool http_pool(FLAGS_num_http_server_threads);
+
+  Server server(event_base, &internal_pool, &http_pool, db.get(),
+                etcd_client.get(), &url_fetcher, &log_verifier);
+  server.Initialise(false /* is_mirror */);
+
+  Frontend frontend(
+      new FrontendSigner(db.get(), server.consistent_store(), &log_signer));
+  unique_ptr<StalenessTracker> staleness_tracker(
+      new StalenessTracker(server.cluster_state_controller(), &internal_pool,
+                           event_base.get()));
+  CertificateHttpHandlerV2 handler(server.log_lookup(), db.get(),
+                                   server.cluster_state_controller(), &checker,
+                                   &frontend, &internal_pool, event_base.get(),
+                                   staleness_tracker.get());
+
+  // Connect the handler, proxy and server together
+  handler.SetProxy(server.proxy());
+  handler.Add(server.http_server());
+
+  TreeSigner tree_signer(
+      std::chrono::duration<double>(FLAGS_guard_window_seconds), db.get(),
+      server.log_lookup()->GetCompactMerkleTree(new Sha256Hasher),
+      server.consistent_store(), &log_signer);
+
+  if (stand_alone_mode) {
+    // Set up a simple single-node environment.
+    //
+    // Put a sensible single-node config into FakeEtcd. For a real clustered
+    // log
+    // we'd expect a ClusterConfig already to be present within etcd as part of
+    // the provisioning of the log.
+    //
+    // TODO(alcutter): Note that we're currently broken wrt to restarting the
+    // log server when there's data in the log.  It's a temporary thing though,
+    // so fear ye not.
+    ct::ClusterConfig config;
+    config.set_minimum_serving_nodes(1);
+    config.set_minimum_serving_fraction(1);
+    LOG(INFO) << "Setting default single-node ClusterConfig:\n"
+              << config.DebugString();
+    server.consistent_store()->SetClusterConfig(config);
+
+    // Since we're a single node cluster, we'll settle that we're the
+    // master here, so that we can populate the initial STH
+    // (StrictConsistentStore won't allow us to do so unless we're master.)
+    server.election()->StartElection();
+    server.election()->WaitToBecomeMaster();
+
+    {
+      EtcdClient::Response resp;
+      util::SyncTask task(event_base.get());
+      etcd_client->Create("/root/sequence_mapping", "", &resp, task.task());
+      task.Wait();
+      CHECK_EQ(util::Status::OK, task.status());
+    }
+
+    // Do an initial signing run to get the initial STH, again this is
+    // temporary until we re-populate FakeEtcd from the DB.
+    CHECK_EQ(tree_signer.UpdateTree(), TreeSigner::OK);
+
+    // Need to boot-strap the Serving STH too because we consider it an error
+    // if it's not set, which in turn causes us to not attempt to become
+    // master:
+    server.consistent_store()->SetServingSTH(tree_signer.LatestSTH());
+  }
+
+  server.WaitForReplication();
+
+  // TODO(pphaneuf): We should be remaining in an "unhealthy state"
+  // (either not accepting any requests, or returning some internal
+  // server error) until we have an STH to serve.
+  const function<bool()> is_master(bind(&Server::IsMaster, &server));
+  thread sequencer(&SequenceEntries, &tree_signer, is_master);
+  thread cleanup(&CleanUpEntries, server.consistent_store(), is_master);
+  thread signer(&SignMerkleTree, &tree_signer, server.consistent_store(),
+                server.cluster_state_controller());
+
+  server.Run();
+
+  return 0;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/event.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/event.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/event.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/event.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,285 @@
+/* -*- indent-tabs-mode: nil -*- */
+#include "server/event.h"
+
+#include <limits.h>
+#include <openssl/evp.h>
+#include <openssl/pem.h>
+
+time_t Services::rough_time_;
+
+FD::FD(EventLoop* loop, int fd, CanDelete deletable)
+    : fd_(fd), loop_(loop), wants_erase_(false), deletable_(deletable) {
+  DCHECK_GE(fd, 0);
+  CHECK_LT((unsigned)fd, (unsigned)FD_SETSIZE);
+  loop->Add(this);
+  Activity();
+}
+
+void FD::Close() {
+  DCHECK_EQ(deletable_, DELETE) << "Can't call Close() on a non-deletable FD";
+  if (wants_erase_) {
+    LOG(INFO) << "Attempting to close an already closed fd " << fd();
+    return;
+  }
+  LOG(INFO) << "Closing fd " << fd() << std::endl;
+  wants_erase_ = true;
+  shutdown(fd(), SHUT_RDWR);
+  close(fd());
+}
+
+bool FD::WillAccept(int fd) {
+  if (fd >= kFDLimit - kFDLimitWindow)
+    loop()->MaybeDropOne();
+  return fd < kFDLimit;
+}
+
+void Listener::ReadIsAllowed() {
+  int in = accept(fd(), NULL, NULL);
+  CHECK_GE(in, 0);
+  if (!WillAccept(in)) {
+    static char sorry[] = "No free connections.\n";
+
+    // we have to consume the result.
+    ssize_t s = write(in, sorry, sizeof sorry);
+    if (s != sizeof sorry)
+      LOG(WARNING) << "Failed to write sorry correctly.";
+    shutdown(in, SHUT_RDWR);
+    close(in);
+    return;
+  }
+  Accepted(in);
+}
+
+void Listener::WriteIsAllowed() {
+  DLOG(FATAL) << "WriteIsAllowed() called on a read-only Listener.";
+}
+
+time_t EventLoop::ProcessRepeatedEvents() {
+  if (events_.empty())
+    return INT_MAX;
+  Services::SetRoughTime();
+  time_t now = Services::RoughTime();
+  time_t earliest = INT_MAX;
+  for (std::vector<RepeatedEvent*>::iterator it = events_.begin();
+       it != events_.end(); ++it) {
+    RepeatedEvent* event = *it;
+    time_t trigger = event->Trigger();
+    if (trigger <= now) {
+      event->Execute();
+      LOG(INFO) << "Executed " << event->Description() << " with a delay of "
+                << difftime(now, trigger) << " seconds";
+      event->Activity();
+      trigger = event->Trigger();
+      CHECK_GT(trigger, now);
+    }
+    earliest = std::min(earliest, trigger);
+  }
+  CHECK_GT(earliest, 0);
+  return earliest - now;
+}
+
+void EventLoop::OneLoop() {
+  time_t select_timeout = ProcessRepeatedEvents();
+  // Do not schedule any repeated events between now and the next
+  // select - they will get ignored until select returns.
+  CHECK_GT(select_timeout, 0);
+
+  fd_set readers, writers;
+  int max = -1;
+
+  memset(&readers, '\0', sizeof readers);
+  memset(&writers, '\0', sizeof writers);
+  for (std::deque<FD*>::const_iterator pfd = fds_.begin(); pfd != fds_.end();
+       ++pfd) {
+    FD* fd = *pfd;
+
+    DCHECK(!fd->WantsErase());
+    if (fd->WantsWrite())
+      Set(fd->fd(), &writers, &max);
+    if (fd->WantsRead())
+      Set(fd->fd(), &readers, &max);
+  }
+
+  CHECK_GE(max, 0);
+
+  struct timeval tv;
+  tv.tv_sec = select_timeout;
+  tv.tv_usec = 0;
+
+  int r = select(max + 1, &readers, &writers, NULL, &tv);
+  if (r == 0)
+    return;
+
+  CHECK_GT(r, 0);
+
+  Services::SetRoughTime();
+  int n = 0;
+  for (std::deque<FD*>::iterator pfd = fds_.begin(); pfd != fds_.end();) {
+    FD* fd = *pfd;
+
+    if (EraseCheck(&pfd))
+      continue;
+
+    if (FD_ISSET(fd->fd(), &writers)) {
+      DCHECK(fd->WantsWrite());
+      fd->WriteIsAllowed();
+      fd->Activity();
+      ++n;
+    }
+
+    if (EraseCheck(&pfd))
+      continue;
+
+    if (FD_ISSET(fd->fd(), &readers)) {
+      DCHECK(fd->WantsRead());
+      fd->ReadIsAllowed();
+      fd->Activity();
+      ++n;
+    }
+
+    if (EraseCheck(&pfd))
+      continue;
+
+    ++pfd;
+  }
+  CHECK_LE(n, r);
+}
+
+void EventLoop::Stop() {
+  go_ = false;
+}
+
+void EventLoop::Forever() {
+  for (; go_;)
+    OneLoop();
+}
+
+void EventLoop::MaybeDropOne() {
+  std::deque<FD*>::iterator drop = fds_.end();
+  time_t oldest = Services::RoughTime() - kIdleTime;
+
+  for (std::deque<FD*>::iterator pfd = fds_.begin(); pfd != fds_.end();
+       ++pfd) {
+    FD* fd = *pfd;
+
+    if (fd->CanDrop() && fd->LastActivity() < oldest) {
+      oldest = fd->LastActivity();
+      drop = pfd;
+    }
+  }
+  if (drop != fds_.end())
+    (*drop)->Close();
+}
+
+bool EventLoop::EraseCheck(std::deque<FD*>::iterator* pfd) {
+  if ((**pfd)->WantsErase()) {
+    delete **pfd;
+    *pfd = fds_.erase(*pfd);
+    return true;
+  }
+  return false;
+}
+
+// static
+void EventLoop::Set(int fd, fd_set* fdset, int* max) {
+  DCHECK_GE(fd, 0);
+  CHECK_LT((unsigned)fd, (unsigned)FD_SETSIZE);
+  FD_SET(fd, fdset);
+  if (fd > *max)
+    *max = fd;
+}
+
+void Server::ReadIsAllowed() {
+  char buf[1024];
+
+  ssize_t n = read(fd(), buf, sizeof buf);
+  VLOG(1) << "read " << n << " bytes from " << fd();
+  if (n <= 0) {
+    Close();
+    return;
+  }
+  rbuffer_.append(buf, (size_t)n);
+  BytesRead(&rbuffer_);
+}
+
+void Server::WriteIsAllowed() {
+  ssize_t n = write(fd(), wbuffer_.data(), wbuffer_.length());
+  VLOG(1) << "wrote " << n << " bytes to " << fd();
+  if (n <= 0) {
+    Close();
+    return;
+  }
+  wbuffer_.erase(0, n);
+}
+
+void UDPServer::ReadIsAllowed() {
+  char buf[2048];
+  struct sockaddr_in sa;
+  socklen_t sa_len = sizeof sa;
+
+  ssize_t in = recvfrom(fd(), buf, sizeof buf, 0, (sockaddr*)&sa, &sa_len);
+  CHECK_GE(in, 1);
+  CHECK_EQ(sa_len, sizeof sa);
+  // LOG(INFO) << "UDP packet " << util::HexString(std::string(buf, in));
+  PacketRead(sa, buf, in);
+}
+
+void UDPServer::WriteIsAllowed() {
+  CHECK(!write_queue_.empty());
+  WBuffer wbuf = write_queue_.front();
+  write_queue_.pop_front();
+  ssize_t out = sendto(fd(), wbuf.packet.data(), wbuf.packet.length(), 0,
+                       (const sockaddr*)&wbuf.sa, sizeof wbuf.sa);
+  CHECK_NE(out, -1);
+  CHECK_EQ((size_t)out, wbuf.packet.length());
+}
+
+void UDPServer::QueuePacket(const sockaddr_in& to, const char* buf,
+                            size_t len) {
+  WBuffer wbuf;
+  wbuf.sa = to;
+  wbuf.packet = std::string(buf, len);
+  write_queue_.push_back(wbuf);
+}
+
+bool Services::InitServer(int* sock, int port, const char* ip, int type) {
+  bool ret = false;
+  struct sockaddr_in server;
+  int s = -1;
+
+  memset(&server, 0, sizeof(server));
+  server.sin_family = AF_INET;
+  server.sin_port = htons((unsigned short)port);
+  if (ip == NULL)
+    server.sin_addr.s_addr = htonl(INADDR_ANY);
+  else
+    memcpy(&server.sin_addr.s_addr, ip, 4);
+
+  if (type == SOCK_STREAM)
+    s = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);
+  else /* type == SOCK_DGRAM */
+    s = socket(AF_INET, SOCK_DGRAM, IPPROTO_UDP);
+  if (s == -1)
+    goto err;
+
+  {
+    int j = 1;
+    setsockopt(s, SOL_SOCKET, SO_REUSEADDR, &j, sizeof j);
+  }
+
+  if (bind(s, (struct sockaddr*)&server, sizeof(server)) == -1) {
+    perror("bind");
+    goto err;
+  }
+  /* Make it 128 for linux */
+  if (type == SOCK_STREAM && listen(s, 128) == -1)
+    goto err;
+  *sock = s;
+  ret = true;
+err:
+  if (!ret && s != -1) {
+    shutdown(s, SHUT_RDWR);
+    close(s);
+  }
+  return ret;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/event.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/event.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/event.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/event.h	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,274 @@
+/* -*- mode: c++; indent-tabs-mode: nil -*- */
+#ifndef CERT_TRANS_SERVER_EVENT_H_
+#define CERT_TRANS_SERVER_EVENT_H_
+
+#include <glog/logging.h>
+#include <netinet/in.h>
+#include <sys/socket.h>
+#include <sys/types.h>
+#include <time.h>
+#include <deque>
+#include <string>
+
+#include "base/macros.h"
+
+class Services {
+ public:
+  // because time is expensive, for most tasks we can just use some
+  // time sampled within this event handling loop. So, the main loop
+  // needs to call SetRoughTime() appropriately.
+  static time_t RoughTime() {
+    if (rough_time_ == 0)
+      rough_time_ = time(NULL);
+    return rough_time_;
+  }
+
+  static void SetRoughTime() {
+    rough_time_ = 0;
+  }
+
+  static bool InitServer(int* sock, int port, const char* ip, int type);
+
+ private:
+  // This class is only used as a namespace, it should never be
+  // instantiated.
+  // TODO(pphaneuf): Make this into normal functions in a namespace.
+  Services();
+
+  static time_t rough_time_;
+};
+
+class EventLoop;
+
+class FD {
+ public:
+  enum CanDelete { DELETE, NO_DELETE };
+
+  FD(EventLoop* loop, int fd, CanDelete deletable = DELETE);
+
+  virtual ~FD() = default;
+
+  virtual bool WantsWrite() const = 0;
+
+  virtual void WriteIsAllowed() = 0;
+
+  virtual bool WantsRead() const = 0;
+
+  virtual void ReadIsAllowed() = 0;
+
+  bool WantsErase() const {
+    return wants_erase_;
+  }
+
+  void Close();
+
+  int fd() const {
+    return fd_;
+  }
+
+  bool CanDrop() const {
+    return deletable_ == DELETE;
+  }
+
+  // Don't forget to call me if anything happens!
+  void Activity() {
+    last_activity_ = Services::RoughTime();
+  }
+
+  time_t LastActivity() const {
+    return last_activity_;
+  }
+
+ protected:
+  EventLoop* loop() const {
+    return loop_;
+  }
+
+  bool WillAccept(int fd);
+
+ private:
+  int fd_;
+  EventLoop* loop_;
+  bool wants_erase_;
+  CanDelete deletable_;
+  time_t last_activity_;
+
+  // Note that while you can set these low for test, they behave a
+  // bit strangely when set low - for example, it is quite easy to
+  // hit the limit even if the window is not 0. I'm guessing 1000
+  // and 100 would be good numbers. Note EventLoop::kIdleTime below,
+  // also.
+  static const int kFDLimit = 1000;
+  static const int kFDLimitWindow = 1;
+
+  DISALLOW_COPY_AND_ASSIGN(FD);
+};
+
+class Listener : public FD {
+ public:
+  Listener(EventLoop* loop, int fd) : FD(loop, fd, NO_DELETE) {
+  }
+
+  bool WantsRead() const {
+    return true;
+  }
+
+  void ReadIsAllowed();
+
+  bool WantsWrite() const {
+    return false;
+  }
+
+  void WriteIsAllowed();
+
+  virtual void Accepted(int fd) = 0;
+};
+
+class RepeatedEvent {
+ public:
+  RepeatedEvent(time_t repeat_frequency_seconds)
+      : frequency_(repeat_frequency_seconds),
+        last_activity_(Services::RoughTime()) {
+  }
+
+  // The time when we should execute next.
+  time_t Trigger() {
+    return last_activity_ + frequency_;
+  }
+
+  virtual std::string Description() = 0;
+
+  virtual void Execute() = 0;
+
+  void Activity() {
+    last_activity_ = Services::RoughTime();
+  }
+
+ private:
+  time_t frequency_;
+  time_t last_activity_;
+};
+
+class EventLoop {
+ public:
+  EventLoop() : go_(true) {
+  }
+
+  void Add(FD* fd) {
+    fds_.push_back(fd);
+  }
+
+  void Add(RepeatedEvent* event) {
+    events_.push_back(event);
+  }
+
+  // Returns remaining time until the next alarm.
+  time_t ProcessRepeatedEvents();
+
+  void OneLoop();
+
+  void Forever();
+
+  void MaybeDropOne();
+
+  void Stop();
+
+ private:
+  bool EraseCheck(std::deque<FD*>::iterator* pfd);
+
+  static void Set(int fd, fd_set* fdset, int* max);
+
+  std::deque<FD*> fds_;
+  std::vector<RepeatedEvent*> events_;
+  // This should probably be set to 2 for anything but test (or 1 or 0).
+  // 2: everything gets a chance to speak.
+  // 1: sometimes the clock will tick before some get a chance to speak.
+  // 0: maybe no-one ever gets a chance to speak.
+  static const time_t kIdleTime = 20;
+
+  bool go_;
+
+  DISALLOW_COPY_AND_ASSIGN(EventLoop);
+};
+
+class Server : public FD {
+ public:
+  Server(EventLoop* loop, int fd) : FD(loop, fd) {
+  }
+
+  bool WantsRead() const {
+    return true;
+  }
+
+  void ReadIsAllowed();
+
+  // There are fresh bytes available in rbuffer.  It is the callee's
+  // responsibility to remove consumed bytes from rbuffer. This will
+  // NOT be called again until more data arrives from the network,
+  // even if there are unconsumed bytes in rbuffer.
+  virtual void BytesRead(std::string* rbuffer) = 0;
+
+  bool WantsWrite() const {
+    return !wbuffer_.empty();
+  }
+
+  void WriteIsAllowed();
+
+  void Write(std::string str) {
+    wbuffer_.append(str);
+  }
+
+ private:
+  std::string rbuffer_;
+  std::string wbuffer_;
+};
+
+class UDPServer : public FD {
+ public:
+  UDPServer(EventLoop* loop, int fd) : FD(loop, fd, NO_DELETE) {
+  }
+
+  bool WantsRead() const {
+    return true;
+  }
+
+  void ReadIsAllowed();
+
+  bool WantsWrite() const {
+    return !write_queue_.empty();
+  }
+
+  void WriteIsAllowed();
+
+  // A packet has been read. It will not be re-presented if you do not
+  // process it now.
+  virtual void PacketRead(const sockaddr_in& from, const char* buf,
+                          size_t len) = 0;
+
+  // Queue a packet for sending
+  void QueuePacket(const sockaddr_in& to, const char* buf, size_t len);
+  void QueuePacket(const sockaddr_in& to, const unsigned char* buf,
+                   size_t len) {
+    QueuePacket(to, reinterpret_cast<const char*>(buf), len);
+  }
+
+ private:
+  struct WBuffer {
+    sockaddr_in sa;
+    std::string packet;
+  };
+  std::deque<WBuffer> write_queue_;
+};
+
+class UDPEchoServer : public UDPServer {
+ public:
+  UDPEchoServer(EventLoop* loop, int fd) : UDPServer(loop, fd) {
+  }
+
+  virtual void PacketRead(const sockaddr_in& from, const char* buf,
+                          size_t len) {
+    QueuePacket(from, buf, len);
+  }
+};
+
+#endif  // CERT_TRANS_SERVER_EVENT_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/handler.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/handler.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/handler.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/handler.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,352 @@
+#include "server/handler.h"
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <stdint.h>
+#include <stdlib.h>
+#include <algorithm>
+#include <algorithm>
+#include <functional>
+#include <memory>
+#include <mutex>
+#include <string>
+#include <vector>
+
+#include "log/cert.h"
+#include "log/cert_checker.h"
+#include "log/cluster_state_controller.h"
+#include "log/log_lookup.h"
+#include "log/logged_entry.h"
+#include "monitoring/latency.h"
+#include "monitoring/monitoring.h"
+#include "server/json_output.h"
+#include "server/proxy.h"
+#include "util/json_wrapper.h"
+#include "util/thread_pool.h"
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::Counter;
+using cert_trans::HttpHandler;
+using cert_trans::Latency;
+using cert_trans::LoggedEntry;
+using cert_trans::Proxy;
+using cert_trans::ScopedLatency;
+using ct::ShortMerkleAuditProof;
+using ct::SignedCertificateTimestamp;
+using ct::SignedTreeHead;
+using std::bind;
+using std::chrono::milliseconds;
+using std::chrono::seconds;
+using std::lock_guard;
+using std::make_shared;
+using std::multimap;
+using std::min;
+using std::mutex;
+using std::placeholders::_1;
+using std::string;
+using std::unique_ptr;
+using std::vector;
+
+DEFINE_int32(max_leaf_entries_per_response, 1000,
+             "maximum number of entries to put in the response of a "
+             "get-entries request");
+
+namespace {
+
+
+static Latency<milliseconds, string> http_server_request_latency_ms(
+    "total_http_server_request_latency_ms", "path",
+    "Total request latency in ms broken down by path");
+
+
+}  // namespace
+
+
+HttpHandler::HttpHandler(LogLookup* log_lookup, const ReadOnlyDatabase* db,
+                         const ClusterStateController* controller,
+                         ThreadPool* pool, libevent::Base* event_base,
+                         StalenessTracker* staleness_tracker)
+    : log_lookup_(CHECK_NOTNULL(log_lookup)),
+      db_(CHECK_NOTNULL(db)),
+      controller_(CHECK_NOTNULL(controller)),
+      proxy_(nullptr),
+      pool_(CHECK_NOTNULL(pool)),
+      event_base_(CHECK_NOTNULL(event_base)),
+      staleness_tracker_(CHECK_NOTNULL(staleness_tracker)) {
+}
+
+
+HttpHandler::~HttpHandler() {
+}
+
+
+void StatsHandlerInterceptor(const string& path,
+                             const libevent::HttpServer::HandlerCallback& cb,
+                             evhttp_request* req) {
+  ScopedLatency total_http_server_request_latency(
+      http_server_request_latency_ms.GetScopedLatency(path));
+
+  cb(req);
+}
+
+
+void HttpHandler::AddEntryReply(evhttp_request* req,
+                                const util::Status& add_status,
+                                const SignedCertificateTimestamp& sct) const {
+  if (!add_status.ok() &&
+      add_status.CanonicalCode() != util::error::ALREADY_EXISTS) {
+    VLOG(1) << "error adding chain: " << add_status;
+    const int response_code(add_status.CanonicalCode() ==
+                                    util::error::RESOURCE_EXHAUSTED
+                                ? HTTP_SERVUNAVAIL
+                                : HTTP_BADREQUEST);
+    return SendJsonError(event_base_, req, response_code,
+                         add_status.error_message());
+  }
+
+  JsonObject json_reply;
+  json_reply.Add("sct_version", static_cast<int64_t>(0));
+  json_reply.AddBase64("id", sct.id().key_id());
+  json_reply.Add("timestamp", sct.timestamp());
+  json_reply.Add("extensions", "");
+  json_reply.Add("signature", sct.signature());
+
+  SendJsonReply(event_base_, req, HTTP_OK, json_reply);
+}
+
+void HttpHandler::ProxyInterceptor(
+    const libevent::HttpServer::HandlerCallback& local_handler,
+    evhttp_request* request) {
+  VLOG(2) << "Running proxy interceptor...";
+  // TODO(alcutter): We can be a bit smarter about when to proxy off
+  // the request - being stale wrt to the current serving STH doesn't
+  // automatically mean we're unable to answer this request.
+  if (staleness_tracker_->IsNodeStale()) {
+    // Can't do this on the libevent thread since it can block on the lock in
+    // ClusterStatusController::GetFreshNodes().
+    pool_->Add(bind(&Proxy::ProxyRequest, proxy_, request));
+  } else {
+    local_handler(request);
+  }
+}
+
+
+void HttpHandler::AddProxyWrappedHandler(
+    libevent::HttpServer* server, const string& path,
+    const libevent::HttpServer::HandlerCallback& local_handler) {
+  const libevent::HttpServer::HandlerCallback stats_handler(
+      bind(&StatsHandlerInterceptor, path, local_handler, _1));
+  CHECK(server->AddHandler(path, bind(&HttpHandler::ProxyInterceptor, this,
+                                      stats_handler, _1)));
+}
+
+
+void HttpHandler::Add(libevent::HttpServer* server) {
+  CHECK_NOTNULL(server);
+  // TODO(pphaneuf): An optional prefix might be nice?
+  // TODO(pphaneuf): Find out which methods are CPU intensive enough
+  // that they should be spun off to the thread pool.
+  AddProxyWrappedHandler(server, "/ct/v1/get-entries",
+                         bind(&HttpHandler::GetEntries, this, _1));
+  AddProxyWrappedHandler(server, "/ct/v1/get-proof-by-hash",
+                         bind(&HttpHandler::GetProof, this, _1));
+  AddProxyWrappedHandler(server, "/ct/v1/get-sth",
+                         bind(&HttpHandler::GetSTH, this, _1));
+  AddProxyWrappedHandler(server, "/ct/v1/get-sth-consistency",
+                         bind(&HttpHandler::GetConsistency, this, _1));
+
+  // Now add any sub-class handlers.
+  AddHandlers(server);
+}
+
+
+void HttpHandler::SetProxy(Proxy* proxy) {
+  LOG_IF(FATAL, proxy_) << "Attempting to re-add a Proxy.";
+  proxy_ = CHECK_NOTNULL(proxy);
+}
+
+
+void HttpHandler::GetEntries(evhttp_request* req) const {
+  if (evhttp_request_get_command(req) != EVHTTP_REQ_GET) {
+    return SendJsonError(event_base_, req, HTTP_BADMETHOD,
+                         "Method not allowed.");
+  }
+
+  const libevent::QueryParams query(libevent::ParseQuery(req));
+
+  const int64_t start(libevent::GetIntParam(query, "start"));
+  if (start < 0) {
+    return SendJsonError(event_base_, req, HTTP_BADREQUEST,
+                         "Missing or invalid \"start\" parameter.");
+  }
+
+  int64_t end(libevent::GetIntParam(query, "end"));
+  if (end < start) {
+    return SendJsonError(event_base_, req, HTTP_BADREQUEST,
+                         "Missing or invalid \"end\" parameter.");
+  }
+
+  // Limit the number of entries returned in a single request.
+  end = std::min(end, start + FLAGS_max_leaf_entries_per_response);
+
+  // Sekrit parameter to indicate that SCTs should be included too.
+  // This is non-standard, and is only used internally by other log nodes when
+  // "following" nodes with more data.
+  const bool include_scts(libevent::GetBoolParam(query, "include_scts"));
+
+  BlockingGetEntries(req, start, end, include_scts);
+}
+
+
+void HttpHandler::GetProof(evhttp_request* req) const {
+  if (evhttp_request_get_command(req) != EVHTTP_REQ_GET) {
+    return SendJsonError(event_base_, req, HTTP_BADMETHOD,
+                         "Method not allowed.");
+  }
+
+  const libevent::QueryParams query(libevent::ParseQuery(req));
+
+  string b64_hash;
+  if (!libevent::GetParam(query, "hash", &b64_hash)) {
+    return SendJsonError(event_base_, req, HTTP_BADREQUEST,
+                         "Missing or invalid \"hash\" parameter.");
+  }
+
+  const string hash(util::FromBase64(b64_hash.c_str()));
+  if (hash.empty()) {
+    return SendJsonError(event_base_, req, HTTP_BADREQUEST,
+                         "Invalid \"hash\" parameter.");
+  }
+
+  const int64_t tree_size(libevent::GetIntParam(query, "tree_size"));
+  if (tree_size < 0 ||
+      static_cast<int64_t>(tree_size) > log_lookup_->GetSTH().tree_size()) {
+    return SendJsonError(event_base_, req, HTTP_BADREQUEST,
+                         "Missing or invalid \"tree_size\" parameter.");
+  }
+
+  ShortMerkleAuditProof proof;
+  if (log_lookup_->AuditProof(hash, tree_size, &proof) != LogLookup::OK) {
+    return SendJsonError(event_base_, req, HTTP_BADREQUEST,
+                         "Couldn't find hash.");
+  }
+
+  JsonArray json_audit;
+  for (int i = 0; i < proof.path_node_size(); ++i) {
+    json_audit.AddBase64(proof.path_node(i));
+  }
+
+  JsonObject json_reply;
+  json_reply.Add("leaf_index", proof.leaf_index());
+  json_reply.Add("audit_path", json_audit);
+
+  SendJsonReply(event_base_, req, HTTP_OK, json_reply);
+}
+
+
+void HttpHandler::GetSTH(evhttp_request* req) const {
+  if (evhttp_request_get_command(req) != EVHTTP_REQ_GET) {
+    return SendJsonError(event_base_, req, HTTP_BADMETHOD,
+                         "Method not allowed.");
+  }
+
+  const SignedTreeHead& sth(log_lookup_->GetSTH());
+
+  VLOG(2) << "SignedTreeHead:\n" << sth.DebugString();
+
+  JsonObject json_reply;
+  json_reply.Add("tree_size", sth.tree_size());
+  json_reply.Add("timestamp", sth.timestamp());
+  json_reply.AddBase64("sha256_root_hash", sth.sha256_root_hash());
+  json_reply.Add("tree_head_signature", sth.signature());
+
+  VLOG(2) << "GetSTH:\n" << json_reply.DebugString();
+
+  SendJsonReply(event_base_, req, HTTP_OK, json_reply);
+}
+
+
+void HttpHandler::GetConsistency(evhttp_request* req) const {
+  if (evhttp_request_get_command(req) != EVHTTP_REQ_GET) {
+    return SendJsonError(event_base_, req, HTTP_BADMETHOD,
+                         "Method not allowed.");
+  }
+
+  const libevent::QueryParams query(libevent::ParseQuery(req));
+
+  const int64_t first(libevent::GetIntParam(query, "first"));
+  if (first < 0) {
+    return SendJsonError(event_base_, req, HTTP_BADREQUEST,
+                         "Missing or invalid \"first\" parameter.");
+  }
+
+  const int64_t second(libevent::GetIntParam(query, "second"));
+  if (second < first) {
+    return SendJsonError(event_base_, req, HTTP_BADREQUEST,
+                         "Missing or invalid \"second\" parameter.");
+  }
+
+  const vector<string> consistency(
+      log_lookup_->ConsistencyProof(first, second));
+  JsonArray json_cons;
+  for (vector<string>::const_iterator it = consistency.begin();
+       it != consistency.end(); ++it) {
+    json_cons.AddBase64(*it);
+  }
+
+  JsonObject json_reply;
+  json_reply.Add("consistency", json_cons);
+
+  SendJsonReply(event_base_, req, HTTP_OK, json_reply);
+}
+
+
+void HttpHandler::BlockingGetEntries(evhttp_request* req, int64_t start,
+                                     int64_t end, bool include_scts) const {
+  JsonArray json_entries;
+  auto it(db_->ScanEntries(start));
+  for (int64_t i = start; i <= end; ++i) {
+    LoggedEntry entry;
+
+    if (!it->GetNextEntry(&entry) || entry.sequence_number() != i) {
+      break;
+    }
+
+    string leaf_input;
+    string extra_data;
+    string sct_data;
+    if (!entry.SerializeForLeaf(&leaf_input) ||
+        !entry.SerializeExtraData(&extra_data) ||
+        (include_scts &&
+         Serializer::SerializeSCT(entry.sct(), &sct_data) !=
+             cert_trans::serialization::SerializeResult::OK)) {
+      LOG(WARNING) << "Failed to serialize entry @ " << i << ":\n"
+                   << entry.DebugString();
+      return SendJsonError(event_base_, req, HTTP_INTERNAL,
+                           "Serialization failed.");
+    }
+
+    JsonObject json_entry;
+    json_entry.AddBase64("leaf_input", leaf_input);
+    json_entry.AddBase64("extra_data", extra_data);
+
+    if (include_scts) {
+      // This is non-standard for this implementation, and is currently only
+      // used by other nodes when "following" to fetch data from each other:
+      json_entry.AddBase64("sct", sct_data);
+    }
+
+    json_entries.Add(&json_entry);
+  }
+
+  if (json_entries.Length() < 1) {
+    return SendJsonError(event_base_, req, HTTP_BADREQUEST,
+                         "Entry not found.");
+  }
+
+  JsonObject json_reply;
+  json_reply.Add("entries", json_entries);
+
+  SendJsonReply(event_base_, req, HTTP_OK, json_reply);
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/handler.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/handler.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/handler.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/handler.h	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,80 @@
+#ifndef CERT_TRANS_SERVER_HANDLER_H_
+#define CERT_TRANS_SERVER_HANDLER_H_
+
+#include <stdint.h>
+#include <memory>
+#include <mutex>
+#include <string>
+
+#include "proto/ct.pb.h"
+#include "server/staleness_tracker.h"
+#include "util/libevent_wrapper.h"
+#include "util/sync_task.h"
+#include "util/task.h"
+
+class Frontend;
+
+namespace cert_trans {
+
+class CertChain;
+class CertChecker;
+class ClusterStateController;
+class LogLookup;
+class LoggedEntry;
+class PreCertChain;
+class Proxy;
+class ReadOnlyDatabase;
+class ThreadPool;
+
+
+class HttpHandler {
+ public:
+  // Does not take ownership of its parameters, which must outlive
+  // this instance.
+  HttpHandler(LogLookup* log_lookup, const ReadOnlyDatabase* db,
+              const ClusterStateController* controller, ThreadPool* pool,
+              libevent::Base* event_base, StalenessTracker* staleness_tracker);
+  virtual ~HttpHandler();
+
+  void Add(libevent::HttpServer* server);
+
+  void SetProxy(Proxy* proxy);
+
+ protected:
+  // Implemented by subclasses which want to add their own extra http handlers.
+  virtual void AddHandlers(libevent::HttpServer* server) = 0;
+
+  void AddEntryReply(evhttp_request* req, const util::Status& add_status,
+                     const ct::SignedCertificateTimestamp& sct) const;
+
+  void ProxyInterceptor(
+      const libevent::HttpServer::HandlerCallback& local_handler,
+      evhttp_request* request);
+
+  void AddProxyWrappedHandler(
+      libevent::HttpServer* server, const std::string& path,
+      const libevent::HttpServer::HandlerCallback& local_handler);
+
+  void GetEntries(evhttp_request* req) const;
+  void GetProof(evhttp_request* req) const;
+  void GetSTH(evhttp_request* req) const;
+  void GetConsistency(evhttp_request* req) const;
+
+  void BlockingGetEntries(evhttp_request* req, int64_t start, int64_t end,
+                          bool include_scts) const;
+
+  LogLookup* const log_lookup_;
+  const ReadOnlyDatabase* const db_;
+  const ClusterStateController* const controller_;
+  Proxy* proxy_;
+  ThreadPool* const pool_;
+  libevent::Base* const event_base_;
+  StalenessTracker* const staleness_tracker_;
+
+  DISALLOW_COPY_AND_ASSIGN(HttpHandler);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_SERVER_HANDLER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/handler_v2.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/handler_v2.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/handler_v2.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/handler_v2.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,175 @@
+#include "server/handler_v2.h"
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <algorithm>
+#include <string>
+#include <vector>
+
+#include "log/cert.h"
+#include "log/cert_checker.h"
+#include "log/cluster_state_controller.h"
+#include "log/log_lookup.h"
+#include "log/logged_entry.h"
+#include "monitoring/latency.h"
+#include "monitoring/monitoring.h"
+#include "server/json_output.h"
+#include "server/proxy.h"
+#include "util/json_wrapper.h"
+#include "util/thread_pool.h"
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::Counter;
+using cert_trans::HttpHandlerV2;
+using cert_trans::Latency;
+using cert_trans::LoggedEntry;
+using cert_trans::Proxy;
+using cert_trans::ScopedLatency;
+using ct::ShortMerkleAuditProof;
+using ct::SignedCertificateTimestamp;
+using ct::SignedTreeHead;
+using std::bind;
+using std::chrono::milliseconds;
+using std::chrono::seconds;
+using std::lock_guard;
+using std::make_shared;
+using std::multimap;
+using std::min;
+using std::mutex;
+using std::placeholders::_1;
+using std::string;
+using std::unique_ptr;
+using std::vector;
+
+DEFINE_int32(max_leaf_entries_per_response, 1000,
+             "maximum number of entries to put in the response of a "
+             "get-entries request");
+
+namespace {
+
+
+static Latency<milliseconds, string> http_server_request_latency_ms(
+    "total_http_server_request_latency_ms", "path",
+    "Total request latency in ms broken down by path");
+
+
+}  // namespace
+
+
+HttpHandlerV2::HttpHandlerV2(LogLookup* log_lookup, const ReadOnlyDatabase* db,
+                             const ClusterStateController* controller,
+                             ThreadPool* pool, libevent::Base* event_base,
+                             StalenessTracker* staleness_tracker)
+    : log_lookup_(CHECK_NOTNULL(log_lookup)),
+      db_(CHECK_NOTNULL(db)),
+      controller_(CHECK_NOTNULL(controller)),
+      proxy_(nullptr),
+      pool_(CHECK_NOTNULL(pool)),
+      event_base_(CHECK_NOTNULL(event_base)),
+      staleness_tracker_(CHECK_NOTNULL(staleness_tracker)) {
+}
+
+
+HttpHandlerV2::~HttpHandlerV2() {
+}
+
+
+void StatsHandlerInterceptor(const string& path,
+                             const libevent::HttpServer::HandlerCallback& cb,
+                             evhttp_request* req) {
+  ScopedLatency total_http_server_request_latency(
+      http_server_request_latency_ms.GetScopedLatency(path));
+
+  cb(req);
+}
+
+
+void HttpHandlerV2::AddEntryReply(
+    evhttp_request* req, const util::Status& add_status,
+    const SignedCertificateTimestamp& sct) const {
+  return SendJsonError(event_base_, req, HTTP_NOTIMPLEMENTED,
+                       "Not yet implemented.");
+}
+
+void HttpHandlerV2::ProxyInterceptor(
+    const libevent::HttpServer::HandlerCallback& local_handler,
+    evhttp_request* request) {
+  VLOG(2) << "Running proxy interceptor...";
+  // TODO(alcutter): We can be a bit smarter about when to proxy off
+  // the request - being stale wrt to the current serving STH doesn't
+  // automatically mean we're unable to answer this request.
+  if (staleness_tracker_->IsNodeStale()) {
+    // Can't do this on the libevent thread since it can block on the lock in
+    // ClusterStatusController::GetFreshNodes().
+    pool_->Add(bind(&Proxy::ProxyRequest, proxy_, request));
+  } else {
+    local_handler(request);
+  }
+}
+
+
+void HttpHandlerV2::AddProxyWrappedHandler(
+    libevent::HttpServer* server, const string& path,
+    const libevent::HttpServer::HandlerCallback& local_handler) {
+  const libevent::HttpServer::HandlerCallback stats_handler(
+      bind(&StatsHandlerInterceptor, path, local_handler, _1));
+  CHECK(server->AddHandler(path, bind(&HttpHandlerV2::ProxyInterceptor, this,
+                                      stats_handler, _1)));
+}
+
+
+void HttpHandlerV2::Add(libevent::HttpServer* server) {
+  CHECK_NOTNULL(server);
+  // TODO(pphaneuf): An optional prefix might be nice?
+  // TODO(pphaneuf): Find out which methods are CPU intensive enough
+  // that they should be spun off to the thread pool.
+  AddProxyWrappedHandler(server, "/ct/v2/get-entries",
+                         bind(&HttpHandlerV2::GetEntries, this, _1));
+  AddProxyWrappedHandler(server, "/ct/v2/get-proof-by-hash",
+                         bind(&HttpHandlerV2::GetProof, this, _1));
+  AddProxyWrappedHandler(server, "/ct/v2/get-sth",
+                         bind(&HttpHandlerV2::GetSTH, this, _1));
+  AddProxyWrappedHandler(server, "/ct/v2/get-sth-consistency",
+                         bind(&HttpHandlerV2::GetConsistency, this, _1));
+
+  // Now add any sub-class handlers.
+  AddHandlers(server);
+}
+
+
+void HttpHandlerV2::SetProxy(Proxy* proxy) {
+  LOG_IF(FATAL, proxy_) << "Attempting to re-add a Proxy.";
+  proxy_ = CHECK_NOTNULL(proxy);
+}
+
+
+void HttpHandlerV2::GetEntries(evhttp_request* req) const {
+  return SendJsonError(event_base_, req, HTTP_NOTIMPLEMENTED,
+                       "Not yet implemented.");
+}
+
+
+void HttpHandlerV2::GetProof(evhttp_request* req) const {
+  return SendJsonError(event_base_, req, HTTP_NOTIMPLEMENTED,
+                       "Not yet implemented.");
+}
+
+
+void HttpHandlerV2::GetSTH(evhttp_request* req) const {
+  return SendJsonError(event_base_, req, HTTP_NOTIMPLEMENTED,
+                       "Not yet implemented.");
+}
+
+
+void HttpHandlerV2::GetConsistency(evhttp_request* req) const {
+  return SendJsonError(event_base_, req, HTTP_NOTIMPLEMENTED,
+                       "Not yet implemented.");
+}
+
+
+void HttpHandlerV2::BlockingGetEntries(evhttp_request* req, int64_t start,
+                                       int64_t end, bool include_scts) const {
+  return SendJsonError(event_base_, req, HTTP_NOTIMPLEMENTED,
+                       "Not yet implemented.");
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/handler_v2.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/handler_v2.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/handler_v2.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/handler_v2.h	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,81 @@
+#ifndef CERT_TRANS_SERVER_HANDLER_V2_H_
+#define CERT_TRANS_SERVER_HANDLER_V2_H_
+
+#include <stdint.h>
+#include <memory>
+#include <mutex>
+#include <string>
+
+#include "proto/ct.pb.h"
+#include "server/staleness_tracker.h"
+#include "util/libevent_wrapper.h"
+#include "util/sync_task.h"
+#include "util/task.h"
+
+class Frontend;
+
+namespace cert_trans {
+
+class CertChain;
+class CertChecker;
+class ClusterStateController;
+class LogLookup;
+class LoggedEntry;
+class PreCertChain;
+class Proxy;
+class ReadOnlyDatabase;
+class ThreadPool;
+
+
+class HttpHandlerV2 {
+ public:
+  // Does not take ownership of its parameters, which must outlive
+  // this instance.
+  HttpHandlerV2(LogLookup* log_lookup, const ReadOnlyDatabase* db,
+                const ClusterStateController* controller, ThreadPool* pool,
+                libevent::Base* event_base,
+                StalenessTracker* staleness_tracker);
+  virtual ~HttpHandlerV2();
+
+  void Add(libevent::HttpServer* server);
+
+  void SetProxy(Proxy* proxy);
+
+ protected:
+  // Implemented by subclasses which want to add their own extra http handlers.
+  virtual void AddHandlers(libevent::HttpServer* server) = 0;
+
+  void AddEntryReply(evhttp_request* req, const util::Status& add_status,
+                     const ct::SignedCertificateTimestamp& sct) const;
+
+  void ProxyInterceptor(
+      const libevent::HttpServer::HandlerCallback& local_handler,
+      evhttp_request* request);
+
+  void AddProxyWrappedHandler(
+      libevent::HttpServer* server, const std::string& path,
+      const libevent::HttpServer::HandlerCallback& local_handler);
+
+  void GetEntries(evhttp_request* req) const;
+  void GetProof(evhttp_request* req) const;
+  void GetSTH(evhttp_request* req) const;
+  void GetConsistency(evhttp_request* req) const;
+
+  void BlockingGetEntries(evhttp_request* req, int64_t start, int64_t end,
+                          bool include_scts) const;
+
+  LogLookup* const log_lookup_;
+  const ReadOnlyDatabase* const db_;
+  const ClusterStateController* const controller_;
+  Proxy* proxy_;
+  ThreadPool* const pool_;
+  libevent::Base* const event_base_;
+  StalenessTracker* const staleness_tracker_;
+
+  DISALLOW_COPY_AND_ASSIGN(HttpHandlerV2);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_SERVER_HANDLER_V2_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/json_output.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/json_output.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/json_output.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/json_output.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,113 @@
+#include "server/json_output.h"
+
+#include <glog/logging.h>
+#include <string>
+
+#include "monitoring/latency.h"
+#include "monitoring/monitoring.h"
+#include "util/json_wrapper.h"
+#include "util/libevent_wrapper.h"
+
+using std::string;
+
+namespace cert_trans {
+namespace {
+
+
+static Counter<string>* total_http_server_requests(
+    Counter<string>::New("total_http_server_requests", "path",
+                         "Total number of HTTP requests received for a given "
+                         "path."));
+static Counter<string, int>* total_http_server_response_codes(
+    Counter<string, int>::New("total_http_server_response_codes", "path",
+                              "response_code",
+                              "Total number of responses sent with a given "
+                              "HTTP response code for a given path."));
+
+static const char kJsonContentType[] = "application/json; charset=utf-8";
+
+
+string LogRequest(evhttp_request* req, int http_status, int resp_body_length) {
+  evhttp_connection* conn = evhttp_request_get_connection(req);
+  char* peer_addr;
+  ev_uint16_t peer_port;
+  evhttp_connection_get_peer(conn, &peer_addr, &peer_port);
+
+  string http_verb;
+  switch (evhttp_request_get_command(req)) {
+    case EVHTTP_REQ_DELETE:
+      http_verb = "DELETE";
+      break;
+    case EVHTTP_REQ_GET:
+      http_verb = "GET";
+      break;
+    case EVHTTP_REQ_HEAD:
+      http_verb = "HEAD";
+      break;
+    case EVHTTP_REQ_POST:
+      http_verb = "POST";
+      break;
+    case EVHTTP_REQ_PUT:
+      http_verb = "PUT";
+      break;
+    default:
+      http_verb = "UNKNOWN";
+      break;
+  }
+
+  const string path(evhttp_uri_get_path(evhttp_request_get_evhttp_uri(req)));
+  total_http_server_requests->Increment(path);
+  total_http_server_response_codes->Increment(path, http_status);
+
+  const string uri(evhttp_request_get_uri(req));
+  return string(peer_addr) + " \"" + http_verb + " " + uri + "\" " +
+         std::to_string(http_status) + " " + std::to_string(resp_body_length);
+}
+
+
+}  // namespace
+
+
+void SendJsonReply(libevent::Base* base, evhttp_request* req, int http_status,
+                   const JsonObject& json) {
+  CHECK_NOTNULL(base);
+  CHECK_NOTNULL(req);
+  CHECK_EQ(evhttp_add_header(evhttp_request_get_output_headers(req),
+                             "Content-Type", kJsonContentType),
+           0);
+  if (http_status == HTTP_SERVUNAVAIL) {
+    CHECK_EQ(evhttp_add_header(evhttp_request_get_output_headers(req),
+                               "Retry-After", "10"),
+             0);
+  }
+  const string resp_body(json.ToString());
+  CHECK_GT(evbuffer_add_printf(evhttp_request_get_output_buffer(req), "%s",
+                               resp_body.c_str()),
+           0);
+
+  const string logstr(LogRequest(req, http_status, resp_body.size()));
+  const auto send_reply([req, http_status, logstr]() {
+    evhttp_send_reply(req, http_status, /*reason*/ NULL, /*databuf*/ NULL);
+
+    VLOG(1) << logstr;
+  });
+
+  if (!libevent::Base::OnEventThread()) {
+    base->Add(send_reply);
+  } else {
+    send_reply();
+  }
+}
+
+
+void SendJsonError(libevent::Base* base, evhttp_request* req, int http_status,
+                   const string& error_msg) {
+  JsonObject json_reply;
+  json_reply.Add("error_message", error_msg);
+  json_reply.AddBoolean("success", false);
+
+  SendJsonReply(base, req, http_status, json_reply);
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/json_output.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/json_output.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/json_output.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/json_output.h	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,26 @@
+#ifndef CERT_TRANS_SERVER_JSON_OUTPUT_H_
+#define CERT_TRANS_SERVER_JSON_OUTPUT_H_
+
+#include <string>
+
+struct evhttp_request;
+class JsonObject;
+
+namespace cert_trans {
+namespace libevent {
+class Base;
+}  // namespace libevent
+
+
+void SendJsonReply(libevent::Base* base, evhttp_request* req, int http_status,
+                   const JsonObject& json);
+
+
+void SendJsonError(libevent::Base* base, evhttp_request* req, int http_status,
+                   const std::string& error_msg);
+
+
+}  // namespace cert_trans
+
+
+#endif  // CERT_TRANS_SERVER_JSON_OUTPUT_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/log_processes.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/log_processes.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/log_processes.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/log_processes.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,173 @@
+#include "server/log_processes.h"
+
+#include <gflags/gflags.h>
+#include <iostream>
+
+#include "monitoring/latency.h"
+#include "monitoring/monitoring.h"
+#include "server/metrics.h"
+
+DEFINE_int32(tree_signing_frequency_seconds, 600,
+             "How often should we issue a new signed tree head. Approximate: "
+             "the signer process will kick off if in the beginning of the "
+             "server select loop, at least this period has elapsed since the "
+             "last signing. Set this well below the MMD to ensure we sign in "
+             "a timely manner. Must be greater than 0.");
+DEFINE_int32(sequencing_frequency_seconds, 10,
+             "How often should new entries be sequenced. The sequencing runs "
+             "in parallel with the tree signing and cleanup.");
+DEFINE_int32(cleanup_frequency_seconds, 10,
+             "How often should new entries be cleanedup. The cleanup runs in "
+             "in parallel with the tree signing and sequencing.");
+
+using cert_trans::Counter;
+using cert_trans::Gauge;
+using cert_trans::Latency;
+using google::RegisterFlagValidator;
+using ct::SignedTreeHead;
+using std::function;
+using std::chrono::milliseconds;
+using std::chrono::seconds;
+using std::chrono::steady_clock;
+
+namespace {
+
+Gauge<>* latest_local_tree_size_gauge =
+    Gauge<>::New("latest_local_tree_size",
+                 "Size of latest locally generated STH.");
+
+Counter<bool>* sequencer_total_runs = Counter<bool>::New(
+    "sequencer_total_runs", "successful",
+    "Total number of sequencer runs broken out by success.");
+
+Latency<milliseconds> sequencer_sequence_latency_ms(
+    "sequencer_sequence_latency_ms",
+    "Total time spent sequencing entries by sequencer");
+
+Counter<bool>* signer_total_runs =
+    Counter<bool>::New("signer_total_runs", "successful",
+                       "Total number of signer runs broken out by success.");
+
+Latency<milliseconds> signer_run_latency_ms("signer_run_latency_ms",
+                                            "Total runtime of signer");
+
+static bool ValidateIsPositive(const char* flagname, int value) {
+  if (value <= 0) {
+    std::cout << flagname << " must be greater than 0" << std::endl;
+    return false;
+  }
+  return true;
+}
+
+static const bool sign_dummy =
+    RegisterFlagValidator(&FLAGS_tree_signing_frequency_seconds,
+                          &ValidateIsPositive);
+}
+
+namespace cert_trans {
+
+void SignMerkleTree(TreeSigner* tree_signer, ConsistentStore* store,
+                    ClusterStateController* controller) {
+  CHECK_NOTNULL(tree_signer);
+  CHECK_NOTNULL(store);
+  CHECK_NOTNULL(controller);
+  const steady_clock::duration period(
+      (seconds(FLAGS_tree_signing_frequency_seconds)));
+  steady_clock::time_point target_run_time(steady_clock::now());
+
+  while (true) {
+    {
+      ScopedLatency signer_run_latency(
+          signer_run_latency_ms.GetScopedLatency());
+      const TreeSigner::UpdateResult result(tree_signer->UpdateTree());
+      switch (result) {
+        case TreeSigner::OK: {
+          const SignedTreeHead latest_sth(tree_signer->LatestSTH());
+          latest_local_tree_size_gauge->Set(latest_sth.tree_size());
+          controller->NewTreeHead(latest_sth);
+          signer_total_runs->Increment(true /* successful */);
+          break;
+        }
+        case TreeSigner::INSUFFICIENT_DATA:
+          LOG(INFO) << "Can't update tree because we don't have all the "
+                    << "entries locally, will try again later.";
+          signer_total_runs->Increment(false /* successful */);
+          break;
+        default:
+          LOG(FATAL) << "Error updating tree: " << result;
+      }
+    }
+
+    const steady_clock::time_point now(steady_clock::now());
+    while (target_run_time <= now) {
+      target_run_time += period;
+    }
+    std::this_thread::sleep_for(target_run_time - now);
+  }
+}
+
+void CleanUpEntries(ConsistentStore* store,
+                    const function<bool()>& is_master) {
+  CHECK_NOTNULL(store);
+  CHECK(is_master);
+  const steady_clock::duration period(
+      (seconds(FLAGS_cleanup_frequency_seconds)));
+  steady_clock::time_point target_run_time(steady_clock::now());
+
+  while (true) {
+    if (is_master()) {
+      // Keep cleaning up until there's no more work to do.
+      // This should help to keep the etcd contents size down during heavy
+      // load.
+      while (true) {
+        const util::StatusOr<int64_t> num_cleaned(store->CleanupOldEntries());
+        if (!num_cleaned.ok()) {
+          LOG(WARNING) << "Problem cleaning up old entries: "
+                       << num_cleaned.status();
+          break;
+        }
+        if (num_cleaned.ValueOrDie() == 0) {
+          break;
+        }
+      }
+    }
+
+    const steady_clock::time_point now(steady_clock::now());
+    while (target_run_time <= now) {
+      target_run_time += period;
+    }
+
+    std::this_thread::sleep_for(target_run_time - now);
+  }
+}
+
+
+void SequenceEntries(TreeSigner* tree_signer,
+                     const function<bool()>& is_master) {
+  CHECK_NOTNULL(tree_signer);
+  CHECK(is_master);
+  const steady_clock::duration period(
+      (seconds(FLAGS_sequencing_frequency_seconds)));
+  steady_clock::time_point target_run_time(steady_clock::now());
+
+  while (true) {
+    if (is_master()) {
+      const ScopedLatency sequencer_sequence_latency(
+          sequencer_sequence_latency_ms.GetScopedLatency());
+      util::Status status(tree_signer->SequenceNewEntries());
+      if (!status.ok()) {
+        LOG(WARNING) << "Problem sequencing new entries: " << status;
+      }
+      sequencer_total_runs->Increment(status.ok());
+    }
+
+    const steady_clock::time_point now(steady_clock::now());
+    while (target_run_time <= now) {
+      target_run_time += period;
+    }
+
+    std::this_thread::sleep_for(target_run_time - now);
+  }
+}
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/log_processes.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/log_processes.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/log_processes.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/log_processes.h	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,25 @@
+#ifndef CERT_TRANS_SERVER_LOG_PROCESSES_H_
+#define CERT_TRANS_SERVER_LOG_PROCESSES_H_
+
+#include <functional>
+
+#include "log/logged_entry.h"
+#include "log/tree_signer.h"
+
+namespace cert_trans {
+
+// Common processes that are called by server threads at intervals. This
+// code is shared by binaries that write to logs, currently ct-server
+// (all versions) and xjson-server.
+
+void CleanUpEntries(ConsistentStore* store,
+                    const std::function<bool()>& is_master);
+
+void SequenceEntries(TreeSigner* tree_signer,
+                     const std::function<bool()>& is_master);
+
+void SignMerkleTree(TreeSigner* tree_signer, ConsistentStore* store,
+                    ClusterStateController* controller);
+}
+
+#endif  // CERT_TRANS_SERVER_LOG_PROCESSES_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/metrics.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/metrics.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/metrics.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/metrics.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,52 @@
+#include "server/metrics.h"
+
+#include <event2/buffer.h>
+#include <event2/http.h>
+#include <cstring>
+#include <sstream>
+
+#include "monitoring/prometheus/exporter.h"
+
+using std::ostringstream;
+using std::strncmp;
+
+namespace cert_trans {
+namespace {
+
+const char kPrometheusProtoContentType[] =
+    "application/vnd.google.protobuf;"
+    "proto=io.prometheus.client.MetricFamily;encoding=delimited";
+const size_t kPrometheusProtoContentTypeLen =
+    std::strlen(kPrometheusProtoContentType);
+
+}  // namespace
+
+
+void ExportPrometheusMetrics(evhttp_request* req) {
+  if (evhttp_request_get_command(req) != EVHTTP_REQ_GET) {
+    evhttp_send_reply(req, HTTP_BADMETHOD, /*reason*/ nullptr,
+                      /*databuf*/ nullptr);
+    return;
+  }
+  ostringstream oss;
+  const char* req_accept(
+      evhttp_find_header(evhttp_request_get_input_headers(req), "Accept"));
+  if (req_accept &&
+      std::strncmp(req_accept, kPrometheusProtoContentType,
+                   kPrometheusProtoContentTypeLen) == 0) {
+    evhttp_add_header(evhttp_request_get_output_headers(req), "Content-Type",
+                      kPrometheusProtoContentType);
+    ExportMetricsToPrometheus(&oss);
+  } else {
+    evhttp_add_header(evhttp_request_get_output_headers(req), "Content-Type",
+                      "text/html");
+    ExportMetricsToHtml(&oss);
+  }
+
+  evbuffer_add(evhttp_request_get_output_buffer(req), oss.str().data(),
+               oss.str().size());
+  evhttp_send_reply(req, HTTP_OK, /*reason*/ nullptr, /*databuf*/ nullptr);
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/metrics.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/metrics.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/metrics.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/metrics.h	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,14 @@
+#ifndef CERT_TRANS_SERVER_METRICS_H_
+#define CERT_TRANS_SERVER_METRICS_H_
+
+struct evhttp_request;
+
+namespace cert_trans {
+
+
+void ExportPrometheusMetrics(evhttp_request* req);
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_SERVER_METRICS_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/proxy.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/proxy.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/proxy.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/proxy.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,186 @@
+#include "server/proxy.h"
+
+#include <event2/buffer.h>
+#include <event2/http.h>
+#include <event2/http_compat.h>
+#include <event2/keyvalq_struct.h>
+#include <glog/logging.h>
+#include <algorithm>
+#include <string>
+#include <unordered_set>
+#include <vector>
+
+#include "monitoring/monitoring.h"
+#include "proto/ct.pb.h"
+#include "server/json_output.h"
+#include "util/libevent_wrapper.h"
+
+
+using ct::ClusterNodeState;
+using std::bind;
+using std::getline;
+using std::make_pair;
+using std::pair;
+using std::placeholders::_1;
+using std::rand;
+using std::string;
+using std::stringstream;
+using std::unique_ptr;
+using std::unordered_set;
+using std::vector;
+using util::Executor;
+using util::Task;
+
+namespace cert_trans {
+namespace {
+
+
+static Counter<string>* total_proxied_requests(
+    Counter<string>::New("total_proxied_requests", "path",
+                         "Number of proxied API requests by path."));
+static Counter<string, int>* total_proxied_responses(
+    Counter<string, int>::New("total_proxied_responses", "path", "status_code",
+                              "Number of proxied API requests by path "
+                              "and status code."));
+
+
+void ProxyRequestDone(libevent::Base* base, evhttp_request* request,
+                      const string& path, UrlFetcher::Response* response,
+                      Task* task) {
+  CHECK_NOTNULL(request);
+  CHECK_NOTNULL(task);
+  unique_ptr<UrlFetcher::Response> response_deleter(CHECK_NOTNULL(response));
+
+  total_proxied_requests->Increment(path);
+  total_proxied_responses->Increment(path, response->status_code);
+
+  if (!task->status().ok()) {
+    return SendJsonError(base, request, HTTP_INTERNAL,
+                         "Proxied request failed.");
+  }
+
+  // TODO(alcutter): Consider retrying the proxied request some number of times
+  // in the case where the request fails.
+  FilterHeaders(&response->headers);
+  for (auto it(response->headers.begin()); it != response->headers.end();
+       ++it) {
+    CHECK_EQ(evhttp_add_header(evhttp_request_get_output_headers(request),
+                               it->first.c_str(), it->second.c_str()),
+             0);
+  }
+  CHECK_GT(evbuffer_add_printf(evhttp_request_get_output_buffer(request), "%s",
+                               response->body.c_str()),
+           -1);
+
+  const int response_code(response->status_code);
+  base->Add([request, response_code]() {
+    evhttp_send_reply(request, response_code, /*reason*/ NULL,
+                      /*databuf*/ NULL);
+  });
+}
+
+
+}  // namespace
+
+
+// Filters out any headers which should not be proxied on.
+// See http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.10
+void FilterHeaders(UrlFetcher::Headers* headers) {
+  const auto connection_range(headers->equal_range("Connection"));
+
+  unordered_set<string> connection_headers;
+  for (auto it(connection_range.first); it != connection_range.second; ++it) {
+    stringstream ss(it->second);
+    string token;
+    while (getline(ss, token, ',')) {
+      token.erase(remove(token.begin(), token.end(), ' '), token.end());
+      if (!token.empty()) {
+        connection_headers.insert(token);
+      }
+    }
+  }
+
+  headers->erase(connection_range.first, connection_range.second);
+
+  for (const string& header : connection_headers) {
+    const auto range(headers->equal_range(header));
+    if (range.first != headers->end()) {
+      headers->erase(range.first, range.second);
+    }
+  }
+}
+
+
+Proxy::Proxy(libevent::Base* base,
+             const GetFreshNodesFunction& get_fresh_nodes, UrlFetcher* fetcher,
+             Executor* executor)
+    : base_(CHECK_NOTNULL(base)),
+      get_fresh_nodes_(get_fresh_nodes),
+      fetcher_(CHECK_NOTNULL(fetcher)),
+      executor_(CHECK_NOTNULL(executor)) {
+  CHECK(get_fresh_nodes_);
+}
+
+
+void Proxy::ProxyRequest(evhttp_request* req) const {
+  CHECK_NOTNULL(req);
+
+  const vector<ClusterNodeState> fresh_nodes(get_fresh_nodes_());
+  if (fresh_nodes.empty()) {
+    return SendJsonError(base_, req, HTTP_SERVUNAVAIL,
+                         "No node able to serve request.");
+  }
+  const ClusterNodeState& target(fresh_nodes[rand() % fresh_nodes.size()]);
+
+  URL url(evhttp_request_uri(req));
+  url.SetProtocol("http");
+  url.SetHost(target.hostname());
+  url.SetPort(target.log_port());
+
+  UrlFetcher::Request fetcher_req(url);
+
+  switch (evhttp_request_get_command(req)) {
+    case EVHTTP_REQ_DELETE:
+      fetcher_req.verb = UrlFetcher::Verb::DELETE;
+      break;
+    case EVHTTP_REQ_GET:
+      fetcher_req.verb = UrlFetcher::Verb::GET;
+      break;
+    case EVHTTP_REQ_POST:
+      fetcher_req.verb = UrlFetcher::Verb::POST;
+      break;
+    case EVHTTP_REQ_PUT:
+      fetcher_req.verb = UrlFetcher::Verb::PUT;
+      break;
+    default:
+      return SendJsonError(base_, req, HTTP_BADMETHOD,
+                           "Bad method requested.");
+      break;
+  }
+
+  for (evkeyval* ptr = evhttp_request_get_input_headers(req)->tqh_first; ptr;
+       ptr = ptr->next.tqe_next) {
+    fetcher_req.headers.insert(make_pair(ptr->key, ptr->value));
+  }
+  FilterHeaders(&fetcher_req.headers);
+  if (fetcher_req.verb == UrlFetcher::Verb::PUT ||
+      fetcher_req.verb == UrlFetcher::Verb::POST) {
+    const size_t body_length(
+        evbuffer_get_length(evhttp_request_get_input_buffer(req)));
+    string body(reinterpret_cast<const char*>(evbuffer_pullup(
+                    evhttp_request_get_input_buffer(req), body_length)),
+                body_length);
+    CHECK_EQ(0, evbuffer_drain(evhttp_request_get_input_buffer(req),
+                               body_length));
+    fetcher_req.body.swap(body);
+  }
+  VLOG(1) << "Proxying request to " << url.Host() << ":" << url.Port()
+          << url.PathQuery();
+  UrlFetcher::Response* resp(new UrlFetcher::Response);
+  fetcher_->Fetch(fetcher_req, resp, new Task(bind(&ProxyRequestDone, base_,
+                                                   req, url.Path(), resp, _1),
+                                              executor_));
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/proxy.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/proxy.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/proxy.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/proxy.h	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,57 @@
+#ifndef CERT_TRANS_SERVER_PROXY_H_
+#define CERT_TRANS_SERVER_PROXY_H_
+
+#include <functional>
+#include <vector>
+
+#include "base/macros.h"
+#include "net/url_fetcher.h"
+
+
+struct evhttp_request;
+
+namespace ct {
+class ClusterNodeState;
+}  // namespace ct
+
+namespace util {
+class Executor;
+class Status;
+class Task;
+}  // namespace util
+
+
+namespace cert_trans {
+namespace libevent {
+class Base;
+}  // namespace libevent
+
+
+// Visible for testing
+void FilterHeaders(UrlFetcher::Headers* headers);
+
+
+class Proxy {
+ public:
+  typedef std::function<std::vector<ct::ClusterNodeState>()>
+      GetFreshNodesFunction;
+  Proxy(libevent::Base* base, const GetFreshNodesFunction& get_fresh_nodes,
+        UrlFetcher* fetcher, util::Executor* executor);
+
+  virtual ~Proxy() = default;
+
+  virtual void ProxyRequest(evhttp_request* req) const;
+
+ private:
+  libevent::Base* const base_;
+  const GetFreshNodesFunction get_fresh_nodes_;
+  UrlFetcher* const fetcher_;
+  util::Executor* const executor_;
+
+  DISALLOW_COPY_AND_ASSIGN(Proxy);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_SERVER_PROXY_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/proxy_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/proxy_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/proxy_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/proxy_test.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,104 @@
+#include "server/proxy.h"
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "util/testing.h"
+
+using cert_trans::FilterHeaders;
+using cert_trans::UrlFetcher;
+using std::make_pair;
+using std::shared_ptr;
+using std::string;
+
+class ProxyTest : public ::testing::Test {};
+
+
+TEST_F(ProxyTest, TestFilterHeadersLeavesUnrelatedHeadersAlone) {
+  UrlFetcher::Headers headers;
+  headers.insert(make_pair("one", "1"));
+  headers.insert(make_pair("two", "2"));
+  headers.insert(make_pair("three", "3"));
+  headers.insert(make_pair("four", "4"));
+
+  UrlFetcher::Headers response(headers);
+
+  FilterHeaders(&response);
+  EXPECT_EQ(headers, response);
+}
+
+
+string GetAll(const UrlFetcher::Headers& headers, const string& key) {
+  const auto range(headers.equal_range(key));
+  std::string ret;
+  for (auto it(range.first); it != range.second; ++it) {
+    if (!ret.empty()) {
+      ret += ", ";
+    }
+    ret += it->second;
+  }
+  return ret;
+}
+
+
+TEST_F(ProxyTest, TestFilterHeadersRemovesReferencedHeaders) {
+  UrlFetcher::Headers expected;
+  expected.insert(make_pair("one", "1"));
+  expected.insert(make_pair("four", "4"));
+
+  UrlFetcher::Headers response(expected);
+  response.insert(make_pair("two", "2"));
+  response.insert(make_pair("three", "3"));
+  response.insert(make_pair("Connection", "two, three, wibble"));
+
+
+  FilterHeaders(&response);
+  EXPECT_EQ(expected.size(), response.size());
+  EXPECT_EQ(GetAll(expected, "one"), GetAll(response, "one"));
+  EXPECT_EQ(GetAll(expected, "four"), GetAll(response, "four"));
+}
+
+
+TEST_F(ProxyTest, TestFilterHeadersHandlesMultipleReferencedHeaders) {
+  UrlFetcher::Headers expected;
+  expected.insert(make_pair("one", "1a"));
+  expected.insert(make_pair("four", "4"));
+
+  UrlFetcher::Headers response(expected);
+  response.insert(make_pair("two", "2a"));
+  response.insert(make_pair("two", "2b"));
+  response.insert(make_pair("three", "3"));
+  response.insert(make_pair("Connection", "two, three, wibble"));
+
+
+  FilterHeaders(&response);
+  EXPECT_EQ(expected.size(), response.size());
+  EXPECT_EQ(GetAll(expected, "one"), GetAll(response, "one"));
+  EXPECT_EQ(GetAll(expected, "four"), GetAll(response, "four"));
+}
+
+
+TEST_F(ProxyTest, TestFilterHeadersHandlesMultipleConnectionHeaders) {
+  UrlFetcher::Headers expected;
+  expected.insert(make_pair("one", "1a"));
+  expected.insert(make_pair("four", "4"));
+
+  UrlFetcher::Headers response(expected);
+  response.insert(make_pair("two", "2"));
+  response.insert(make_pair("three", "3"));
+  response.insert(make_pair("Connection", "two"));
+  response.insert(make_pair("Connection", "three"));
+  response.insert(make_pair("Connection", "wibble"));
+
+
+  FilterHeaders(&response);
+  EXPECT_EQ(expected.size(), response.size());
+  EXPECT_EQ(GetAll(expected, "one"), GetAll(response, "one"));
+  EXPECT_EQ(GetAll(expected, "four"), GetAll(response, "four"));
+}
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/server.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/server.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/server.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/server.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,262 @@
+#include "server/server.h"
+
+#include <gflags/gflags.h>
+#include <chrono>
+#include <csignal>
+#include <functional>
+
+#include "log/cluster_state_controller.h"
+#include "log/etcd_consistent_store.h"
+#include "log/frontend.h"
+#include "log/log_lookup.h"
+#include "log/log_verifier.h"
+#include "monitoring/gcm/exporter.h"
+#include "monitoring/monitoring.h"
+#include "server/metrics.h"
+#include "server/proxy.h"
+#include "util/thread_pool.h"
+#include "util/uuid.h"
+
+using std::bind;
+using std::chrono::seconds;
+using std::chrono::steady_clock;
+using std::placeholders::_1;
+using std::shared_ptr;
+using std::signal;
+using std::string;
+using std::this_thread::sleep_for;
+using std::thread;
+
+// These flags are DEFINEd in server_helper to keep the validation logic
+// related to server startup options in one place.
+DECLARE_string(server);
+DECLARE_int32(port);
+DECLARE_string(etcd_root);
+
+DEFINE_int32(node_state_refresh_seconds, 10,
+             "How often to refresh the ClusterNodeState entry for this node.");
+DEFINE_int32(watchdog_seconds, 120,
+             "How many seconds without successfully refreshing this node's "
+             "before firing the watchdog timer.");
+DEFINE_bool(watchdog_timeout_is_fatal, true,
+            "Exit if the watchdog timer fires.");
+
+namespace cert_trans {
+
+
+Gauge<>* latest_local_tree_size_gauge() {
+  static Gauge<>* const gauge(
+      Gauge<>::New("latest_local_tree_size",
+                   "Size of latest locally generated STH."));
+
+  return gauge;
+}
+
+
+namespace {
+
+
+void RefreshNodeState(ClusterStateController* controller, util::Task* task) {
+  CHECK_NOTNULL(task);
+  const steady_clock::duration period(
+      (seconds(FLAGS_node_state_refresh_seconds)));
+  steady_clock::time_point target_run_time(steady_clock::now());
+
+  while (true) {
+    if (task->CancelRequested()) {
+      task->Return(util::Status::CANCELLED);
+      alarm(0);
+    }
+    // If we haven't managed to refresh our state file in a timely fashion,
+    // then send us a SIGALRM:
+    alarm(FLAGS_watchdog_seconds);
+
+    controller->RefreshNodeState();
+
+    const steady_clock::time_point now(steady_clock::now());
+    while (target_run_time <= now) {
+      target_run_time += period;
+    }
+    sleep_for(target_run_time - now);
+  }
+}
+
+
+void WatchdogTimeout(int) {
+  if (FLAGS_watchdog_timeout_is_fatal) {
+    LOG(FATAL) << "Watchdog timed out, killing process.";
+  } else {
+    LOG(INFO) << "Watchdog timeout out, ignoring.";
+  }
+}
+
+
+string GetNodeId(Database* db) {
+  string node_id;
+  if (db->NodeId(&node_id) != Database::LOOKUP_OK) {
+    node_id = UUID4();
+    LOG(INFO) << "Initializing Node DB with UUID: " << node_id;
+    db->InitializeNode(node_id);
+  } else {
+    LOG(INFO) << "Found DB with Node UUID: " << node_id;
+  }
+  return node_id;
+}
+
+
+}  // namespace
+
+
+// static
+void Server::StaticInit() {
+  CHECK_NE(SIG_ERR, signal(SIGALRM, &WatchdogTimeout));
+}
+
+
+Server::Server(const shared_ptr<libevent::Base>& event_base,
+               ThreadPool* internal_pool, ThreadPool* http_pool, Database* db,
+               EtcdClient* etcd_client, UrlFetcher* url_fetcher,
+               const LogVerifier* log_verifier)
+    : event_base_(event_base),
+      event_pump_(new libevent::EventPumpThread(event_base_)),
+      http_server_(*event_base_),
+      db_(CHECK_NOTNULL(db)),
+      log_verifier_(CHECK_NOTNULL(log_verifier)),
+      node_id_(GetNodeId(db_)),
+      url_fetcher_(CHECK_NOTNULL(url_fetcher)),
+      etcd_client_(CHECK_NOTNULL(etcd_client)),
+      election_(event_base_, etcd_client_, FLAGS_etcd_root + "/election",
+                node_id_),
+      internal_pool_(CHECK_NOTNULL(internal_pool)),
+      server_task_(internal_pool_),
+      consistent_store_(&election_,
+                        new EtcdConsistentStore(event_base_.get(),
+                                                internal_pool_, etcd_client_,
+                                                &election_, FLAGS_etcd_root,
+                                                node_id_)),
+      http_pool_(CHECK_NOTNULL(http_pool)) {
+  CHECK_LT(0, FLAGS_port);
+
+  if (FLAGS_monitoring == kPrometheus) {
+    http_server_.AddHandler("/metrics", ExportPrometheusMetrics);
+  } else if (FLAGS_monitoring == kGcm) {
+    gcm_exporter_.reset(
+        new GCMExporter(FLAGS_server, url_fetcher_, internal_pool_));
+  } else {
+    LOG(FATAL) << "Please set --monitoring to one of the supported values.";
+  }
+
+  http_server_.Bind(nullptr, FLAGS_port);
+  election_.StartElection();
+}
+
+
+Server::~Server() {
+  server_task_.Cancel();
+  node_refresh_thread_->join();
+  server_task_.Wait();
+}
+
+
+bool Server::IsMaster() const {
+  return election_.IsMaster();
+}
+
+
+MasterElection* Server::election() {
+  return &election_;
+}
+
+
+ConsistentStore* Server::consistent_store() {
+  return &consistent_store_;
+}
+
+
+ClusterStateController* Server::cluster_state_controller() {
+  return cluster_controller_.get();
+}
+
+
+LogLookup* Server::log_lookup() {
+  return log_lookup_.get();
+}
+
+
+ContinuousFetcher* Server::continuous_fetcher() {
+  return fetcher_.get();
+}
+
+
+Proxy* Server::proxy() {
+  return proxy_.get();
+}
+
+
+libevent::HttpServer* Server::http_server() {
+  return &http_server_;
+}
+
+
+void Server::WaitForReplication() const {
+  // If we're joining an existing cluster, this node needs to get its database
+  // up-to-date with the serving_sth before we can do anything, so we'll wait
+  // here for that:
+  util::StatusOr<ct::SignedTreeHead> serving_sth(
+      consistent_store_.GetServingSTH());
+  if (serving_sth.ok()) {
+    while (db_->TreeSize() < serving_sth.ValueOrDie().tree_size()) {
+      LOG(WARNING) << "Waiting for local database to catch up to serving_sth ("
+                   << db_->TreeSize() << " of "
+                   << serving_sth.ValueOrDie().tree_size() << ")";
+      sleep(1);
+    }
+  }
+}
+
+
+void Server::Initialise(bool is_mirror) {
+  fetcher_ = ContinuousFetcher::New(event_base_.get(), internal_pool_, db_,
+                                    log_verifier_, !is_mirror);
+
+  log_lookup_.reset(new LogLookup(db_));
+
+  cluster_controller_.reset(
+      new ClusterStateController(internal_pool_, event_base_, url_fetcher_,
+                                 db_, &consistent_store_, &election_,
+                                 fetcher_.get()));
+
+  // Publish this node's hostname:port info
+  cluster_controller_->SetNodeHostPort(FLAGS_server, FLAGS_port);
+  {
+    ct::SignedTreeHead db_sth;
+    if (db_->LatestTreeHead(&db_sth) == Database::LOOKUP_OK) {
+      const LogVerifier::LogVerifyResult sth_verify_result(
+          log_verifier_->VerifySignedTreeHead(db_sth));
+      if (sth_verify_result != LogVerifier::VERIFY_OK) {
+        LOG(FATAL) << "STH retrieved from DB did not verify: "
+                   << LogVerifier::VerifyResultString(sth_verify_result);
+      }
+      cluster_controller_->NewTreeHead(db_sth);
+    }
+  }
+
+  node_refresh_thread_.reset(new thread(&RefreshNodeState,
+                                        cluster_controller_.get(),
+                                        server_task_.task()));
+
+  proxy_.reset(new Proxy(event_base_.get(),
+                         bind(&ClusterStateController::GetFreshNodes,
+                              cluster_controller_.get()),
+                         url_fetcher_, http_pool_));
+}
+
+
+void Server::Run() {
+  // Ding the temporary event pump because we're about to enter the event loop
+  event_pump_.reset();
+  event_base_->Dispatch();
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/server.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/server.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/server.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/server.h	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,91 @@
+#ifndef CERT_TRANS_SERVER_SERVER_H_
+#define CERT_TRANS_SERVER_SERVER_H_
+
+#include <stdint.h>
+#include <memory>
+#include <string>
+#include <thread>
+
+#include "base/macros.h"
+#include "log/strict_consistent_store.h"
+#include "monitoring/gauge.h"
+#include "util/libevent_wrapper.h"
+#include "util/masterelection.h"
+#include "util/sync_task.h"
+
+class Frontend;
+class LogVerifier;
+
+namespace cert_trans {
+
+class ClusterStateController;
+// TODO(pphaneuf): Not needed?
+class ConsistentStore;
+class ContinuousFetcher;
+class Database;
+class EtcdClient;
+class GCMExporter;
+class LogLookup;
+class LogSigner;
+class LoggedEntry;
+class Proxy;
+class ThreadPool;
+class UrlFetcher;
+
+// Size of latest locally generated STH.
+Gauge<>* latest_local_tree_size_gauge();
+
+
+class Server {
+ public:
+  static void StaticInit();
+
+  // Doesn't take ownership of anything.
+  Server(const std::shared_ptr<libevent::Base>& event_base,
+         ThreadPool* internal_pool, ThreadPool* http_pool, Database* db,
+         EtcdClient* etcd_client, UrlFetcher* url_fetcher,
+         const LogVerifier* log_verifier);
+  ~Server();
+
+  bool IsMaster() const;
+  MasterElection* election();
+  ConsistentStore* consistent_store();
+  ClusterStateController* cluster_state_controller();
+  LogLookup* log_lookup();
+  ContinuousFetcher* continuous_fetcher();
+  Proxy* proxy();
+  libevent::HttpServer* http_server();
+
+  void Initialise(bool is_mirror);
+  void WaitForReplication() const;
+  void Run();
+
+ private:
+  const std::shared_ptr<libevent::Base> event_base_;
+  std::unique_ptr<libevent::EventPumpThread> event_pump_;
+  libevent::HttpServer http_server_;
+  Database* const db_;
+  const LogVerifier* const log_verifier_;
+  const std::string node_id_;
+  UrlFetcher* const url_fetcher_;
+  EtcdClient* const etcd_client_;
+  MasterElection election_;
+  ThreadPool* const internal_pool_;
+  util::SyncTask server_task_;
+  StrictConsistentStore consistent_store_;
+  const std::unique_ptr<Frontend> frontend_;
+  std::unique_ptr<LogLookup> log_lookup_;
+  std::unique_ptr<ClusterStateController> cluster_controller_;
+  std::unique_ptr<ContinuousFetcher> fetcher_;
+  ThreadPool* const http_pool_;
+  std::unique_ptr<Proxy> proxy_;
+  std::unique_ptr<std::thread> node_refresh_thread_;
+  std::unique_ptr<GCMExporter> gcm_exporter_;
+
+  DISALLOW_COPY_AND_ASSIGN(Server);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_SERVER_SERVER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/server_helper.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/server_helper.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/server_helper.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/server_helper.cc	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,140 @@
+#include "log/strict_consistent_store.h"
+#include "server/server.h"
+#include "server/server_helper.h"
+#include "util/fake_etcd.h"
+
+using cert_trans::Server;
+using google::RegisterFlagValidator;
+using std::string;
+using std::unique_ptr;
+
+// Main server configuration flags
+DEFINE_string(server, "localhost", "Server host");
+DEFINE_int32(port, 6962, "Server port");
+DEFINE_string(etcd_root, "/root", "Root of cluster entries in etcd.");
+DEFINE_string(etcd_servers, "",
+              "Comma separated list of 'hostname:port' of the etcd server(s)");
+DEFINE_bool(i_know_stand_alone_mode_can_lose_data, false,
+            "Set this to allow stand-alone mode, even though it will lose "
+            "submissions in the case of a crash.");
+
+// Storage related flags
+// TODO(alcutter): Just specify a root dir with a single flag.
+DEFINE_string(cert_dir, "", "Storage directory for certificates");
+DEFINE_string(tree_dir, "", "Storage directory for trees");
+DEFINE_string(meta_dir, "", "Storage directory for meta info");
+DEFINE_string(sqlite_db, "",
+              "SQLite database for certificate and tree storage");
+DEFINE_string(leveldb_db, "",
+              "LevelDB database for certificate and tree storage");
+// TODO(ekasper): sanity-check these against the directory structure.
+DEFINE_int32(cert_storage_depth, 0,
+             "Subdirectory depth for certificates; if the directory is not "
+             "empty, must match the existing depth.");
+DEFINE_int32(tree_storage_depth, 0,
+             "Subdirectory depth for tree signatures; if the directory is not "
+             "empty, must match the existing depth");
+
+// Basic sanity checks on flag values.
+static bool ValidateWrite(const char* flagname, const string& path) {
+  if (path != "" && access(path.c_str(), W_OK) != 0) {
+    std::cout << "Cannot modify " << flagname << " at " << path << std::endl;
+    return false;
+  }
+  return true;
+}
+
+static bool ValidateIsNonNegative(const char* flagname, int value) {
+  if (value < 0) {
+    std::cout << flagname << " must not be negative" << std::endl;
+    return false;
+  }
+  return true;
+}
+
+static bool ValidatePort(const char*, int port) {
+  if (port <= 0 || port > 65535) {
+    std::cout << "Port value " << port << " is invalid. " << std::endl;
+    return false;
+  }
+  return true;
+}
+
+static const bool port_dummy =
+    RegisterFlagValidator(&FLAGS_port, &ValidatePort);
+
+static const bool cert_dir_dummy =
+    RegisterFlagValidator(&FLAGS_cert_dir, &ValidateWrite);
+
+static const bool tree_dir_dummy =
+    RegisterFlagValidator(&FLAGS_tree_dir, &ValidateWrite);
+
+static const bool c_st_dummy =
+    RegisterFlagValidator(&FLAGS_cert_storage_depth, &ValidateIsNonNegative);
+
+static const bool t_st_dummy =
+    RegisterFlagValidator(&FLAGS_tree_storage_depth, &ValidateIsNonNegative);
+
+namespace cert_trans {
+
+void EnsureValidatorsRegistered() {
+  CHECK(cert_dir_dummy && tree_dir_dummy && c_st_dummy && t_st_dummy &&
+        port_dummy);
+}
+
+
+bool IsStandalone(bool warn_data_loss) {
+  const bool stand_alone_mode(FLAGS_etcd_servers.empty());
+  if (stand_alone_mode && warn_data_loss &&
+      !FLAGS_i_know_stand_alone_mode_can_lose_data) {
+    LOG(FATAL) << "attempted to run in stand-alone mode without the "
+                  "--i_know_stand_alone_mode_can_lose_data flag";
+  }
+
+  if (!stand_alone_mode && FLAGS_server.empty()) {
+    // Part of a cluster so server must be set
+    LOG(FATAL) << "not in stand-alone mode but --server is empty";
+  }
+
+  return stand_alone_mode;
+}
+
+
+unique_ptr<Database> ProvideDatabase() {
+  if (!FLAGS_sqlite_db.empty() + !FLAGS_leveldb_db.empty() +
+          (!FLAGS_cert_dir.empty() | !FLAGS_tree_dir.empty()) !=
+      1) {
+    LOG(FATAL) << "Must specify exactly one database type. Check flags.";
+  }
+
+  if (FLAGS_sqlite_db.empty() && FLAGS_leveldb_db.empty()) {
+    CHECK_NE(FLAGS_cert_dir, FLAGS_tree_dir)
+        << "Certificate directory and tree directory must differ";
+  }
+
+  if (!FLAGS_sqlite_db.empty()) {
+    return unique_ptr<Database>(new SQLiteDB(FLAGS_sqlite_db));
+  } else if (!FLAGS_leveldb_db.empty()) {
+    return unique_ptr<Database>(new LevelDB(FLAGS_leveldb_db));
+  } else {
+    return unique_ptr<Database>(
+        new FileDB(new FileStorage(FLAGS_cert_dir, FLAGS_cert_storage_depth),
+                   new FileStorage(FLAGS_tree_dir, FLAGS_tree_storage_depth),
+                   new FileStorage(FLAGS_meta_dir, 0)));
+  }
+
+  LOG(FATAL) << "No usable database is configured by flags";
+}
+
+
+unique_ptr<EtcdClient> ProvideEtcdClient(libevent::Base* event_base,
+                                         ThreadPool* pool,
+                                         UrlFetcher* fetcher) {
+  // No need to enforce --warn-data-loss here as it will already have been
+  // done if required
+  return unique_ptr<EtcdClient>(
+      IsStandalone(false)
+          ? new FakeEtcdClient(event_base)
+          : new EtcdClient(pool, fetcher, SplitHosts(FLAGS_etcd_servers)));
+}
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/server_helper.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/server_helper.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/server_helper.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/server_helper.h	2017-01-15 10:56:31.046591151 +0100
@@ -0,0 +1,58 @@
+#ifndef CERT_TRANS_SERVER_SERVER_HELPER_H_
+#define CERT_TRANS_SERVER_SERVER_HELPER_H_
+
+#include <gflags/gflags.h>
+#include <openssl/crypto.h>
+#include <chrono>
+#include <csignal>
+#include <cstring>
+#include <functional>
+#include <iostream>
+#include <memory>
+#include <mutex>
+
+#include "base/macros.h"
+#include "log/database.h"
+#include "log/file_db.h"
+#include "log/file_storage.h"
+#include "log/leveldb_db.h"
+#include "log/sqlite_db.h"
+#include "util/etcd.h"
+#include "util/executor.h"
+#include "util/libevent_wrapper.h"
+#include "util/thread_pool.h"
+
+namespace cert_trans {
+
+// This includes code common to multiple CT servers. It handles parsing
+// flags and creating objects that are used by multiple servers. Anything that
+// is specific one type of CT server should not be in this class.
+//
+// Do not link server_helper into servers that don't use it as it will confuse
+// the user with extra flags.
+//
+// Note methods named ProvideX create a new instance of X each call. Typically
+// they are called once during server initialization and the return object
+// lifetime is the same as that of the server.
+
+// Calling this will CHECK if the flag validators failed to register
+void EnsureValidatorsRegistered();
+
+// Tests if the server was configured in standalone mode. Note can CHECK if
+// the command line options are inconsistent. If warn_data_loss is true
+// the user must set the --i_know_stand_alone_mode_can_lose_data flag as
+// standalone servers are inherently prone to data loss, though useful for
+// development and testing.
+bool IsStandalone(bool warn_data_loss);
+
+// Create one of the supported database types based on flags settings
+std::unique_ptr<Database> ProvideDatabase();
+
+// Create an EtcdClient implementation, either fake or real based on flags
+std::unique_ptr<EtcdClient> ProvideEtcdClient(libevent::Base* event_base,
+                                              ThreadPool* pool,
+                                              UrlFetcher* fetcher);
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_SERVER_SERVER_HELPER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/staleness_tracker.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/staleness_tracker.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/staleness_tracker.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/staleness_tracker.cc	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,66 @@
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <algorithm>
+#include <string>
+#include <vector>
+
+#include "log/cluster_state_controller.h"
+#include "log/logged_entry.h"
+#include "server/staleness_tracker.h"
+#include "util/thread_pool.h"
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::StalenessTracker;
+using cert_trans::LoggedEntry;
+using std::bind;
+using std::chrono::seconds;
+using std::lock_guard;
+using std::mutex;
+
+DEFINE_int32(staleness_check_delay_secs, 5,
+             "number of seconds between node staleness checks");
+
+
+StalenessTracker::StalenessTracker(const ClusterStateController* controller,
+                                   ThreadPool* pool,
+                                   libevent::Base* event_base)
+    : controller_(CHECK_NOTNULL(controller)),
+      pool_(CHECK_NOTNULL(pool)),
+      event_base_(CHECK_NOTNULL(event_base)),
+      task_(pool_),
+      node_is_stale_(controller_->NodeIsStale()) {
+  event_base_->Delay(seconds(FLAGS_staleness_check_delay_secs),
+                     task_.task()->AddChild(
+                         bind(&StalenessTracker::UpdateNodeStaleness, this)));
+}
+
+
+StalenessTracker::~StalenessTracker() {
+  task_.task()->Return();
+  task_.Wait();
+}
+
+
+bool StalenessTracker::IsNodeStale() const {
+  lock_guard<mutex> lock(mutex_);
+  return node_is_stale_;
+}
+
+
+void StalenessTracker::UpdateNodeStaleness() {
+  if (!task_.task()->IsActive()) {
+    // We're shutting down, just return.
+    return;
+  }
+
+  const bool node_is_stale(controller_->NodeIsStale());
+  {
+    lock_guard<mutex> lock(mutex_);
+    node_is_stale_ = node_is_stale;
+  }
+
+  event_base_->Delay(seconds(FLAGS_staleness_check_delay_secs),
+                     task_.task()->AddChild(
+                         bind(&StalenessTracker::UpdateNodeStaleness, this)));
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/staleness_tracker.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/staleness_tracker.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/staleness_tracker.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/staleness_tracker.h	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,48 @@
+#ifndef CERT_TRANS_SERVER_STALENESS_TRACKER_H_
+#define CERT_TRANS_SERVER_STALENESS_TRACKER_H_
+
+#include <memory>
+#include <mutex>
+#include <string>
+
+#include "log/logged_entry.h"
+#include "util/libevent_wrapper.h"
+#include "util/sync_task.h"
+#include "util/task.h"
+
+namespace cert_trans {
+
+class ClusterStateController;
+class ThreadPool;
+
+
+class StalenessTracker {
+ public:
+  // Does not take ownership of its parameters, which must outlive
+  // this instance.
+  StalenessTracker(const ClusterStateController* controller, ThreadPool* pool,
+                   libevent::Base* event_base);
+  virtual ~StalenessTracker();
+
+  // Check if we consider our node to be stale
+  bool IsNodeStale() const;
+  // Update our view of node staleness from the controller. This causes
+  // periodic updates to be scheduled
+  void UpdateNodeStaleness();
+
+ private:
+  const ClusterStateController* const controller_;
+  ThreadPool* const pool_;
+  libevent::Base* const event_base_;
+
+  util::SyncTask task_;
+  mutable std::mutex mutex_;
+  bool node_is_stale_;
+
+  DISALLOW_COPY_AND_ASSIGN(StalenessTracker);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_SERVER_STALENESS_TRACKER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/x_json_handler.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/x_json_handler.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/x_json_handler.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/x_json_handler.cc	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,102 @@
+#include "server/x_json_handler.h"
+
+#include <functional>
+
+#include "log/frontend.h"
+#include "server/json_output.h"
+#include "util/statusor.h"
+#include "util/thread_pool.h"
+
+namespace cert_trans {
+
+using ct::LogEntry;
+using ct::SignedCertificateTimestamp;
+using ct::X_JSON_ENTRY;
+using std::bind;
+using std::make_shared;
+using std::move;
+using std::multimap;
+using std::placeholders::_1;
+using std::shared_ptr;
+using std::string;
+using util::Status;
+
+
+namespace {
+
+
+shared_ptr<JsonObject> ExtractJson(libevent::Base* base, evhttp_request* req) {
+  CHECK_NOTNULL(base);
+  CHECK_NOTNULL(req);
+  if (evhttp_request_get_command(req) != EVHTTP_REQ_POST) {
+    SendJsonError(base, req, HTTP_BADMETHOD, "Method not allowed.");
+    return nullptr;
+  }
+
+  // TODO(pphaneuf): Should we check that Content-Type says
+  // "application/json", as recommended by RFC4627?
+  shared_ptr<JsonObject> json_body(
+      make_shared<JsonObject>(evhttp_request_get_input_buffer(req)));
+  if (!json_body->Ok() || !json_body->IsType(json_type_object)) {
+    SendJsonError(base, req, HTTP_BADREQUEST,
+                  "Unable to parse provided JSON.");
+    return nullptr;
+  }
+
+  VLOG(2) << "ExtractJson:\n" << json_body->DebugString();
+  return json_body;
+}
+
+
+}  // namespace
+
+
+XJsonHttpHandler::XJsonHttpHandler(LogLookup* log_lookup,
+                                   const ReadOnlyDatabase* db,
+                                   const ClusterStateController* controller,
+                                   Frontend* frontend, ThreadPool* pool,
+                                   libevent::Base* event_base,
+                                   StalenessTracker* staleness_tracker)
+    : HttpHandler(log_lookup, db, controller, pool, event_base,
+                  staleness_tracker),
+      frontend_(frontend) {
+}
+
+
+void XJsonHttpHandler::AddHandlers(libevent::HttpServer* server) {
+  if (frontend_) {
+    // Proxy the add-* calls too, technically we could serve them, but a
+    // more up-to-date node will have a better chance of handling dupes
+    // correctly, rather than bloating the tree.
+    AddProxyWrappedHandler(server, "/ct/v1/add-json",
+                           bind(&XJsonHttpHandler::AddJson, this, _1));
+  }
+}
+
+
+void XJsonHttpHandler::AddJson(evhttp_request* req) {
+  shared_ptr<JsonObject> json(ExtractJson(event_base_, req));
+  if (!json) {
+    return;
+  }
+
+  pool_->Add(bind(&XJsonHttpHandler::BlockingAddJson, this, req, json));
+}
+
+
+void XJsonHttpHandler::BlockingAddJson(evhttp_request* req,
+                                       shared_ptr<JsonObject> json) const {
+  SignedCertificateTimestamp sct;
+
+  LogEntry entry;
+  // do this here for now
+  entry.set_type(X_JSON_ENTRY);
+  entry.mutable_x_json_entry()->set_json(json->ToString());
+
+  AddEntryReply(req, CHECK_NOTNULL(frontend_)
+                         ->QueueProcessedEntry(Status::OK, entry, &sct),
+                sct);
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/x_json_handler.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/x_json_handler.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/x_json_handler.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/x_json_handler.h	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,44 @@
+#ifndef CERT_TRANS_SERVER_X_JSON_HANDLER_H_
+#define CERT_TRANS_SERVER_X_JSON_HANDLER_H_
+
+#include <memory>
+
+#include "log/logged_entry.h"
+#include "server/handler.h"
+#include "server/staleness_tracker.h"
+#include "util/json_wrapper.h"
+
+namespace cert_trans {
+
+
+class XJsonHttpHandler : public HttpHandler {
+ public:
+  // Does not take ownership of its parameters, which must outlive this
+  // instance.  The |frontend| parameters can be NULL, in which case this
+  // server will not accept "add-json" requests.
+  XJsonHttpHandler(LogLookup* log_lookup, const ReadOnlyDatabase* db,
+                   const ClusterStateController* controller,
+                   Frontend* frontend, ThreadPool* pool,
+                   libevent::Base* event_base, StalenessTracker*);
+
+  ~XJsonHttpHandler() = default;
+
+ protected:
+  void AddHandlers(libevent::HttpServer* server) override;
+
+ private:
+  Frontend* const frontend_;
+
+  void AddJson(evhttp_request* req);
+
+  void BlockingAddJson(evhttp_request* req,
+                       std::shared_ptr<JsonObject> json) const;
+
+  DISALLOW_COPY_AND_ASSIGN(XJsonHttpHandler);
+};
+
+
+}  // namespace cert_trans
+
+
+#endif  // CERT_TRANS_SERVER_X_JSON_HANDLER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/xjson-server.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/xjson-server.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/server/xjson-server.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/server/xjson-server.cc	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,205 @@
+/* -*- indent-tabs-mode: nil -*- */
+
+#include <gflags/gflags.h>
+#include <openssl/err.h>
+#include <signal.h>
+#include <signal.h>
+#include <stdlib.h>
+#include <unistd.h>
+#include <iostream>
+#include <string>
+#include <string>
+
+#include "config.h"
+#include "log/cert_checker.h"
+#include "log/cert_submission_handler.h"
+#include "log/cluster_state_controller.h"
+#include "log/etcd_consistent_store.h"
+#include "log/frontend.h"
+#include "log/frontend_signer.h"
+#include "log/log_lookup.h"
+#include "log/log_signer.h"
+#include "log/log_verifier.h"
+#include "log/strict_consistent_store.h"
+#include "log/tree_signer.h"
+#include "merkletree/merkle_verifier.h"
+#include "proto/xjson_serializer.h"
+#include "server/log_processes.h"
+#include "server/server.h"
+#include "server/server_helper.h"
+#include "server/staleness_tracker.h"
+#include "server/x_json_handler.h"
+#include "util/etcd.h"
+#include "util/init.h"
+#include "util/libevent_wrapper.h"
+#include "util/read_key.h"
+#include "util/status.h"
+#include "util/uuid.h"
+
+DEFINE_string(key, "", "PEM-encoded server private key file");
+DEFINE_double(guard_window_seconds, 60,
+              "Unsequenced entries newer than this "
+              "number of seconds will not be sequenced.");
+DEFINE_int32(num_http_server_threads, 16,
+             "Number of threads for servicing the incoming HTTP requests.");
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::CleanUpEntries;
+using cert_trans::ClusterStateController;
+using cert_trans::ConsistentStore;
+using cert_trans::Database;
+using cert_trans::EtcdClient;
+using cert_trans::EtcdConsistentStore;
+using cert_trans::LoggedEntry;
+using cert_trans::ReadPrivateKey;
+using cert_trans::SequenceEntries;
+using cert_trans::Server;
+using cert_trans::SignMerkleTree;
+using cert_trans::StalenessTracker;
+using cert_trans::ThreadPool;
+using cert_trans::TreeSigner;
+using cert_trans::UrlFetcher;
+using cert_trans::XJsonHttpHandler;
+using ct::ClusterNodeState;
+using ct::SignedTreeHead;
+using google::RegisterFlagValidator;
+using std::bind;
+using std::function;
+using std::make_shared;
+using std::shared_ptr;
+using std::string;
+using std::thread;
+using std::unique_ptr;
+
+
+namespace {
+
+// Basic sanity checks on flag values.
+static bool ValidateRead(const char* flagname, const string& path) {
+  if (access(path.c_str(), R_OK) != 0) {
+    std::cout << "Cannot access " << flagname << " at " << path << std::endl;
+    return false;
+  }
+  return true;
+}
+
+static const bool key_dummy = RegisterFlagValidator(&FLAGS_key, &ValidateRead);
+
+}  // namespace
+
+
+int main(int argc, char* argv[]) {
+  // Ignore various signals whilst we start up.
+  signal(SIGHUP, SIG_IGN);
+  signal(SIGINT, SIG_IGN);
+  signal(SIGTERM, SIG_IGN);
+
+  ConfigureSerializerForV1XJSON();
+  util::InitCT(&argc, &argv);
+
+  Server::StaticInit();
+
+  util::StatusOr<EVP_PKEY*> pkey(ReadPrivateKey(FLAGS_key));
+  CHECK_EQ(pkey.status(), util::Status::OK);
+  LogSigner log_signer(pkey.ValueOrDie());
+
+  cert_trans::EnsureValidatorsRegistered();
+  const unique_ptr<Database> db(cert_trans::ProvideDatabase());
+  CHECK(db) << "No database instance created, check flag settings";
+
+  shared_ptr<libevent::Base> event_base(make_shared<libevent::Base>());
+  ThreadPool internal_pool(8);
+  UrlFetcher url_fetcher(event_base.get(), &internal_pool);
+
+  const bool stand_alone_mode(cert_trans::IsStandalone(true));
+  LOG(INFO) << "Running in "
+            << (stand_alone_mode ? "STAND-ALONE" : "CLUSTERED") << " mode.";
+
+  unique_ptr<EtcdClient> etcd_client(
+      cert_trans::ProvideEtcdClient(event_base.get(), &internal_pool,
+                                    &url_fetcher));
+
+  const LogVerifier log_verifier(new LogSigVerifier(pkey.ValueOrDie()),
+                                 new MerkleVerifier(unique_ptr<Sha256Hasher>(
+                                     new Sha256Hasher)));
+
+  ThreadPool http_pool(FLAGS_num_http_server_threads);
+
+  Server server(event_base, &internal_pool, &http_pool, db.get(),
+                etcd_client.get(), &url_fetcher, &log_verifier);
+  server.Initialise(false /* is_mirror */);
+
+  Frontend frontend(
+      new FrontendSigner(db.get(), server.consistent_store(), &log_signer));
+  unique_ptr<StalenessTracker> staleness_tracker(
+      new StalenessTracker(server.cluster_state_controller(), &internal_pool,
+                           event_base.get()));
+  XJsonHttpHandler handler(server.log_lookup(), db.get(),
+                           server.cluster_state_controller(), &frontend,
+                           &internal_pool, event_base.get(),
+                           staleness_tracker.get());
+
+  // Connect the handler, proxy and server together
+  handler.SetProxy(server.proxy());
+  handler.Add(server.http_server());
+
+  TreeSigner tree_signer(std::chrono::duration<double>(FLAGS_guard_window_seconds), db.get(), server.log_lookup()->GetCompactMerkleTree(new Sha256Hasher), server.consistent_store(), &log_signer);
+
+  if (stand_alone_mode) {
+    // Set up a simple single-node environment.
+    //
+    // Put a sensible single-node config into FakeEtcd. For a real clustered
+    // log
+    // we'd expect a ClusterConfig already to be present within etcd as part of
+    // the provisioning of the log.
+    //
+    // TODO(alcutter): Note that we're currently broken wrt to restarting the
+    // log server when there's data in the log.  It's a temporary thing though,
+    // so fear ye not.
+    ct::ClusterConfig config;
+    config.set_minimum_serving_nodes(1);
+    config.set_minimum_serving_fraction(1);
+    LOG(INFO) << "Setting default single-node ClusterConfig:\n"
+              << config.DebugString();
+    server.consistent_store()->SetClusterConfig(config);
+
+    // Since we're a single node cluster, we'll settle that we're the
+    // master here, so that we can populate the initial STH
+    // (StrictConsistentStore won't allow us to do so unless we're master.)
+    server.election()->StartElection();
+    server.election()->WaitToBecomeMaster();
+
+    {
+      EtcdClient::Response resp;
+      util::SyncTask task(event_base.get());
+      etcd_client->Create("/root/sequence_mapping", "", &resp, task.task());
+      task.Wait();
+      CHECK_EQ(util::Status::OK, task.status());
+    }
+
+    // Do an initial signing run to get the initial STH, again this is
+    // temporary until we re-populate FakeEtcd from the DB.
+    CHECK_EQ(tree_signer.UpdateTree(), TreeSigner::OK);
+
+    // Need to boot-strap the Serving STH too because we consider it an error
+    // if it's not set, which in turn causes us to not attempt to become
+    // master:
+    server.consistent_store()->SetServingSTH(tree_signer.LatestSTH());
+  }
+
+  server.WaitForReplication();
+
+  // TODO(pphaneuf): We should be remaining in an "unhealthy state"
+  // (either not accepting any requests, or returning some internal
+  // server error) until we have an STH to serve.
+  const function<bool()> is_master(bind(&Server::IsMaster, &server));
+  thread sequencer(&SequenceEntries, &tree_signer, is_master);
+  thread cleanup(&CleanUpEntries, server.consistent_store(), is_master);
+  thread signer(&SignMerkleTree, &tree_signer, server.consistent_store(),
+                server.cluster_state_controller());
+
+  server.Run();
+
+  return 0;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/third_party/curl/hostcheck.c src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/third_party/curl/hostcheck.c
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/third_party/curl/hostcheck.c	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/third_party/curl/hostcheck.c	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,214 @@
+/***************************************************************************
+ *                                  _   _ ____  _
+ *  Project                     ___| | | |  _ \| |
+ *                             / __| | | | |_) | |
+ *                            | (__| |_| |  _ <| |___
+ *                             \___|\___/|_| \_\_____|
+ *
+ * Copyright (C) 1998 - 2012, Daniel Stenberg, <daniel@haxx.se>, et al.
+ *
+ * This software is licensed as described in the file COPYING, which
+ * you should have received as part of this distribution. The terms
+ * are also available at http://curl.haxx.se/docs/copyright.html.
+ *
+ * You may opt to use, copy, modify, merge, publish, distribute and/or sell
+ * copies of the Software, and permit persons to whom the Software is
+ * furnished to do so, under the terms of the COPYING file.
+ *
+ * This software is distributed on an "AS IS" basis, WITHOUT WARRANTY OF ANY
+ * KIND, either express or implied.
+ *
+ ***************************************************************************/
+
+/* This file is an amalgamation of hostcheck.c and most of rawstr.c
+   from cURL.  The contents of the COPYING file mentioned above are:
+
+COPYRIGHT AND PERMISSION NOTICE
+
+Copyright (c) 1996 - 2013, Daniel Stenberg, <daniel@haxx.se>.
+
+All rights reserved.
+
+Permission to use, copy, modify, and distribute this software for any purpose
+with or without fee is hereby granted, provided that the above copyright
+notice and this permission notice appear in all copies.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF THIRD PARTY RIGHTS. IN
+NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
+DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
+OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE
+OR OTHER DEALINGS IN THE SOFTWARE.
+
+Except as contained in this notice, the name of a copyright holder shall not
+be used in advertising or otherwise to promote the sale, use or other dealings
+in this Software without prior written authorization of the copyright holder.
+*/
+
+#include "hostcheck.h"
+#include <string.h>
+
+/* Portable, consistent toupper (remember EBCDIC). Do not use toupper() because
+   its behavior is altered by the current locale. */
+static char Curl_raw_toupper(char in) {
+  switch (in) {
+    case 'a':
+      return 'A';
+    case 'b':
+      return 'B';
+    case 'c':
+      return 'C';
+    case 'd':
+      return 'D';
+    case 'e':
+      return 'E';
+    case 'f':
+      return 'F';
+    case 'g':
+      return 'G';
+    case 'h':
+      return 'H';
+    case 'i':
+      return 'I';
+    case 'j':
+      return 'J';
+    case 'k':
+      return 'K';
+    case 'l':
+      return 'L';
+    case 'm':
+      return 'M';
+    case 'n':
+      return 'N';
+    case 'o':
+      return 'O';
+    case 'p':
+      return 'P';
+    case 'q':
+      return 'Q';
+    case 'r':
+      return 'R';
+    case 's':
+      return 'S';
+    case 't':
+      return 'T';
+    case 'u':
+      return 'U';
+    case 'v':
+      return 'V';
+    case 'w':
+      return 'W';
+    case 'x':
+      return 'X';
+    case 'y':
+      return 'Y';
+    case 'z':
+      return 'Z';
+  }
+  return in;
+}
+
+/*
+ * Curl_raw_equal() is for doing "raw" case insensitive strings. This is meant
+ * to be locale independent and only compare strings we know are safe for
+ * this.  See http://daniel.haxx.se/blog/2008/10/15/strcasecmp-in-turkish/ for
+ * some further explanation to why this function is necessary.
+ *
+ * The function is capable of comparing a-z case insensitively even for
+ * non-ascii.
+ */
+
+static int Curl_raw_equal(const char *first, const char *second) {
+  while (*first && *second) {
+    if (Curl_raw_toupper(*first) != Curl_raw_toupper(*second))
+      /* get out of the loop as soon as they don't match */
+      break;
+    first++;
+    second++;
+  }
+  /* we do the comparison here (possibly again), just to make sure that if the
+     loop above is skipped because one of the strings reached zero, we must not
+     return this as a successful match */
+  return (Curl_raw_toupper(*first) == Curl_raw_toupper(*second));
+}
+
+static int Curl_raw_nequal(const char *first, const char *second, size_t max) {
+  while (*first && *second && max) {
+    if (Curl_raw_toupper(*first) != Curl_raw_toupper(*second)) {
+      break;
+    }
+    max--;
+    first++;
+    second++;
+  }
+  if (0 == max)
+    return 1; /* they are equal this far */
+
+  return Curl_raw_toupper(*first) == Curl_raw_toupper(*second);
+}
+
+/*
+ * Match a hostname against a wildcard pattern.
+ * E.g.
+ *  "foo.host.com" matches "*.host.com".
+ *
+ * We use the matching rule described in RFC6125, section 6.4.3.
+ * http://tools.ietf.org/html/rfc6125#section-6.4.3
+ */
+
+static int hostmatch(const char *hostname, const char *pattern) {
+  const char *pattern_label_end, *pattern_wildcard, *hostname_label_end;
+  int wildcard_enabled;
+  size_t prefixlen, suffixlen;
+  pattern_wildcard = strchr(pattern, '*');
+  if (pattern_wildcard == NULL)
+    return Curl_raw_equal(pattern, hostname) ? CURL_HOST_MATCH
+                                             : CURL_HOST_NOMATCH;
+
+  /* We require at least 2 dots in pattern to avoid too wide wildcard
+     match. */
+  wildcard_enabled = 1;
+  pattern_label_end = strchr(pattern, '.');
+  if (pattern_label_end == NULL ||
+      strchr(pattern_label_end + 1, '.') == NULL ||
+      pattern_wildcard > pattern_label_end ||
+      Curl_raw_nequal(pattern, "xn--", 4)) {
+    wildcard_enabled = 0;
+  }
+  if (!wildcard_enabled)
+    return Curl_raw_equal(pattern, hostname) ? CURL_HOST_MATCH
+                                             : CURL_HOST_NOMATCH;
+
+  hostname_label_end = strchr(hostname, '.');
+  if (hostname_label_end == NULL ||
+      !Curl_raw_equal(pattern_label_end, hostname_label_end))
+    return CURL_HOST_NOMATCH;
+
+  /* The wildcard must match at least one character, so the left-most
+     label of the hostname is at least as large as the left-most label
+     of the pattern. */
+  if (hostname_label_end - hostname < pattern_label_end - pattern)
+    return CURL_HOST_NOMATCH;
+
+  prefixlen = pattern_wildcard - pattern;
+  suffixlen = pattern_label_end - (pattern_wildcard + 1);
+  return Curl_raw_nequal(pattern, hostname, prefixlen) &&
+                 Curl_raw_nequal(pattern_wildcard + 1,
+                                 hostname_label_end - suffixlen, suffixlen)
+             ? CURL_HOST_MATCH
+             : CURL_HOST_NOMATCH;
+}
+
+int Curl_cert_hostcheck(const char *match_pattern, const char *hostname) {
+  if (!match_pattern || !*match_pattern || !hostname ||
+      !*hostname) /* sanity check */
+    return 0;
+
+  if (Curl_raw_equal(hostname, match_pattern)) /* trivial case */
+    return 1;
+
+  if (hostmatch(hostname, match_pattern) == CURL_HOST_MATCH)
+    return 1;
+  return 0;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/third_party/curl/hostcheck.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/third_party/curl/hostcheck.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/third_party/curl/hostcheck.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/third_party/curl/hostcheck.h	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,29 @@
+#ifndef HEADER_CURL_HOSTCHECK_H
+#define HEADER_CURL_HOSTCHECK_H
+/***************************************************************************
+ *                                  _   _ ____  _
+ *  Project                     ___| | | |  _ \| |
+ *                             / __| | | | |_) | |
+ *                            | (__| |_| |  _ <| |___
+ *                             \___|\___/|_| \_\_____|
+ *
+ * Copyright (C) 1998 - 2012, Daniel Stenberg, <daniel@haxx.se>, et al.
+ *
+ * This software is licensed as described in the file COPYING, which
+ * you should have received as part of this distribution. The terms
+ * are also available at http://curl.haxx.se/docs/copyright.html.
+ *
+ * You may opt to use, copy, modify, merge, publish, distribute and/or sell
+ * copies of the Software, and permit persons to whom the Software is
+ * furnished to do so, under the terms of the COPYING file.
+ *
+ * This software is distributed on an "AS IS" basis, WITHOUT WARRANTY OF ANY
+ * KIND, either express or implied.
+ *
+ ***************************************************************************/
+
+#define CURL_HOST_NOMATCH 0
+#define CURL_HOST_MATCH 1
+int Curl_cert_hostcheck(const char* match_pattern, const char* hostname);
+
+#endif /* HEADER_CURL_HOSTCHECK_H */
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/third_party/isec_partners/openssl_hostname_validation.c src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/third_party/isec_partners/openssl_hostname_validation.c
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/third_party/isec_partners/openssl_hostname_validation.c	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/third_party/isec_partners/openssl_hostname_validation.c	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,180 @@
+/* Obtained from: https://github.com/iSECPartners/ssl-conservatory */
+
+/*
+Copyright (C) 2012, iSEC Partners.
+
+Permission is hereby granted, free of charge, to any person obtaining a copy of
+this software and associated documentation files (the "Software"), to deal in
+the Software without restriction, including without limitation the rights to
+use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+of the Software, and to permit persons to whom the Software is furnished to do
+so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
+ */
+
+/*
+ * Helper functions to perform basic hostname validation using OpenSSL.
+ *
+ * Please read "everything-you-wanted-to-know-about-openssl.pdf" before
+ * attempting to use this code. This whitepaper describes how the code works,
+ * how it should be used, and what its limitations are.
+ *
+ * Author:  Alban Diquet
+ * License: See LICENSE
+ *
+ */
+
+
+#include <openssl/x509v3.h>
+#include <openssl/ssl.h>
+
+#include "third_party/curl/hostcheck.h"
+#include "third_party/isec_partners/openssl_hostname_validation.h"
+
+#define HOSTNAME_MAX_SIZE 255
+
+/**
+* Tries to find a match for hostname in the certificate's Common Name field.
+*
+* Returns MatchFound if a match was found.
+* Returns MatchNotFound if no matches were found.
+* Returns MalformedCertificate if the Common Name had a NUL character embedded
+* in it.
+* Returns Error if the Common Name could not be extracted.
+*/
+static HostnameValidationResult matches_common_name(const char *hostname,
+                                                    const X509 *server_cert) {
+  int common_name_loc = -1;
+  X509_NAME_ENTRY *common_name_entry = NULL;
+  ASN1_STRING *common_name_asn1 = NULL;
+  char *common_name_str = NULL;
+
+  // Find the position of the CN field in the Subject field of the certificate
+  common_name_loc =
+      X509_NAME_get_index_by_NID(X509_get_subject_name((X509 *)server_cert),
+                                 NID_commonName, -1);
+  if (common_name_loc < 0) {
+    return Error;
+  }
+
+  // Extract the CN field
+  common_name_entry =
+      X509_NAME_get_entry(X509_get_subject_name((X509 *)server_cert),
+                          common_name_loc);
+  if (common_name_entry == NULL) {
+    return Error;
+  }
+
+  // Convert the CN field to a C string
+  common_name_asn1 = X509_NAME_ENTRY_get_data(common_name_entry);
+  if (common_name_asn1 == NULL) {
+    return Error;
+  }
+  common_name_str = (char *)ASN1_STRING_data(common_name_asn1);
+
+  // Make sure there isn't an embedded NUL character in the CN
+  if ((size_t)ASN1_STRING_length(common_name_asn1) !=
+      strlen(common_name_str)) {
+    return MalformedCertificate;
+  }
+
+  // Compare expected hostname with the CN
+  if (Curl_cert_hostcheck(common_name_str, hostname) == CURL_HOST_MATCH) {
+    return MatchFound;
+  } else {
+    return MatchNotFound;
+  }
+}
+
+
+/**
+* Tries to find a match for hostname in the certificate's Subject Alternative
+* Name extension.
+*
+* Returns MatchFound if a match was found.
+* Returns MatchNotFound if no matches were found.
+* Returns MalformedCertificate if any of the hostnames had a NUL character
+* embedded in it.
+* Returns NoSANPresent if the SAN extension was not present in the certificate.
+*/
+static HostnameValidationResult matches_subject_alternative_name(
+    const char *hostname, const X509 *server_cert) {
+  HostnameValidationResult result = MatchNotFound;
+  int i;
+  int san_names_nb = -1;
+  STACK_OF(GENERAL_NAME) *san_names = NULL;
+
+  // Try to extract the names within the SAN extension from the certificate
+  san_names =
+      X509_get_ext_d2i((X509 *)server_cert, NID_subject_alt_name, NULL, NULL);
+  if (san_names == NULL) {
+    return NoSANPresent;
+  }
+  san_names_nb = sk_GENERAL_NAME_num(san_names);
+
+  // Check each name within the extension
+  for (i = 0; i < san_names_nb; i++) {
+    const GENERAL_NAME *current_name = sk_GENERAL_NAME_value(san_names, i);
+
+    if (current_name->type == GEN_DNS) {
+      // Current name is a DNS name, let's check it
+      char *dns_name = (char *)ASN1_STRING_data(current_name->d.dNSName);
+
+      // Make sure there isn't an embedded NUL character in the DNS name
+      if ((size_t)ASN1_STRING_length(current_name->d.dNSName) !=
+          strlen(dns_name)) {
+        result = MalformedCertificate;
+        break;
+      } else {  // Compare expected hostname with the DNS name
+        if (Curl_cert_hostcheck(dns_name, hostname) == CURL_HOST_MATCH) {
+          result = MatchFound;
+          break;
+        }
+      }
+    }
+  }
+  sk_GENERAL_NAME_pop_free(san_names, GENERAL_NAME_free);
+
+  return result;
+}
+
+
+/**
+* Validates the server's identity by looking for the expected hostname in the
+* server's certificate. As described in RFC 6125, it first tries to find a
+* match
+* in the Subject Alternative Name extension. If the extension is not present in
+* the certificate, it checks the Common Name instead.
+*
+* Returns MatchFound if a match was found.
+* Returns MatchNotFound if no matches were found.
+* Returns MalformedCertificate if any of the hostnames had a NUL character
+* embedded in it.
+* Returns Error if there was an error.
+*/
+HostnameValidationResult validate_hostname(const char *hostname,
+                                           const X509 *server_cert) {
+  HostnameValidationResult result;
+
+  if ((hostname == NULL) || (server_cert == NULL))
+    return Error;
+
+  // First try the Subject Alternative Names extension
+  result = matches_subject_alternative_name(hostname, server_cert);
+  if (result == NoSANPresent) {
+    // Extension was not found: try the Common Name
+    result = matches_common_name(hostname, server_cert);
+  }
+
+  return result;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/third_party/isec_partners/openssl_hostname_validation.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/third_party/isec_partners/openssl_hostname_validation.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/third_party/isec_partners/openssl_hostname_validation.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/third_party/isec_partners/openssl_hostname_validation.h	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,59 @@
+/* Obtained from: https://github.com/iSECPartners/ssl-conservatory */
+
+/*
+Copyright (C) 2012, iSEC Partners.
+
+Permission is hereby granted, free of charge, to any person obtaining a copy of
+this software and associated documentation files (the "Software"), to deal in
+the Software without restriction, including without limitation the rights to
+use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
+of the Software, and to permit persons to whom the Software is furnished to do
+so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
+ */
+
+/*
+ * Helper functions to perform basic hostname validation using OpenSSL.
+ *
+ * Please read "everything-you-wanted-to-know-about-openssl.pdf" before
+ * attempting to use this code. This whitepaper describes how the code works,
+ * how it should be used, and what its limitations are.
+ *
+ * Author:  Alban Diquet
+ * License: See LICENSE
+ *
+ */
+
+typedef enum {
+  MatchFound,
+  MatchNotFound,
+  NoSANPresent,
+  MalformedCertificate,
+  Error
+} HostnameValidationResult;
+
+/**
+* Validates the server's identity by looking for the expected hostname in the
+* server's certificate. As described in RFC 6125, it first tries to find a
+* match
+* in the Subject Alternative Name extension. If the extension is not present in
+* the certificate, it checks the Common Name instead.
+*
+* Returns MatchFound if a match was found.
+* Returns MatchNotFound if no matches were found.
+* Returns MalformedCertificate if any of the hostnames had a NUL character
+* embedded in it.
+* Returns Error if there was an error.
+*/
+HostnameValidationResult validate_hostname(const char* hostname,
+                                           const X509* server_cert);
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/clustertool.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/clustertool.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/clustertool.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/clustertool.cc	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,41 @@
+#include "tools/clustertool.h"
+
+#include <openssl/err.h>
+#include <memory>
+#include <string>
+
+#include "proto/ct.pb.h"
+#include "util/status.h"
+
+using util::Status;
+using ct::ClusterConfig;
+
+namespace cert_trans {
+
+
+Status InitLog(const ClusterConfig& cluster_config, TreeSigner* tree_signer,
+               ConsistentStore* consistent_store) {
+  if (tree_signer->UpdateTree() != TreeSigner::OK) {
+    return Status(util::error::UNKNOWN, "Failed to Update Tree");
+  }
+
+  Status status(consistent_store->SetServingSTH(tree_signer->LatestSTH()));
+  if (!status.ok()) {
+    return status;
+  }
+
+  return SetClusterConfig(cluster_config, consistent_store);
+}
+
+
+Status SetClusterConfig(const ClusterConfig& cluster_config,
+                        ConsistentStore* consistent_store) {
+  if (cluster_config.etcd_reject_add_pending_threshold() < 0) {
+    return Status(util::error::INVALID_ARGUMENT,
+                  "etcd_reject_add_pending_threshold cannot be less than 0");
+  }
+  return consistent_store->SetClusterConfig(cluster_config);
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/clustertool.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/clustertool.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/clustertool.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/clustertool.h	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,34 @@
+#ifndef CERT_TRANS_TOOLS_CLUSTERTOOL_H_
+#define CERT_TRANS_TOOLS_CLUSTERTOOL_H_
+
+#include "log/consistent_store.h"
+#include "log/logged_entry.h"
+#include "log/tree_signer.h"
+
+namespace ct {
+class ClusterConfig;
+}  // namespace ct
+
+namespace util {
+class Status;
+}  // namespace util
+
+namespace cert_trans {
+
+
+// Initialise a fresh log cluster:
+//  - Creates /serving_sth containing a new STH of size zero
+//  - Creates the /cluster_config entry.
+util::Status InitLog(const ct::ClusterConfig& cluster_config,
+                     TreeSigner* tree_signer,
+                     ConsistentStore* consistent_store);
+
+// Sets the cluster config
+util::Status SetClusterConfig(const ct::ClusterConfig& cluster_config,
+                              ConsistentStore* consistent_store);
+
+
+}  // namespace cert_trans
+
+
+#endif  // CERT_TRANS_TOOLS_CLUSTERTOOL_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/clustertool_main.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/clustertool_main.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/clustertool_main.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/clustertool_main.cc	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,186 @@
+#include <event2/thread.h>
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <google/protobuf/text_format.h>
+#include <openssl/err.h>
+#include <fstream>
+#include <iostream>
+#include <sstream>
+
+#include "log/etcd_consistent_store.h"
+#include "log/log_signer.h"
+#include "log/logged_entry.h"
+#include "log/sqlite_db.h"
+#include "log/strict_consistent_store.h"
+#include "log/tree_signer.h"
+#include "proto/cert_serializer.h"
+#include "proto/ct.pb.h"
+#include "tools/clustertool.h"
+#include "util/etcd.h"
+#include "util/init.h"
+#include "util/masterelection.h"
+#include "util/read_key.h"
+#include "util/status.h"
+#include "util/thread_pool.h"
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::ConsistentStore;
+using cert_trans::Database;
+using cert_trans::EtcdClient;
+using cert_trans::EtcdConsistentStore;
+using cert_trans::LoggedEntry;
+using cert_trans::MasterElection;
+using cert_trans::ReadPrivateKey;
+using cert_trans::SQLiteDB;
+using cert_trans::SplitHosts;
+using cert_trans::StrictConsistentStore;
+using cert_trans::ThreadPool;
+using cert_trans::TreeSigner;
+using cert_trans::UrlFetcher;
+using ct::ClusterConfig;
+using ct::SignedTreeHead;
+using google::protobuf::TextFormat;
+using libevent::EventPumpThread;
+using std::ifstream;
+using std::make_shared;
+using std::ostringstream;
+using std::shared_ptr;
+using std::string;
+using std::unique_ptr;
+using util::Status;
+
+DEFINE_string(cluster_config, "",
+              "Path of file containing the cluster config (in ASCII proto "
+              "format.)");
+DEFINE_string(etcd_servers, "",
+              "Comma separated list of 'hostname:port' of the etcd server(s)");
+DEFINE_string(key, "", "PEM-encoded server private key file");
+
+
+namespace {
+
+
+const char kDefaultClusterConfig[] =
+    "minimum_serving_nodes: 2\n"
+    "minimum_serving_fraction: 0.75\n";
+
+
+void Usage() {
+  std::cerr << "Usage:\n"
+            << "  clustertool [flags] <command> [command opts]\n"
+            << "\n"
+            << "Commands:\n"
+            << "  initlog     Initialise a new log.\n"
+            << "  set_config  Set/Change a cluster's config.\n";
+}
+
+
+unique_ptr<LogSigner> BuildLogSigner() {
+  CHECK(!FLAGS_key.empty());
+  util::StatusOr<EVP_PKEY*> pkey(ReadPrivateKey(FLAGS_key));
+  CHECK_EQ(pkey.status(), util::Status::OK);
+  return unique_ptr<LogSigner>(new LogSigner(pkey.ValueOrDie()));
+}
+
+
+unique_ptr<TreeSigner> BuildTreeSigner(Database* db,
+                                       ConsistentStore* consistent_store,
+                                       LogSigner* log_signer) {
+  return unique_ptr<TreeSigner>(
+      new TreeSigner(std::chrono::duration<double>(0), db,
+                     unique_ptr<CompactMerkleTree>(new CompactMerkleTree(
+                         unique_ptr<Sha256Hasher>(new Sha256Hasher))),
+                     consistent_store, log_signer));
+}
+
+
+unique_ptr<MasterElection> BuildAndJoinMasterElection(
+    const string node_id, const shared_ptr<libevent::Base>& base,
+    EtcdClient* etcd_client) {
+  const string kLockDir("/election");
+  MasterElection* election(
+      new MasterElection(base, etcd_client, kLockDir, node_id));
+  election->StartElection();
+  election->WaitToBecomeMaster();
+  return unique_ptr<MasterElection>(election);
+}
+
+
+ClusterConfig LoadConfig() {
+  ClusterConfig cluster_config;
+  string cluster_config_str;
+  if (FLAGS_cluster_config.empty()) {
+    LOG(WARNING) << "Using default ClusterConfig";
+    cluster_config_str = kDefaultClusterConfig;
+  } else {
+    ifstream ifs(FLAGS_cluster_config);
+    if (!ifs) {
+      LOG(FATAL) << "Couldn't open " << FLAGS_cluster_config;
+    }
+    ostringstream conf_stream;
+    conf_stream << ifs.rdbuf();
+    cluster_config_str = conf_stream.str();
+  }
+  if (!TextFormat::ParseFromString(cluster_config_str, &cluster_config)) {
+    LOG(FATAL) << "Couldn't parse ClusterConfig:\n" << cluster_config_str;
+  }
+  LOG(INFO) << "Using config:\n" << cluster_config.DebugString();
+  return cluster_config;
+}
+
+
+}  // namespace
+
+
+int main(int argc, char* argv[]) {
+  FLAGS_logtostderr = true;
+
+  ConfigureSerializerForV1CT();
+  util::InitCT(&argc, &argv);
+
+  if (argc == 1) {
+    Usage();
+    return util::error::INVALID_ARGUMENT;
+  }
+
+  CHECK(!FLAGS_etcd_servers.empty());
+
+  const shared_ptr<libevent::Base> event_base(make_shared<libevent::Base>());
+  std::unique_ptr<libevent::EventPumpThread> pump(
+      new libevent::EventPumpThread(event_base));
+  ThreadPool pool;
+  UrlFetcher fetcher(event_base.get(), &pool);
+
+  EtcdClient etcd_client(&pool, &fetcher, SplitHosts(FLAGS_etcd_servers));
+
+  const string node_id("clustertool");
+  unique_ptr<MasterElection> election(
+      BuildAndJoinMasterElection(node_id, event_base, &etcd_client));
+  ThreadPool internal_pool(4);
+  StrictConsistentStore consistent_store(
+      election.get(),
+      new EtcdConsistentStore(event_base.get(), &internal_pool, &etcd_client,
+                              election.get(), "/root", node_id));
+  SQLiteDB db("/tmp/clustertooldb");
+
+  const string command(argv[1]);
+  Status status;
+  if (command == "initlog") {
+    unique_ptr<LogSigner> log_signer(BuildLogSigner());
+    unique_ptr<TreeSigner> tree_signer(
+        BuildTreeSigner(&db, &consistent_store, log_signer.get()));
+    status = InitLog(LoadConfig(), tree_signer.get(), &consistent_store);
+  } else if (command == "set_config") {
+    CHECK(!FLAGS_cluster_config.empty());
+    status = SetClusterConfig(LoadConfig(), &consistent_store);
+  } else {
+    Usage();
+  }
+
+  LOG(INFO) << status;
+  election->StopElection();
+
+  // TODO(alcutter): Watches hang forever even when Cancel()'d, fix that.
+  exit(status.error_code());
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/db_tool.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/db_tool.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/db_tool.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/db_tool.cc	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,133 @@
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <limits.h>
+#include <functional>
+#include <iostream>
+#include <memory>
+
+#include "log/database.h"
+#include "log/file_db.h"
+#include "log/file_storage.h"
+#include "log/leveldb_db.h"
+#include "log/logged_entry.h"
+#include "log/sqlite_db.h"
+#include "proto/serializer.h"
+#include "util/init.h"
+#include "util/util.h"
+
+DEFINE_string(cert_dir, "", "Storage directory for certificates");
+DEFINE_string(tree_dir, "", "Storage directory for trees");
+DEFINE_string(meta_dir, "", "Storage directory for meta info");
+DEFINE_int32(cert_storage_depth, 0,
+             "Subdirectory depth for certificates; if the directory is not "
+             "empty, must match the existing depth.");
+DEFINE_int32(tree_storage_depth, 0,
+             "Subdirectory depth for tree signatures; if the directory is not "
+             "empty, must match the existing depth");
+DEFINE_string(sqlite_db, "",
+              "SQLite database for certificate and tree storage");
+DEFINE_string(leveldb_db, "",
+              "LevelDB database for certificate and tree storage");
+
+DEFINE_int64(start, 0, "Starting sequence number (inclusive).");
+DEFINE_int64(end, std::numeric_limits<int64_t>::max(),
+             "Ending sequence number (inclusive).");
+
+using cert_trans::FileDB;
+using cert_trans::FileStorage;
+using cert_trans::LevelDB;
+using cert_trans::LoggedEntry;
+using cert_trans::ReadOnlyDatabase;
+using cert_trans::SQLiteDB;
+using cert_trans::serialization::SerializeResult;
+using std::cerr;
+using std::cout;
+using std::function;
+using std::string;
+using std::unique_ptr;
+using util::InitCT;
+using util::ToBase64;
+
+
+void Usage() {
+  cerr << "Usage: db_tool [flags] <command>\n"
+       << "Where <command> is one of:\n"
+       << "  dump_leaf_inputs\n";
+}
+
+
+void ForEachLeaf(const ReadOnlyDatabase* db,
+                 const function<void(const LoggedEntry& cert)>& f) {
+  unique_ptr<ReadOnlyDatabase::Iterator> it(db->ScanEntries(FLAGS_start));
+  LoggedEntry cert;
+  while (it->GetNextEntry(&cert)) {
+    if (cert.sequence_number() > FLAGS_end) {
+      break;
+    }
+    f(cert);
+  }
+}
+
+
+int DumpLeafInputs(const ReadOnlyDatabase* db) {
+  CHECK_NOTNULL(db);
+  ForEachLeaf(db, [](const LoggedEntry& cert) {
+    string serialized;
+    const SerializeResult r(Serializer::SerializeSCTSignatureInput(
+        cert.contents().sct(), cert.contents().entry(), &serialized));
+    if (r != SerializeResult::OK) {
+      LOG(FATAL) << "Failed to serialize entry with seq# "
+                 << cert.sequence_number() << " : " << r;
+    }
+
+    cout << cert.sequence_number() << " " << ToBase64(serialized) << "\n";
+  });
+  return 0;
+}
+
+
+int main(int argc, char* argv[]) {
+  InitCT(&argc, &argv);
+
+  if (argc != 2) {
+    Usage();
+    return 1;
+  }
+
+  // ------8<----------8<---------8<-----------
+  // TODO(alcutter): Refactor this out into a common CreateDatabase() call
+  // somewhere.
+  if (!FLAGS_sqlite_db.empty() + !FLAGS_leveldb_db.empty() +
+          (!FLAGS_cert_dir.empty() | !FLAGS_tree_dir.empty()) !=
+      1) {
+    LOG(FATAL) << "Must only specify one database type.";
+  }
+
+  if (FLAGS_sqlite_db.empty() && FLAGS_leveldb_db.empty()) {
+    CHECK_NE(FLAGS_cert_dir, FLAGS_tree_dir)
+        << "Certificate directory and tree directory must differ";
+  }
+
+  unique_ptr<ReadOnlyDatabase> db;
+
+  if (!FLAGS_sqlite_db.empty()) {
+    db.reset(new SQLiteDB(FLAGS_sqlite_db));
+  } else if (!FLAGS_leveldb_db.empty()) {
+    db.reset(new LevelDB(FLAGS_leveldb_db));
+  } else {
+    db.reset(
+        new FileDB(new FileStorage(FLAGS_cert_dir, FLAGS_cert_storage_depth),
+                   new FileStorage(FLAGS_tree_dir, FLAGS_tree_storage_depth),
+                   new FileStorage(FLAGS_meta_dir, 0)));
+  }
+  // ------8<----------8<---------8<-----------
+
+  if (strcmp(argv[1], "dump_leaf_inputs") == 0) {
+    return DumpLeafInputs(db.get());
+  } else {
+    Usage();
+    return 1;
+  }
+
+  return 0;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/dump_cert.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/dump_cert.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/dump_cert.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/dump_cert.cc	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,49 @@
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <fstream>
+#include <iostream>
+
+#include "proto/ct.pb.h"
+#include "util/init.h"
+#include "util/util.h"
+
+using std::cout;
+using std::endl;
+using std::ifstream;
+
+namespace {
+
+
+void DumpLoggedCert(const char* filename) {
+  ifstream input(filename);
+  ct::LoggedEntryPB pb;
+  CHECK(pb.ParseFromIstream(&input));
+
+  if (pb.has_sequence_number())
+    cout << "sequence number: " << pb.sequence_number() << endl;
+
+  if (pb.has_merkle_leaf_hash())
+    cout << "merkle_leaf_hash: " << util::ToBase64(pb.merkle_leaf_hash())
+         << endl;
+
+  if (pb.contents().has_sct())
+    cout << "--- begin sct" << endl
+         << pb.contents().sct().DebugString() << "--- end sct" << endl;
+
+  if (pb.contents().has_entry())
+    cout << "--- begin entry" << endl
+         << pb.contents().entry().DebugString() << "--- end entry" << endl;
+}
+
+
+}  // namespace
+
+
+int main(int argc, char* argv[]) {
+  util::InitCT(&argc, &argv);
+
+  for (int i = 1; i < argc; ++i)
+    DumpLoggedCert(argv[i]);
+
+  return 0;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/dump_sth.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/dump_sth.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/dump_sth.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/dump_sth.cc	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,39 @@
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <fstream>
+#include <iostream>
+
+#include "proto/ct.pb.h"
+#include "version.h"
+
+using std::cout;
+using std::endl;
+using std::ifstream;
+
+namespace {
+
+
+void DumpSth(const char* filename) {
+  ifstream input(filename);
+  ct::SignedTreeHead pb;
+  CHECK(pb.ParseFromIstream(&input));
+
+  cout << pb.DebugString() << endl;
+}
+
+
+}  // namespace
+
+
+int main(int argc, char* argv[]) {
+  google::SetVersionString(cert_trans::kBuildVersion);
+  google::ParseCommandLineFlags(&argc, &argv, true);
+  google::InitGoogleLogging(argv[0]);
+
+  LOG(INFO) << "Build version: " << google::VersionString();
+
+  for (int i = 1; i < argc; ++i)
+    DumpSth(argv[i]);
+
+  return 0;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/etcd_watch.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/etcd_watch.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/etcd_watch.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/etcd_watch.cc	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,56 @@
+#include <event2/thread.h>
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <iostream>
+
+#include "util/etcd.h"
+#include "util/init.h"
+#include "util/libevent_wrapper.h"
+#include "util/sync_task.h"
+#include "util/thread_pool.h"
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::EtcdClient;
+using cert_trans::ThreadPool;
+using cert_trans::UrlFetcher;
+using std::cout;
+using std::endl;
+using std::vector;
+using util::SyncTask;
+
+DEFINE_string(etcd, "127.0.0.1", "etcd server address");
+DEFINE_int32(etcd_port, 4001, "etcd server port");
+DEFINE_string(key, "/foo", "path to watch");
+
+
+void Notify(const vector<EtcdClient::Node>& updates) {
+  for (const auto& update : updates) {
+    if (!update.deleted_) {
+      cout << "key changed: " << update.ToString() << endl;
+    } else {
+      cout << "key deleted: " << update.ToString() << endl;
+    }
+  }
+}
+
+
+int main(int argc, char* argv[]) {
+  util::InitCT(&argc, &argv);
+
+  libevent::Base event_base;
+  ThreadPool pool;
+  UrlFetcher fetcher(&event_base, &pool);
+  EtcdClient etcd(&pool, &fetcher, FLAGS_etcd, FLAGS_etcd_port);
+
+  SyncTask task(&event_base);
+  etcd.Watch(FLAGS_key, Notify, task.task());
+
+  event_base.Dispatch();
+
+  // This shouldn't really happen.
+  task.Wait();
+  LOG(INFO) << "status: " << task.status();
+
+  return 0;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/prepare_etcd.sh src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/prepare_etcd.sh
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tools/prepare_etcd.sh	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tools/prepare_etcd.sh	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,23 @@
+#!/bin/bash
+DIR=$(cd "$(dirname "${BASH_SOURCE[0]}" )" && pwd)
+
+if [ $# -ne 3 ]; then
+  echo "Usage $0 <etcd host> <etcd port> <log key pem>"
+  exit 1;
+fi
+
+ETCD_HOST=$1
+ETCD_PORT=$2
+LOG_KEY=$3
+
+ETCD=http://${ETCD_HOST}:${ETCD_PORT}
+curl -L -X PUT ${ETCD}/v2/keys/root -d dir=true
+curl -L -X PUT ${ETCD}/v2/keys/root/entries -d dir=true
+curl -L -X PUT ${ETCD}/v2/keys/root/nodes -d dir=true
+curl -L -X PUT ${ETCD}/v2/keys/root/serving_sth
+curl -L -X PUT ${ETCD}/v2/keys/root/cluster_config
+curl -L -X PUT ${ETCD}/v2/keys/root/sequence_mapping
+${DIR}/ct-clustertool initlog \
+    --key=${LOG_KEY} \
+    --etcd_servers="${ETCD_HOST}:${ETCD_PORT}" \
+    --logtostderr
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tsan_suppressions src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tsan_suppressions
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/tsan_suppressions	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/tsan_suppressions	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,2 @@
+# some noise from glog
+race:RawLog__SetLastTime
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/bench_etcd.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/bench_etcd.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/bench_etcd.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/bench_etcd.cc	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,127 @@
+#include <event2/thread.h>
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <functional>
+#include <memory>
+#include <string>
+#include <thread>
+#include <vector>
+
+#include "util/etcd.h"
+#include "util/libevent_wrapper.h"
+#include "util/sync_task.h"
+#include "util/thread_pool.h"
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::EtcdClient;
+using cert_trans::ThreadPool;
+using cert_trans::UrlFetcher;
+using std::bind;
+using std::make_shared;
+using std::placeholders::_1;
+using std::shared_ptr;
+using std::string;
+using std::thread;
+using std::to_string;
+using std::vector;
+using util::Status;
+using util::SyncTask;
+using util::Task;
+
+DEFINE_string(etcd, "127.0.0.1", "etcd server address");
+DEFINE_int32(etcd_port, 4001, "etcd server port");
+DEFINE_int32(requests_per_thread, 10, "number of requests per thread");
+DEFINE_int32(bytes_per_request, 10, "number of bytes per requests");
+DEFINE_int32(num_threads, 1, "number of threads");
+DEFINE_string(test_key, "/bench_etcd", "base etcd key for testing");
+
+namespace {
+
+
+struct State {
+  State(EtcdClient* etcd, int thread_num, Task* task)
+      : etcd_(CHECK_NOTNULL(etcd)),
+        key_prefix_(FLAGS_test_key + "/" + to_string(thread_num) + "/"),
+        task_(CHECK_NOTNULL(task)),
+        data_(FLAGS_bytes_per_request, 'x'),
+        next_key_(0),
+        num_left_(FLAGS_requests_per_thread) {
+    CHECK_GT(num_left_, 0);
+  }
+
+  void MakeRequest();
+  void RequestDone(Task* child_task);
+
+  EtcdClient* const etcd_;
+  const string key_prefix_;
+  Task* const task_;
+  const string data_;
+
+  int64_t next_key_;
+  EtcdClient::Response resp_;
+  int num_left_;
+};
+
+
+void State::MakeRequest() {
+  etcd_->Create(key_prefix_ + to_string(next_key_), "value", &resp_,
+                task_->AddChild(bind(&State::RequestDone, this, _1)));
+}
+
+
+void State::RequestDone(Task* child_task) {
+  CHECK_EQ(Status::OK, child_task->status());
+  --num_left_;
+  next_key_ = resp_.etcd_index;
+
+  if (num_left_ > 0) {
+    MakeRequest();
+  } else {
+    task_->Return();
+  }
+}
+
+
+void test_etcd(int thread_num) {
+  const shared_ptr<libevent::Base> event_base(make_shared<libevent::Base>());
+  libevent::EventPumpThread pump(event_base);
+  ThreadPool pool;
+  UrlFetcher fetcher(event_base.get(), &pool);
+  EtcdClient etcd(&pool, &fetcher, FLAGS_etcd, FLAGS_etcd_port);
+  SyncTask task(event_base.get());
+  State state(&etcd, thread_num, task.task());
+
+  // Get the ball rolling...
+  state.MakeRequest();
+
+  LOG(INFO) << "waiting for test completion";
+  task.Wait();
+  LOG(INFO) << "test complete";
+}
+
+
+}  // namespace
+
+
+int main(int argc, char* argv[]) {
+  google::ParseCommandLineFlags(&argc, &argv, true);
+  google::InitGoogleLogging(argv[0]);
+  evthread_use_pthreads();
+
+  CHECK_GT(FLAGS_requests_per_thread, 0);
+  CHECK_GE(FLAGS_bytes_per_request, 0);
+  CHECK_GT(FLAGS_num_threads, 0);
+
+  vector<thread> threads;
+  for (int i = 0; i < FLAGS_num_threads; ++i) {
+    threads.emplace_back(bind(test_etcd, i));
+  }
+
+  for (vector<thread>::iterator it = threads.begin(); it != threads.end();
+       ++it) {
+    it->join();
+  }
+
+  return 0;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/bignum.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/bignum.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/bignum.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/bignum.cc	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,26 @@
+#include "util/bignum.h"
+
+namespace cert_trans {
+
+
+BigNum::BigNum() {
+  BN_init(&bn_);
+}
+
+
+BigNum::BigNum(int64_t w) : BigNum() {
+  assert(BN_set_word(&bn_, w) == 1);
+}
+
+
+BigNum::BigNum(const BigNum& other) : BigNum() {
+  assert(BN_copy(&bn_, &other.bn_) != nullptr);
+}
+
+
+BigNum::~BigNum() {
+  BN_free(&bn_);
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/bignum.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/bignum.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/bignum.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/bignum.h	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,173 @@
+#ifndef CERT_TRANS_UTIL_BIGNUM_H_
+#define CERT_TRANS_UTIL_BIGNUM_H_
+
+#include <openssl/bn.h>
+#include <cassert>
+
+namespace cert_trans {
+
+
+class BigNum {
+ public:
+  BigNum();
+  explicit BigNum(int64_t w);
+  BigNum(const BigNum& other);
+  ~BigNum();
+
+  const BIGNUM* bn() const;
+  BIGNUM* bn();
+
+  int num_bits() const;
+
+  BigNum& operator-=(const BigNum& n);
+  BigNum& operator-=(int64_t n);
+  BigNum& operator+=(const BigNum& n);
+  BigNum& operator+=(int64_t n);
+  BigNum& operator<<=(int n);
+  BigNum& operator>>=(int n);
+
+ private:
+  BIGNUM bn_;
+
+  friend bool operator==(const BigNum& a, const BigNum& b);
+  friend bool operator==(const BigNum& a, int64_t b);
+  friend bool operator<(const BigNum& a, const BigNum& b);
+  friend bool operator<(const BigNum& a, int64_t b);
+  friend bool operator>(const BigNum& a, const BigNum& b);
+  friend bool operator>(const BigNum& a, int64_t b);
+};
+
+
+inline const BIGNUM* BigNum::bn() const {
+  return &bn_;
+}
+
+
+inline BIGNUM* BigNum::bn() {
+  return &bn_;
+}
+
+
+inline int BigNum::num_bits() const {
+  return BN_num_bits(&bn_);
+}
+
+
+inline BigNum& BigNum::operator-=(const BigNum& n) {
+  assert(BN_sub(&bn_, &bn_, &n.bn_) == 1);
+  return *this;
+}
+
+
+inline BigNum& BigNum::operator-=(int64_t n) {
+  assert(BN_sub_word(&bn_, n) == 1);
+  return *this;
+}
+
+
+inline BigNum& BigNum::operator+=(const BigNum& n) {
+  assert(BN_add(&bn_, &bn_, &n.bn_) == 1);
+  return *this;
+}
+
+
+inline BigNum& BigNum::operator+=(int64_t n) {
+  assert(BN_add_word(&bn_, n) == 1);
+  return *this;
+}
+
+
+inline BigNum& BigNum::operator<<=(int n) {
+  assert(BN_lshift(&bn_, &bn_, n) == 1);
+  return *this;
+}
+
+
+inline BigNum& BigNum::operator>>=(int n) {
+  assert(BN_rshift(&bn_, &bn_, n) == 1);
+  return *this;
+}
+
+
+template <typename T, typename U>
+inline BigNum operator+(const T& a, const U& b) {
+  BigNum r(a);
+  r += b;
+  return r;
+}
+
+
+template <typename T, typename U>
+inline BigNum operator-(const T& a, const U& b) {
+  BigNum r(a);
+  r -= b;
+  return r;
+}
+
+
+inline BigNum operator<<(const BigNum& a, int n) {
+  BigNum r(a);
+  r <<= n;
+  return r;
+}
+
+
+inline BigNum operator>>(const BigNum& a, int n) {
+  BigNum r(a);
+  r >>= n;
+  return r;
+}
+
+
+inline bool operator==(const BigNum& a, const BigNum& b) {
+  return BN_cmp(&a.bn_, &b.bn_) == 0;
+}
+
+
+namespace internal {
+
+
+inline const BigNum& AsBigNum(const BigNum& n) {
+  return n;
+}
+
+
+inline BigNum AsBigNum(int64_t n) {
+  return BigNum(n);
+}
+
+
+}  // namespace internal
+
+
+template <typename T, typename U>
+inline bool operator==(const T& a, const U& b) {
+  return internal::AsBigNum(a) == internal::AsBigNum(b);
+}
+
+
+inline bool operator<(const BigNum& a, const BigNum& b) {
+  return BN_cmp(&a.bn_, &b.bn_) < 0;
+}
+
+
+template <typename T, typename U>
+inline bool operator<(const T& a, const U& b) {
+  return internal::AsBigNum(a) < internal::AsBigNum(b);
+}
+
+
+inline bool operator>(const BigNum& a, const BigNum& b) {
+  return BN_cmp(&a.bn_, &b.bn_) > 0;
+}
+
+
+template <typename T, typename U>
+inline bool operator>(const T& a, const U& b) {
+  return internal::AsBigNum(a) > internal::AsBigNum(b);
+}
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_BIGNUM_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/bignum_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/bignum_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/bignum_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/bignum_test.cc	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,191 @@
+#include "util/bignum.h"
+
+#include <gtest/gtest.h>
+
+#include "util/testing.h"
+
+
+namespace cert_trans {
+
+
+TEST(BigNumTest, TestDefaultCtor) {
+  BigNum n;
+  EXPECT_EQ(n, 0);
+}
+
+
+TEST(BigNumTest, TestWordCtor) {
+  const int kValue(0x1234);
+  BigNum n(kValue);
+  EXPECT_EQ(n, kValue);
+}
+
+
+TEST(BigNumTest, TestCopyCtor) {
+  const int kValue(0x1234);
+  BigNum n(kValue);
+  BigNum o(n);
+  EXPECT_EQ(o, kValue);
+}
+
+
+TEST(BigNumTest, TestSubtractEqualsOperator) {
+  const int kValue(0x1234);
+  const int kDelta(10);
+  BigNum n(kValue);
+  n -= kDelta;
+  EXPECT_EQ(n, kValue - kDelta);
+}
+
+
+TEST(BigNumTest, TestSubtractEqualsBigNumOperator) {
+  const int kValue(0x1234);
+  const int kDelta(10);
+  BigNum n(kValue);
+  BigNum d(kDelta);
+  n -= d;
+  EXPECT_EQ(n, kValue - kDelta);
+}
+
+
+TEST(BigNumTest, TestAddEqualsOperator) {
+  const int kValue(0x1234);
+  const int kDelta(10);
+  BigNum n(kValue);
+  n += kDelta;
+  EXPECT_EQ(n, kValue + kDelta);
+}
+
+
+TEST(BigNumTest, TestAddEqualsBigNumOperator) {
+  const int kValue(0x1234);
+  const int kDelta(10);
+  BigNum n(kValue);
+  BigNum d(kDelta);
+  n += d;
+  EXPECT_EQ(n, kValue + kDelta);
+}
+
+
+TEST(BigNumTest, TestEqualsBigNumOperator) {
+  const int kValue(0x1234);
+  BigNum n(kValue);
+  BigNum o(n);
+  EXPECT_EQ(o, n);
+}
+
+
+TEST(BigNumTest, TestLShiftEqualsOperator) {
+  const int kValue(0x1234);
+  BigNum n(kValue);
+  n <<= 2;
+  EXPECT_EQ(n, kValue << 2);
+}
+
+
+TEST(BigNumTest, TestRShiftEqualsOperator) {
+  const int kValue(0x1234);
+  BigNum n(kValue);
+  n >>= 2;
+  EXPECT_EQ(n, kValue >> 2);
+}
+
+
+TEST(BigNumTest, TestBigNumEqualsBigNumOperator) {
+  const int kValue(0x1234);
+  BigNum n(kValue);
+  BigNum o(kValue);
+  EXPECT_EQ(n, o);
+}
+
+
+TEST(BigNumTest, TestBigNumEqualsIntOperator) {
+  const int kValue(0x1234);
+  BigNum n(kValue);
+  EXPECT_EQ(n, kValue);
+}
+
+
+TEST(BigNumTest, TestBigNumLessThanBigNumOperator) {
+  const int kValue(0x1234);
+  BigNum n(kValue - 1);
+  BigNum o(kValue);
+  EXPECT_LT(n, o);
+}
+
+
+TEST(BigNumTest, TestBigNumLessThanIntOperator) {
+  const int kValue(0x1234);
+  BigNum n(kValue - 1);
+  EXPECT_LT(n, kValue);
+}
+
+
+TEST(BigNumTest, TestBigNumGreaterThanBigNumOperator) {
+  const int kValue(0x1234);
+  BigNum n(kValue + 1);
+  BigNum o(kValue);
+  EXPECT_GT(n, o);
+}
+
+
+TEST(BigNumTest, TestBigNumGreaterThanIntOperator) {
+  const int kValue(0x1234);
+  BigNum n(kValue + 1);
+  EXPECT_GT(n, kValue);
+}
+
+
+TEST(BigNumTest, TestBigNumAddBigNumOperator) {
+  const int kValue(0x1234);
+  BigNum n(kValue);
+  BigNum o(kValue);
+  EXPECT_EQ(kValue + kValue, n + o);
+}
+
+
+TEST(BigNumTest, TestBigNumAddIntOperator) {
+  const int kValue(0x1234);
+  BigNum n(kValue);
+  EXPECT_EQ(kValue + kValue, n + kValue);
+}
+
+
+TEST(BigNumTest, TestBigNumSubtractBigNumOperator) {
+  const int kValue(0x1234);
+  const int kDelta(100);
+  BigNum n(kValue);
+  BigNum o(kDelta);
+  EXPECT_EQ(kValue - kDelta, n - o);
+}
+
+
+TEST(BigNumTest, TestBigNumSubtractIntOperator) {
+  const int kValue(0x1234);
+  const int kDelta(100);
+  BigNum n(kValue);
+  EXPECT_EQ(kValue - kDelta, n - kDelta);
+}
+
+
+TEST(BigNumTest, TestBigNumLeftShiftOperator) {
+  const int kValue(0x1234);
+  BigNum n(kValue);
+  EXPECT_EQ(kValue << 3, n << 3);
+}
+
+
+TEST(BigNumTest, TestBigNumRightShiftOperator) {
+  const int kValue(0x1234);
+  BigNum n(kValue);
+  EXPECT_EQ(kValue >> 3, n >> 3);
+}
+
+
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/cms_scoped_types.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/cms_scoped_types.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/cms_scoped_types.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/cms_scoped_types.h	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,17 @@
+#ifndef CERT_TRANS_UTIL_CMS_SCOPED_TYPES_H_
+#define CERT_TRANS_UTIL_CMS_SCOPED_TYPES_H_
+
+#include <openssl/cms.h>
+
+#include "util/openssl_scoped_types.h"
+
+namespace cert_trans {
+
+
+using ScopedCMS_ContentInfo =
+    ScopedOpenSSLType<CMS_ContentInfo, CMS_ContentInfo_free>;
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_CMS_SCOPED_TYPES_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/compare.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/compare.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/compare.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/compare.h	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,34 @@
+#ifndef CERT_TRANS_UTIL_COMPARE_H_
+#define CERT_TRANS_UTIL_COMPARE_H_
+
+#include <ctype.h>
+#include <algorithm>
+#include <string>
+
+namespace cert_trans {
+
+
+template <class T>
+struct ci_less;
+
+
+template <>
+struct ci_less<int> {
+  bool operator()(int lhs, int rhs) const {
+    return tolower(lhs) < tolower(rhs);
+  }
+};
+
+
+template <>
+struct ci_less<std::string> {
+  bool operator()(const std::string& lhs, const std::string& rhs) const {
+    return std::lexicographical_compare(lhs.begin(), lhs.end(), rhs.begin(),
+                                        rhs.end(), ci_less<int>());
+  }
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_COMPARE_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/etcd.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/etcd.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/etcd.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/etcd.cc	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,1048 @@
+#include "util/etcd.h"
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <ctime>
+#include <utility>
+#include <event2/http.h>
+
+#include "util/json_wrapper.h"
+#include "util/libevent_wrapper.h"
+#include "util/statusor.h"
+
+namespace libevent = cert_trans::libevent;
+
+using std::atoll;
+using std::bind;
+using std::chrono::seconds;
+using std::chrono::system_clock;
+using std::ctime;
+using std::list;
+using std::lock_guard;
+using std::make_pair;
+using std::make_shared;
+using std::map;
+using std::max;
+using std::move;
+using std::mutex;
+using std::ostringstream;
+using std::placeholders::_1;
+using std::shared_ptr;
+using std::stoi;
+using std::string;
+using std::time_t;
+using std::to_string;
+using std::unique_ptr;
+using std::vector;
+using util::Executor;
+using util::Status;
+using util::StatusOr;
+using util::SyncTask;
+using util::Task;
+
+DEFINE_int32(etcd_watch_error_retry_delay_seconds, 5,
+             "delay between retrying etcd watch requests");
+DEFINE_bool(etcd_consistent, true,
+            "Add consistent=true param to all requests. Do not turn this off "
+            "unless you *know* what you're doing.");
+DEFINE_bool(etcd_quorum, true,
+            "Add quorum=true param to all requests. Do not turn this off "
+            "unless you *know* what you're doing.");
+DEFINE_int32(etcd_connection_timeout_seconds, 10,
+             "Number of seconds after which to timeout etcd connections.");
+
+namespace cert_trans {
+
+namespace {
+
+const char* kStoreStats[] = {"setsFail",
+                             "getsSuccess",
+                             "watchers",
+                             "expireCount",
+                             "createFail",
+                             "setsSuccess",
+                             "compareAndDeleteFail",
+                             "createSuccess",
+                             "deleteFail",
+                             "compareAndSwapSuccess",
+                             "compareAndSwapFail",
+                             "compareAndDeleteSuccess",
+                             "updateFail",
+                             "deleteSuccess",
+                             "updateSuccess",
+                             "getsFail"};
+
+const char kKeysSpace[] = "/v2/keys";
+const char kStatsSpace[] = "/v2/stats";
+
+const char kStoreStatsKey[] = "/store";
+
+
+util::error::Code ErrorCodeForHttpResponseCode(int response_code) {
+  switch (response_code) {
+    case 200:
+    case 201:
+      return util::error::OK;
+    case 400:
+      return util::error::ABORTED;
+    case 403:
+      return util::error::PERMISSION_DENIED;
+    case 404:
+      return util::error::NOT_FOUND;
+    case 412:
+      return util::error::FAILED_PRECONDITION;
+    case 500:
+      return util::error::UNAVAILABLE;
+    default:
+      return util::error::UNKNOWN;
+  }
+}
+
+
+util::error::Code StatusCodeFromEtcdErrorCode(int etcd_code) {
+  switch (etcd_code) {
+    case 100:  // Key not found
+      return util::error::NOT_FOUND;
+    case 101:  // Compare failed
+    case 102:  // Not a file
+    case 104:  // Not a directory
+    case 105:  // Key already exists
+    case 107:  // Root is read-only
+    case 108:  // Directory not empty
+      return util::error::FAILED_PRECONDITION;
+
+    case 201:  // PrevValue missing
+    case 202:  // Provided TTL is not a number
+    case 203:  // Provided index is not a number
+    case 209:  // Invalid field
+    case 210:  // Invalid POST form
+      return util::error::FAILED_PRECONDITION;
+
+    case 300:  // Raft Internal Error
+    case 301:  // During Leader Election
+      return util::error::UNAVAILABLE;
+
+    case 400:  // Watcher is cleared due to etcd recovery
+    case 401:  // Event in requested index is outdated and cleared.
+      return util::error::ABORTED;
+
+    default:
+      return util::error::UNKNOWN;
+  }
+}
+
+
+string EtcdErrorMessage(const JsonObject& json) {
+  const JsonString message(json, "message");
+  const JsonString cause(json, "cause");
+
+  string ret("Etcd message: ");
+  if (message.Ok()) {
+    ret += message.Value();
+    if (cause.Ok()) {
+      ret += ", cause: " + string(cause.Value());
+    }
+  } else {
+    ret = json.DebugString();
+  }
+  return ret;
+}
+
+
+Status StatusFromResponse(int response_code, const JsonObject& json) {
+  // Prefer the etcd errorCode if there is one:
+  if (json.Ok()) {
+    const JsonInt error_code(json, "errorCode");
+    if (error_code.Ok()) {
+      return Status(StatusCodeFromEtcdErrorCode(error_code.Value()),
+                    EtcdErrorMessage(json));
+    }
+  }
+  // Otherwise use the HTTP code:
+  const util::error::Code error_code(
+      ErrorCodeForHttpResponseCode(response_code));
+  const string error_message(
+      error_code == util::error::OK ? "" : json.DebugString());
+  return Status(error_code, error_message);
+}
+
+
+StatusOr<EtcdClient::Node> ParseNodeFromJson(const JsonObject& json_node) {
+  const JsonInt createdIndex(json_node, "createdIndex");
+  if (!createdIndex.Ok()) {
+    return Status(util::error::FAILED_PRECONDITION,
+                  "Invalid JSON: Couldn't find 'createdIndex'");
+  }
+
+  const JsonInt modifiedIndex(json_node, "modifiedIndex");
+  if (!modifiedIndex.Ok()) {
+    return Status(util::error::FAILED_PRECONDITION,
+                  "Invalid JSON: Couldn't find 'modifiedIndex'");
+  }
+
+  const JsonString key(json_node, "key");
+  if (!key.Ok()) {
+    return Status(util::error::FAILED_PRECONDITION,
+                  "Invalid JSON: Couldn't find 'key'");
+  }
+
+  const JsonString value(json_node, "value");
+  const JsonBoolean isDir(json_node, "dir");
+  const bool is_dir(isDir.Ok() && isDir.Value());
+  const bool deleted(!value.Ok() && !is_dir);
+  vector<EtcdClient::Node> nodes;
+  if (is_dir && !deleted) {
+    const JsonArray json_nodes(json_node, "nodes");
+    if (json_nodes.Ok()) {
+      for (int i = 0; i < json_nodes.Length(); ++i) {
+        const JsonObject json_entry(json_nodes, i);
+        if (!json_entry.Ok()) {
+          return Status(util::error::FAILED_PRECONDITION,
+                        "Invalid JSON: Couldn't get 'nodes' index " +
+                            to_string(i));
+        }
+
+        StatusOr<EtcdClient::Node> entry(ParseNodeFromJson(json_entry));
+        if (!entry.status().ok()) {
+          return entry.status();
+        }
+
+        if (entry.ValueOrDie().deleted_) {
+          return Status(util::error::FAILED_PRECONDITION,
+                        "Deleted sub-node " + string(key.Value()));
+        }
+
+        nodes.emplace_back(entry.ValueOrDie());
+      }
+    }
+  }
+
+  return EtcdClient::Node(createdIndex.Value(), modifiedIndex.Value(),
+                          key.Value(), is_dir,
+                          (deleted || is_dir) ? "" : value.Value(),
+                          move(nodes), deleted);
+}
+
+
+void GetRequestDone(const string& keyname, EtcdClient::GetResponse* resp,
+                    Task* parent_task, EtcdClient::GenericResponse* gen_resp,
+                    Task* task) {
+  *resp = EtcdClient::GetResponse();
+  resp->etcd_index = gen_resp->etcd_index;
+  if (!task->status().ok()) {
+    // TODO(pphaneuf): Handle connection timeout (status DEADLINE_EXCEEDED)
+    // better here? Or add deadline support here and in UrlFetcher,
+    // with retries, so that this doesn't get all the way here?
+    parent_task->Return(
+        Status(task->status().CanonicalCode(),
+               task->status().error_message() + " (" + keyname + ")"));
+    return;
+  }
+
+  const JsonObject json_node(*gen_resp->json_body, "node");
+  if (!json_node.Ok()) {
+    parent_task->Return(Status(util::error::FAILED_PRECONDITION,
+                               "Invalid JSON: Couldn't find 'node'"));
+    return;
+  }
+
+  StatusOr<EtcdClient::Node> node(ParseNodeFromJson(json_node));
+  if (!node.status().ok()) {
+    parent_task->Return(node.status());
+    return;
+  }
+
+  resp->node = node.ValueOrDie();
+  parent_task->Return();
+}
+
+
+void CopyStat(const string& key, const JsonObject& from,
+              map<string, int64_t>* to) {
+  CHECK_NOTNULL(to);
+  const JsonInt stat(from, key.c_str());
+  if (!stat.Ok()) {
+    LOG(WARNING) << "Failed to find stat " << key;
+    return;
+  }
+  (*to)[key] = stat.Value();
+}
+
+
+void GetStoreStatsRequestDone(EtcdClient::StatsResponse* resp,
+                              Task* parent_task,
+                              EtcdClient::GenericResponse* gen_resp,
+                              Task* task) {
+  *resp = EtcdClient::StatsResponse();
+  resp->etcd_index = gen_resp->etcd_index;
+  if (!task->status().ok()) {
+    parent_task->Return(task->status());
+    return;
+  }
+
+  if (!gen_resp->json_body->Ok()) {
+    parent_task->Return(Status(util::error::FAILED_PRECONDITION,
+                               "Invalid JSON: json_body not Ok."));
+    return;
+  }
+
+  for (const auto& stat : kStoreStats) {
+    CopyStat(stat, *gen_resp->json_body, &resp->stats);
+  }
+  parent_task->Return();
+}
+
+
+void CreateRequestDone(EtcdClient::Response* resp, Task* parent_task,
+                       EtcdClient::GenericResponse* gen_resp, Task* task) {
+  if (!task->status().ok()) {
+    parent_task->Return(task->status());
+    return;
+  }
+
+  const JsonObject json_node(*gen_resp->json_body, "node");
+  if (!json_node.Ok()) {
+    parent_task->Return(Status(util::error::FAILED_PRECONDITION,
+                               "Invalid JSON: Couldn't find 'node'"));
+    return;
+  }
+
+  StatusOr<EtcdClient::Node> node(ParseNodeFromJson(json_node));
+  if (!node.status().ok()) {
+    parent_task->Return(node.status());
+    return;
+  }
+
+  CHECK_EQ(node.ValueOrDie().created_index_,
+           node.ValueOrDie().modified_index_);
+  resp->etcd_index = node.ValueOrDie().modified_index_;
+  parent_task->Return();
+}
+
+
+void UpdateRequestDone(EtcdClient::Response* resp, Task* parent_task,
+                       EtcdClient::GenericResponse* gen_resp, Task* task) {
+  *resp = EtcdClient::Response();
+  if (!task->status().ok()) {
+    parent_task->Return(task->status());
+    return;
+  }
+
+  const JsonObject json_node(*gen_resp->json_body, "node");
+  if (!json_node.Ok()) {
+    parent_task->Return(Status(util::error::FAILED_PRECONDITION,
+                               "Invalid JSON: Couldn't find 'node'"));
+    return;
+  }
+
+  StatusOr<EtcdClient::Node> node(ParseNodeFromJson(json_node));
+  if (!node.status().ok()) {
+    parent_task->Return(node.status());
+    return;
+  }
+
+  resp->etcd_index = node.ValueOrDie().modified_index_;
+  parent_task->Return();
+}
+
+
+void ForceSetRequestDone(EtcdClient::Response* resp, Task* parent_task,
+                         EtcdClient::GenericResponse* gen_resp, Task* task) {
+  *resp = EtcdClient::Response();
+  if (!task->status().ok()) {
+    parent_task->Return(task->status());
+    return;
+  }
+
+  const JsonObject json_node(*gen_resp->json_body, "node");
+  if (!json_node.Ok()) {
+    parent_task->Return(Status(util::error::FAILED_PRECONDITION,
+                               "Invalid JSON: Couldn't find 'node'"));
+    return;
+  }
+
+  StatusOr<EtcdClient::Node> node(ParseNodeFromJson(json_node));
+  if (!node.status().ok()) {
+    parent_task->Return(node.status());
+    return;
+  }
+
+  resp->etcd_index = node.ValueOrDie().modified_index_;
+  parent_task->Return();
+}
+
+
+string UrlEscapeAndJoinParams(const map<string, string>& params) {
+  string retval;
+
+  bool first(true);
+  for (map<string, string>::const_iterator it = params.begin();
+       it != params.end(); ++it) {
+    if (first)
+      first = false;
+    else
+      retval += "&";
+
+    unique_ptr<char, void (*)(void*)> first(
+        evhttp_uriencode(it->first.c_str(), it->first.size(), 0), &free);
+    unique_ptr<char, void (*)(void*)> second(
+        evhttp_uriencode(it->second.c_str(), it->second.size(), 0), &free);
+
+    retval += first.get();
+    retval += "=";
+    retval += second.get();
+  }
+
+  return retval;
+}
+
+
+static const EtcdClient::Node kInvalidNode(-1, -1, "", false, "", {}, true);
+
+
+}  // namespace
+
+
+struct EtcdClient::RequestState {
+  RequestState(UrlFetcher::Verb verb, const string& key,
+               const string& key_space, map<string, string> params,
+               const HostPortPair& host_port, GenericResponse* gen_resp,
+               Task* parent_task)
+      : gen_resp_(CHECK_NOTNULL(gen_resp)),
+        parent_task_(CHECK_NOTNULL(parent_task)) {
+    CHECK(!key.empty());
+    CHECK_EQ(key[0], '/');
+
+    req_.verb = verb;
+    SetHostPort(host_port);
+
+    if (FLAGS_etcd_consistent) {
+      params.insert(make_pair("consistent", "true"));
+    } else {
+#pragma clang diagnostic push
+#pragma clang diagnostic ignored "-Wunknown-pragmas"
+#pragma clang diagnostic ignored "-Wunused-local-typedef"
+      LOG_EVERY_N(WARNING, 100) << "Sending request without 'consistent=true'";
+#pragma clang diagnotic pop
+    }
+    if (FLAGS_etcd_quorum) {
+      params.insert(make_pair("quorum", "true"));
+    } else {
+#pragma clang diagnostic push
+#pragma clang diagnostic ignored "-Wunknown-pragmas"
+#pragma clang diagnostic ignored "-Wunused-local-typedef"
+      LOG_EVERY_N(WARNING, 100) << "Sending request without 'quorum=true'";
+#pragma clang diagnotic pop
+    }
+
+    req_.url.SetPath(key_space + key);
+    switch (req_.verb) {
+      case UrlFetcher::Verb::POST:
+      case UrlFetcher::Verb::PUT:
+        req_.headers.insert(
+            make_pair("Content-Type", "application/x-www-form-urlencoded"));
+        req_.body = UrlEscapeAndJoinParams(params);
+        break;
+
+      default:
+        req_.url.SetQuery(UrlEscapeAndJoinParams(params));
+    }
+    VLOG(2) << "path query: " << req_.url.PathQuery();
+  }
+
+  void SetHostPort(const HostPortPair& host_port) {
+    CHECK(!host_port.first.empty());
+    CHECK_GT(host_port.second, 0);
+    req_.url.SetProtocol("http");
+    req_.url.SetHost(host_port.first);
+    req_.url.SetPort(host_port.second);
+  }
+
+  GenericResponse* const gen_resp_;
+  Task* const parent_task_;
+
+  UrlFetcher::Request req_;
+  UrlFetcher::Response resp_;
+};
+
+
+struct EtcdClient::WatchState {
+  WatchState(const string& key, const WatchCallback& cb, Task* task)
+      : key_(key),
+        cb_(cb),
+        task_(CHECK_NOTNULL(task)),
+        highest_index_seen_(-1) {
+  }
+
+  ~WatchState() {
+    VLOG(1) << "EtcdClient::Watch: no longer watching " << key_;
+  }
+
+  const string key_;
+  const WatchCallback cb_;
+  Task* const task_;
+
+  int64_t highest_index_seen_;
+  map<string, int64_t> known_keys_;
+};
+
+
+void EtcdClient::WatchInitialGetDone(WatchState* state, GetResponse* resp,
+                                     Task* task) {
+  unique_ptr<GetResponse> resp_deleter(resp);
+  if (state->task_->CancelRequested()) {
+    state->task_->Return(Status::CANCELLED);
+    return;
+  }
+
+  // TODO(pphaneuf): Need better error handling here. Have to review
+  // what the possible errors are, for now we'll just retry after a delay.
+  if (!task->status().ok()) {
+    LOG(WARNING) << "Initial get error: " << task->status() << ", will retry "
+                 << "in " << FLAGS_etcd_watch_error_retry_delay_seconds
+                 << " second(s)";
+    state->task_->executor()->Delay(
+        seconds(FLAGS_etcd_watch_error_retry_delay_seconds),
+        state->task_->AddChild([this, state](Task*) {
+          this->WatchRequestDone(state, nullptr, nullptr);
+        }));
+    return;
+  }
+
+  state->highest_index_seen_ =
+      max(state->highest_index_seen_, resp->etcd_index);
+
+  vector<Node> nodes;
+  if (resp->node.is_dir_) {
+    nodes = move(resp->node.nodes_);
+  } else {
+    nodes.push_back(resp->node);
+  }
+
+  vector<Node> updates;
+  map<string, int64_t> new_known_keys;
+  VLOG(1) << "WatchGet " << state << " : num updates = " << nodes.size();
+  for (const auto& node : nodes) {
+    // This simply shouldn't happen, but since I think it shouldn't
+    // prevent us from continuing processing, CHECKing on this would
+    // just be mean...
+    LOG_IF(WARNING, resp->etcd_index < node.modified_index_)
+        << "X-Etcd-Index (" << resp->etcd_index
+        << ") smaller than node modifiedIndex (" << node.modified_index_
+        << ") for key \"" << node.key_ << "\"";
+
+    map<string, int64_t>::iterator it(state->known_keys_.find(node.key_));
+    if (it == state->known_keys_.end() || it->second < node.modified_index_) {
+      VLOG(1) << "WatchGet " << state << " : updated node " << node.key_
+              << " @ " << node.modified_index_;
+      // Nodes received in an initial get should *always* exist!
+      CHECK(!node.deleted_);
+      updates.emplace_back(node);
+    }
+
+    new_known_keys[node.key_] = node.modified_index_;
+    if (it != state->known_keys_.end()) {
+      VLOG(1) << "WatchGet " << state << " : stale update " << node.key_
+              << " @ " << node.modified_index_;
+      state->known_keys_.erase(it);
+    }
+  }
+
+  // The keys still in known_keys_ at this point have been deleted.
+  for (const auto& key : state->known_keys_) {
+    // TODO(pphaneuf): Passing in -1 for the created and modified
+    // indices, is that a problem? We do have a "last known" modified
+    // index in key.second...
+    updates.emplace_back(Node(-1, -1, key.first, false, "", {}, true));
+  }
+
+  state->known_keys_.swap(new_known_keys);
+
+  SendWatchUpdates(state, move(updates));
+}
+
+
+void EtcdClient::WatchRequestDone(WatchState* state, GetResponse* get_resp,
+                                  Task* child_task) {
+  // We clean up this way instead of using util::Task::DeleteWhenDone,
+  // because our task is long-lived, and we do not want to accumulate
+  // these objects.
+  unique_ptr<GetResponse> get_resp_deleter(get_resp);
+
+  if (state->task_->CancelRequested()) {
+    state->task_->Return(Status::CANCELLED);
+    return;
+  }
+
+  // Handle when the request index is too old, we have to restart the
+  // watch logic (or start the watch logic the first time).
+  if (!child_task ||
+      (child_task->status().CanonicalCode() == util::error::ABORTED &&
+       get_resp->etcd_index >= 0)) {
+    // On the first time here, we don't actually have a gen_resp, we
+    // just want to start the watch logic.
+    if (get_resp) {
+      VLOG(1) << "etcd index: " << get_resp->etcd_index;
+      state->highest_index_seen_ =
+          max(state->highest_index_seen_, get_resp->etcd_index);
+    }
+
+    GetResponse* const resp(new GetResponse);
+    Get(state->key_, resp,
+        state->task_->AddChild(
+            bind(&EtcdClient::WatchInitialGetDone, this, state, resp, _1)));
+
+    return;
+  }
+
+  if (!child_task->status().ok()) {
+    VLOG(1) << "Watch request errored: " << child_task->status();
+    StartWatchRequest(state);
+    return;
+  }
+
+  vector<Node> updates;
+  state->highest_index_seen_ =
+      max(state->highest_index_seen_, get_resp->node.modified_index_);
+  updates.emplace_back(get_resp->node);
+
+  if (!get_resp->node.deleted_) {
+    state->known_keys_[get_resp->node.key_] = get_resp->node.modified_index_;
+  } else {
+    VLOG(1) << "erased key: " << get_resp->node.key_;
+    state->known_keys_.erase(get_resp->node.key_);
+  }
+
+  SendWatchUpdates(state, move(updates));
+}
+
+
+// This method should always be called on the executor of
+// state->task_.
+void EtcdClient::SendWatchUpdates(WatchState* state,
+                                  const vector<Node>& updates) {
+  if (!updates.empty() || state->highest_index_seen_ == -1) {
+    state->cb_(updates);
+  }
+
+  // Only start the next request once the callback has return, to make
+  // sure they are always delivered in order.
+  StartWatchRequest(state);
+}
+
+
+void EtcdClient::StartWatchRequest(WatchState* state) {
+  if (state->task_->CancelRequested()) {
+    state->task_->Return(Status::CANCELLED);
+    return;
+  }
+
+  Request req(state->key_);
+  req.recursive = true;
+  req.wait_index = state->highest_index_seen_ + 1;
+
+  GetResponse* const get_resp(new GetResponse);
+  Get(req, get_resp, state->task_->AddChild(bind(&EtcdClient::WatchRequestDone,
+                                                 this, state, get_resp, _1)));
+}
+
+
+EtcdClient::Node::Node(int64_t created_index, int64_t modified_index,
+                       const string& key, bool is_dir, const string& value,
+                       vector<Node>&& nodes, bool deleted)
+    : created_index_(created_index),
+      modified_index_(modified_index),
+      key_(key),
+      is_dir_(is_dir),
+      value_(value),
+      nodes_(move(nodes)),
+      expires_(system_clock::time_point::max()),
+      deleted_(deleted) {
+  CHECK(!deleted_ || value_.empty());
+  CHECK(!deleted_ || nodes_.empty());
+  CHECK(!is_dir_ || value_.empty());
+  CHECK(is_dir_ || nodes_.empty());
+}
+
+
+// static
+const EtcdClient::Node& EtcdClient::Node::InvalidNode() {
+  return kInvalidNode;
+}
+
+
+string EtcdClient::Node::ToString() const {
+  ostringstream oss;
+  oss << "[" << key_ << ": '" << value_ << "' c: " << created_index_
+      << " m: " << modified_index_;
+  if (HasExpiry()) {
+    time_t time_c = system_clock::to_time_t(expires_);
+    oss << " expires: " << ctime(&time_c);
+  }
+
+  oss << " dir: " << is_dir_ << " deleted: " << deleted_ << "]";
+  return oss.str();
+}
+
+
+bool EtcdClient::Node::HasExpiry() const {
+  return expires_ < system_clock::time_point::max();
+}
+
+
+EtcdClient::EtcdClient(Executor* executor, UrlFetcher* fetcher,
+                       const string& host, uint16_t port)
+    : EtcdClient(executor, fetcher,
+                 list<HostPortPair>{HostPortPair(host, port)}) {
+}
+
+
+EtcdClient::EtcdClient(Executor* executor, UrlFetcher* fetcher,
+                       const list<HostPortPair>& etcds)
+    : executor_(CHECK_NOTNULL(executor)),
+      log_version_task_(new SyncTask(executor_)),
+      fetcher_(CHECK_NOTNULL(fetcher)),
+      etcds_(etcds),
+      logged_version_(false) {
+  CHECK(!etcds_.empty()) << "No etcd hosts provided.";
+  VLOG(1) << "EtcdClient: " << this;
+
+  for (const auto& e : etcds_) {
+    CHECK(!e.first.empty()) << "Empty host specified";
+    CHECK_GT(e.second, 0) << "Invalid port specified";
+  }
+}
+
+
+EtcdClient::HostPortPair EtcdClient::ChooseNextServer() {
+  lock_guard<mutex> lock(lock_);
+
+  etcds_.emplace_back(etcds_.front());
+  etcds_.pop_front();
+
+  LOG(INFO) << "Selected new etcd server: " << etcds_.front().first << ":"
+            << etcds_.front().second;
+  return etcds_.front();
+}
+
+
+EtcdClient::EtcdClient()
+    : executor_(nullptr), log_version_task_(nullptr), fetcher_(nullptr) {
+}
+
+
+EtcdClient::~EtcdClient() {
+  VLOG(1) << "~EtcdClient: " << this;
+  if (log_version_task_) {
+    log_version_task_->task()->Return();
+    log_version_task_->Wait();
+  }
+}
+
+
+void EtcdClient::FetchDone(RequestState* etcd_req, Task* task) {
+  VLOG(2) << "EtcdClient::FetchDone: " << task->status();
+
+  if (!task->status().ok()) {
+    if (task->status().error_code() == util::error::UNAVAILABLE) {
+      // Seems etcd wasn't available; pick a new etcd server and retry
+      LOG(WARNING) << "Etcd fetch failed: " << task->status() << ", retrying "
+                   << "on next etcd server.";
+      etcd_req->SetHostPort(ChooseNextServer());
+      fetcher_->Fetch(etcd_req->req_, &etcd_req->resp_,
+                      etcd_req->parent_task_->AddChild(
+                          bind(&EtcdClient::FetchDone, this, etcd_req, _1)));
+      return;
+    }
+    // Otherwise just let the requestor know.
+    etcd_req->parent_task_->Return(task->status());
+    return;
+  }
+
+  VLOG(2) << "response:\n" << etcd_req->resp_;
+
+  if (etcd_req->resp_.status_code == 307) {
+    UrlFetcher::Headers::const_iterator it(
+        etcd_req->resp_.headers.find("location"));
+
+    if (it == etcd_req->resp_.headers.end()) {
+      etcd_req->parent_task_->Return(
+          Status(util::error::INTERNAL,
+                 "etcd returned a redirect without a Location header?"));
+      return;
+    }
+
+    const URL url(it->second);
+    if (url.Host().empty() || url.Port() == 0) {
+      etcd_req->parent_task_->Return(
+          Status(util::error::INTERNAL,
+                 "could not parse Location header from etcd: " + it->second));
+      return;
+    }
+
+    etcd_req->SetHostPort(
+        UpdateEndpoint(HostPortPair(url.Host(), url.Port())));
+
+    MaybeLogEtcdVersion();
+
+    fetcher_->Fetch(etcd_req->req_, &etcd_req->resp_,
+                    etcd_req->parent_task_->AddChild(
+                        bind(&EtcdClient::FetchDone, this, etcd_req, _1)));
+    return;
+  }
+
+  etcd_req->gen_resp_->json_body =
+      make_shared<JsonObject>(etcd_req->resp_.body);
+  CHECK_NOTNULL(etcd_req->gen_resp_->json_body.get());
+  if (!etcd_req->gen_resp_->json_body->Ok()) {
+    LOG(WARNING) << "Got invalid JSON: " << etcd_req->resp_.body;
+  }
+
+  etcd_req->gen_resp_->etcd_index = -1;
+
+  UrlFetcher::Headers::const_iterator it(
+      etcd_req->resp_.headers.find("X-Etcd-Index"));
+  if (it != etcd_req->resp_.headers.end()) {
+    etcd_req->gen_resp_->etcd_index = atoll(it->second.c_str());
+  }
+
+  etcd_req->parent_task_->Return(
+      StatusFromResponse(etcd_req->resp_.status_code,
+                         *etcd_req->gen_resp_->json_body));
+}
+
+
+EtcdClient::HostPortPair EtcdClient::GetEndpoint() const {
+  lock_guard<mutex> lock(lock_);
+  return etcds_.front();
+}
+
+
+EtcdClient::HostPortPair EtcdClient::UpdateEndpoint(
+    HostPortPair&& new_endpoint) {
+  lock_guard<mutex> lock(lock_);
+  logged_version_ = false;
+  auto it(find(etcds_.begin(), etcds_.end(), new_endpoint));
+  if (it == etcds_.end()) {
+    // TODO(alcutter): We don't really have a way of knowing when to remove
+    // etcd endpoints at the moment.  We should really be querying the etcd
+    // cluster for its members and using that list.
+    etcds_.emplace_front(move(new_endpoint));
+  } else {
+    etcds_.splice(etcds_.begin(), etcds_, it);
+  }
+
+  LOG(INFO) << "Selected new etcd server: " << etcds_.front().first << ":"
+            << etcds_.front().second;
+  return etcds_.front();
+}
+
+
+void EtcdClient::Get(const Request& req, GetResponse* resp, Task* task) {
+  map<string, string> params;
+  if (req.recursive) {
+    params["recursive"] = "true";
+  }
+  if (req.wait_index > 0) {
+    params["wait"] = "true";
+    params["waitIndex"] = to_string(req.wait_index);
+    // TODO(pphaneuf): This is a hack, as "wait" is not incompatible
+    // with "quorum=true". It should be left to the caller, though
+    // (and I'm not sure defaulting to "quorum=true" is that good an
+    // idea, even).
+    params["quorum"] = "false";
+  }
+  GenericResponse* const gen_resp(new GenericResponse);
+  task->DeleteWhenDone(gen_resp);
+  Generic(req.key, kKeysSpace, params, UrlFetcher::Verb::GET, gen_resp,
+          task->AddChild(
+              bind(&GetRequestDone, req.key, resp, task, gen_resp, _1)));
+}
+
+
+void EtcdClient::Create(const string& key, const string& value, Response* resp,
+                        Task* task) {
+  map<string, string> params;
+  params["value"] = value;
+  params["prevExist"] = "false";
+  GenericResponse* const gen_resp(new GenericResponse);
+  task->DeleteWhenDone(gen_resp);
+  Generic(key, kKeysSpace, params, UrlFetcher::Verb::PUT, gen_resp,
+          task->AddChild(bind(&CreateRequestDone, resp, task, gen_resp, _1)));
+}
+
+
+void EtcdClient::CreateWithTTL(const string& key, const string& value,
+                               const seconds& ttl, Response* resp,
+                               Task* task) {
+  map<string, string> params;
+  params["value"] = value;
+  params["prevExist"] = "false";
+  params["ttl"] = to_string(ttl.count());
+  GenericResponse* const gen_resp(new GenericResponse);
+  task->DeleteWhenDone(gen_resp);
+  Generic(key, kKeysSpace, params, UrlFetcher::Verb::PUT, gen_resp,
+          task->AddChild(bind(&CreateRequestDone, resp, task, gen_resp, _1)));
+}
+
+
+void EtcdClient::Update(const string& key, const string& value,
+                        const int64_t previous_index, Response* resp,
+                        Task* task) {
+  map<string, string> params;
+  params["value"] = value;
+  params["prevIndex"] = to_string(previous_index);
+  GenericResponse* const gen_resp(new GenericResponse);
+  task->DeleteWhenDone(gen_resp);
+  Generic(key, kKeysSpace, params, UrlFetcher::Verb::PUT, gen_resp,
+          task->AddChild(bind(&UpdateRequestDone, resp, task, gen_resp, _1)));
+}
+
+
+void EtcdClient::UpdateWithTTL(const string& key, const string& value,
+                               const seconds& ttl,
+                               const int64_t previous_index, Response* resp,
+                               Task* task) {
+  map<string, string> params;
+  params["value"] = value;
+  params["prevIndex"] = to_string(previous_index);
+  params["ttl"] = to_string(ttl.count());
+  GenericResponse* const gen_resp(new GenericResponse);
+  task->DeleteWhenDone(gen_resp);
+  Generic(key, kKeysSpace, params, UrlFetcher::Verb::PUT, gen_resp,
+          task->AddChild(bind(&UpdateRequestDone, resp, task, gen_resp, _1)));
+}
+
+
+void EtcdClient::ForceSet(const string& key, const string& value,
+                          Response* resp, Task* task) {
+  map<string, string> params;
+  params["value"] = value;
+  GenericResponse* const gen_resp(new GenericResponse);
+  task->DeleteWhenDone(gen_resp);
+  Generic(key, kKeysSpace, params, UrlFetcher::Verb::PUT, gen_resp,
+          task->AddChild(
+              bind(&ForceSetRequestDone, resp, task, gen_resp, _1)));
+}
+
+
+void EtcdClient::ForceSetWithTTL(const string& key, const string& value,
+                                 const seconds& ttl, Response* resp,
+                                 Task* task) {
+  map<string, string> params;
+  params["value"] = value;
+  params["ttl"] = to_string(ttl.count());
+  GenericResponse* const gen_resp(new GenericResponse);
+  task->DeleteWhenDone(gen_resp);
+  Generic(key, kKeysSpace, params, UrlFetcher::Verb::PUT, gen_resp,
+          task->AddChild(
+              bind(&ForceSetRequestDone, resp, task, gen_resp, _1)));
+}
+
+
+void EtcdClient::Delete(const string& key, const int64_t current_index,
+                        Task* task) {
+  map<string, string> params;
+  params["prevIndex"] = to_string(current_index);
+  GenericResponse* const gen_resp(new GenericResponse);
+  task->DeleteWhenDone(gen_resp);
+
+  Generic(key, kKeysSpace, params, UrlFetcher::Verb::DELETE, gen_resp, task);
+}
+
+
+void EtcdClient::ForceDelete(const string& key, Task* task) {
+  GenericResponse* const gen_resp(new GenericResponse);
+  task->DeleteWhenDone(gen_resp);
+
+  Generic(key, kKeysSpace, map<string, string>(), UrlFetcher::Verb::DELETE,
+          gen_resp, task);
+}
+
+
+void EtcdClient::GetStoreStats(StatsResponse* resp, Task* task) {
+  map<string, string> params;
+  GenericResponse* const gen_resp(new GenericResponse);
+  task->DeleteWhenDone(gen_resp);
+
+  Generic(kStoreStatsKey, kStatsSpace, params, UrlFetcher::Verb::GET, gen_resp,
+          task->AddChild(
+              bind(&GetStoreStatsRequestDone, resp, task, gen_resp, _1)));
+}
+
+
+void EtcdClient::Watch(const string& key, const WatchCallback& cb,
+                       Task* task) {
+  VLOG(1) << "EtcdClient::Watch: " << key;
+
+  WatchState* const state(new WatchState(key, cb, task));
+  task->DeleteWhenDone(state);
+
+  // This will kick off the watch logic, with an initial get request.
+  WatchRequestDone(state, nullptr, nullptr);
+}
+
+
+void EtcdClient::Generic(const string& key, const string& key_space,
+                         const map<string, string>& params,
+                         UrlFetcher::Verb verb, GenericResponse* resp,
+                         Task* task) {
+  MaybeLogEtcdVersion();
+  RequestState* const etcd_req(new RequestState(verb, key, key_space, params,
+                                                GetEndpoint(), resp, task));
+  task->DeleteWhenDone(etcd_req);
+
+  fetcher_->Fetch(etcd_req->req_, &etcd_req->resp_,
+                  etcd_req->parent_task_->AddChild(
+                      bind(&EtcdClient::FetchDone, this, etcd_req, _1)));
+}
+
+list<EtcdClient::HostPortPair> SplitHosts(const string& hosts_string) {
+  vector<string> hosts(util::split(hosts_string, ','));
+
+  list<EtcdClient::HostPortPair> ret;
+  for (const auto& h : hosts) {
+    // First check that the entire etcd URL can be parsed by evhttp
+    unique_ptr<evhttp_uri, void (*)(evhttp_uri*)> uri(
+        evhttp_uri_parse(h.c_str()), &evhttp_uri_free);
+
+    if (!uri) {
+      LOG(FATAL) << "Invalid etcd_server url specified: " << h;
+    }
+
+    vector<string> hp(util::split(h, ':'));
+    CHECK_EQ(static_cast<size_t>(2), hp.size())
+        << "Invalid host:port string: '" << h << "'";
+    const int port(stoi(hp[1]));
+    CHECK_LT(0, port) << "Port is <= 0";
+    CHECK_GE(65535, port) << "Port is > 65535";
+
+    ret.emplace_back(EtcdClient::HostPortPair(hp[0], port));
+  }
+  return ret;
+}
+
+void EtcdClient::MaybeLogEtcdVersion() {
+  lock_guard<mutex> lock(lock_);
+  if (logged_version_) {
+    return;
+  }
+  logged_version_ = true;
+
+  const UrlFetcher::Request req(URL("http://" + etcds_.front().first + ":" +
+                                    to_string(etcds_.front().second) +
+                                    "/version"));
+  UrlFetcher::Response* const resp(new UrlFetcher::Response);
+  fetcher_->Fetch(req, resp, log_version_task_->task()->AddChild([this, resp](
+                                 Task* child_task) {
+    unique_ptr<UrlFetcher::Response> resp_deleter(resp);
+    if (!child_task->status().ok()) {
+      LOG(WARNING) << "Failed to fetch etcd version: " << child_task->status();
+    } else {
+      LOG(INFO) << "Etcd version: " << resp->body;
+    }
+  }));
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/etcd_delete.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/etcd_delete.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/etcd_delete.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/etcd_delete.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,127 @@
+#include "util/etcd_delete.h"
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <functional>
+#include <mutex>
+
+using std::bind;
+using std::move;
+using std::mutex;
+using std::placeholders::_1;
+using std::string;
+using std::unique_lock;
+using std::vector;
+using util::Status;
+using util::Task;
+using util::TaskHold;
+
+DEFINE_int32(etcd_delete_concurrency, 4,
+             "number of etcd keys to delete at a time");
+
+namespace cert_trans {
+namespace {
+
+
+class DeleteState {
+ public:
+  DeleteState(EtcdClient* client, vector<string>&& keys, Task* task)
+      : client_(CHECK_NOTNULL(client)),
+        task_(CHECK_NOTNULL(task)),
+        outstanding_(0),
+        keys_(move(keys)),
+        it_(keys_.begin()) {
+    CHECK_GT(FLAGS_etcd_delete_concurrency, 0);
+
+    if (it_ == keys_.end()) {
+      // Nothing to do!
+      task_->Return();
+    } else {
+      StartNextRequest(unique_lock<mutex>(mutex_));
+    }
+  }
+
+  ~DeleteState() {
+    CHECK_EQ(outstanding_, 0);
+  }
+
+ private:
+  void RequestDone(Task* child_task);
+  void StartNextRequest(unique_lock<mutex>&& lock);
+
+  EtcdClient* const client_;
+  Task* const task_;
+  mutex mutex_;
+  int outstanding_;
+  const vector<string> keys_;
+  vector<string>::const_iterator it_;
+};
+
+
+void DeleteState::RequestDone(Task* child_task) {
+  unique_lock<mutex> lock(mutex_);
+  --outstanding_;
+
+  // If a child task has an error (except for not found, this is close
+  // enough to success), return that error, and do not start any more
+  // requests.
+  if (!child_task->status().ok() &&
+      child_task->status().CanonicalCode() != util::error::NOT_FOUND) {
+    lock.unlock();
+    task_->Return(child_task->status());
+    return;
+  }
+
+  if (it_ != keys_.end()) {
+    StartNextRequest(move(lock));
+  } else {
+    if (outstanding_ < 1) {
+      // No more keys to get, and this was the last one to complete.
+      lock.unlock();
+      task_->Return();
+    }
+  }
+}
+
+
+void DeleteState::StartNextRequest(unique_lock<mutex>&& lock) {
+  CHECK(lock.owns_lock());
+
+  if (task_->CancelRequested()) {
+    // In case the task uses an inline executor.
+    lock.unlock();
+    task_->Return(Status::CANCELLED);
+    return;
+  }
+
+  while (outstanding_ < FLAGS_etcd_delete_concurrency && it_ != keys_.end() &&
+         task_->IsActive()) {
+    CHECK(lock.owns_lock());
+    const string& key(*it_);
+    ++it_;
+    ++outstanding_;
+
+    // In case the task uses an inline executor.
+    lock.unlock();
+
+    client_->ForceDelete(key, task_->AddChild(
+                                  bind(&DeleteState::RequestDone, this, _1)));
+
+    // We must be holding the lock to evaluate the loop condition.
+    lock.lock();
+  }
+}
+
+
+}  // namespace
+
+
+void EtcdForceDeleteKeys(EtcdClient* client, vector<string>&& keys,
+                         Task* task) {
+  TaskHold hold(CHECK_NOTNULL(task));
+  DeleteState* const state(new DeleteState(client, move(keys), task));
+  task->DeleteWhenDone(state);
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/etcd_delete.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/etcd_delete.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/etcd_delete.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/etcd_delete.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,21 @@
+#ifndef CERT_TRANS_UTIL_ETCD_DELETE_H_
+#define CERT_TRANS_UTIL_ETCD_DELETE_H_
+
+#include <stdint.h>
+#include <string>
+#include <vector>
+
+#include "util/etcd.h"
+
+namespace cert_trans {
+
+
+// Force delete keys in batches (implemented using concurrent
+// requests). The "keys" argument are pairs of key and modified index.
+void EtcdForceDeleteKeys(EtcdClient* client, std::vector<std::string>&& keys,
+                         util::Task* task);
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_ETCD_DELETE_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/etcd_delete_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/etcd_delete_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/etcd_delete_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/etcd_delete_test.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,227 @@
+#include <gflags/gflags.h>
+#include <gtest/gtest.h>
+
+#include "util/etcd_delete.h"
+#include "util/mock_etcd.h"
+#include "util/status_test_util.h"
+#include "util/sync_task.h"
+#include "util/testing.h"
+#include "util/thread_pool.h"
+
+using std::bind;
+using std::chrono::seconds;
+using std::move;
+using std::placeholders::_2;
+using std::placeholders::_3;
+using std::string;
+using std::vector;
+using testing::DoAll;
+using testing::Exactly;
+using testing::Expectation;
+using testing::IgnoreResult;
+using testing::Invoke;
+using testing::InvokeWithoutArgs;
+using testing::Mock;
+using testing::MockFunction;
+using testing::SaveArg;
+using testing::StrictMock;
+using testing::_;
+using util::Status;
+using util::SyncTask;
+using util::Task;
+using util::testing::StatusIs;
+
+DECLARE_int32(etcd_delete_concurrency);
+
+namespace cert_trans {
+namespace {
+
+
+class EtcdDeleteTest : public ::testing::Test {
+ protected:
+  EtcdDeleteTest() : pool_(1) {
+    FLAGS_etcd_delete_concurrency = 2;
+  }
+
+  ThreadPool pool_;
+  StrictMock<MockEtcdClient> client_;
+};
+
+
+typedef EtcdDeleteTest EtcdDeleteDeathTest;
+
+
+TEST_F(EtcdDeleteDeathTest, ConcurrencyTooLow) {
+  FLAGS_etcd_delete_concurrency = 0;
+  SyncTask sync(&pool_);
+
+  EXPECT_DEATH(EtcdForceDeleteKeys(&client_, {}, sync.task()),
+               "FLAGS_etcd_delete_concurrency > 0");
+
+  sync.task()->Return();
+  sync.Wait();
+}
+
+
+TEST_F(EtcdDeleteDeathTest, NoClient) {
+  SyncTask sync(&pool_);
+
+  EXPECT_DEATH(EtcdForceDeleteKeys(nullptr, {}, sync.task()),
+               "'client' Must be non NULL");
+
+  sync.task()->Return();
+  sync.Wait();
+}
+
+
+TEST_F(EtcdDeleteDeathTest, NoTask) {
+  EXPECT_DEATH(EtcdForceDeleteKeys(&client_, {}, nullptr),
+               "'task' Must be non NULL");
+}
+
+
+TEST_F(EtcdDeleteTest, NothingToDo) {
+  SyncTask sync(&pool_);
+  EtcdForceDeleteKeys(&client_, {}, sync.task());
+  sync.Wait();
+  EXPECT_OK(sync.status());
+}
+
+
+TEST_F(EtcdDeleteTest, AlreadyCancelled) {
+  SyncTask sync(&pool_);
+  sync.Cancel();
+  EtcdForceDeleteKeys(&client_, {"/foo"}, sync.task());
+  sync.Wait();
+  EXPECT_THAT(sync.status(), StatusIs(util::error::CANCELLED));
+}
+
+
+TEST_F(EtcdDeleteTest, CancelDuring) {
+  vector<string> keys{"/one", "/two", "/three"};
+  ASSERT_LT(static_cast<size_t>(FLAGS_etcd_delete_concurrency), keys.size());
+  SyncTask sync(&pool_);
+
+  Task* first_task(nullptr);
+  Notification first;
+  Task* second_task(nullptr);
+  Notification second;
+  EXPECT_CALL(client_, ForceDelete("/one", _))
+      .WillOnce(DoAll(SaveArg<1>(&first_task),
+                      InvokeWithoutArgs(&first, &Notification::Notify)));
+  EXPECT_CALL(client_, ForceDelete("/two", _))
+      .WillOnce(DoAll(SaveArg<1>(&second_task),
+                      InvokeWithoutArgs(&second, &Notification::Notify)));
+  EtcdForceDeleteKeys(&client_, move(keys), sync.task());
+
+  ASSERT_TRUE(first.WaitForNotificationWithTimeout(seconds(1)));
+  ASSERT_TRUE(first_task);
+  ASSERT_TRUE(second.WaitForNotificationWithTimeout(seconds(1)));
+  ASSERT_TRUE(second_task);
+
+  sync.Cancel();
+  first_task->Return();
+  second_task->Return();
+
+  sync.Wait();
+  EXPECT_THAT(sync.status(), StatusIs(util::error::CANCELLED));
+}
+
+
+TEST_F(EtcdDeleteTest, WithinConcurrency) {
+  vector<string> keys{"/one", "/two", "/three"};
+  ASSERT_LT(static_cast<size_t>(FLAGS_etcd_delete_concurrency), keys.size());
+  SyncTask sync(&pool_);
+
+  Task* first_task(nullptr);
+  Notification first;
+  Task* second_task(nullptr);
+  Notification second;
+  EXPECT_CALL(client_, ForceDelete("/one", _))
+      .WillOnce(DoAll(SaveArg<1>(&first_task),
+                      InvokeWithoutArgs(&first, &Notification::Notify)));
+  EXPECT_CALL(client_, ForceDelete("/two", _))
+      .WillOnce(DoAll(SaveArg<1>(&second_task),
+                      InvokeWithoutArgs(&second, &Notification::Notify)));
+  EtcdForceDeleteKeys(&client_, move(keys), sync.task());
+
+  ASSERT_TRUE(first.WaitForNotificationWithTimeout(seconds(1)));
+  ASSERT_TRUE(first_task);
+  ASSERT_TRUE(second.WaitForNotificationWithTimeout(seconds(1)));
+  ASSERT_TRUE(second_task);
+
+  // Make sure all the expected calls were called.
+  Mock::VerifyAndClearExpectations(&client_);
+
+  MockFunction<void()> cleanup;
+  second_task->CleanupWhenDone(bind(&MockFunction<void()>::Call, &cleanup));
+  Expectation first_done(EXPECT_CALL(cleanup, Call()).Times(Exactly(1)));
+
+  // Set up the expectation for the third call, but only once one of
+  // the first requests "completes".
+  Task* third_task(nullptr);
+  Notification third;
+  EXPECT_CALL(client_, ForceDelete("/three", _))
+      .After(first_done)
+      .WillOnce(DoAll(SaveArg<1>(&third_task),
+                      InvokeWithoutArgs(&third, &Notification::Notify)));
+
+  second_task->Return();
+
+  ASSERT_TRUE(third.WaitForNotificationWithTimeout(seconds(1)));
+  ASSERT_TRUE(third_task);
+
+  first_task->Return();
+  third_task->Return();
+
+  sync.Wait();
+  EXPECT_OK(sync.status());
+}
+
+
+TEST_F(EtcdDeleteTest, ErrorHandling) {
+  vector<string> keys{"/one", "/two", "/three"};
+  ASSERT_LT(static_cast<size_t>(FLAGS_etcd_delete_concurrency), keys.size());
+  SyncTask sync(&pool_);
+
+  Task* first_task(nullptr);
+  Notification first;
+  Task* second_task(nullptr);
+  Notification second;
+  EXPECT_CALL(client_, ForceDelete("/one", _))
+      .WillOnce(DoAll(SaveArg<1>(&first_task),
+                      InvokeWithoutArgs(&first, &Notification::Notify)));
+  EXPECT_CALL(client_, ForceDelete("/two", _))
+      .WillOnce(DoAll(SaveArg<1>(&second_task),
+                      InvokeWithoutArgs(&second, &Notification::Notify)));
+  EtcdForceDeleteKeys(&client_, move(keys), sync.task());
+
+  ASSERT_TRUE(first.WaitForNotificationWithTimeout(seconds(1)));
+  ASSERT_TRUE(first_task);
+  ASSERT_TRUE(second.WaitForNotificationWithTimeout(seconds(1)));
+  ASSERT_TRUE(second_task);
+
+  // Make sure all the expected calls were called.
+  Mock::VerifyAndClearExpectations(&client_);
+
+  second_task->Return(Status(util::error::DATA_LOSS, "things are bad"));
+
+  // Make sure the error propagates...
+  Notification first_cancelled;
+  first_task->WhenCancelled(bind(&Notification::Notify, &first_cancelled));
+  ASSERT_TRUE(first_cancelled.WaitForNotificationWithTimeout(seconds(1)));
+  first_task->Return();
+
+  sync.Wait();
+  EXPECT_THAT(sync.status(), StatusIs(util::error::DATA_LOSS));
+}
+
+
+}  // namespace
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/etcd.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/etcd.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/etcd.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/etcd.h	2017-01-15 10:56:31.047591151 +0100
@@ -0,0 +1,178 @@
+#ifndef CERT_TRANS_UTIL_ETCD_H_
+#define CERT_TRANS_UTIL_ETCD_H_
+
+#include <stdint.h>
+#include <chrono>
+#include <list>
+#include <map>
+#include <memory>
+#include <mutex>
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "base/macros.h"
+#include "net/url_fetcher.h"
+#include "util/status.h"
+#include "util/sync_task.h"
+#include "util/task.h"
+#include "util/util.h"
+
+class JsonObject;
+
+namespace cert_trans {
+
+
+class EtcdClient {
+ public:
+  typedef std::pair<std::string, uint16_t> HostPortPair;
+
+  struct Node {
+    static const Node& InvalidNode();
+
+    Node() : Node(InvalidNode()) {
+    }
+
+    Node(int64_t created_index, int64_t modified_index, const std::string& key,
+         bool is_dir, const std::string& value, std::vector<Node>&& nodes,
+         bool deleted);
+
+    bool HasExpiry() const;
+
+    std::string ToString() const;
+
+    int64_t created_index_;
+    int64_t modified_index_;
+    std::string key_;
+    bool is_dir_;
+    std::string value_;
+    std::vector<Node> nodes_;
+    std::chrono::system_clock::time_point expires_;
+    bool deleted_;
+  };
+
+  struct Request {
+    Request(const std::string& thekey)
+        : key(thekey), recursive(false), wait_index(0) {
+    }
+
+    std::string key;
+    bool recursive;
+    int64_t wait_index;
+  };
+
+  struct Response {
+    Response() : etcd_index(-1) {
+    }
+
+    int64_t etcd_index;
+  };
+
+  struct GetResponse : public Response {
+    Node node;
+  };
+
+  struct GenericResponse : public Response {
+    std::shared_ptr<JsonObject> json_body;
+  };
+
+  struct StatsResponse : public Response {
+    std::map<std::string, int64_t> stats;
+  };
+
+  typedef std::function<void(const std::vector<Node>& updates)> WatchCallback;
+
+  EtcdClient(util::Executor* executor, UrlFetcher* fetcher,
+             const std::string& host, uint16_t port);
+
+  EtcdClient(util::Executor* executir, UrlFetcher* fetcher,
+             const std::list<HostPortPair>& etcds);
+
+  virtual ~EtcdClient();
+
+  virtual void Get(const Request& req, GetResponse* resp, util::Task* task);
+
+  virtual void Create(const std::string& key, const std::string& value,
+                      Response* resp, util::Task* task);
+
+  virtual void CreateWithTTL(const std::string& key, const std::string& value,
+                             const std::chrono::seconds& ttl, Response* resp,
+                             util::Task* task);
+
+  virtual void Update(const std::string& key, const std::string& value,
+                      const int64_t previous_index, Response* resp,
+                      util::Task* task);
+
+  virtual void UpdateWithTTL(const std::string& key, const std::string& value,
+                             const std::chrono::seconds& ttl,
+                             const int64_t previous_index, Response* resp,
+                             util::Task* task);
+
+  virtual void ForceSet(const std::string& key, const std::string& value,
+                        Response* resp, util::Task* task);
+
+  virtual void ForceSetWithTTL(const std::string& key,
+                               const std::string& value,
+                               const std::chrono::seconds& ttl, Response* resp,
+                               util::Task* task);
+
+  virtual void Delete(const std::string& key, const int64_t current_index,
+                      util::Task* task);
+
+  virtual void ForceDelete(const std::string& key, util::Task* task);
+
+  virtual void GetStoreStats(StatsResponse* resp, util::Task* task);
+
+  // The "cb" will be called on the "task" executor. Also, only one
+  // will be sent to the executor at a time (for a given call to this
+  // method, not for all of them), to make sure they are received in
+  // order.
+  virtual void Watch(const std::string& key, const WatchCallback& cb,
+                     util::Task* task);
+
+ protected:
+  // Testing only
+  EtcdClient();
+
+ private:
+  struct RequestState;
+  struct WatchState;
+
+  HostPortPair ChooseNextServer();
+  HostPortPair GetEndpoint() const;
+  HostPortPair UpdateEndpoint(HostPortPair&& new_endpoint);
+  void FetchDone(RequestState* etcd_req, util::Task* task);
+  void Generic(const std::string& key, const std::string& key_space,
+               const std::map<std::string, std::string>& params,
+               UrlFetcher::Verb verb, GenericResponse* resp, util::Task* task);
+
+  void WatchInitialGetDone(WatchState* state, GetResponse* resp,
+                           util::Task* task);
+  void SendWatchUpdates(WatchState* state, const std::vector<Node>& updates);
+  void StartWatchRequest(WatchState* state);
+  void WatchRequestDone(WatchState* state, GetResponse* gen_resp,
+                        util::Task* child_task);
+
+  void MaybeLogEtcdVersion();
+
+  util::Executor* const executor_;
+  std::unique_ptr<util::SyncTask> log_version_task_;
+  UrlFetcher* const fetcher_;
+
+  mutable std::mutex lock_;
+  std::list<HostPortPair> etcds_;
+  bool logged_version_;
+
+  DISALLOW_COPY_AND_ASSIGN(EtcdClient);
+};
+
+
+// Splits strings of the form "host:port,host:port,..." to a list of
+// HostPortPairs.
+std::list<EtcdClient::HostPortPair> SplitHosts(
+    const std::string& hosts_string);
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_ETCD_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/etcd_masterelection.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/etcd_masterelection.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/etcd_masterelection.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/etcd_masterelection.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,54 @@
+#include <event2/thread.h>
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <atomic>
+
+#include "util/etcd.h"
+#include "util/libevent_wrapper.h"
+#include "util/masterelection.h"
+#include "util/thread_pool.h"
+
+namespace libevent = cert_trans::libevent;
+
+using cert_trans::EtcdClient;
+using cert_trans::MasterElection;
+using cert_trans::ThreadPool;
+using cert_trans::UrlFetcher;
+using std::make_shared;
+using std::shared_ptr;
+
+DEFINE_string(etcd, "127.0.0.1", "etcd server address");
+DEFINE_int32(etcd_port, 4001, "etcd server port");
+DEFINE_string(proposal_dir, "/master", "path to watch");
+DEFINE_string(node_id, "", "unique node id.");
+
+
+int main(int argc, char* argv[]) {
+  google::ParseCommandLineFlags(&argc, &argv, true);
+  google::InitGoogleLogging(argv[0]);
+  evthread_use_pthreads();
+  CHECK(!FLAGS_node_id.empty()) << "Must set --node_id";
+
+  const shared_ptr<libevent::Base> event_base(make_shared<libevent::Base>());
+  ThreadPool pool;
+  UrlFetcher fetcher(event_base.get(), &pool);
+
+  EtcdClient etcd(&pool, &fetcher, FLAGS_etcd, FLAGS_etcd_port);
+  MasterElection election(event_base, &etcd, FLAGS_proposal_dir,
+                          FLAGS_node_id);
+  election.StartElection();
+
+  libevent::EventPumpThread pump(event_base);
+
+  LOG(INFO) << "Waiting to become master...";
+  election.WaitToBecomeMaster();
+  LOG(INFO) << "I'm the boss!";
+
+  sleep(10);
+
+  LOG(INFO) << "Giving it all up and going fishing instead...";
+  election.StopElection();
+  LOG(INFO) << "Gone fishin'.";
+
+  return 0;
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/etcd_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/etcd_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/etcd_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/etcd_test.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,1223 @@
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <list>
+#include <memory>
+#include <string>
+
+#include "net/mock_url_fetcher.h"
+#include "util/etcd.h"
+#include "util/json_wrapper.h"
+#include "util/libevent_wrapper.h"
+#include "util/status_test_util.h"
+#include "util/sync_task.h"
+#include "util/testing.h"
+
+DECLARE_int32(etcd_watch_error_retry_delay_seconds);
+
+namespace cert_trans {
+
+using std::bind;
+using std::chrono::seconds;
+using std::list;
+using std::make_pair;
+using std::make_shared;
+using std::placeholders::_1;
+using std::placeholders::_2;
+using std::placeholders::_3;
+using std::shared_ptr;
+using std::string;
+using std::to_string;
+using std::unique_ptr;
+using std::vector;
+using testing::ElementsAre;
+using testing::HasSubstr;
+using testing::Invoke;
+using testing::InSequence;
+using testing::IsEmpty;
+using testing::Pair;
+using testing::StrCaseEq;
+using testing::StrictMock;
+using testing::_;
+using util::Status;
+using util::SyncTask;
+using util::Task;
+using util::testing::StatusIs;
+
+namespace {
+
+typedef UrlFetcher::Request FetchRequest;
+
+const char kEntryKey[] = "/some/key";
+const char kDirKey[] = "/some";
+const char kGetJson[] =
+    "{"
+    "  \"action\": \"get\","
+    "  \"node\": {"
+    "    \"createdIndex\": 6,"
+    "    \"key\": \"/some/key\","
+    "    \"modifiedIndex\": 9,"
+    "    \"value\": \"123\""
+    "  }"
+    "}";
+
+const char kGetAllJson[] =
+    "{"
+    "  \"action\": \"get\","
+    "  \"node\": {"
+    "    \"createdIndex\": 1,"
+    "    \"dir\": true,"
+    "    \"key\": \"/some\","
+    "    \"modifiedIndex\": 2,"
+    "    \"nodes\": ["
+    "      {"
+    "        \"createdIndex\": 6,"
+    "        \"key\": \"/some/key1\","
+    "        \"modifiedIndex\": 9,"
+    "        \"value\": \"123\""
+    "      }, {"
+    "        \"createdIndex\": 7,"
+    "        \"key\": \"/some/key2\","
+    "        \"modifiedIndex\": 7,"
+    "        \"value\": \"456\""
+    "      },"
+    "    ]"
+    "  }"
+    "}";
+
+const char kCreateJson[] =
+    "{"
+    "  \"action\": \"set\","
+    "  \"node\": {"
+    "    \"createdIndex\": 7,"
+    "    \"key\": \"/some/key\","
+    "    \"modifiedIndex\": 7,"
+    "    \"value\": \"123\""
+    "  }"
+    "}";
+
+const char kUpdateJson[] =
+    "{"
+    "  \"action\": \"set\","
+    "  \"node\": {"
+    "    \"createdIndex\": 5,"
+    "    \"key\": \"/some/key\","
+    "    \"modifiedIndex\": 6,"
+    "    \"value\": \"123\""
+    "  },"
+    "  \"prevNode\": {"
+    "    \"createdIndex\": 5,"
+    "    \"key\": \"/some/key\","
+    "    \"modifiedIndex\": 5,"
+    "    \"value\": \"old\""
+    "  }"
+    "}";
+
+const char kDeleteJson[] =
+    "{"
+    "  \"action\": \"delete\","
+    "  \"node\": {"
+    "    \"createdIndex\": 5,"
+    "    \"key\": \"/some/key\","
+    "    \"modifiedIndex\": 6,"
+    "  },"
+    "  \"prevNode\": {"
+    "    \"createdIndex\": 5,"
+    "    \"key\": \"/some/key\","
+    "    \"modifiedIndex\": 5,"
+    "    \"value\": \"123\""
+    "  }"
+    "}";
+
+const char kKeyNotFoundJson[] =
+    "{"
+    "   \"index\" : 17,"
+    "   \"message\" : \"Key not found\","
+    "   \"errorCode\" : 100,"
+    "   \"cause\" : \"/testdir/345\""
+    "}";
+
+const char kKeyAlreadyExistsJson[] =
+    "{"
+    "   \"index\" : 18,"
+    "   \"errorCode\" : 105,"
+    "   \"message\" : \"Key already exists\","
+    "   \"cause\" : \"/a\""
+    "}";
+
+const char kCompareFailedJson[] =
+    "{"
+    "   \"errorCode\": 101,"
+    "   \"message\": \"Compare failed\","
+    "   \"cause\": \"[two != one]\","
+    "   \"index\": 8"
+    "}";
+
+const char kStoreStatsJson[] =
+    "{"
+    "   \"setsFail\" : 1,"
+    "   \"getsSuccess\" : 2,"
+    "   \"watchers\" : 3,"
+    "   \"expireCount\" : 4,"
+    "   \"createFail\" : 5,"
+    "   \"setsSuccess\" : 6,"
+    "   \"compareAndDeleteFail\" : 7,"
+    "   \"createSuccess\" : 8,"
+    "   \"deleteFail\" : 9,"
+    "   \"compareAndSwapSuccess\" : 10,"
+    "   \"compareAndSwapFail\" : 11,"
+    "   \"compareAndDeleteSuccess\" : 12,"
+    "   \"updateFail\" : 13,"
+    "   \"deleteSuccess\" : 14,"
+    "   \"updateSuccess\" : 15,"
+    "   \"getsFail\" : 16"
+    "}";
+
+const char kVersionString[] = "ETCD VERSION";
+
+const char kEtcdHost[] = "etcd.example.net";
+const int kEtcdPort = 4242;
+
+const char kEtcdHost2[] = "etcd2.example.net";
+const int kEtcdPort2 = 5252;
+
+const char kEtcdHost3[] = "etcd3.example.net";
+const int kEtcdPort3 = 6262;
+
+const char kDefaultSpace[] = "/v2/keys";
+
+
+string GetEtcdUrl(const string& key, const string& key_space = kDefaultSpace,
+                  const string& host = kEtcdHost,
+                  const uint16_t port = kEtcdPort) {
+  CHECK(!key.empty() && key[0] == '/') << "key isn't slash-prefixed: " << key;
+  return "http://" + string(host) + ":" + to_string(port) + key_space + key;
+}
+
+
+void HandleFetch(Status status, int status_code,
+                 const UrlFetcher::Headers& headers, const string& body,
+                 const UrlFetcher::Request& req, UrlFetcher::Response* resp,
+                 Task* task) {
+  resp->status_code = status_code;
+  resp->headers = headers;
+  resp->body = body;
+  task->Return(status);
+}
+
+
+class EtcdTest : public ::testing::Test {
+ public:
+  EtcdTest()
+      : base_(make_shared<libevent::Base>()),
+        pump_(base_),
+        client_(base_.get(), &url_fetcher_, kEtcdHost, kEtcdPort) {
+    ExpectVersionCalls(url_fetcher_, kEtcdHost, kEtcdPort);
+    ExpectVersionCalls(url_fetcher_, kEtcdHost2, kEtcdPort2);
+    ExpectVersionCalls(url_fetcher_, kEtcdHost3, kEtcdPort3);
+  }
+
+ protected:
+  void ExpectVersionCalls(MockUrlFetcher& fetcher, const string& host,
+                          uint16_t port) {
+    EXPECT_CALL(
+        url_fetcher_,
+        Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                URL(GetEtcdUrl("/version", "", host, port)),
+                                IsEmpty(), ""),
+              _, _))
+        .WillRepeatedly(
+            Invoke(bind(HandleFetch, Status::OK, 200, UrlFetcher::Headers{},
+                        kVersionString, _1, _2, _3)));
+  }
+
+  shared_ptr<JsonObject> MakeJson(const string& json) {
+    return make_shared<JsonObject>(json);
+  }
+
+  const shared_ptr<libevent::Base> base_;
+  MockUrlFetcher url_fetcher_;
+  libevent::EventPumpThread pump_;
+  EtcdClient client_;
+};
+
+
+typedef EtcdTest EtcdDeathTest;
+
+
+TEST_F(EtcdTest, Get) {
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                      URL(GetEtcdUrl(kEntryKey) +
+                                          "?consistent=true&quorum=true"),
+                                      IsEmpty(), ""),
+                    _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "11")},
+                      kGetJson, _1, _2, _3)));
+
+  SyncTask task(base_.get());
+  EtcdClient::GetResponse resp;
+  client_.Get(string(kEntryKey), &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(11, resp.etcd_index);
+  EXPECT_EQ(9, resp.node.modified_index_);
+  EXPECT_EQ("123", resp.node.value_);
+}
+
+
+TEST_F(EtcdTest, GetRecursive) {
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(
+                        UrlFetcher::Verb::GET,
+                        URL(GetEtcdUrl(kEntryKey) +
+                            "?consistent=true&quorum=true&recursive=true"),
+                        IsEmpty(), ""),
+                    _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "11")},
+                      kGetJson, _1, _2, _3)));
+
+  SyncTask task(base_.get());
+  EtcdClient::Request req(kEntryKey);
+  req.recursive = true;
+  EtcdClient::GetResponse resp;
+  client_.Get(req, &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(11, resp.etcd_index);
+  EXPECT_EQ(9, resp.node.modified_index_);
+  EXPECT_EQ("123", resp.node.value_);
+}
+
+
+TEST_F(EtcdTest, GetForInvalidKey) {
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                      URL(GetEtcdUrl(kEntryKey) +
+                                          "?consistent=true&quorum=true"),
+                                      IsEmpty(), ""),
+                    _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 404,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "17")},
+                      kKeyNotFoundJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::GetResponse resp;
+  client_.Get(string(kEntryKey), &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::NOT_FOUND,
+                                      AllOf(HasSubstr("Key not found"),
+                                            HasSubstr(string(kEntryKey)))));
+}
+
+
+TEST_F(EtcdTest, GetAll) {
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                      URL(GetEtcdUrl(kDirKey) +
+                                          "?consistent=true&quorum=true"),
+                                      IsEmpty(), ""),
+                    _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kGetAllJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::GetResponse resp;
+  client_.Get(string(kDirKey), &resp, task.task());
+  task.Wait();
+  ASSERT_OK(task);
+  EXPECT_TRUE(resp.node.is_dir_);
+  ASSERT_EQ(static_cast<size_t>(2), resp.node.nodes_.size());
+  EXPECT_EQ(9, resp.node.nodes_[0].modified_index_);
+  EXPECT_EQ("123", resp.node.nodes_[0].value_);
+  EXPECT_EQ(7, resp.node.nodes_[1].modified_index_);
+  EXPECT_EQ("456", resp.node.nodes_[1].value_);
+}
+
+
+TEST_F(EtcdTest, GetWaitTooOld) {
+  const int kOldIndex(42);
+  const int kNewIndex(2015);
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                      URL(GetEtcdUrl(kEntryKey) +
+                                          "?consistent=true&quorum=false&"
+                                          "recursive=true&wait=true&"
+                                          "waitIndex=" +
+                                          to_string(kOldIndex)),
+                                      IsEmpty(), ""),
+                    _, _))
+      .WillOnce(Invoke(bind(
+          HandleFetch, Status::OK, 404,
+          UrlFetcher::Headers{make_pair("x-etcd-index", to_string(kNewIndex))},
+          kKeyNotFoundJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::Request req(kEntryKey);
+  req.recursive = true;
+  req.wait_index = kOldIndex;
+  EtcdClient::GetResponse resp;
+  client_.Get(req, &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::NOT_FOUND,
+                                      AllOf(HasSubstr("Key not found"),
+                                            HasSubstr(string(kEntryKey)))));
+  EXPECT_EQ(kNewIndex, resp.etcd_index);
+}
+
+
+TEST_F(EtcdTest, Create) {
+  EXPECT_CALL(
+      url_fetcher_,
+      Fetch(IsUrlFetchRequest(
+                UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+                ElementsAre(Pair(StrCaseEq("content-type"),
+                                 "application/x-www-form-urlencoded")),
+                "consistent=true&prevExist=false&quorum=true&value=123"),
+            _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kCreateJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  client_.Create(kEntryKey, "123", &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(7, resp.etcd_index);
+}
+
+
+TEST_F(EtcdTest, CreateFails) {
+  EXPECT_CALL(
+      url_fetcher_,
+      Fetch(IsUrlFetchRequest(
+                UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+                ElementsAre(Pair(StrCaseEq("content-type"),
+                                 "application/x-www-form-urlencoded")),
+                "consistent=true&prevExist=false&quorum=true&value=123"),
+            _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 412,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kKeyAlreadyExistsJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  client_.Create(kEntryKey, "123", &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::FAILED_PRECONDITION,
+                                      HasSubstr("Key already exists")));
+}
+
+
+TEST_F(EtcdTest, CreateWithTTL) {
+  EXPECT_CALL(
+      url_fetcher_,
+      Fetch(
+          IsUrlFetchRequest(
+              UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+              ElementsAre(Pair(StrCaseEq("content-type"),
+                               "application/x-www-form-urlencoded")),
+              "consistent=true&prevExist=false&quorum=true&ttl=100&value=123"),
+          _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kCreateJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  client_.CreateWithTTL(kEntryKey, "123", seconds(100), &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(7, resp.etcd_index);
+}
+
+
+TEST_F(EtcdTest, CreateWithTTLFails) {
+  EXPECT_CALL(
+      url_fetcher_,
+      Fetch(
+          IsUrlFetchRequest(
+              UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+              ElementsAre(Pair(StrCaseEq("content-type"),
+                               "application/x-www-form-urlencoded")),
+              "consistent=true&prevExist=false&quorum=true&ttl=100&value=123"),
+          _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 412,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kKeyAlreadyExistsJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  client_.CreateWithTTL(kEntryKey, "123", seconds(100), &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::FAILED_PRECONDITION,
+                                      HasSubstr("Key already exists")));
+}
+
+
+TEST_F(EtcdTest, Update) {
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(
+                        UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+                        ElementsAre(Pair(StrCaseEq("content-type"),
+                                         "application/x-www-form-urlencoded")),
+                        "consistent=true&prevIndex=5&quorum=true&value=123"),
+                    _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kUpdateJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  client_.Update(kEntryKey, "123", 5, &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(6, resp.etcd_index);
+}
+
+
+TEST_F(EtcdTest, UpdateFails) {
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(
+                        UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+                        ElementsAre(Pair(StrCaseEq("content-type"),
+                                         "application/x-www-form-urlencoded")),
+                        "consistent=true&prevIndex=5&quorum=true&value=123"),
+                    _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 412,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kCompareFailedJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  client_.Update(kEntryKey, "123", 5, &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::FAILED_PRECONDITION,
+                                      HasSubstr("Compare failed")));
+}
+
+
+TEST_F(EtcdTest, UpdateWithTTL) {
+  EXPECT_CALL(
+      url_fetcher_,
+      Fetch(IsUrlFetchRequest(
+                UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+                ElementsAre(Pair(StrCaseEq("content-type"),
+                                 "application/x-www-form-urlencoded")),
+                "consistent=true&prevIndex=5&quorum=true&ttl=100&value=123"),
+            _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kUpdateJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  client_.UpdateWithTTL(kEntryKey, "123", seconds(100), 5, &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(6, resp.etcd_index);
+}
+
+
+TEST_F(EtcdTest, UpdateWithTTLFails) {
+  EXPECT_CALL(
+      url_fetcher_,
+      Fetch(IsUrlFetchRequest(
+                UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+                ElementsAre(Pair(StrCaseEq("content-type"),
+                                 "application/x-www-form-urlencoded")),
+                "consistent=true&prevIndex=5&quorum=true&ttl=100&value=123"),
+            _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 412,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kCompareFailedJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  client_.UpdateWithTTL(kEntryKey, "123", seconds(100), 5, &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::FAILED_PRECONDITION,
+                                      HasSubstr("Compare failed")));
+}
+
+
+TEST_F(EtcdTest, ForceSetForPreexistingKey) {
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(
+                        UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+                        ElementsAre(Pair(StrCaseEq("content-type"),
+                                         "application/x-www-form-urlencoded")),
+                        "consistent=true&quorum=true&value=123"),
+                    _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kUpdateJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  client_.ForceSet(kEntryKey, "123", &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(6, resp.etcd_index);
+}
+
+
+TEST_F(EtcdTest, ForceSetForNewKey) {
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(
+                        UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+                        ElementsAre(Pair(StrCaseEq("content-type"),
+                                         "application/x-www-form-urlencoded")),
+                        "consistent=true&quorum=true&value=123"),
+                    _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kCreateJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  client_.ForceSet(kEntryKey, "123", &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(7, resp.etcd_index);
+}
+
+
+TEST_F(EtcdTest, ForceSetWithTTLForPreexistingKey) {
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(
+                        UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+                        ElementsAre(Pair(StrCaseEq("content-type"),
+                                         "application/x-www-form-urlencoded")),
+                        "consistent=true&quorum=true&ttl=100&value=123"),
+                    _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kUpdateJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  client_.ForceSetWithTTL(kEntryKey, "123", std::chrono::duration<int>(100),
+                          &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(6, resp.etcd_index);
+}
+
+
+TEST_F(EtcdTest, ForceSetWithTTLForNewKey) {
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(
+                        UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+                        ElementsAre(Pair(StrCaseEq("content-type"),
+                                         "application/x-www-form-urlencoded")),
+                        "consistent=true&quorum=true&ttl=100&value=123"),
+                    _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kCreateJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  client_.ForceSetWithTTL(kEntryKey, "123", seconds(100), &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(7, resp.etcd_index);
+}
+
+
+TEST_F(EtcdTest, Delete) {
+  EXPECT_CALL(
+      url_fetcher_,
+      Fetch(IsUrlFetchRequest(UrlFetcher::Verb::DELETE,
+                              URL(GetEtcdUrl(kEntryKey) +
+                                  "?consistent=true&prevIndex=5&quorum=true"),
+                              IsEmpty(), ""),
+            _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kDeleteJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  client_.Delete(kEntryKey, 5, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+}
+
+
+TEST_F(EtcdTest, DeleteFails) {
+  EXPECT_CALL(
+      url_fetcher_,
+      Fetch(IsUrlFetchRequest(UrlFetcher::Verb::DELETE,
+                              URL(GetEtcdUrl(kEntryKey) +
+                                  "?consistent=true&prevIndex=5&quorum=true"),
+                              IsEmpty(), ""),
+            _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 412,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kCompareFailedJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  client_.Delete(kEntryKey, 5, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::FAILED_PRECONDITION,
+                                      HasSubstr("Compare failed")));
+}
+
+
+TEST_F(EtcdTest, ForceDelete) {
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(UrlFetcher::Verb::DELETE,
+                                      URL(GetEtcdUrl(kEntryKey) +
+                                          "?consistent=true&quorum=true"),
+                                      IsEmpty(), ""),
+                    _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kDeleteJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  client_.ForceDelete(kEntryKey, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+}
+
+
+TEST_F(EtcdTest, WatchInitialGetFailureCausesRetry) {
+  FLAGS_etcd_watch_error_retry_delay_seconds = 1;
+  {
+    InSequence s;
+    EXPECT_CALL(url_fetcher_,
+                Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                        URL(GetEtcdUrl(kEntryKey) +
+                                            "?consistent=true&quorum=true"),
+                                        IsEmpty(), ""),
+                      _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status(util::error::UNAVAILABLE, ""), 0,
+                        UrlFetcher::Headers{}, "", _1, _2, _3)));
+    EXPECT_CALL(url_fetcher_,
+                Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                        URL(GetEtcdUrl(kEntryKey) +
+                                            "?consistent=true&quorum=true"),
+                                        IsEmpty(), ""),
+                      _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status::OK, 200,
+                        UrlFetcher::Headers{make_pair("x-etcd-index", "9")},
+                        kGetJson, _1, _2, _3)));
+  }
+
+  SyncTask task(base_.get());
+  client_.Watch(kEntryKey,
+                [&task](const vector<EtcdClient::Node>& updates) {
+                  EXPECT_EQ(static_cast<size_t>(1), updates.size());
+                  EXPECT_EQ(9, updates[0].modified_index_);
+                  EXPECT_EQ("123", updates[0].value_);
+                  task.Cancel();
+                },
+                task.task());
+  task.Wait();
+}
+
+
+TEST_F(EtcdTest, WatchInitialGetFailureRetriesOnNextEtcd) {
+  FLAGS_etcd_watch_error_retry_delay_seconds = 1;
+  EtcdClient multi_client(base_.get(), &url_fetcher_,
+                          {EtcdClient::HostPortPair(kEtcdHost, kEtcdPort),
+                           EtcdClient::HostPortPair(kEtcdHost2, kEtcdPort2)});
+  {
+    InSequence s;
+    EXPECT_CALL(url_fetcher_,
+                Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                        URL(GetEtcdUrl(kEntryKey) +
+                                            "?consistent=true&quorum=true"),
+                                        IsEmpty(), ""),
+                      _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status(util::error::UNAVAILABLE, ""), 0,
+                        UrlFetcher::Headers{}, "", _1, _2, _3)));
+    EXPECT_CALL(
+        url_fetcher_,
+        Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                URL(GetEtcdUrl(kEntryKey, kDefaultSpace,
+                                               kEtcdHost2, kEtcdPort2) +
+                                    "?consistent=true&quorum=true"),
+                                IsEmpty(), ""),
+              _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status::OK, 200,
+                        UrlFetcher::Headers{make_pair("x-etcd-index", "9")},
+                        kGetJson, _1, _2, _3)));
+  }
+
+  SyncTask task(base_.get());
+  multi_client.Watch(kEntryKey,
+                     [&task](const vector<EtcdClient::Node>& updates) {
+                       EXPECT_EQ(static_cast<size_t>(1), updates.size());
+                       EXPECT_EQ(9, updates[0].modified_index_);
+                       EXPECT_EQ("123", updates[0].value_);
+                       task.Cancel();
+                     },
+                     task.task());
+  task.Wait();
+}
+
+
+TEST_F(EtcdTest, WatchHangingGetTimeoutCausesRetry) {
+  FLAGS_etcd_watch_error_retry_delay_seconds = 1;
+
+  {
+    InSequence s;
+    EXPECT_CALL(url_fetcher_,
+                Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                        URL(GetEtcdUrl(kEntryKey) +
+                                            "?consistent=true&quorum=true"),
+                                        IsEmpty(), ""),
+                      _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status::OK, 200,
+                        UrlFetcher::Headers{make_pair("x-etcd-index", "9")},
+                        kGetJson, _1, _2, _3)));
+    EXPECT_CALL(url_fetcher_,
+                Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                        URL(GetEtcdUrl(kEntryKey) +
+                                            "?consistent=true&quorum=false" +
+                                            "&recursive=true&wait=true" +
+                                            "&waitIndex=10"),
+                                        IsEmpty(), ""),
+                      _, _))
+        .WillOnce(Invoke(bind(HandleFetch,
+                              Status(util::error::DEADLINE_EXCEEDED, ""), 0,
+                              UrlFetcher::Headers{}, "", _1, _2, _3)));
+    EXPECT_CALL(url_fetcher_,
+                Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                        URL(GetEtcdUrl(kEntryKey) +
+                                            "?consistent=true&quorum=false" +
+                                            "&recursive=true&wait=true" +
+                                            "&waitIndex=10"),
+                                        IsEmpty(), ""),
+                      _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status::OK, 200,
+                        UrlFetcher::Headers{make_pair("x-etcd-index", "9")},
+                        kGetJson, _1, _2, _3)));
+  }
+
+  SyncTask task(base_.get());
+  int num_updates(0);
+  client_.Watch(kEntryKey,
+                [&task,
+                 &num_updates](const vector<EtcdClient::Node>& updates) {
+                  EXPECT_EQ(static_cast<size_t>(1), updates.size());
+                  EXPECT_EQ(9, updates[0].modified_index_);
+                  EXPECT_EQ("123", updates[0].value_);
+                  if (num_updates == 1) {
+                    task.Cancel();
+                  }
+                  ++num_updates;
+                },
+                task.task());
+  task.Wait();
+}
+
+
+TEST_F(EtcdTest, UnavailableEtcdRetriesOnNewServer) {
+  EtcdClient multi_client(base_.get(), &url_fetcher_,
+                          {EtcdClient::HostPortPair(kEtcdHost, kEtcdPort),
+                           EtcdClient::HostPortPair(kEtcdHost2, kEtcdPort2)});
+
+  {
+    InSequence s;
+
+    // first server fails
+    EXPECT_CALL(
+        url_fetcher_,
+        Fetch(IsUrlFetchRequest(
+                  UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+                  ElementsAre(Pair(StrCaseEq("content-type"),
+                                   "application/x-www-form-urlencoded")),
+                  "consistent=true&prevIndex=5&quorum=true&ttl=100&value=123"),
+              _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status(util::error::UNAVAILABLE, ""), 0,
+                        UrlFetcher::Headers{}, "", _1, _2, _3)));
+    // second does too
+    EXPECT_CALL(
+        url_fetcher_,
+        Fetch(IsUrlFetchRequest(
+                  UrlFetcher::Verb::PUT,
+                  URL(GetEtcdUrl(kEntryKey, kDefaultSpace, kEtcdHost2,
+                                 kEtcdPort2)),
+                  ElementsAre(Pair(StrCaseEq("content-type"),
+                                   "application/x-www-form-urlencoded")),
+                  "consistent=true&prevIndex=5&quorum=true&ttl=100&value=123"),
+              _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status(util::error::UNAVAILABLE, ""), 0,
+                        UrlFetcher::Headers{}, "", _1, _2, _3)));
+    // try with first again, fail.
+    EXPECT_CALL(
+        url_fetcher_,
+        Fetch(IsUrlFetchRequest(
+                  UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+                  ElementsAre(Pair(StrCaseEq("content-type"),
+                                   "application/x-www-form-urlencoded")),
+                  "consistent=true&prevIndex=5&quorum=true&ttl=100&value=123"),
+              _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status(util::error::UNAVAILABLE, ""), 0,
+                        UrlFetcher::Headers{}, "", _1, _2, _3)));
+    // finally the second etcd is up:
+    EXPECT_CALL(
+        url_fetcher_,
+        Fetch(IsUrlFetchRequest(
+                  UrlFetcher::Verb::PUT,
+                  URL(GetEtcdUrl(kEntryKey, kDefaultSpace, kEtcdHost2,
+                                 kEtcdPort2)),
+                  ElementsAre(Pair(StrCaseEq("content-type"),
+                                   "application/x-www-form-urlencoded")),
+                  "consistent=true&prevIndex=5&quorum=true&ttl=100&value=123"),
+              _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status::OK, 200, UrlFetcher::Headers{},
+                        kUpdateJson, _1, _2, _3)));
+  }
+
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  multi_client.UpdateWithTTL(kEntryKey, "123", seconds(100), 5, &resp,
+                             task.task());
+  task.Wait();
+  EXPECT_OK(task.status());
+}
+
+
+TEST_F(EtcdTest, FollowsMasterChangeRedirectToNewHost) {
+  // Excludes kEtcdHost3:
+  EtcdClient multi_client(base_.get(), &url_fetcher_,
+                          {EtcdClient::HostPortPair(kEtcdHost, kEtcdPort),
+                           EtcdClient::HostPortPair(kEtcdHost2, kEtcdPort2)});
+
+  {
+    InSequence s;
+
+    // first server redirects to a new master which was previously unknown to
+    // the log server:
+    EXPECT_CALL(
+        url_fetcher_,
+        Fetch(IsUrlFetchRequest(
+                  UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+                  ElementsAre(Pair(StrCaseEq("content-type"),
+                                   "application/x-www-form-urlencoded")),
+                  "consistent=true&prevIndex=5&quorum=true&ttl=100&value=123"),
+              _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status::OK, 307,
+                        UrlFetcher::Headers{make_pair(
+                            "location", GetEtcdUrl(kEntryKey, kDefaultSpace,
+                                                   kEtcdHost3, kEtcdPort3))},
+                        "", _1, _2, _3)));
+    // log should attempt to contact the new:
+    EXPECT_CALL(
+        url_fetcher_,
+        Fetch(IsUrlFetchRequest(
+                  UrlFetcher::Verb::PUT,
+                  URL(GetEtcdUrl(kEntryKey, kDefaultSpace, kEtcdHost3,
+                                 kEtcdPort3)),
+                  ElementsAre(Pair(StrCaseEq("content-type"),
+                                   "application/x-www-form-urlencoded")),
+                  "consistent=true&prevIndex=5&quorum=true&ttl=100&value=123"),
+              _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status::OK, 200, UrlFetcher::Headers{},
+                        kUpdateJson, _1, _2, _3)));
+  }
+
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  multi_client.UpdateWithTTL(kEntryKey, "123", seconds(100), 5, &resp,
+                             task.task());
+  task.Wait();
+  EXPECT_OK(task.status());
+}
+
+
+TEST_F(EtcdTest, FollowsMasterChangeRedirectToKnownHost) {
+  EtcdClient multi_client(base_.get(), &url_fetcher_,
+                          {EtcdClient::HostPortPair(kEtcdHost, kEtcdPort),
+                           EtcdClient::HostPortPair(kEtcdHost2, kEtcdPort2)});
+
+  {
+    InSequence s;
+
+    // first server redirects to a new master which was previously known to the
+    // log server:
+    EXPECT_CALL(
+        url_fetcher_,
+        Fetch(IsUrlFetchRequest(
+                  UrlFetcher::Verb::PUT, URL(GetEtcdUrl(kEntryKey)),
+                  ElementsAre(Pair(StrCaseEq("content-type"),
+                                   "application/x-www-form-urlencoded")),
+                  "consistent=true&prevIndex=5&quorum=true&ttl=100&value=123"),
+              _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status::OK, 307,
+                        UrlFetcher::Headers{make_pair(
+                            "location", GetEtcdUrl(kEntryKey, kDefaultSpace,
+                                                   kEtcdHost2, kEtcdPort2))},
+                        "", _1, _2, _3)));
+    // log should attempt to contact the new master:
+    EXPECT_CALL(
+        url_fetcher_,
+        Fetch(IsUrlFetchRequest(
+                  UrlFetcher::Verb::PUT,
+                  URL(GetEtcdUrl(kEntryKey, kDefaultSpace, kEtcdHost2,
+                                 kEtcdPort2)),
+                  ElementsAre(Pair(StrCaseEq("content-type"),
+                                   "application/x-www-form-urlencoded")),
+                  "consistent=true&prevIndex=5&quorum=true&ttl=100&value=123"),
+              _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status::OK, 200, UrlFetcher::Headers{},
+                        kUpdateJson, _1, _2, _3)));
+  }
+
+  SyncTask task(base_.get());
+  EtcdClient::Response resp;
+  multi_client.UpdateWithTTL(kEntryKey, "123", seconds(100), 5, &resp,
+                             task.task());
+  task.Wait();
+  EXPECT_OK(task.status());
+}
+
+
+TEST_F(EtcdTest, GetStoreStats) {
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                      URL(GetEtcdUrl("/store", "/v2/stats") +
+                                          "?consistent=true&quorum=true"),
+                                      IsEmpty(), ""),
+                    _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "1")},
+                      kStoreStatsJson, _1, _2, _3)));
+  SyncTask task(base_.get());
+  EtcdClient::StatsResponse response;
+  client_.GetStoreStats(&response, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(1, response.stats["setsFail"]);
+  EXPECT_EQ(2, response.stats["getsSuccess"]);
+  EXPECT_EQ(3, response.stats["watchers"]);
+  EXPECT_EQ(4, response.stats["expireCount"]);
+  EXPECT_EQ(5, response.stats["createFail"]);
+  EXPECT_EQ(6, response.stats["setsSuccess"]);
+  EXPECT_EQ(7, response.stats["compareAndDeleteFail"]);
+  EXPECT_EQ(8, response.stats["createSuccess"]);
+  EXPECT_EQ(9, response.stats["deleteFail"]);
+  EXPECT_EQ(10, response.stats["compareAndSwapSuccess"]);
+  EXPECT_EQ(11, response.stats["compareAndSwapFail"]);
+  EXPECT_EQ(12, response.stats["compareAndDeleteSuccess"]);
+  EXPECT_EQ(13, response.stats["updateFail"]);
+  EXPECT_EQ(14, response.stats["deleteSuccess"]);
+  EXPECT_EQ(15, response.stats["updateSuccess"]);
+  EXPECT_EQ(16, response.stats["getsFail"]);
+}
+
+
+TEST_F(EtcdTest, SplitHosts) {
+  const string hosts(string(kEtcdHost) + ":" + to_string(kEtcdPort) + "," +
+                     kEtcdHost2 + ":" + to_string(kEtcdPort2));
+  const list<EtcdClient::HostPortPair> split_hosts(SplitHosts(hosts));
+  EXPECT_EQ(static_cast<size_t>(2), split_hosts.size());
+  EXPECT_EQ(kEtcdHost, split_hosts.front().first);
+  EXPECT_EQ(kEtcdPort, split_hosts.front().second);
+  EXPECT_EQ(kEtcdHost2, split_hosts.back().first);
+  EXPECT_EQ(kEtcdPort2, split_hosts.back().second);
+}
+
+
+TEST_F(EtcdTest, SplitHostsIgnoresBlanks) {
+  const string hosts(string(kEtcdHost) + ":" + to_string(kEtcdPort) + ",," +
+                     kEtcdHost2 + ":" + to_string(kEtcdPort2));
+  const list<EtcdClient::HostPortPair> split_hosts(SplitHosts(hosts));
+  EXPECT_EQ(static_cast<size_t>(2), split_hosts.size());
+  EXPECT_EQ(kEtcdHost, split_hosts.front().first);
+  EXPECT_EQ(kEtcdPort, split_hosts.front().second);
+  EXPECT_EQ(kEtcdHost2, split_hosts.back().first);
+  EXPECT_EQ(kEtcdPort2, split_hosts.back().second);
+}
+
+
+TEST_F(EtcdTest, SplitHostsIgnoresTrailingComma) {
+  const string hosts(string(kEtcdHost) + ":" + to_string(kEtcdPort) + "," +
+                     kEtcdHost2 + ":" + to_string(kEtcdPort2) + ",");
+  const list<EtcdClient::HostPortPair> split_hosts(SplitHosts(hosts));
+  EXPECT_EQ(static_cast<size_t>(2), split_hosts.size());
+  EXPECT_EQ(kEtcdHost, split_hosts.front().first);
+  EXPECT_EQ(kEtcdPort, split_hosts.front().second);
+  EXPECT_EQ(kEtcdHost2, split_hosts.back().first);
+  EXPECT_EQ(kEtcdPort2, split_hosts.back().second);
+}
+
+
+TEST_F(EtcdTest, SplitHostsIgnoresPrecedingComma) {
+  const string hosts("," + string(kEtcdHost) + ":" + to_string(kEtcdPort) +
+                     "," + kEtcdHost2 + ":" + to_string(kEtcdPort2));
+  const list<EtcdClient::HostPortPair> split_hosts(SplitHosts(hosts));
+  EXPECT_EQ(static_cast<size_t>(2), split_hosts.size());
+  EXPECT_EQ(kEtcdHost, split_hosts.front().first);
+  EXPECT_EQ(kEtcdPort, split_hosts.front().second);
+  EXPECT_EQ(kEtcdHost2, split_hosts.back().first);
+  EXPECT_EQ(kEtcdPort2, split_hosts.back().second);
+}
+
+
+TEST_F(EtcdTest, SplitHostsWithAllBlanks) {
+  const list<EtcdClient::HostPortPair> split_hosts(SplitHosts(",,,,"));
+  EXPECT_EQ(static_cast<size_t>(0), split_hosts.size());
+}
+
+
+TEST_F(EtcdTest, SplitHostsWithEmptyString) {
+  const list<EtcdClient::HostPortPair> split_hosts(SplitHosts(""));
+  EXPECT_EQ(static_cast<size_t>(0), split_hosts.size());
+}
+
+
+TEST_F(EtcdDeathTest, SplitHostsWithInvalidHostPortString) {
+  EXPECT_DEATH(SplitHosts("host:2:monkey"), "Invalid host:port string");
+}
+
+
+TEST_F(EtcdDeathTest, SplitHostsWithNegativePort) {
+  EXPECT_DEATH(SplitHosts("host:-1"), "Port is <= 0");
+}
+
+
+TEST_F(EtcdDeathTest, SplitHostsWithOutOfRangePort) {
+  EXPECT_DEATH(SplitHosts("host:65536"), "Port is > 65535");
+}
+
+TEST_F(EtcdDeathTest, SplitHostsWithQuotedUrlInList) {
+  EXPECT_DEATH(SplitHosts("host:123,\"host:4002\", host:456"),
+               "Invalid etcd_server url specified: \\\"host:4002\\\"");
+}
+
+TEST_F(EtcdDeathTest, SplitHostsWithQuotedUrl) {
+  EXPECT_DEATH(SplitHosts("\"host:4001\""),
+               "Invalid etcd_server url specified: \\\"host:4001\\\"");
+}
+
+
+// Test that if the SplitHosts validation failed the bad URL would still
+// be caught
+TEST_F(EtcdDeathTest, UrlRejectsQuotedValue) {
+  EXPECT_DEATH(URL("\"host:4001\""), "URL invalid: \"host:4001\"");
+}
+
+TEST_F(EtcdTest, LogsVersion) {
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                      URL(GetEtcdUrl(kEntryKey) +
+                                          "?consistent=true&quorum=true"),
+                                      IsEmpty(), ""),
+                    _, _))
+      .Times(2)
+      .WillRepeatedly(
+          Invoke(bind(HandleFetch, Status::OK, 200,
+                      UrlFetcher::Headers{make_pair("x-etcd-index", "11")},
+                      kGetJson, _1, _2, _3)));
+
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                      URL(GetEtcdUrl("/version", "")),
+                                      IsEmpty(), ""),
+                    _, _))
+      .WillOnce(
+          Invoke(bind(HandleFetch, Status::OK, 200, UrlFetcher::Headers{},
+                      kVersionString, _1, _2, _3)));
+
+  // Version fetching is lazy, so we have to run some other request to kick
+  // it off
+  {
+    SyncTask task(base_.get());
+    EtcdClient::GetResponse resp;
+    client_.Get(string(kEntryKey), &resp, task.task());
+    task.Wait();
+  }
+  // However, a second call to the same etcd should not cause another version
+  // request to be sent
+  {
+    SyncTask task(base_.get());
+    EtcdClient::GetResponse resp;
+    client_.Get(string(kEntryKey), &resp, task.task());
+    task.Wait();
+  }
+}
+
+
+TEST_F(EtcdTest, LogsVersionWhenChangingServer) {
+  {
+    InSequence s;
+    EXPECT_CALL(url_fetcher_,
+                Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                        URL(GetEtcdUrl(kEntryKey) +
+                                            "?consistent=true&quorum=true"),
+                                        IsEmpty(), ""),
+                      _, _))
+        .WillOnce(Invoke(bind(
+            HandleFetch, Status::OK, 307,
+            UrlFetcher::Headers{make_pair("x-etcd-index", "11"),
+                                make_pair("location", GetEtcdUrl("/", ""))},
+            kGetJson, _1, _2, _3)));
+
+    EXPECT_CALL(url_fetcher_,
+                Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                        URL(GetEtcdUrl(kEntryKey) +
+                                            "?consistent=true&quorum=true"),
+                                        IsEmpty(), ""),
+                      _, _))
+        .WillOnce(
+            Invoke(bind(HandleFetch, Status::OK, 200,
+                        UrlFetcher::Headers{make_pair("x-etcd-index", "11")},
+                        kGetJson, _1, _2, _3)));
+  }
+
+  EXPECT_CALL(url_fetcher_,
+              Fetch(IsUrlFetchRequest(UrlFetcher::Verb::GET,
+                                      URL(GetEtcdUrl("/version", "")),
+                                      IsEmpty(), ""),
+                    _, _))
+      .Times(2)
+      .WillRepeatedly(
+          Invoke(bind(HandleFetch, Status::OK, 200, UrlFetcher::Headers{},
+                      kVersionString, _1, _2, _3)));
+
+  // Version fetching is lazy, so we have to run some other request to kick
+  // it off.
+  // But the first response returns a redirect to another etcd master, so
+  // when we follow that we should perform another version request.
+  {
+    SyncTask task(base_.get());
+    EtcdClient::GetResponse resp;
+    client_.Get(string(kEntryKey), &resp, task.task());
+    task.Wait();
+  }
+}
+
+
+}  // namespace
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/executor.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/executor.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/executor.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/executor.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,31 @@
+#ifndef CERT_TRANS_UTIL_EXECUTOR_H_
+#define CERT_TRANS_UTIL_EXECUTOR_H_
+
+#include <chrono>
+#include <functional>
+
+#include "base/macros.h"
+
+namespace util {
+class Task;
+
+
+class Executor {
+ public:
+  virtual ~Executor() = default;
+
+  virtual void Add(const std::function<void()>& closure) = 0;
+  virtual void Delay(const std::chrono::duration<double>& delay,
+                     Task* task) = 0;
+
+ protected:
+  Executor() = default;
+
+ private:
+  DISALLOW_COPY_AND_ASSIGN(Executor);
+};
+
+
+}  // namespace util
+
+#endif  // CERT_TRANS_UTIL_EXECUTOR_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/fake_etcd.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/fake_etcd.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/fake_etcd.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/fake_etcd.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,566 @@
+#include "util/fake_etcd.h"
+
+#include <glog/logging.h>
+
+#include "util/json_wrapper.h"
+
+using std::bind;
+using std::chrono::seconds;
+using std::chrono::system_clock;
+using std::function;
+using std::get;
+using std::lock_guard;
+using std::make_shared;
+using std::make_tuple;
+using std::map;
+using std::move;
+using std::multimap;
+using std::mutex;
+using std::ostringstream;
+using std::shared_ptr;
+using std::stoi;
+using std::string;
+using std::to_string;
+using std::tuple;
+using std::unique_lock;
+using std::vector;
+using util::Status;
+using util::StatusOr;
+using util::Task;
+
+namespace cert_trans {
+namespace {
+
+
+string NormalizeKey(const string& input) {
+  CHECK(!input.empty());
+  CHECK_EQ(input[0], '/');
+
+  string::size_type offset(0);
+  string output;
+  while (offset < input.size()) {
+    const string::size_type next_part(input.find_first_not_of('/', offset));
+    const string::size_type next_slash(input.find_first_of('/', next_part));
+
+    if (next_part != string::npos) {
+      const string part(
+          input.substr(next_part - 1, next_slash - next_part + 1));
+
+      if (part == "/..") {
+        const string::size_type prev_slash(output.find_last_of('/'));
+        if (prev_slash != string::npos) {
+          output.erase(prev_slash);
+        }
+      } else if (part != "/.") {
+        output.append(part);
+      }
+    }
+
+    offset = next_slash;
+  }
+
+  if (output.empty()) {
+    output.push_back('/');
+  }
+
+  return output;
+}
+
+
+bool WatchMatchesKey(const string& watch_key, const string& notify_key,
+                     bool recursive) {
+  if (watch_key == notify_key) {
+    return true;
+  }
+
+  if (!recursive) {
+    return false;
+  }
+
+  const string dir(watch_key + "/");
+  return watch_key == "/" || notify_key.compare(0, dir.size(), dir) == 0;
+}
+
+
+}  // namespace
+
+namespace {
+const char* kStoreStats[] = {"setsFail",
+                             "getsSuccess",
+                             "watchers",
+                             "expireCount",
+                             "createFail",
+                             "setsSuccess",
+                             "compareAndDeleteFail",
+                             "createSuccess",
+                             "deleteFail",
+                             "compareAndSwapSuccess",
+                             "compareAndSwapFail",
+                             "compareAndDeleteSuccess",
+                             "updateFail",
+                             "deleteSuccess",
+                             "updateSuccess",
+                             "getsFail"};
+}  // namespace
+
+
+FakeEtcdClient::FakeEtcdClient(libevent::Base* base)
+    : base_(CHECK_NOTNULL(base)), parent_task_(base_), index_(1) {
+  for (const auto& s : kStoreStats) {
+    stats_[s] = 0;
+  }
+}
+
+
+FakeEtcdClient::~FakeEtcdClient() {
+  parent_task_.task()->Return();
+  parent_task_.Wait();
+  CHECK_EQ(parent_task_.status(), Status::OK);
+}
+
+
+void FakeEtcdClient::DumpEntries(const unique_lock<mutex>& lock) const {
+  CHECK(lock.owns_lock());
+  for (const auto& pair : entries_) {
+    VLOG(1) << pair.second.ToString();
+  }
+}
+
+
+void FakeEtcdClient::Watch(const string& rawkey, const WatchCallback& cb,
+                           Task* task) {
+  const string key(NormalizeKey(rawkey));
+  unique_lock<mutex> lock(mutex_);
+  vector<Node> initial_updates;
+  map<string, Node>::const_iterator it(entries_.find(key));
+  if (it != entries_.end()) {
+    if (it->second.is_dir_) {
+      const string key_prefix(key + "/");
+      for (++it; it != entries_.end() &&
+                 it->first.compare(0, key_prefix.size(), key_prefix) == 0;
+           ++it) {
+        CHECK(!it->second.deleted_);
+        initial_updates.emplace_back(it->second);
+      }
+    } else {
+      CHECK(!it->second.deleted_);
+      initial_updates.emplace_back(it->second);
+    }
+  }
+  ScheduleWatchCallback(lock, task, bind(cb, move(initial_updates)));
+  watches_[key].push_back(make_pair(cb, task));
+  task->WhenCancelled(bind(&FakeEtcdClient::CancelWatch, this, task));
+  ++stats_["watchers"];
+}
+
+
+void FakeEtcdClient::PurgeExpiredEntriesWithLock(
+    const unique_lock<mutex>& lock) {
+  CHECK(lock.owns_lock());
+  for (auto it = entries_.begin(); it != entries_.end();) {
+    if (it->second.expires_ < system_clock::now()) {
+      VLOG(1) << "Deleting expired entry " << it->first;
+      it->second.deleted_ = true;
+      NotifyForPath(lock, it->first);
+      it = entries_.erase(it);
+      ++stats_["expireCount"];
+    } else {
+      ++it;
+    }
+  }
+}
+
+
+void FakeEtcdClient::PurgeExpiredEntries() {
+  unique_lock<mutex> lock(mutex_);
+  PurgeExpiredEntriesWithLock(lock);
+}
+
+
+void FakeEtcdClient::NotifyForPath(const unique_lock<mutex>& lock,
+                                   const string& path) {
+  CHECK(lock.owns_lock());
+  VLOG(1) << "notifying " << path;
+  const map<string, Node>::const_iterator node_it(entries_.find(path));
+  CHECK(node_it != entries_.end());
+  const Node& node(node_it->second);
+
+  const multimap<string, tuple<bool, GetResponse*, Task*>>::iterator last(
+      waiting_gets_.upper_bound(path));
+  multimap<string, tuple<bool, GetResponse*, Task*>>::iterator it;
+  for (it = waiting_gets_.begin(); it != last;) {
+    if (WatchMatchesKey(it->first, node.key_, get<0>(it->second))) {
+      get<1>(it->second)->node = node;
+      get<2>(it->second)->Return();
+      it = waiting_gets_.erase(it);
+    } else {
+      ++it;
+    }
+  }
+
+  for (const auto& pair : watches_) {
+    if (path.find(pair.first) == 0) {
+      for (const auto& cb_cookie : pair.second) {
+        ScheduleWatchCallback(lock, cb_cookie.second,
+                              bind(cb_cookie.first, vector<Node>{node}));
+      }
+    }
+  }
+}
+
+
+void FakeEtcdClient::Get(const Request& req, GetResponse* resp, Task* task) {
+  VLOG(1) << "GET " << req.key;
+  const string key(NormalizeKey(req.key));
+
+  CHECK_NE(key, "/") << "not implemented";
+
+  task->CleanupWhenDone(
+      bind(&FakeEtcdClient::UpdateOperationStats, this, "gets", task));
+
+  unique_lock<mutex> lock(mutex_);
+  PurgeExpiredEntriesWithLock(lock);
+  resp->etcd_index = index_;
+
+  if (req.wait_index > 0) {
+    if (req.wait_index <= index_) {
+      // Our fake history log is *very* small!
+      task->Return(
+          Status(util::error::ABORTED,
+                 "The event in requested index is outdated and cleared"));
+      return;
+    }
+
+    waiting_gets_.insert(
+        make_pair(key, make_tuple(req.recursive, resp, task)));
+    task->WhenCancelled(
+        bind(&FakeEtcdClient::CancelWaitingGet, this, key, task));
+    return;
+  }
+
+  map<string, Node>::const_iterator it(entries_.find(key));
+  if (it == entries_.end()) {
+    task->Return(Status(util::error::NOT_FOUND, "not found"));
+    return;
+  }
+  resp->node = it->second;
+  ++it;
+
+  vector<Node*> parent_nodes{&resp->node};
+  while (!parent_nodes.empty() && it != entries_.end()) {
+    const string key_prefix(parent_nodes.back()->key_ + "/");
+    if (it->first.compare(0, key_prefix.size(), key_prefix) > 0) {
+      parent_nodes.pop_back();
+      continue;
+    }
+
+    if (req.recursive) {
+      parent_nodes.back()->nodes_.emplace_back(it->second);
+
+      if (it->second.is_dir_) {
+        // The node we just added is now the current parent node.
+        parent_nodes.push_back(&parent_nodes.back()->nodes_.back());
+      }
+    } else {
+      if (it->first.find_first_of('/', key_prefix.size()) == string::npos) {
+        resp->node.nodes_.emplace_back(it->second);
+      }
+    }
+
+    ++it;
+  }
+  task->Return();
+}
+
+
+void FakeEtcdClient::InternalPut(const string& rawkey, const string& value,
+                                 const system_clock::time_point& expires,
+                                 bool create, int64_t prev_index,
+                                 Response* resp, Task* task) {
+  const string key(NormalizeKey(rawkey));
+  CHECK_NE(key.back(), '/');
+  CHECK(!create || prev_index <= 0);
+
+  vector<string> parents;
+  for (string::size_type offset = 0; offset < key.size();) {
+    const string::size_type next_slash(key.find_first_of('/', offset + 1));
+    if (next_slash == string::npos) {
+      break;
+    }
+
+    parents.emplace_back(key.substr(offset + 1, next_slash - offset - 1));
+    offset = next_slash;
+  }
+
+  *resp = EtcdClient::Response();
+  unique_lock<mutex> lock(mutex_);
+  PurgeExpiredEntriesWithLock(lock);
+  const int64_t new_index(index_ + 1);
+
+  // If we're creating, make sure all the parent entries exist and are
+  // directories, creating them as needed.
+  if (create) {
+    string parent_key;
+    for (const string& path : parents) {
+      parent_key.append("/" + path);
+      // Either this inserts a directory, or it fails, and it gets us
+      // the entry. If we insert a directory, then success is
+      // guaranteed below, so we're sure to update index_
+      // appropriately.
+      if (!entries_.insert(make_pair(parent_key,
+                                     Node(new_index, new_index, parent_key,
+                                          true, "", {}, false)))
+               .first->second.is_dir_) {
+        task->Return(Status(util::error::ABORTED, "Not a directory"));
+        return;
+      }
+    }
+  }
+
+  Node node(new_index, new_index, key, false, value, {}, false);
+  node.expires_ = expires;
+  const map<string, Node>::const_iterator entry(entries_.find(key));
+  if (create && entry != entries_.end()) {
+    task->Return(
+        Status(util::error::FAILED_PRECONDITION, key + " already exists"));
+    return;
+  }
+
+  if (prev_index > 0) {
+    if (entry == entries_.end()) {
+      task->Return(Status(util::error::FAILED_PRECONDITION,
+                          "node doesn't exist: " + key));
+      return;
+    }
+    if (prev_index != entry->second.modified_index_) {
+      task->Return(Status(util::error::FAILED_PRECONDITION,
+                          "incorrect index:  prevIndex=" +
+                              to_string(prev_index) + " but modified_index_=" +
+                              to_string(entry->second.modified_index_)));
+      return;
+    }
+    node.created_index_ = entry->second.created_index_;
+  }
+
+  entries_[key] = node;
+  resp->etcd_index = new_index;
+  index_ = new_index;
+  task->Return();
+  NotifyForPath(lock, key);
+  DumpEntries(lock);
+  if (expires < system_clock::time_point::max()) {
+    const std::chrono::duration<double> delay(expires - system_clock::now());
+    base_->Delay(delay, parent_task_.task()->AddChild(
+                            bind(&FakeEtcdClient::PurgeExpiredEntries, this)));
+  }
+}
+
+
+void FakeEtcdClient::InternalDelete(const string& key,
+                                    const int64_t current_index, Task* task) {
+  VLOG(1) << "DELETE " << key;
+  CHECK(!key.empty());
+  CHECK_EQ(key.front(), '/');
+  CHECK_NE(key.back(), '/');
+
+  const string op_name(current_index > 0 ? "compareAndDelete" : "delete");
+
+  unique_lock<mutex> lock(mutex_);
+  PurgeExpiredEntriesWithLock(lock);
+  const map<string, Node>::iterator entry(entries_.find(key));
+  if (entry == entries_.end()) {
+    ++stats_[op_name + "Fail"];
+    task->Return(Status(util::error::NOT_FOUND, "Node doesn't exist: " + key));
+    return;
+  }
+  if (current_index > 0 && entry->second.modified_index_ != current_index) {
+    ++stats_[op_name + "Fail"];
+    task->Return(Status(util::error::FAILED_PRECONDITION,
+                        "Incorrect index:  prevIndex=" +
+                            to_string(current_index) +
+                            " but modified_index_=" +
+                            to_string(entry->second.modified_index_)));
+    return;
+  }
+  entry->second.modified_index_ = ++index_;
+  entry->second.value_.clear();
+  entry->second.deleted_ = true;
+  ++stats_[op_name + "Success"];
+  task->Return();
+  NotifyForPath(lock, key);
+  entries_.erase(entry);
+}
+
+
+void FakeEtcdClient::UpdateOperationStats(const string& op, const Task* task) {
+  CHECK_NOTNULL(task);
+  if (!task->IsActive()) {
+    std::lock_guard<std::mutex> lock(mutex_);
+    ++stats_[op + (task->status().ok() ? "Success" : "Fail")];
+  }
+}
+
+
+void FakeEtcdClient::Create(const string& key, const string& value,
+                            Response* resp, Task* task) {
+  task->CleanupWhenDone(
+      bind(&FakeEtcdClient::UpdateOperationStats, this, "create", task));
+  InternalPut(key, value, system_clock::time_point::max(), true, -1, resp,
+              task);
+}
+
+
+void FakeEtcdClient::CreateWithTTL(const string& key, const string& value,
+                                   const seconds& ttl, Response* resp,
+                                   Task* task) {
+  task->CleanupWhenDone(
+      bind(&FakeEtcdClient::UpdateOperationStats, this, "create", task));
+  InternalPut(key, value, system_clock::now() + ttl, true, -1, resp, task);
+}
+
+
+void FakeEtcdClient::Update(const string& key, const string& value,
+                            const int64_t previous_index, Response* resp,
+                            Task* task) {
+  task->CleanupWhenDone(bind(&FakeEtcdClient::UpdateOperationStats, this,
+                             "compareAndSwap", task));
+  InternalPut(key, value, system_clock::time_point::max(), false,
+              previous_index, resp, task);
+}
+
+
+void FakeEtcdClient::UpdateWithTTL(const string& key, const string& value,
+                                   const seconds& ttl,
+                                   const int64_t previous_index,
+                                   Response* resp, Task* task) {
+  task->CleanupWhenDone(bind(&FakeEtcdClient::UpdateOperationStats, this,
+                             "compareAndSwap", task));
+  InternalPut(key, value, system_clock::now() + ttl, false, previous_index,
+              resp, task);
+}
+
+
+void FakeEtcdClient::ForceSet(const string& key, const string& value,
+                              Response* resp, Task* task) {
+  task->CleanupWhenDone(
+      bind(&FakeEtcdClient::UpdateOperationStats, this, "sets", task));
+  InternalPut(key, value, system_clock::time_point::max(), false, -1, resp,
+              task);
+}
+
+
+void FakeEtcdClient::ForceSetWithTTL(const std::string& key,
+                                     const std::string& value,
+                                     const std::chrono::seconds& ttl,
+                                     Response* resp, util::Task* task) {
+  task->CleanupWhenDone(
+      bind(&FakeEtcdClient::UpdateOperationStats, this, "sets", task));
+  InternalPut(key, value, system_clock::now() + ttl, false, -1, resp, task);
+}
+
+
+void FakeEtcdClient::Delete(const string& key, const int64_t current_index,
+                            Task* task) {
+  CHECK_GT(current_index, 0);
+  InternalDelete(key, current_index, task);
+}
+
+
+void FakeEtcdClient::ForceDelete(const string& key, Task* task) {
+  InternalDelete(key, 0, task);
+}
+
+
+void FakeEtcdClient::GetStoreStats(StatsResponse* resp, Task* task) {
+  CHECK_NOTNULL(resp);
+  CHECK_NOTNULL(task);
+  resp->stats = stats_;
+  task->Return();
+}
+
+
+void FakeEtcdClient::CancelWatch(Task* task) {
+  lock_guard<mutex> lock(mutex_);
+  bool found(false);
+  for (auto& pair : watches_) {
+    for (auto it(pair.second.begin()); it != pair.second.end();) {
+      if (it->second == task) {
+        CHECK(!found);
+        found = true;
+        VLOG(1) << "Removing watcher " << it->second << " on " << pair.first;
+        --stats_["watchers"];
+        // Outstanding notifications have a hold on this task, so they
+        // will all go through before the task actually completes. But
+        // we won't be sending new notifications.
+        task->Return(Status::CANCELLED);
+        it = pair.second.erase(it);
+      } else {
+        ++it;
+      }
+    }
+  }
+}
+
+
+void FakeEtcdClient::CancelWaitingGet(const string& key, Task* task) {
+  lock_guard<mutex> lock(mutex_);
+  const multimap<string, tuple<bool, GetResponse*, Task*>>::iterator last(
+      waiting_gets_.upper_bound(key));
+
+  for (auto it = waiting_gets_.lower_bound(key); it != last; ++it) {
+    if (get<2>(it->second) == task) {
+      waiting_gets_.erase(it);
+      task->Return(Status::CANCELLED);
+      return;
+    }
+  }
+}
+
+
+void FakeEtcdClient::ScheduleWatchCallback(
+    const unique_lock<mutex>& lock, Task* task,
+    const std::function<void()>& callback) {
+  CHECK(lock.owns_lock());
+  const bool already_running(!watches_callbacks_.empty());
+
+  task->AddHold();
+  watches_callbacks_.emplace_back(make_pair(task, move(callback)));
+
+  // TODO(pphaneuf): This might fare poorly if the executor is
+  // synchronous.
+  if (!already_running) {
+    watches_callbacks_.front().first->executor()->Add(
+        bind(&FakeEtcdClient::RunWatchCallback, this));
+  }
+}
+
+
+void FakeEtcdClient::RunWatchCallback() {
+  Task* current(nullptr);
+  Task* next(nullptr);
+  function<void()> callback;
+
+  {
+    lock_guard<mutex> lock(mutex_);
+
+    CHECK(!watches_callbacks_.empty());
+    current = move(watches_callbacks_.front().first);
+    callback = move(watches_callbacks_.front().second);
+    watches_callbacks_.pop_front();
+
+    if (!watches_callbacks_.empty()) {
+      next = CHECK_NOTNULL(watches_callbacks_.front().first);
+    }
+  }
+
+  callback();
+  current->RemoveHold();
+
+  // If we have a next executor, schedule ourselves on it.
+  if (next) {
+    next->executor()->Add(bind(&FakeEtcdClient::RunWatchCallback, this));
+  }
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/fake_etcd.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/fake_etcd.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/fake_etcd.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/fake_etcd.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,110 @@
+#ifndef CERT_TRANS_UTIL_FAKE_ETCD_H_
+#define CERT_TRANS_UTIL_FAKE_ETCD_H_
+
+#include <deque>
+#include <map>
+#include <queue>
+#include <string>
+#include <tuple>
+
+#include "util/etcd.h"
+#include "util/libevent_wrapper.h"
+#include "util/statusor.h"
+#include "util/sync_task.h"
+#include "util/task.h"
+
+namespace cert_trans {
+
+
+class FakeEtcdClient : public EtcdClient {
+ public:
+  explicit FakeEtcdClient(libevent::Base* base);
+
+  virtual ~FakeEtcdClient();
+
+  void Get(const Request& req, GetResponse* resp, util::Task* task) override;
+
+  void Create(const std::string& key, const std::string& value, Response* resp,
+              util::Task* task) override;
+
+  void CreateWithTTL(const std::string& key, const std::string& value,
+                     const std::chrono::seconds& ttl, Response* resp,
+                     util::Task* task) override;
+
+  void Update(const std::string& key, const std::string& value,
+              const int64_t previous_index, Response* resp,
+              util::Task* task) override;
+
+  void UpdateWithTTL(const std::string& key, const std::string& value,
+                     const std::chrono::seconds& ttl,
+                     const int64_t previous_index, Response* resp,
+                     util::Task* task) override;
+
+  void ForceSet(const std::string& key, const std::string& value,
+                Response* resp, util::Task* task) override;
+
+  void ForceSetWithTTL(const std::string& key, const std::string& value,
+                       const std::chrono::seconds& ttl, Response* resp,
+                       util::Task* task) override;
+
+  void Delete(const std::string& key, const int64_t current_index,
+              util::Task* task) override;
+
+  void ForceDelete(const std::string& key, util::Task* task) override;
+
+  void GetStoreStats(StatsResponse* resp, util::Task* task) override;
+
+  // The callbacks for *all* watches will be called one at a time, in
+  // order, which is a stronger guarantee than the one
+  // EtcdClient::Watch has.
+  void Watch(const std::string& rawkey, const WatchCallback& cb,
+             util::Task* task) override;
+
+ private:
+  void DumpEntries(const std::unique_lock<std::mutex>& lock) const;
+
+  void PurgeExpiredEntriesWithLock(const std::unique_lock<std::mutex>& lock);
+  void PurgeExpiredEntries();
+
+  void NotifyForPath(const std::unique_lock<std::mutex>& lock,
+                     const std::string& path);
+
+  void InternalPut(const std::string& rawkey, const std::string& value,
+                   const std::chrono::system_clock::time_point& expires,
+                   bool create, int64_t prev_index, Response* resp,
+                   util::Task* task);
+
+  void InternalDelete(const std::string& key, const int64_t current_index,
+                      util::Task* task);
+
+  void UpdateOperationStats(const std::string& op, const util::Task* task);
+
+  void CancelWatch(util::Task* task);
+  void CancelWaitingGet(const std::string& key, util::Task* task);
+
+  // Arranges for the watch callbacks to be called in order. Should be
+  // called with mutex_ held.
+  void ScheduleWatchCallback(const std::unique_lock<std::mutex>& lock,
+                             util::Task* task,
+                             const std::function<void()>& callback);
+  void RunWatchCallback();
+
+  libevent::Base* const base_;
+  util::SyncTask parent_task_;
+  std::mutex mutex_;
+  int64_t index_;
+  std::map<std::string, Node> entries_;
+  std::multimap<std::string, std::tuple<bool, GetResponse*, util::Task*>>
+      waiting_gets_;
+  std::map<std::string, std::vector<std::pair<WatchCallback, util::Task*>>>
+      watches_;
+  std::deque<std::pair<util::Task*, std::function<void()>>> watches_callbacks_;
+  std::map<std::string, int64_t> stats_;
+
+  friend class ElectionTest;
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_FAKE_ETCD_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/fake_etcd_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/fake_etcd_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/fake_etcd_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/fake_etcd_test.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,974 @@
+#include "util/fake_etcd.h"
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <atomic>
+#include <functional>
+#include <memory>
+#include <mutex>
+#include <string>
+#include <thread>
+#include <vector>
+
+#include "base/notification.h"
+#include "util/libevent_wrapper.h"
+#include "util/status_test_util.h"
+#include "util/sync_task.h"
+#include "util/testing.h"
+#include "util/thread_pool.h"
+
+DECLARE_string(trusted_root_certs);
+DEFINE_string(cert_dir, "test/testdata/urlfetcher_test_certs",
+              "Directory containing the test certs.");
+
+namespace cert_trans {
+
+using std::bind;
+using std::chrono::duration;
+using std::chrono::seconds;
+using std::deque;
+using std::function;
+using std::lock_guard;
+using std::map;
+using std::mutex;
+using std::placeholders::_1;
+using std::placeholders::_2;
+using std::placeholders::_3;
+using std::string;
+using std::this_thread::sleep_for;
+using std::unique_ptr;
+using std::vector;
+using testing::DoAll;
+using testing::ElementsAre;
+using testing::InvokeWithoutArgs;
+using testing::Matches;
+using testing::Mock;
+using testing::MockFunction;
+using testing::StrictMock;
+using testing::TestInfo;
+using testing::UnitTest;
+using testing::_;
+using util::Status;
+using util::SyncTask;
+using util::testing::StatusIs;
+
+DEFINE_string(etcd, "", "etcd server address");
+DEFINE_int32(etcd_port, 4001, "etcd server port");
+
+const char kValue[] = "value";
+const char kValue2[] = "value2";
+
+
+class FakeEtcdTest : public ::testing::Test {
+ public:
+  FakeEtcdTest()
+      : base_(std::make_shared<libevent::Base>()),
+        event_pump_(base_),
+        pool_(),
+        fetcher_(base_.get(), &pool_),
+        client_(FLAGS_etcd.empty()
+                    ? new FakeEtcdClient(base_.get())
+                    : new EtcdClient(&pool_, &fetcher_, FLAGS_etcd,
+                                     FLAGS_etcd_port)),
+        key_prefix_(BuildKeyPrefix()) {
+  }
+
+ protected:
+  Status BlockingGet(const string& key, EtcdClient::Node* node,
+                     int64_t* etcd_index = nullptr) {
+    SyncTask task(base_.get());
+    EtcdClient::GetResponse resp;
+    client_->Get(key, &resp, task.task());
+    task.Wait();
+    if (etcd_index) {
+      *etcd_index = resp.etcd_index;
+    }
+    *node = resp.node;
+    return task.status();
+  }
+
+  Status BlockingCreate(const string& key, const string& value,
+                        int64_t* created_index) {
+    SyncTask task(base_.get());
+    EtcdClient::Response resp;
+    client_->Create(key, value, &resp, task.task());
+    task.Wait();
+    *created_index = resp.etcd_index;
+    return task.status();
+  }
+
+  Status BlockingCreateWithTTL(const string& key, const string& value,
+                               const seconds& ttl, int64_t* created_index) {
+    SyncTask task(base_.get());
+    EtcdClient::Response resp;
+    client_->CreateWithTTL(key, value, ttl, &resp, task.task());
+    task.Wait();
+    *created_index = resp.etcd_index;
+    return task.status();
+  }
+
+  Status BlockingUpdate(const string& key, const string& value,
+                        int64_t old_index, int64_t* modified_index) {
+    SyncTask task(base_.get());
+    EtcdClient::Response resp;
+    client_->Update(key, value, old_index, &resp, task.task());
+    task.Wait();
+    *modified_index = resp.etcd_index;
+    return task.status();
+  }
+
+  Status BlockingUpdateWithTTL(const string& key, const string& value,
+                               const seconds& ttl, int64_t previous_index,
+                               int64_t* modified_index) {
+    SyncTask task(base_.get());
+    EtcdClient::Response resp;
+    client_->UpdateWithTTL(key, value, ttl, previous_index, &resp,
+                           task.task());
+    task.Wait();
+    *modified_index = resp.etcd_index;
+    return task.status();
+  }
+
+  Status BlockingForceSet(const string& key, const string& value,
+                          int64_t* modified_index) {
+    SyncTask task(base_.get());
+    EtcdClient::Response resp;
+    client_->ForceSet(key, value, &resp, task.task());
+    task.Wait();
+    *modified_index = resp.etcd_index;
+    return task.status();
+  }
+
+  Status BlockingForceSetWithTTL(const string& key, const string& value,
+                                 const seconds& ttl, int64_t* modified_index) {
+    SyncTask task(base_.get());
+    EtcdClient::Response resp;
+    client_->ForceSetWithTTL(key, value, ttl, &resp, task.task());
+    task.Wait();
+    *modified_index = resp.etcd_index;
+    return task.status();
+  }
+
+  Status BlockingDelete(const string& key, int64_t previous_index) {
+    SyncTask task(base_.get());
+    client_->Delete(key, previous_index, task.task());
+    task.Wait();
+    return task.status();
+  }
+
+  Status BlockingGetStats(map<string, int64_t>* stats) {
+    SyncTask task(base_.get());
+    EtcdClient::StatsResponse resp;
+    client_->GetStoreStats(&resp, task.task());
+    task.Wait();
+    if (task.status().ok()) {
+      *stats = resp.stats;
+    }
+    return task.status();
+  }
+
+  static string BuildKeyPrefix() {
+    const TestInfo* const test_info(
+        UnitTest::GetInstance()->current_test_info());
+    string retval("/testing/");
+    retval.append(test_info->test_case_name());
+    retval.append("/");
+    retval.append(test_info->name());
+    return retval;
+  }
+
+  std::shared_ptr<libevent::Base> base_;
+  libevent::EventPumpThread event_pump_;
+  ThreadPool pool_;
+  UrlFetcher fetcher_;
+  const unique_ptr<EtcdClient> client_;
+  const string key_prefix_;
+};
+
+
+TEST_F(FakeEtcdTest, Create) {
+  map<string, int64_t> expected_stats;
+  ASSERT_OK(BlockingGetStats(&expected_stats));
+  ++expected_stats["createSuccess"];
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(key_prefix_, kValue, &created_index));
+
+  map<string, int64_t> stats;
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+
+  EtcdClient::Node node;
+  EXPECT_OK(BlockingGet(key_prefix_, &node));
+  EXPECT_EQ(kValue, node.value_);
+  EXPECT_EQ(created_index, node.created_index_);
+  EXPECT_EQ(created_index, node.modified_index_);
+}
+
+
+TEST_F(FakeEtcdTest, CreateFailsIfExists) {
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(key_prefix_, kValue, &created_index));
+
+  map<string, int64_t> expected_stats;
+  ASSERT_OK(BlockingGetStats(&expected_stats));
+  ++expected_stats["createFail"];
+
+  EXPECT_THAT(BlockingCreate(key_prefix_, kValue, &created_index),
+              StatusIs(util::error::FAILED_PRECONDITION));
+
+  map<string, int64_t> stats;
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+}
+
+
+TEST_F(FakeEtcdTest, Update) {
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(key_prefix_, kValue, &created_index));
+
+  map<string, int64_t> expected_stats;
+  ASSERT_OK(BlockingGetStats(&expected_stats));
+  ++expected_stats["compareAndSwapSuccess"];
+
+  int64_t modified_index;
+  EXPECT_OK(
+      BlockingUpdate(key_prefix_, kValue2, created_index, &modified_index));
+
+  map<string, int64_t> stats;
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+
+  EtcdClient::Node node;
+  EXPECT_OK(BlockingGet(key_prefix_, &node));
+  EXPECT_EQ(kValue2, node.value_);
+  EXPECT_EQ(created_index, node.created_index_);
+  EXPECT_EQ(modified_index, node.modified_index_);
+  EXPECT_LT(created_index, modified_index);
+}
+
+
+TEST_F(FakeEtcdTest, UpdateFailsWithIncorrectPreviousIndex) {
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(key_prefix_, kValue, &created_index));
+
+  map<string, int64_t> expected_stats;
+  ASSERT_OK(BlockingGetStats(&expected_stats));
+  ++expected_stats["compareAndSwapFail"];
+
+  int64_t modified_index(-1);
+  EXPECT_THAT(BlockingUpdate(key_prefix_, kValue2, created_index - 1,
+                             &modified_index),
+              StatusIs(util::error::FAILED_PRECONDITION));
+  map<string, int64_t> stats;
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+  EXPECT_EQ(-1, modified_index);
+
+  EtcdClient::Node node;
+  EXPECT_OK(BlockingGet(key_prefix_, &node));
+  EXPECT_EQ(kValue, node.value_);  // Not updated!
+  EXPECT_EQ(created_index, node.created_index_);
+  EXPECT_EQ(created_index, node.modified_index_);
+}
+
+
+TEST_F(FakeEtcdTest, CreateWithTTLExpires) {
+  seconds kTtl(3);
+
+  map<string, int64_t> expected_stats;
+  ASSERT_OK(BlockingGetStats(&expected_stats));
+  ++expected_stats["createSuccess"];
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreateWithTTL(key_prefix_, kValue, kTtl, &created_index));
+  map<string, int64_t> stats;
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+
+  EtcdClient::Node node;
+  EXPECT_OK(BlockingGet(key_prefix_, &node));
+  EXPECT_EQ(kValue, node.value_);
+  EXPECT_EQ(created_index, node.created_index_);
+  EXPECT_EQ(created_index, node.modified_index_);
+
+  // Now wait for it to expire
+  sleep_for(kTtl + seconds(1));
+
+  // Vanished, in a puff of digital smoke:
+  expected_stats = stats;
+  ++expected_stats["getsSuccess"];
+  ++expected_stats["expireCount"];
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+  EXPECT_THAT(BlockingGet(key_prefix_, &node),
+              StatusIs(util::error::NOT_FOUND));
+}
+
+
+TEST_F(FakeEtcdTest, UpdateWithTTLExpires) {
+  seconds kTtl(3);
+
+  map<string, int64_t> expected_stats;
+  ASSERT_OK(BlockingGetStats(&expected_stats));
+  ++expected_stats["createSuccess"];
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(key_prefix_, kValue, &created_index));
+
+  map<string, int64_t> stats;
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+
+  expected_stats = stats;
+  ++expected_stats["compareAndSwapSuccess"];
+
+  int64_t modified_index;
+  EXPECT_OK(BlockingUpdateWithTTL(key_prefix_, kValue2, kTtl, created_index,
+                                  &modified_index));
+
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+  EXPECT_LT(created_index, modified_index);
+
+  EtcdClient::Node node;
+  EXPECT_OK(BlockingGet(key_prefix_, &node));
+  EXPECT_EQ(kValue2, node.value_);
+  EXPECT_EQ(created_index, node.created_index_);
+  EXPECT_EQ(modified_index, node.modified_index_);
+
+  // Now wait for it to expire
+  sleep_for(kTtl + seconds(1));
+
+  expected_stats = stats;
+  ++expected_stats["getsSuccess"];
+  ++expected_stats["expireCount"];
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+
+  // Vanished, in a puff of digital smoke:
+  EXPECT_THAT(BlockingGet(key_prefix_, &node),
+              StatusIs(util::error::NOT_FOUND));
+}
+
+
+TEST_F(FakeEtcdTest, ForceSet) {
+  map<string, int64_t> expected_stats;
+  ASSERT_OK(BlockingGetStats(&expected_stats));
+  ++expected_stats["createSuccess"];
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(key_prefix_, kValue, &created_index));
+
+  map<string, int64_t> stats;
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+  expected_stats = stats;
+  ++expected_stats["setsSuccess"];
+
+  int64_t modified_index;
+  EXPECT_OK(BlockingForceSet(key_prefix_, kValue2, &modified_index));
+
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+
+  EtcdClient::Node node;
+  EXPECT_OK(BlockingGet(key_prefix_, &node));
+  EXPECT_EQ(kValue2, node.value_);
+  EXPECT_EQ(modified_index, node.created_index_);
+  EXPECT_EQ(modified_index, node.modified_index_);
+  EXPECT_LT(created_index, modified_index);
+}
+
+
+TEST_F(FakeEtcdTest, ForceSetWithTTLExpires) {
+  seconds kTtl(3);
+
+  map<string, int64_t> expected_stats;
+  ASSERT_OK(BlockingGetStats(&expected_stats));
+  ++expected_stats["createSuccess"];
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(key_prefix_, kValue, &created_index));
+
+  map<string, int64_t> stats;
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+  expected_stats = stats;
+  ++expected_stats["setsSuccess"];
+
+  int64_t modified_index;
+  EXPECT_OK(
+      BlockingForceSetWithTTL(key_prefix_, kValue2, kTtl, &modified_index));
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+  EXPECT_LT(created_index, modified_index);
+
+  EtcdClient::Node node;
+  EXPECT_OK(BlockingGet(key_prefix_, &node));
+  EXPECT_EQ(kValue2, node.value_);
+  EXPECT_EQ(modified_index, node.created_index_);
+  EXPECT_EQ(modified_index, node.modified_index_);
+
+  // Now wait for it to expire
+  sleep_for(kTtl + seconds(1));
+
+  ++expected_stats["getsSuccess"];
+  ++expected_stats["expireCount"];
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+
+  // Vanished, in a puff of digital smoke:
+  EXPECT_THAT(BlockingGet(key_prefix_, &node),
+              StatusIs(util::error::NOT_FOUND));
+}
+
+
+TEST_F(FakeEtcdTest, DeleteNonExistent) {
+  map<string, int64_t> expected_stats;
+  ASSERT_OK(BlockingGetStats(&expected_stats));
+  ++expected_stats["compareAndDeleteFail"];
+
+  Status status(BlockingDelete("/potato", 42));
+  EXPECT_THAT(status, StatusIs(util::error::NOT_FOUND));
+
+  map<string, int64_t> stats;
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+}
+
+
+TEST_F(FakeEtcdTest, DeleteIncorrectIndex) {
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(key_prefix_, kValue, &created_index));
+
+  EtcdClient::Node node;
+  EXPECT_OK(BlockingGet(key_prefix_, &node));
+  EXPECT_EQ(created_index, node.created_index_);
+  EXPECT_EQ(created_index, node.modified_index_);
+
+  map<string, int64_t> expected_stats;
+  ASSERT_OK(BlockingGetStats(&expected_stats));
+  ++expected_stats["compareAndDeleteFail"];
+
+  EXPECT_THAT(BlockingDelete(key_prefix_, created_index + 1),
+              StatusIs(util::error::FAILED_PRECONDITION));
+  map<string, int64_t> stats;
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+
+  EXPECT_OK(BlockingGet(key_prefix_, &node));
+  EXPECT_EQ(created_index, node.created_index_);
+  EXPECT_EQ(created_index, node.modified_index_);
+}
+
+
+TEST_F(FakeEtcdTest, Delete) {
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(key_prefix_, kValue, &created_index));
+
+  EtcdClient::Node node;
+  EXPECT_OK(BlockingGet(key_prefix_, &node));
+  EXPECT_EQ(created_index, node.created_index_);
+  EXPECT_EQ(created_index, node.modified_index_);
+
+  map<string, int64_t> expected_stats;
+  ASSERT_OK(BlockingGetStats(&expected_stats));
+  ++expected_stats["compareAndDeleteSuccess"];
+
+  EXPECT_OK(BlockingDelete(key_prefix_, created_index));
+  map<string, int64_t> stats;
+  ASSERT_OK(BlockingGetStats(&stats));
+  EXPECT_EQ(expected_stats, stats);
+
+  EXPECT_THAT(BlockingGet(key_prefix_, &node),
+              StatusIs(util::error::NOT_FOUND));
+}
+
+
+class CheckingExecutor : public util::Executor {
+ public:
+  CheckingExecutor() : inner_(1), in_executor_(false) {
+  }
+
+  void Add(const std::function<void()>& closure) override {
+    inner_.Add(bind(&CheckingExecutor::Check, this, closure));
+  }
+
+  void Delay(const duration<double>& delay, util::Task* task) override {
+    LOG(FATAL) << "Not implemented";
+  }
+
+
+  void CheckInExecutor() const {
+    lock_guard<mutex> lock(lock_);
+    EXPECT_TRUE(in_executor_);
+  }
+
+ private:
+  void Check(const std::function<void()>& closure) {
+    {
+      lock_guard<mutex> lock(lock_);
+      CHECK(!in_executor_);
+      in_executor_ = true;
+    }
+    closure();
+    {
+      lock_guard<mutex> lock(lock_);
+      CHECK(in_executor_);
+      in_executor_ = false;
+    }
+  }
+
+  ThreadPool inner_;
+  mutable mutex lock_;
+  bool in_executor_;
+};
+
+
+MATCHER_P3(EtcdClientNodeIs, key, value, deleted, "") {
+  return Matches(key)(arg.key_) && Matches(value)(arg.value_) &&
+         Matches(deleted)(arg.deleted_);
+}
+
+
+TEST_F(FakeEtcdTest, WatcherForExecutor) {
+  const string kDir(key_prefix_);
+  const string kPath1(kDir + "/1");
+  const string kPath2(kDir + "/2");
+
+  // Make sure the directory exists and has something in it before watching.
+  int64_t bogus_index;
+  ASSERT_OK(BlockingCreate(kPath1, "", &bogus_index));
+
+  StrictMock<MockFunction<void(const vector<EtcdClient::Node>&)>> watcher;
+  CheckingExecutor checking_executor;
+  SyncTask task(&checking_executor);
+  Notification initial;
+  EXPECT_CALL(watcher, Call(ElementsAre(EtcdClientNodeIs(kPath1, "", false))))
+      .WillOnce(DoAll(InvokeWithoutArgs(&initial, &Notification::Notify),
+                      InvokeWithoutArgs(&checking_executor,
+                                        &CheckingExecutor::CheckInExecutor)));
+
+  client_->Watch(
+      kDir, bind(&MockFunction<void(const vector<EtcdClient::Node>&)>::Call,
+                 &watcher, _1),
+      task.task());
+
+  ASSERT_TRUE(initial.WaitForNotificationWithTimeout(seconds(1)));
+  Mock::VerifyAndClearExpectations(&watcher);
+
+  Notification second;
+  EXPECT_CALL(watcher,
+              Call(ElementsAre(EtcdClientNodeIs(kPath2, kValue, false))))
+      .WillOnce(DoAll(InvokeWithoutArgs(&second, &Notification::Notify),
+                      InvokeWithoutArgs(&checking_executor,
+                                        &CheckingExecutor::CheckInExecutor)));
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(kPath2, kValue, &created_index));
+
+  ASSERT_TRUE(second.WaitForNotificationWithTimeout(seconds(1)));
+
+  task.Cancel();
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::CANCELLED));
+}
+
+
+TEST_F(FakeEtcdTest, WatcherForCreate) {
+  const string kDir(key_prefix_);
+  const string kPath1(kDir + "/1");
+  const string kPath2(kDir + "/2");
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(kPath1, kValue, &created_index));
+
+  StrictMock<MockFunction<void(const vector<EtcdClient::Node>&)>> watcher;
+  Notification initial;
+  EXPECT_CALL(watcher,
+              Call(ElementsAre(EtcdClientNodeIs(kPath1, "value", false))))
+      .WillOnce(InvokeWithoutArgs(&initial, &Notification::Notify));
+
+  util::SyncTask watch_task(base_.get());
+  client_->Watch(
+      kDir, bind(&MockFunction<void(const vector<EtcdClient::Node>&)>::Call,
+                 &watcher, _1),
+      watch_task.task());
+
+  ASSERT_TRUE(initial.WaitForNotificationWithTimeout(seconds(1)));
+  Mock::VerifyAndClearExpectations(&watcher);
+
+  Notification second;
+  EXPECT_CALL(watcher,
+              Call(ElementsAre(EtcdClientNodeIs(kPath2, kValue2, false))))
+      .WillOnce(InvokeWithoutArgs(&second, &Notification::Notify));
+
+  EXPECT_OK(BlockingCreate(kPath2, kValue2, &created_index));
+
+  EXPECT_TRUE(second.WaitForNotificationWithTimeout(seconds(1)));
+
+  watch_task.Cancel();
+  watch_task.Wait();
+  EXPECT_THAT(watch_task.status(), StatusIs(util::error::CANCELLED));
+}
+
+
+TEST_F(FakeEtcdTest, WatcherForDelete) {
+  const string kDir(key_prefix_);
+  const string kPath(kDir + "/subkey");
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(kPath, kValue, &created_index));
+
+  StrictMock<MockFunction<void(const vector<EtcdClient::Node>&)>> watcher;
+  Notification initial;
+  EXPECT_CALL(watcher,
+              Call(ElementsAre(EtcdClientNodeIs(kPath, "value", false))))
+      .WillOnce(InvokeWithoutArgs(&initial, &Notification::Notify));
+
+  util::SyncTask watch_task(base_.get());
+  client_->Watch(
+      kDir, bind(&MockFunction<void(const vector<EtcdClient::Node>&)>::Call,
+                 &watcher, _1),
+      watch_task.task());
+
+  ASSERT_TRUE(initial.WaitForNotificationWithTimeout(seconds(1)));
+  Mock::VerifyAndClearExpectations(&watcher);
+
+  Notification second;
+  EXPECT_CALL(watcher, Call(ElementsAre(EtcdClientNodeIs(kPath, _, true))))
+      .WillOnce(InvokeWithoutArgs(&second, &Notification::Notify));
+
+  EXPECT_OK(BlockingDelete(kPath, created_index));
+
+  EXPECT_TRUE(second.WaitForNotificationWithTimeout(seconds(1)));
+
+  watch_task.Cancel();
+  watch_task.Wait();
+  EXPECT_THAT(watch_task.status(), StatusIs(util::error::CANCELLED));
+}
+
+
+TEST_F(FakeEtcdTest, WatcherWithTTLExpires) {
+  const string kDir(key_prefix_);
+  const string kPath(kDir + "/subkey");
+  const seconds kTtl(3);
+  int64_t created_index;
+  EXPECT_OK(BlockingCreateWithTTL(kPath, kValue, kTtl, &created_index));
+
+  StrictMock<MockFunction<void(const vector<EtcdClient::Node>&)>> watcher;
+  Notification initial;
+  EXPECT_CALL(watcher,
+              Call(ElementsAre(EtcdClientNodeIs(kPath, "value", false))))
+      .WillOnce(InvokeWithoutArgs(&initial, &Notification::Notify));
+
+  util::SyncTask watch_task(base_.get());
+  client_->Watch(
+      kDir, bind(&MockFunction<void(const vector<EtcdClient::Node>&)>::Call,
+                 &watcher, _1),
+      watch_task.task());
+
+  ASSERT_TRUE(initial.WaitForNotificationWithTimeout(seconds(1)));
+  Mock::VerifyAndClearExpectations(&watcher);
+
+  Notification second;
+  EXPECT_CALL(watcher, Call(ElementsAre(EtcdClientNodeIs(kPath, _, true))))
+      .WillOnce(InvokeWithoutArgs(&second, &Notification::Notify));
+
+  EXPECT_TRUE(second.WaitForNotificationWithTimeout(kTtl + seconds(1)));
+
+  watch_task.Cancel();
+  watch_task.Wait();
+  EXPECT_THAT(watch_task.status(), StatusIs(util::error::CANCELLED));
+}
+
+
+TEST_F(FakeEtcdTest, PutUnderNonDir) {
+  const string kPath1(key_prefix_);
+  const string kPath2(kPath1 + "/subkey");
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(kPath1, kValue, &created_index));
+  EXPECT_THAT(BlockingCreate(kPath2, kValue, &created_index),
+              StatusIs(util::error::ABORTED, "Not a directory"));
+}
+
+
+TEST_F(FakeEtcdTest, GetDir) {
+  const string kDir(key_prefix_);
+  const string kPath1(kDir + "/1");
+  const string kPath2(kDir + "/2");
+  const string kPath3(kPath2 + "/1/foo/bar/baz");
+  const string kPath4(kDir + "/3");
+  const string kPath5(kPath4 + "/1");
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(kPath1, kValue, &created_index));
+  EXPECT_OK(BlockingCreate(kPath3, kValue, &created_index));
+  EXPECT_OK(BlockingCreate(kPath5, kValue, &created_index));
+  EXPECT_OK(BlockingCreate(kDir + "x", kValue, &created_index));
+
+  SyncTask task(base_.get());
+  EtcdClient::Request req(kDir);
+  EtcdClient::GetResponse resp;
+  client_->Get(req, &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(kDir, resp.node.key_);
+  EXPECT_TRUE(resp.node.is_dir_);
+  EXPECT_TRUE(resp.node.value_.empty());
+  EXPECT_EQ(static_cast<size_t>(3), resp.node.nodes_.size());
+  // TODO(pphaneuf): Check that the sub-nodes are as we expect them.
+}
+
+
+TEST_F(FakeEtcdTest, GetDirRecursive) {
+  const string kDir(key_prefix_);
+  const string kPath1(kDir + "/sub");
+  const string kPath2(kPath1 + "/key");
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(kPath2, kValue, &created_index));
+
+  SyncTask task(base_.get());
+  EtcdClient::Request req(kDir);
+  req.recursive = true;
+  EtcdClient::GetResponse resp;
+  client_->Get(req, &resp, task.task());
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(kDir, resp.node.key_);
+  EXPECT_TRUE(resp.node.is_dir_);
+  EXPECT_TRUE(resp.node.value_.empty());
+  ASSERT_EQ(static_cast<size_t>(1), resp.node.nodes_.size());
+
+  EXPECT_EQ(kPath1, resp.node.nodes_[0].key_);
+  EXPECT_TRUE(resp.node.nodes_[0].is_dir_);
+  EXPECT_TRUE(resp.node.nodes_[0].value_.empty());
+  ASSERT_EQ(static_cast<size_t>(1), resp.node.nodes_[0].nodes_.size());
+
+  EXPECT_EQ(kPath2, resp.node.nodes_[0].nodes_[0].key_);
+  EXPECT_FALSE(resp.node.nodes_[0].nodes_[0].is_dir_);
+  EXPECT_TRUE(resp.node.nodes_[0].nodes_[0].nodes_.empty());
+  EXPECT_EQ(kValue, resp.node.nodes_[0].nodes_[0].value_);
+}
+
+
+// This test is not expected to pass with the real etcd, it tests an
+// aspect specific to the fake implementation.
+TEST_F(FakeEtcdTest, GetWaitOldIndex) {
+  const string kPath(key_prefix_);
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(kPath, kValue, &created_index));
+
+  SyncTask task(base_.get());
+  EtcdClient::Request req(kPath);
+  req.wait_index = created_index;
+  EtcdClient::GetResponse resp;
+  client_->Get(req, &resp, task.task());
+  task.Wait();
+  EXPECT_THAT(task.status(), StatusIs(util::error::ABORTED));
+  EXPECT_EQ(created_index, resp.etcd_index);
+}
+
+
+TEST_F(FakeEtcdTest, GetWaitNonExistent) {
+  const string kPath(key_prefix_);
+
+  EtcdClient::Node node;
+  int64_t index;
+  EXPECT_THAT(BlockingGet(key_prefix_, &node, &index),
+              StatusIs(util::error::NOT_FOUND));
+
+  SyncTask task(base_.get());
+  EtcdClient::Request req(kPath);
+  req.wait_index = index + 1;
+  EtcdClient::GetResponse resp;
+  client_->Get(req, &resp, task.task());
+  ASSERT_TRUE(task.task()->IsActive());
+
+  sleep_for(seconds(1));
+  EXPECT_TRUE(task.task()->IsActive());
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(kPath, kValue, &created_index));
+
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(created_index - 1, resp.etcd_index);
+  EXPECT_EQ(kPath, resp.node.key_);
+  EXPECT_EQ(kValue, resp.node.value_);
+  EXPECT_EQ(created_index, resp.node.created_index_);
+  EXPECT_EQ(created_index, resp.node.modified_index_);
+  EXPECT_FALSE(resp.node.is_dir_);
+  EXPECT_TRUE(resp.node.nodes_.empty());
+  EXPECT_FALSE(resp.node.deleted_);
+}
+
+
+TEST_F(FakeEtcdTest, GetWaitUpdateExisting) {
+  const string kPath(key_prefix_);
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(kPath, kValue, &created_index));
+
+  SyncTask task(base_.get());
+  EtcdClient::Request req(kPath);
+  req.wait_index = created_index + 1;
+  EtcdClient::GetResponse resp;
+  client_->Get(req, &resp, task.task());
+  ASSERT_TRUE(task.task()->IsActive());
+
+  sleep_for(seconds(1));
+  EXPECT_TRUE(task.task()->IsActive());
+
+  int64_t updated_index;
+  EXPECT_OK(BlockingUpdate(kPath, kValue2, created_index, &updated_index));
+
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(created_index, resp.etcd_index);
+  EXPECT_EQ(kPath, resp.node.key_);
+  EXPECT_EQ(kValue2, resp.node.value_);
+  EXPECT_EQ(created_index, resp.node.created_index_);
+  EXPECT_EQ(updated_index, resp.node.modified_index_);
+  EXPECT_FALSE(resp.node.is_dir_);
+  EXPECT_TRUE(resp.node.nodes_.empty());
+  EXPECT_FALSE(resp.node.deleted_);
+}
+
+
+TEST_F(FakeEtcdTest, GetWaitSetExisting) {
+  const string kPath(key_prefix_);
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(kPath, kValue, &created_index));
+
+  SyncTask task(base_.get());
+  EtcdClient::Request req(kPath);
+  req.wait_index = created_index + 1;
+  EtcdClient::GetResponse resp;
+  client_->Get(req, &resp, task.task());
+  ASSERT_TRUE(task.task()->IsActive());
+
+  sleep_for(seconds(1));
+  EXPECT_TRUE(task.task()->IsActive());
+
+  int64_t updated_index;
+  EXPECT_OK(BlockingForceSet(kPath, kValue2, &updated_index));
+
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(created_index, resp.etcd_index);
+  EXPECT_EQ(kPath, resp.node.key_);
+  EXPECT_EQ(kValue2, resp.node.value_);
+  EXPECT_EQ(updated_index, resp.node.created_index_);
+  EXPECT_EQ(updated_index, resp.node.modified_index_);
+  EXPECT_FALSE(resp.node.is_dir_);
+  EXPECT_TRUE(resp.node.nodes_.empty());
+  EXPECT_FALSE(resp.node.deleted_);
+}
+
+
+TEST_F(FakeEtcdTest, GetWaitDeleteExisting) {
+  const string kPath(key_prefix_);
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(kPath, kValue, &created_index));
+
+  SyncTask task(base_.get());
+  EtcdClient::Request req(kPath);
+  req.wait_index = created_index + 1;
+  EtcdClient::GetResponse resp;
+  client_->Get(req, &resp, task.task());
+  ASSERT_TRUE(task.task()->IsActive());
+
+  sleep_for(seconds(1));
+  EXPECT_TRUE(task.task()->IsActive());
+
+  EXPECT_OK(BlockingDelete(kPath, created_index));
+
+  task.Wait();
+  EXPECT_OK(task);
+  EXPECT_EQ(created_index, resp.etcd_index);
+  EXPECT_EQ(kPath, resp.node.key_);
+  EXPECT_TRUE(resp.node.value_.empty());
+  EXPECT_EQ(created_index, resp.node.created_index_);
+  EXPECT_EQ(created_index + 1, resp.node.modified_index_);
+  EXPECT_FALSE(resp.node.is_dir_);
+  EXPECT_TRUE(resp.node.nodes_.empty());
+  EXPECT_TRUE(resp.node.deleted_);
+}
+
+
+TEST_F(FakeEtcdTest, GetWaitRecursive) {
+  const string kDir1(key_prefix_ + "/1");
+  const string kPath1(kDir1 + "/subkey");
+  const string kDir2(key_prefix_ + "/2");
+
+  EtcdClient::Node node;
+  int64_t index;
+  EXPECT_THAT(BlockingGet(key_prefix_, &node, &index),
+              StatusIs(util::error::NOT_FOUND));
+
+  SyncTask task1(base_.get());
+  EtcdClient::Request req1(kDir1);
+  req1.recursive = true;
+  req1.wait_index = index + 1;
+  EtcdClient::GetResponse resp1;
+  client_->Get(req1, &resp1, task1.task());
+  ASSERT_TRUE(task1.task()->IsActive());
+
+  SyncTask task2(base_.get());
+  EtcdClient::Request req2(kDir2);
+  req2.recursive = true;
+  req2.wait_index = index + 1;
+  EtcdClient::GetResponse resp2;
+  client_->Get(req2, &resp2, task2.task());
+  ASSERT_TRUE(task2.task()->IsActive());
+
+  sleep_for(seconds(1));
+  EXPECT_TRUE(task1.task()->IsActive());
+  EXPECT_TRUE(task2.task()->IsActive());
+
+  int64_t created_index;
+  EXPECT_OK(BlockingCreate(kPath1, kValue, &created_index));
+
+  task1.Wait();
+  EXPECT_OK(task1);
+  EXPECT_EQ(index, resp1.etcd_index);
+  EXPECT_EQ(kPath1, resp1.node.key_);
+  EXPECT_EQ(kValue, resp1.node.value_);
+  EXPECT_EQ(created_index, resp1.node.created_index_);
+  EXPECT_EQ(created_index, resp1.node.modified_index_);
+  EXPECT_FALSE(resp1.node.is_dir_);
+  EXPECT_TRUE(resp1.node.nodes_.empty());
+  EXPECT_FALSE(resp1.node.deleted_);
+
+  sleep_for(seconds(1));
+  EXPECT_TRUE(task2.task()->IsActive());
+  task2.Cancel();
+  task2.Wait();
+  EXPECT_THAT(task2.status(), StatusIs(util::error::CANCELLED));
+}
+
+
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+
+  OpenSSL_add_all_algorithms();
+  ERR_load_BIO_strings();
+  ERR_load_crypto_strings();
+  SSL_load_error_strings();
+  SSL_library_init();
+
+  // Default value of trusted root certs may not be correct on all platforms
+  FLAGS_trusted_root_certs = FLAGS_cert_dir + "/ca-cert.pem";
+
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/init.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/init.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/init.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/init.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,80 @@
+#include "util/init.h"
+
+#include <event2/thread.h>
+#include <evhtp.h>
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <openssl/crypto.h>
+#include <openssl/err.h>
+#include <openssl/ssl.h>
+#include <unistd.h>
+#include <string>
+
+#include "config.h"
+#include "log/ct_extensions.h"
+#include "proto/cert_serializer.h"
+#include "version.h"
+
+using std::string;
+
+namespace util {
+
+
+namespace {
+
+
+void LibEventLog(int severity, const char* msg) {
+  const string msg_s(msg);
+  switch (severity) {
+    case EVENT_LOG_DEBUG:
+      VLOG(1) << msg_s;
+      break;
+    case EVENT_LOG_MSG:
+      LOG(INFO) << msg_s;
+      break;
+    case EVENT_LOG_WARN:
+      LOG(WARNING) << msg_s;
+      break;
+    case EVENT_LOG_ERR:
+      LOG(ERROR) << msg_s;
+      break;
+    default:
+      LOG(ERROR) << "LibEvent(?): " << msg_s;
+      break;
+  }
+}
+
+
+}  // namespace
+
+
+void InitCT(int* argc, char** argv[]) {
+  google::SetVersionString(cert_trans::kBuildVersion);
+  google::ParseCommandLineFlags(argc, argv, true);
+  google::InitGoogleLogging(*argv[0]);
+  google::InstallFailureSignalHandler();
+
+  event_set_log_callback(&LibEventLog);
+
+  evthread_use_pthreads();
+  // Set-up OpenSSL for multithreaded use:
+  evhtp_ssl_use_threads();
+
+  OpenSSL_add_all_algorithms();
+  ERR_load_BIO_strings();
+  ERR_load_crypto_strings();
+  SSL_load_error_strings();
+  SSL_library_init();
+
+  cert_trans::LoadCtExtensions();
+
+  LOG(INFO) << "Build version: " << google::VersionString();
+#ifdef ENABLE_HARDENING
+  LOG(INFO) << "Binary built with hardening enabled.";
+#else
+  LOG(WARNING) << "Binary built with hardening DISABLED.";
+#endif
+}
+
+
+}  // namespace util
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/init.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/init.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/init.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/init.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,13 @@
+#ifndef CERT_TRANS_UTIL_INIT_H_
+#define CERT_TRANS_UTIL_INIT_H_
+
+#include <stdint.h>
+#include <string>
+
+namespace util {
+
+void InitCT(int* argc, char** argv[]);
+
+}  // namespace util
+
+#endif  // CERT_TRANS_UTIL_INIT_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/json_wrapper.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/json_wrapper.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/json_wrapper.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/json_wrapper.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,77 @@
+#include "json_wrapper.h"
+
+#include <memory>
+
+using std::unique_ptr;
+
+
+JsonObject::JsonObject(evbuffer* buffer) : obj_(NULL) {
+  const unique_ptr<json_tokener, void (*)(json_tokener*)> tokener(
+      json_tokener_new(), json_tokener_free);
+
+  evbuffer_ptr ptr;
+  evbuffer_ptr_set(buffer, &ptr, 0, EVBUFFER_PTR_SET);
+
+  unsigned amount_consumed(0);
+
+  while (!obj_ && amount_consumed < evbuffer_get_length(buffer)) {
+    evbuffer_iovec chunk;
+
+    if (evbuffer_peek(buffer, -1, &ptr, &chunk, 1) < 1) {
+      // No more data.
+      break;
+    }
+
+    // This function can be called repeatedly with each chunk of
+    // data. It keeps its state in "*tokener", and will return a
+    // non-NULL value once it finds a full object. If it returns NULL
+    // and the error is "json_tokener_continue", this simply means
+    // that it hasn't yet found an object, we just need to keep
+    // calling it with more data.
+    obj_ = json_tokener_parse_ex(tokener.get(),
+                                 static_cast<char*>(chunk.iov_base),
+                                 chunk.iov_len);
+
+    // Check for a parsing error.
+    if (!obj_ &&
+        json_tokener_get_error(tokener.get()) != json_tokener_continue) {
+      VLOG(1) << "json_tokener_parse_ex: "
+              << json_tokener_error_desc(
+                     json_tokener_get_error(tokener.get()));
+      break;
+    }
+
+    if (obj_) {
+      // At the end of the parsing, we might not have consumed all the
+      // bytes in the iovec.
+      amount_consumed += tokener->char_offset;
+      // No need to update "ptr" here, we're done.
+    } else {
+      amount_consumed += chunk.iov_len;
+      evbuffer_ptr_set(buffer, &ptr, chunk.iov_len, EVBUFFER_PTR_ADD);
+    }
+  }
+
+  // If the parsing was successful, drain the number of bytes
+  // consumed.
+  if (obj_) {
+    evbuffer_drain(buffer, amount_consumed);
+  }
+}
+
+
+JsonObject::JsonObject(const JsonArray& from, int offset, json_type type) {
+  obj_ = json_object_array_get_idx(from.obj_, offset);
+  if (obj_ != NULL) {
+    if (!json_object_is_type(obj_, type)) {
+      LOG(ERROR) << "Don't understand index " << offset << ": "
+                 << from.ToJson();
+      obj_ = NULL;
+      return;
+    }
+  } else {
+    LOG(ERROR) << "No index " << offset;
+    return;
+  }
+  json_object_get(obj_);
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/json_wrapper.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/json_wrapper.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/json_wrapper.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/json_wrapper.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,216 @@
+#ifndef CERT_TRANS_UTIL_JSON_WRAPPER_H_
+#define CERT_TRANS_UTIL_JSON_WRAPPER_H_
+
+#include <glog/logging.h>
+#include <json.h>
+#undef TRUE   // json.h pollution
+#undef FALSE  // json.h pollution
+
+#include <event2/buffer.h>
+#include <sstream>
+#include <string>
+
+#include "base/macros.h"
+#include "proto/serializer.h"
+#include "util/util.h"
+
+class JsonArray;
+
+// It appears that a new object, e.g. from a string, has a reference count
+// of 1, and that any objects "got" from it will get freed when it is freed.
+
+// Note that a JsonObject that is not Ok() should not be used for anything.
+class JsonObject {
+ public:
+  explicit JsonObject(json_object* obj) : obj_(obj) {
+  }
+
+  explicit JsonObject(const std::ostringstream& response) {
+    obj_ = json_tokener_parse(response.str().c_str());
+  }
+
+  explicit JsonObject(const std::string& response) {
+    obj_ = json_tokener_parse(response.c_str());
+  }
+
+  // This constructor is destructive: if a JSON object is parsed
+  // correctly, it will remove it from the front of the buffer. In
+  // case of an error, the buffer is left unchanged.
+  explicit JsonObject(evbuffer* buffer);
+
+  JsonObject(const JsonArray& from, int offset,
+             json_type type = json_type_object);
+
+  JsonObject(const JsonObject& from, const char* field) {
+    InitFromChild(from, field, json_type_object);
+  }
+
+  JsonObject() : obj_(json_object_new_object()) {
+  }
+
+  ~JsonObject() {
+    if (obj_)
+      json_object_put(obj_);
+  }
+
+  // Get the object out, and stop tracking it so we _won't_ put() it
+  // when we are destroyed. The caller needs to ensure it is freed.
+  json_object* Extract() {
+    json_object* tmp = obj_;
+    obj_ = NULL;
+    return tmp;
+  }
+
+  bool Ok() const {
+    return obj_ != NULL;
+  }
+
+  bool IsType(json_type type) const {
+    return json_object_is_type(obj_, type);
+  }
+
+  const char* ToJson() const {
+    return json_object_to_json_string(obj_);
+  }
+
+  void Add(const char* name, const JsonObject& addand) {
+    Add(name, json_object_get(addand.obj_));
+  }
+
+  void Add(const char* name, int64_t value) {
+    Add(name, json_object_new_int64(value));
+  }
+
+  void Add(const char* name, const std::string& value) {
+    Add(name, json_object_new_string(value.c_str()));
+  }
+
+  void AddBase64(const char* name, const std::string& value) {
+    Add(name, util::ToBase64(value));
+  }
+
+  void Add(const char* name, const ct::DigitallySigned& ds) {
+    std::string signature;
+    CHECK_EQ(Serializer::SerializeDigitallySigned(ds, &signature),
+             cert_trans::serialization::SerializeResult::OK);
+    AddBase64(name, signature);
+  }
+
+  void AddBoolean(const char* name, bool b) {
+    Add(name, json_object_new_boolean(b));
+  }
+
+  const char* ToString() const {
+    return json_object_to_json_string(obj_);
+  }
+
+  std::string DebugString() const {
+    return json_object_to_json_string_ext(obj_, JSON_C_TO_STRING_PRETTY);
+  }
+
+ protected:
+  JsonObject(const JsonObject& from, const char* field, json_type type) {
+    InitFromChild(from, field, type);
+  }
+
+  json_object* obj_;
+
+ private:
+  void InitFromChild(const JsonObject& from, const char* field,
+                     json_type type) {
+    if (json_object_object_get_ex(from.obj_, field, &obj_)) {
+      if (!json_object_is_type(obj_, type)) {
+        LOG(ERROR) << "Don't understand " << field
+                   << " field: " << from.ToJson();
+        obj_ = NULL;
+        return;
+      }
+    } else {
+      VLOG(2) << "No " << field << " field";
+      return;
+    }
+    // Increment reference count
+    json_object_get(obj_);
+  }
+
+  void Add(const char* name, json_object* obj) {
+    json_object_object_add(obj_, name, obj);
+  }
+
+  DISALLOW_COPY_AND_ASSIGN(JsonObject);
+};
+
+class JsonBoolean : public JsonObject {
+ public:
+  JsonBoolean(const JsonObject& from, const char* field)
+      : JsonObject(from, field, json_type_boolean) {
+  }
+
+  bool Value() const {
+    return json_object_get_boolean(obj_);
+  }
+};
+
+class JsonString : public JsonObject {
+ public:
+  JsonString(const JsonObject& from, const char* field)
+      : JsonObject(from, field, json_type_string) {
+  }
+
+  JsonString(const JsonArray& from, int offset)
+      : JsonObject(from, offset, json_type_string) {
+  }
+
+  const char* Value() const {
+    return json_object_get_string(obj_);
+  }
+
+  std::string FromBase64() {
+    return util::FromBase64(Value());
+  }
+};
+
+class JsonInt : public JsonObject {
+ public:
+  explicit JsonInt(json_object* jint) : JsonObject(jint) {
+  }
+  JsonInt(const JsonObject& from, const char* field)
+      : JsonObject(from, field, json_type_int) {
+  }
+
+  int64_t Value() const {
+    return json_object_get_int64(obj_);
+  }
+};
+
+class JsonArray : public JsonObject {
+ public:
+  JsonArray(const JsonObject& from, const char* field)
+      : JsonObject(from, field, json_type_array) {
+  }
+
+  JsonArray() : JsonObject(json_object_new_array()) {
+  }
+
+  void Add(json_object* addand) {
+    json_object_array_add(obj_, addand);
+  }
+
+  void Add(const std::string& addand) {
+    Add(json_object_new_string(addand.c_str()));
+  }
+
+  void Add(JsonObject* addand) {
+    Add(addand->Extract());
+  }
+
+  void AddBase64(const std::string& addand) {
+    Add(util::ToBase64(addand));
+  }
+
+  int Length() const {
+    return json_object_array_length(obj_);
+  }
+};
+
+#endif  // CERT_TRANS_UTIL_JSON_WRAPPER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/json_wrapper_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/json_wrapper_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/json_wrapper_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/json_wrapper_test.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,89 @@
+#include "util/json_wrapper.h"
+
+#include <gtest/gtest.h>
+#include <memory>
+
+#include "util/testing.h"
+#include "util/util.h"
+
+using std::shared_ptr;
+using std::string;
+
+class JsonWrapperTest : public ::testing::Test {};
+
+TEST_F(JsonWrapperTest, LargeInt) {
+  int64_t big = 0x123456789aLL;
+  shared_ptr<json_object> jint(json_object_new_int64(big), json_object_put);
+  const char* jsoned = json_object_to_json_string(jint.get());
+  JsonInt jint2(json_tokener_parse(jsoned));
+  CHECK_EQ(big, jint2.Value());
+}
+
+TEST_F(JsonWrapperTest, UnwrapResponse) {
+  static string response(
+      "{\"leaf_index\":3,\"audit_path\":"
+      "[\"j17CTFWsQGwnQkYsebYS7CondFpbzIo+N1jPi9UrqTI=\","
+      "\"QSNVV8/waZ5rezVSTFcSPbKtqjalAwVqdF2Vv0/l3/Q=\"]}");
+  static string p1v(
+      "8f5ec24c55ac406c2742462c79b612ec2a27745a5bcc8a3e3758cf8bd52ba932");
+  static string p2v(
+      "41235557cff0699e6b7b35524c57123db2adaa36a503056a745d95bf4fe5dff4");
+
+  JsonObject jresponse(response);
+  ASSERT_TRUE(jresponse.Ok());
+
+  JsonInt leaf_index(jresponse, "leaf_index");
+  ASSERT_TRUE(leaf_index.Ok());
+  EXPECT_EQ(leaf_index.Value(), 3);
+
+  JsonArray audit_path(jresponse, "audit_path");
+  ASSERT_TRUE(audit_path.Ok());
+  EXPECT_EQ(audit_path.Length(), 2);
+
+  JsonString p1(audit_path, 0);
+  ASSERT_TRUE(p1.Ok());
+  EXPECT_EQ(util::HexString(p1.FromBase64()), p1v);
+
+  JsonString p2(audit_path, 1);
+  ASSERT_TRUE(p2.Ok());
+  EXPECT_EQ(util::HexString(p2.FromBase64()), p2v);
+}
+
+TEST_F(JsonWrapperTest, PartialEvBuffer) {
+  const string partial_input("{ \"foo\": 42 ");
+  const shared_ptr<evbuffer> buffer(CHECK_NOTNULL(evbuffer_new()),
+                                    evbuffer_free);
+
+  evbuffer_add(buffer.get(), partial_input.data(), partial_input.size());
+
+  JsonObject obj(buffer.get());
+  EXPECT_FALSE(obj.Ok());
+  EXPECT_EQ(partial_input.size(), evbuffer_get_length(buffer.get()));
+}
+
+TEST_F(JsonWrapperTest, FragmentedEvBuffer) {
+  const shared_ptr<evbuffer> buffer(CHECK_NOTNULL(evbuffer_new()),
+                                    evbuffer_free);
+  evbuffer_add_printf(buffer.get(), "{ \"foo\": ");
+
+  // Use a separate buffer and evbuffer_add_buffer, to ensure
+  // fragmentation.
+  {
+    const shared_ptr<evbuffer> buffer2(CHECK_NOTNULL(evbuffer_new()),
+                                       evbuffer_free);
+    evbuffer_add_printf(buffer2.get(), "42 }");
+    evbuffer_add_buffer(buffer.get(), buffer2.get());
+  }
+
+  evbuffer_iovec chunks[2];
+  EXPECT_LT(1, evbuffer_peek(buffer.get(), -1, /*start_at*/ NULL, chunks, 2));
+
+  JsonObject obj(buffer.get());
+  EXPECT_TRUE(obj.Ok());
+  EXPECT_EQ(0U, evbuffer_get_length(buffer.get()));
+}
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/libevent_wrapper.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/libevent_wrapper.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/libevent_wrapper.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/libevent_wrapper.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,484 @@
+#include "config.h"
+#include "util/libevent_wrapper.h"
+
+
+#include <arpa/inet.h>
+#ifdef HAVE_ARPA_NAMESER_H
+#include <arpa/nameser.h> /* DNS HEADER struct */
+#endif
+#include <event2/keyvalq_struct.h>
+#include <event2/thread.h>
+#include <evhtp.h>
+#include <glog/logging.h>
+#include <math.h>
+#include <climits>
+#ifdef HAVE_NETDB_H
+#include <netdb.h>
+#endif
+#include <netdb.h>
+#ifdef HAVE_NETINET_IN_H
+#include <netinet/in.h> /* inet_ functions / structs */
+#endif
+#include <resolv.h>
+#include <sys/socket.h>
+#ifdef HAVE_SYS_TYPES_H
+#include <sys/types.h>
+#endif
+#include <signal.h>
+
+using std::bind;
+using std::chrono::duration;
+using std::chrono::duration_cast;
+using std::chrono::microseconds;
+using std::chrono::milliseconds;
+using std::chrono::seconds;
+using std::chrono::system_clock;
+using std::function;
+using std::lock_guard;
+using std::make_pair;
+using std::multimap;
+using std::mutex;
+using std::placeholders::_1;
+using std::recursive_mutex;
+using std::shared_ptr;
+using std::string;
+using std::unique_ptr;
+using std::vector;
+using util::TaskHold;
+
+namespace {
+
+void FreeEvDns(evdns_base* dns) {
+  if (dns) {
+    evdns_base_free(dns, true);
+  }
+}
+
+
+static void Handler_ExitLoop(evutil_socket_t, short, void* base) {
+  event_base_loopexit((event_base*)base, NULL);
+}
+
+
+void SetExitLoopHandler(event_base* base, int signum) {
+  struct event* signal_event;
+  // TODO(pphaneuf): this should be free'd
+  signal_event = evsignal_new(base, signum, Handler_ExitLoop, base);
+  CHECK_NOTNULL(signal_event);
+  CHECK_GE(event_add(signal_event, NULL), 0);
+}
+
+
+void DelayCancel(event* timer, util::Task* task) {
+  event_del(timer);
+  task->Return(util::Status::CANCELLED);
+}
+
+
+void DelayDispatch(evutil_socket_t, short, void* userdata) {
+  static_cast<util::Task*>(CHECK_NOTNULL(userdata))->Return();
+}
+
+
+#ifdef HAVE_THREAD_LOCAL
+thread_local bool on_event_thread = false;
+#elif HAVE___THREAD
+__thread bool on_event_thread = false;
+#else
+#error No suitable thread local storage available
+#endif
+
+
+}  // namespace
+
+namespace cert_trans {
+namespace libevent {
+
+
+struct HttpServer::Handler {
+  Handler(const string& _path, const HandlerCallback& _cb)
+      : path(_path), cb(_cb) {
+  }
+
+  const string path;
+  const HandlerCallback cb;
+};
+
+
+class ResolverImpl : public Base::Resolver {
+ public:
+  string Resolve(const string& host) override {
+    struct addrinfo* info;
+    struct addrinfo hints;
+    memset(&hints, 0, sizeof(hints));
+    // It seems evhtp doesn't support IPv6 addresses because it uses
+    // inet_addr() to parse the passed in "stringified" address.
+    // Restrict to IPv4 addresses for now:
+    hints.ai_family = AF_INET;
+    hints.ai_socktype = SOCK_STREAM;
+    const int resolved(getaddrinfo(host.c_str(), AF_UNSPEC, &hints, &info));
+    if (resolved != 0) {
+      LOG(WARNING) << "Failed to resolve HTTPS hostname " << host << ": "
+                   << gai_strerror(resolved);
+      return nullptr;
+    }
+
+    struct addrinfo* res(info);
+    void* addr(nullptr);
+    while (res && !addr) {
+      switch (res->ai_family) {
+        case AF_INET:
+          addr =
+              &reinterpret_cast<struct sockaddr_in*>(res->ai_addr)->sin_addr;
+          break;
+        case AF_INET6:
+          // Just in case one day evhtp uses inet_pton()
+          addr =
+              &reinterpret_cast<struct sockaddr_in6*>(res->ai_addr)->sin6_addr;
+          break;
+        default:
+          res = res->ai_next;
+          break;
+      }
+    }
+
+    if (!addr) {
+      LOG(WARNING) << "Got no usable address for " << host;
+      return nullptr;
+    }
+
+    char addr_str[INET6_ADDRSTRLEN];
+    inet_ntop(res->ai_family, addr, addr_str, INET6_ADDRSTRLEN);
+    freeaddrinfo(info);
+    return string(addr_str);
+  }
+};
+
+
+Base::Base() : Base(unique_ptr<Resolver>(new ResolverImpl)) {
+}
+
+
+Base::Base(unique_ptr<Resolver> resolver)
+    : base_(CHECK_NOTNULL(event_base_new()), event_base_free),
+      dns_(nullptr, FreeEvDns),
+      wake_closures_(event_new(base_.get(), -1, 0, &Base::RunClosures, this),
+                     &event_free),
+      resolver_(std::move(resolver)) {
+  evthread_make_base_notifiable(base_.get());
+
+  // So much stuff breaks if there's not a Dns client around to keep the
+  // event loop doing stuff that we may as well just have one from the get go.
+  GetDns();
+}
+
+
+Base::~Base() {
+}
+
+
+// static
+bool Base::OnEventThread() {
+  return on_event_thread;
+}
+
+
+// static
+void Base::CheckNotOnEventThread() {
+  CHECK_EQ(false, OnEventThread());
+}
+
+
+void Base::Add(const function<void()>& cb) {
+  lock_guard<mutex> lock(closures_lock_);
+  closures_.push_back(cb);
+  event_active(wake_closures_.get(), 0, 0);
+}
+
+
+void Base::Delay(const duration<double>& delay, util::Task* task) {
+  // If the delay is zero (or less?), what the heck, we're done!
+  if (delay <= delay.zero()) {
+    task->Return();
+    return;
+  }
+
+  // Make sure nothing "bad" happens while we're still setting up our
+  // callbacks.
+  TaskHold hold(task);
+
+  event* timer(CHECK_NOTNULL(evtimer_new(base_.get(), &DelayDispatch, task)));
+
+  // Ensure that the cancellation callback is run on this libevent::Base, to
+  // avoid races during cancellation.
+
+  // Cancellation callbacks are always called before the task enters
+  // the DONE state (and "timer" is freed), and "event_del" is
+  // thread-safe, so it does not matter on which thread "DelayCancel"
+  // is called on.
+  task->WhenCancelled(bind(DelayCancel, timer, task));
+
+  task->CleanupWhenDone(bind(event_free, timer));
+
+  timeval tv;
+  const seconds sec(duration_cast<seconds>(delay));
+  tv.tv_sec = sec.count();
+  tv.tv_usec = duration_cast<microseconds>(delay - sec).count();
+
+  CHECK_EQ(evtimer_add(timer, &tv), 0);
+}
+
+
+void Base::Dispatch() {
+  SetExitLoopHandler(base_.get(), SIGHUP);
+  SetExitLoopHandler(base_.get(), SIGINT);
+  SetExitLoopHandler(base_.get(), SIGTERM);
+
+  // There should /never/ be more than 1 thread trying to call Dispatch(), so
+  // we should expect to always own the lock here.
+  CHECK(dispatch_lock_.try_lock());
+  LOG_IF(WARNING, on_event_thread)
+      << "Huh?, Are you calling Dispatch() from a libevent thread?";
+  const bool old_on_event_thread(on_event_thread);
+  on_event_thread = true;
+  CHECK_EQ(event_base_dispatch(base_.get()), 0);
+  on_event_thread = old_on_event_thread;
+  dispatch_lock_.unlock();
+}
+
+
+void Base::DispatchOnce() {
+  // Only one thread can be running a dispatch loop at a time
+  lock_guard<mutex> lock(dispatch_lock_);
+  LOG_IF(WARNING, on_event_thread)
+      << "Huh?, Are you calling Dispatch() from a libevent thread?";
+  const bool old_on_event_thread(on_event_thread);
+  on_event_thread = true;
+  CHECK_EQ(event_base_loop(base_.get(), EVLOOP_ONCE), 0);
+  on_event_thread = old_on_event_thread;
+}
+
+
+void Base::LoopExit() {
+  event_base_loopexit(base_.get(), nullptr);
+}
+
+
+event* Base::EventNew(evutil_socket_t& sock, short events,
+                      Event* event) const {
+  return CHECK_NOTNULL(
+      event_new(base_.get(), sock, events, &Event::Dispatch, event));
+}
+
+
+evhttp* Base::HttpNew() const {
+  const ev_ssize_t max_http_header_size = 4096;
+  const ev_ssize_t max_http_post_body_size = 32768;
+  evhttp* http_session = CHECK_NOTNULL(evhttp_new(base_.get()));
+  evhttp_set_max_headers_size(http_session, max_http_header_size);
+  evhttp_set_max_body_size(http_session, max_http_post_body_size);
+  return http_session;
+}
+
+
+evdns_base* Base::GetDns() {
+  lock_guard<mutex> lock(dns_lock_);
+
+  if (!dns_) {
+    dns_.reset(CHECK_NOTNULL(evdns_base_new(base_.get(), 1)));
+  }
+
+  return dns_.get();
+}
+
+
+evhtp_connection_t* Base::HttpConnectionNew(const string& host,
+                                            unsigned short port) {
+  return CHECK_NOTNULL(
+      evhtp_connection_new_dns(base_.get(), GetDns(), host.c_str(), port));
+}
+
+
+evhtp_connection_t* Base::HttpsConnectionNew(const string& host,
+                                             unsigned short port,
+                                             SSL_CTX* ssl_ctx) {
+  CHECK_NOTNULL(ssl_ctx);
+
+  // TODO(alcutter): remove this all temporary name resolution stuff when this
+  // PR is merged: https://github.com/ellzey/libevhtp/pull/163
+  const string addr_str(resolver_->Resolve(host));
+  VLOG(1) << "Got addr: " << addr_str << ":" << port;
+  evhtp_connection_t* ret(CHECK_NOTNULL(
+      evhtp_connection_ssl_new(base_.get(), addr_str.c_str(), port, ssl_ctx)));
+  return ret;
+}
+
+
+void Base::RunClosures(evutil_socket_t, short, void* userdata) {
+  Base* self(static_cast<Base*>(CHECK_NOTNULL(userdata)));
+
+  vector<function<void()>> closures;
+  {
+    lock_guard<mutex> lock(self->closures_lock_);
+    closures.swap(self->closures_);
+  }
+
+  for (const auto& closure : closures) {
+    closure();
+  }
+}
+
+
+Event::Event(const Base& base, evutil_socket_t sock, short events,
+             const Callback& cb)
+    : cb_(cb), ev_(base.EventNew(sock, events, this)) {
+}
+
+
+Event::~Event() {
+  event_free(ev_);
+}
+
+
+void Event::Add(const duration<double>& timeout) const {
+  timeval tv;
+  timeval* tvp(NULL);
+
+  if (timeout != duration<double>::zero()) {
+    const seconds sec(duration_cast<seconds>(timeout));
+    tv.tv_sec = sec.count();
+    tv.tv_usec = duration_cast<microseconds>(timeout - sec).count();
+    tvp = &tv;
+  }
+
+  CHECK_EQ(event_add(ev_, tvp), 0);
+}
+
+
+void Event::Dispatch(evutil_socket_t sock, short events, void* userdata) {
+  static_cast<Event*>(userdata)->cb_(sock, events);
+}
+
+
+HttpServer::HttpServer(const Base& base) : http_(base.HttpNew()) {
+}
+
+
+HttpServer::~HttpServer() {
+  evhttp_free(http_);
+  for (vector<Handler*>::iterator it = handlers_.begin();
+       it != handlers_.end(); ++it) {
+    delete *it;
+  }
+}
+
+
+void HttpServer::Bind(const char* address, ev_uint16_t port) {
+  CHECK_EQ(evhttp_bind_socket(http_, address, port), 0);
+}
+
+
+bool HttpServer::AddHandler(const string& path, const HandlerCallback& cb) {
+  Handler* handler(new Handler(path, cb));
+  handlers_.push_back(handler);
+
+  return evhttp_set_cb(http_, path.c_str(), &HandleRequest, handler) == 0;
+}
+
+
+void HttpServer::HandleRequest(evhttp_request* req, void* userdata) {
+  static_cast<Handler*>(userdata)->cb(req);
+}
+
+
+QueryParams ParseQuery(evhttp_request* req) {
+  evkeyvalq keyval;
+  QueryParams retval;
+
+  // We return an empty result in case of a parsing error.
+  if (evhttp_parse_query_str(evhttp_uri_get_query(
+                                 evhttp_request_get_evhttp_uri(req)),
+                             &keyval) == 0) {
+    for (evkeyval* i = keyval.tqh_first; i; i = i->next.tqe_next) {
+      retval.insert(make_pair(i->key, i->value));
+    }
+  }
+
+  return retval;
+}
+
+
+bool GetParam(const QueryParams& query, const string& param, string* value) {
+  CHECK_NOTNULL(value);
+
+  auto it = query.find(param);
+  if (it == query.end()) {
+    return false;
+  }
+
+  const string possible_value(it->second);
+  ++it;
+
+  // Flag duplicate query parameters as invalid.
+  const bool retval(it == query.end() || it->first != param);
+  if (retval) {
+    *value = possible_value;
+  }
+
+  return retval;
+}
+
+
+// Returns -1 on error, and on success too if the parameter contains
+// -1 (so it's advised to only use it when expecting unsigned
+// parameters).
+int64_t GetIntParam(const QueryParams& query, const string& param) {
+  int retval(-1);
+  string value;
+  if (GetParam(query, param, &value)) {
+    errno = 0;
+    const long num(strtol(value.c_str(), /*endptr*/ NULL, 10));
+    // Detect strtol() errors or overflow/underflow when casting to
+    // retval's type clips the value. We do the following by doing it,
+    // and checking that they're still equal afterward (this will
+    // still work if we change retval's type later on).
+    retval = num;
+    if (errno || static_cast<long>(retval) != num) {
+      VLOG(1) << "over/underflow getting \"" << param << "\": " << retval
+              << ", " << num << " (" << strerror(errno) << ")";
+      retval = -1;
+    }
+  }
+
+  return retval;
+}
+
+
+bool GetBoolParam(const QueryParams& query, const string& param) {
+  string value;
+  if (GetParam(query, param, &value)) {
+    return (value == "true");
+  } else {
+    return false;
+  }
+}
+
+
+EventPumpThread::EventPumpThread(const shared_ptr<Base>& base)
+    : base_(base), pump_thread_(bind(&EventPumpThread::Pump, this)) {
+}
+
+
+EventPumpThread::~EventPumpThread() {
+  base_->LoopExit();
+  pump_thread_.join();
+}
+
+
+void EventPumpThread::Pump() {
+  base_->Dispatch();
+}
+
+
+}  // namespace libevent
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/libevent_wrapper.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/libevent_wrapper.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/libevent_wrapper.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/libevent_wrapper.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,159 @@
+#ifndef CERT_TRANS_UTIL_LIBEVENT_WRAPPER_H_
+#define CERT_TRANS_UTIL_LIBEVENT_WRAPPER_H_
+
+#include <event2/dns.h>
+#include <event2/event.h>
+#include <atomic>
+#include <chrono>
+// TODO(alcutter): Use evhtp for the HttpServer too.
+#include <event2/http.h>
+#include <evhtp.h>
+#include <functional>
+#include <map>
+#include <memory>
+#include <mutex>
+#include <string>
+#include <thread>
+#include <vector>
+
+#include "base/macros.h"
+#include "util/executor.h"
+#include "util/task.h"
+
+namespace cert_trans {
+namespace libevent {
+
+
+class Event;
+
+
+class Base : public util::Executor {
+ public:
+  class Resolver {
+   public:
+    virtual std::string Resolve(const std::string& host) = 0;
+  };
+
+  static bool OnEventThread();
+  static void CheckNotOnEventThread();
+
+  Base();
+  Base(std::unique_ptr<Resolver> resolver);
+  ~Base();
+
+  // Arranges to run the closure on the main loop.
+  void Add(const std::function<void()>& cb) override;
+
+  void Delay(const std::chrono::duration<double>& delay,
+             util::Task* task) override;
+
+  void Dispatch();
+  void DispatchOnce();
+  void LoopExit();
+
+  event* EventNew(evutil_socket_t& sock, short events, Event* event) const;
+  evhttp* HttpNew() const;
+  evdns_base* GetDns();
+  evhtp_connection_t* HttpConnectionNew(const std::string& host,
+                                        unsigned short port);
+  evhtp_connection_t* HttpsConnectionNew(const std::string& host,
+                                         unsigned short port,
+                                         SSL_CTX* ssl_ctx);
+
+ private:
+  static void RunClosures(evutil_socket_t sock, short flag, void* userdata);
+
+  const std::unique_ptr<event_base, void (*)(event_base*)> base_;
+  std::mutex dispatch_lock_;
+
+  std::mutex dns_lock_;
+  // "dns_" should be after base_, so that it gets destroyed first.
+  std::unique_ptr<evdns_base, void (*)(evdns_base*)> dns_;
+
+  std::mutex closures_lock_;
+  // "wake_closures_" should be after base_, so that it gets destroyed
+  // first.
+  const std::unique_ptr<event, void (*)(event*)> wake_closures_;
+  std::vector<std::function<void()>> closures_;
+  std::unique_ptr<Resolver> resolver_;
+
+  DISALLOW_COPY_AND_ASSIGN(Base);
+};
+
+
+class Event {
+ public:
+  typedef std::function<void(evutil_socket_t, short)> Callback;
+
+  Event(const Base& base, evutil_socket_t sock, short events,
+        const Callback& cb);
+  ~Event();
+
+  void Add(const std::chrono::duration<double>& timeout) const;
+  // Note that this is only public so |Base| can use it.
+  static void Dispatch(evutil_socket_t sock, short events, void* userdata);
+
+ private:
+  const Callback cb_;
+  event* const ev_;
+
+  DISALLOW_COPY_AND_ASSIGN(Event);
+};
+
+
+class HttpServer {
+ public:
+  typedef std::function<void(evhttp_request*)> HandlerCallback;
+
+  explicit HttpServer(const Base& base);
+  ~HttpServer();
+
+  void Bind(const char* address, ev_uint16_t port);
+
+  // Returns false if there was an error adding the handler.
+  bool AddHandler(const std::string& path, const HandlerCallback& cb);
+
+ private:
+  struct Handler;
+
+  static void HandleRequest(evhttp_request* req, void* userdata);
+
+  evhttp* const http_;
+  // Could have been a vector<Handler>, but it is important that
+  // pointers to entries remain valid.
+  std::vector<Handler*> handlers_;
+
+  DISALLOW_COPY_AND_ASSIGN(HttpServer);
+};
+
+typedef std::multimap<std::string, std::string> QueryParams;
+
+QueryParams ParseQuery(evhttp_request* req);
+
+bool GetParam(const QueryParams& query, const std::string& param,
+              std::string* value);
+
+int64_t GetIntParam(const QueryParams& query, const std::string& param);
+
+bool GetBoolParam(const QueryParams& query, const std::string& param);
+
+
+class EventPumpThread {
+ public:
+  EventPumpThread(const std::shared_ptr<Base>& base);
+  ~EventPumpThread();
+
+ private:
+  void Pump();
+
+  const std::shared_ptr<Base> base_;
+  std::thread pump_thread_;
+
+  DISALLOW_COPY_AND_ASSIGN(EventPumpThread);
+};
+
+
+}  // namespace libevent
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_LIBEVENT_WRAPPER_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/libevent_wrapper_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/libevent_wrapper_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/libevent_wrapper_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/libevent_wrapper_test.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,67 @@
+#include "util/libevent_wrapper.h"
+
+#include <gtest/gtest.h>
+
+#include "util/testing.h"
+
+namespace cert_trans {
+namespace libevent {
+
+void DoNothing() {
+}
+
+class LibEventWrapperTest : public ::testing::Test {
+ public:
+  void ExpectToBeOnEventThread(const bool expect) {
+    EXPECT_EQ(expect, Base::OnEventThread());
+  }
+
+  void DispatchAnotherBase() {
+    std::shared_ptr<Base> base(std::make_shared<Base>());
+    base->Add(std::bind(&DoNothing));
+    base->DispatchOnce();
+  }
+};
+
+typedef class LibEventWrapperTest LibEventWrapperDeathTest;
+
+
+TEST_F(LibEventWrapperTest, TestOnEventThread) {
+  ExpectToBeOnEventThread(false);
+  std::shared_ptr<Base> base(std::make_shared<Base>());
+  base->Add(
+      std::bind(&LibEventWrapperTest::ExpectToBeOnEventThread, this, true));
+  base->DispatchOnce();
+}
+
+
+TEST_F(LibEventWrapperTest, TestTurtlesAllTheWayDown) {
+  ExpectToBeOnEventThread(false);
+  std::shared_ptr<Base> base(std::make_shared<Base>());
+  base->Add(std::bind(&LibEventWrapperTest::DispatchAnotherBase, this));
+  base->DispatchOnce();
+}
+
+
+TEST_F(LibEventWrapperDeathTest, TestCheckNotOnEventThread) {
+  // Should be fine:
+  Base::CheckNotOnEventThread();
+  // But...
+  EXPECT_DEATH(
+      {
+        std::shared_ptr<Base> base(std::make_shared<Base>());
+        base->Add(std::bind(&Base::CheckNotOnEventThread));
+        base->DispatchOnce();
+      },
+      "OnEventThread");
+}
+
+
+}  // namespace libevent
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/masterelection.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/masterelection.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/masterelection.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/masterelection.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,553 @@
+#include "util/masterelection.h"
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <climits>
+#include <functional>
+
+#include "monitoring/monitoring.h"
+#include "util/periodic_closure.h"
+
+namespace cert_trans {
+
+using cert_trans::Gauge;
+using std::bind;
+using std::chrono::seconds;
+using std::mutex;
+using std::placeholders::_1;
+using std::placeholders::_2;
+using std::shared_ptr;
+using std::string;
+using std::unique_lock;
+using std::unique_ptr;
+using std::vector;
+using util::Task;
+
+DEFINE_int32(master_keepalive_interval_seconds, 60,
+             "Interval between refreshing mastership proposal.");
+DEFINE_int32(masterelection_retry_delay_seconds, 5,
+             "Seconds to delay before retrying a failed attempt to create a "
+             "proposal file.");
+
+namespace {
+
+static Gauge<>* is_master_gauge(
+    Gauge<>::New("master", "Non-zero if this node is currently the master."));
+
+
+static Gauge<>* participating_in_election_gauge(
+    Gauge<>::New("participating_in_election",
+                 "Non-zero if this node is currently participating in the "
+                 "masterelection."));
+
+static Counter<>* proposal_creation_failures(
+    Counter<>::New("election_proposal_creation_failures",
+                   "Total number of failures to create an election "
+                   "proposal."));
+
+
+// Special backing string which indicates that we're not backing any proposal.
+const char kNoBacking[] = "";
+
+
+// Returns |s| with a '/' appended if the last char is not already a '/'
+string EnsureEndsWithSlash(const string& s) {
+  if (s.empty() || s.back() != '/') {
+    return s + '/';
+  } else {
+    return s;
+  }
+}
+
+
+}  // namespace
+
+
+std::ostream& operator<<(std::ostream& output,
+                         MasterElection::ProposalState state) {
+  switch (state) {
+    case MasterElection::ProposalState::NONE:
+      output << "NONE";
+      break;
+    case MasterElection::ProposalState::AWAITING_CREATION:
+      output << "AWAITING_CREATION";
+      break;
+    case MasterElection::ProposalState::CREATING:
+      output << "CREATING";
+      break;
+    case MasterElection::ProposalState::UP_TO_DATE:
+      output << "UP_TO_DATE";
+      break;
+    case MasterElection::ProposalState::AWAITING_UPDATE:
+      output << "AWAITING_UPDATE";
+      break;
+    case MasterElection::ProposalState::UPDATING:
+      output << "UPDATING";
+      break;
+    case MasterElection::ProposalState::AWAITING_DELETE:
+      output << "AWAITING_DELETE";
+      break;
+    case MasterElection::ProposalState::DELETING:
+      output << "DELETING";
+      break;
+  }
+
+  return output;
+}
+
+
+MasterElection::MasterElection(const shared_ptr<libevent::Base>& base,
+                               EtcdClient* client, const string& proposal_dir,
+                               const string& node_id)
+    : base_(base),
+      client_(CHECK_NOTNULL(client)),
+      proposal_dir_(EnsureEndsWithSlash(proposal_dir)),
+      my_proposal_path_(proposal_dir_ + node_id),
+      proposal_state_(ProposalState::NONE),
+      running_(false),
+      backed_proposal_(kNoBacking),
+      is_master_(false) {
+  CHECK_NE(kNoBacking, node_id);
+  is_master_gauge->Set(0);
+  participating_in_election_gauge->Set(0);
+}
+
+
+// Testing only c'tor
+MasterElection::MasterElection()
+    : client_(nullptr), proposal_state_(ProposalState::NONE) {
+}
+
+
+MasterElection::~MasterElection() {
+  VLOG(1) << my_proposal_path_ << ": Destroying election";
+  CHECK_EQ(proposal_state_, ProposalState::NONE);
+  VLOG(1) << "~" << my_proposal_path_;
+}
+
+
+void MasterElection::StartElection() {
+  {
+    unique_lock<mutex> lock(mutex_);
+    if (running_) {
+      return;
+    }
+    VLOG(1) << my_proposal_path_ << ": Joining election";
+    running_ = true;
+    participating_in_election_gauge->Set(1);
+
+    Transition(lock, ProposalState::AWAITING_CREATION);
+  }
+  base_->Add(bind(&MasterElection::CreateProposal, this));
+}
+
+
+void MasterElection::StopElection() {
+  unique_lock<mutex> lock(mutex_);
+  if (!running_) {
+    return;
+  }
+  VLOG(1) << my_proposal_path_ << ": Departing election.";
+  running_ = false;
+  participating_in_election_gauge->Set(0);
+
+  // Stop the updates from the watch. Do this without holding the lock
+  // because the watch callback takes that lock. This means that we'll
+  // stop updating our proposal, and maybe delay a master election,
+  // but that's okay, as we're about to delete our proposal
+  // altogether.
+  lock.unlock();
+  VLOG(1) << my_proposal_path_ << ": Cancelling watch...";
+  proposal_watch_->Cancel();
+  proposal_watch_->Wait();
+  proposal_watch_.reset();
+
+  lock.lock();
+  is_master_ = false;
+  is_master_cv_.notify_all();
+
+  // But wait for any in-flight updates to finish
+  VLOG(1) << my_proposal_path_ << ": waiting for in-flight proposal update "
+          << "to complete.";
+  proposal_state_cv_.wait(lock, [this]() {
+    return proposal_state_ == ProposalState::UP_TO_DATE;
+  });
+
+  // No more refresh callbacks (this is not synchronous, the refresh
+  // callback might be running right now, trying to lock the mutex, so
+  // the callback has to be able to handle itself after we've
+  // stopped):
+  proposal_refresh_callback_.reset();
+
+  // Delete our proposal so we can't accidentally become master after we've
+  // left:
+  Transition(lock, ProposalState::AWAITING_DELETE);
+  base_->Add(bind(&MasterElection::DeleteProposal, this));
+  // Wait for the proposal to actually be deleted before we return.
+  VLOG(1) << my_proposal_path_ << ": Waiting for delete to complete.";
+  proposal_state_cv_.wait(lock, [this]() {
+    return proposal_state_ == ProposalState::NONE;
+  });
+  VLOG(1) << my_proposal_path_ << ": Departed election.";
+}
+
+
+bool MasterElection::WaitToBecomeMaster() const {
+  VLOG(1) << my_proposal_path_ << ": Waiting to become master";
+  unique_lock<mutex> lock(mutex_);
+  // We'll unblock if either we're master, or someone stopped the election.
+  is_master_cv_.wait(lock,
+                     [this, &lock]() { return IsMaster(lock) || !running_; });
+  return IsMaster(lock);
+}
+
+
+bool MasterElection::IsMaster() const {
+  unique_lock<mutex> lock(mutex_);
+  return IsMaster(lock);
+}
+
+
+bool MasterElection::IsMaster(const unique_lock<mutex>& lock) const {
+  CHECK(lock.owns_lock());
+  return is_master_;
+}
+
+
+void MasterElection::Transition(const unique_lock<mutex>& lock,
+                                const ProposalState to) {
+  CHECK(lock.owns_lock());
+  VLOG(1) << my_proposal_path_ << ": Transition " << proposal_state_ << " -> "
+          << to;
+  switch (proposal_state_) {
+    case ProposalState::NONE:
+      CHECK_EQ(to, ProposalState::AWAITING_CREATION);
+      break;
+    case ProposalState::AWAITING_CREATION:
+      CHECK_EQ(to, ProposalState::CREATING);
+      break;
+    case ProposalState::CREATING:
+      CHECK(to == ProposalState::AWAITING_CREATION ||
+            to == ProposalState::UP_TO_DATE)
+          << "proposal_state_: " << proposal_state_ << " to: " << to;
+      break;
+    case ProposalState::UP_TO_DATE:
+      CHECK(to == ProposalState::AWAITING_UPDATE ||
+            to == ProposalState::AWAITING_DELETE)
+          << "proposal_state_: " << proposal_state_ << " to: " << to;
+      break;
+    case ProposalState::AWAITING_UPDATE:
+      CHECK_EQ(to, ProposalState::UPDATING);
+      break;
+    case ProposalState::UPDATING:
+      CHECK_EQ(to, ProposalState::UP_TO_DATE);
+      break;
+    case ProposalState::AWAITING_DELETE:
+      CHECK_EQ(to, ProposalState::DELETING);
+      break;
+    case ProposalState::DELETING:
+      CHECK_EQ(to, ProposalState::NONE);
+      break;
+    default:
+      CHECK(false) << "Unknown state: " << proposal_state_;
+  }
+  proposal_state_ = to;
+  proposal_state_cv_.notify_all();
+}
+
+
+void MasterElection::CreateProposal() {
+  unique_lock<mutex> lock(mutex_);
+  Transition(lock, ProposalState::CREATING);
+
+  // We'll create an empty file indicating we're not backing anyone, so as to
+  // avoid disrupting an existing settled election.
+  // Technically this could already exist if we had mastership before, crashed,
+  // and then restarted before the TTL expired.
+  EtcdClient::Response* const resp(new EtcdClient::Response);
+  client_->CreateWithTTL(
+      my_proposal_path_, kNoBacking,
+      seconds(FLAGS_master_keepalive_interval_seconds * 2), resp,
+      new Task(bind(&MasterElection::ProposalCreateDone, this, resp, _1),
+               base_.get()));
+}
+
+
+void MasterElection::ProposalCreateDone(EtcdClient::Response* resp,
+                                        Task* task) {
+  unique_ptr<EtcdClient::Response> resp_deleter(resp);
+  unique_ptr<Task> task_deleter(task);
+  unique_lock<mutex> lock(mutex_);
+
+  if (!task->status().ok()) {
+    proposal_creation_failures->Increment();
+    Transition(lock, ProposalState::AWAITING_CREATION);
+    LOG(WARNING) << "Problem creating proposal: " << task->status() << " "
+                 << "will retry.";
+    base_->Delay(seconds(FLAGS_masterelection_retry_delay_seconds),
+                 new Task(bind(&MasterElection::CreateProposal, this),
+                          base_.get()));
+    return;
+  }
+
+  Transition(lock, ProposalState::UP_TO_DATE);
+
+  VLOG(1) << my_proposal_path_ << ": Mastership proposal created at index "
+          << resp->etcd_index;
+
+  my_proposal_modified_index_ = my_proposal_create_index_ = resp->etcd_index;
+  // Start a periodic callback to keep our proposal from being garbage
+  // collected
+  CHECK(!proposal_refresh_callback_);
+  VLOG(1) << my_proposal_path_ << ": Creating refresh Callback";
+  proposal_refresh_callback_.reset(new PeriodicClosure(
+      base_, seconds(FLAGS_master_keepalive_interval_seconds),
+      bind(&MasterElection::ProposalKeepAliveCallback, this)));
+
+  // Watch the proposal directory so we're aware of other proposals
+  // coming and going
+  VLOG(1) << my_proposal_path_ << ": Watching proposals";
+  CHECK(!proposal_watch_);
+  proposal_watch_.reset(new util::SyncTask(base_.get()));
+  client_->Watch(proposal_dir_,
+                 bind(&MasterElection::OnProposalUpdate, this, _1),
+                 proposal_watch_->task());
+  VLOG(1) << my_proposal_path_ << ": Joined election";
+}
+
+
+bool MasterElection::MaybeUpdateProposal(const unique_lock<mutex>& lock,
+                                         const string& backed) {
+  CHECK(lock.owns_lock());
+  if (proposal_state_ == ProposalState::UPDATING ||
+      proposal_state_ == ProposalState::AWAITING_UPDATE) {
+    // Don't want to have more than one proposal update happening at
+    // the same time so we'll just bail this one.  It's ok, though,
+    // because the currently in-flight update will cause a call to
+    // ProposalUpdate() via the watch which should prompt another
+    // update attempt if it turns out to still be necessary.
+    VLOG(1) << my_proposal_path_ << ": Dropping proposal update backing "
+            << backed << " because already have a proposal update in "
+            << "flight.";
+    return false;
+  }
+  Transition(lock, ProposalState::AWAITING_UPDATE);
+  base_->Add(bind(&MasterElection::UpdateProposal, this, backed));
+  return true;
+}
+
+
+void MasterElection::UpdateProposal(const string& backed) {
+  unique_lock<mutex> lock(mutex_);
+  Transition(lock, ProposalState::UPDATING);
+
+  VLOG(1) << my_proposal_path_ << ": Updating proposal backing " << backed;
+
+  // TODO(alcutter): Set the HTTP timeout inside here to something sensible.
+  EtcdClient::Response* const resp(new EtcdClient::Response);
+  client_->UpdateWithTTL(my_proposal_path_, backed,
+                         seconds(FLAGS_master_keepalive_interval_seconds * 2),
+                         my_proposal_modified_index_, resp,
+                         new Task(bind(&MasterElection::ProposalUpdateDone,
+                                       this, resp, _1),
+                                  base_.get()));
+}
+
+
+void MasterElection::ProposalUpdateDone(EtcdClient::Response* resp,
+                                        Task* task) {
+  unique_ptr<EtcdClient::Response> resp_deleter(resp);
+  unique_lock<mutex> lock(mutex_);
+  // TODO(alcutter): Handle this
+  CHECK(task->status().ok()) << my_proposal_path_ << ": " << task->status();
+  Transition(lock, ProposalState::UP_TO_DATE);
+
+  // Keep a note of the current modification index of our proposal since
+  // we'll need it in order to update or delete the proposal
+  my_proposal_modified_index_ = resp->etcd_index;
+  VLOG(1) << my_proposal_path_ << ": Proposal refreshed @ "
+          << resp->etcd_index;
+}
+
+
+void MasterElection::DeleteProposal() {
+  unique_lock<mutex> lock(mutex_);
+  Transition(lock, ProposalState::DELETING);
+
+  VLOG(1) << my_proposal_path_ << ": Deleting proposal";
+  client_->Delete(my_proposal_path_, my_proposal_modified_index_,
+                  new Task(bind(&MasterElection::ProposalDeleteDone, this, _1),
+                           base_.get()));
+}
+
+
+void MasterElection::ProposalDeleteDone(Task* task) {
+  unique_lock<mutex> lock(mutex_);
+  if (!task->status().ok()) {
+    LOG(WARNING) << "error deleting proposal: " << task->status();
+  }
+
+  VLOG(1) << my_proposal_path_ << ": Delete done.";
+
+  // Now clean up
+  my_proposal_create_index_ = -1;
+  proposals_.clear();
+  Transition(lock, ProposalState::NONE);
+}
+
+
+void MasterElection::ProposalKeepAliveCallback() {
+  unique_lock<mutex> lock(mutex_);
+  VLOG(1) << my_proposal_path_ << ": Proposal Keep-Alive fired.";
+  if (!running_) {
+    VLOG(1) << my_proposal_path_
+            << ": But we're not running so bailing on updates.";
+    return;
+  }
+
+  MaybeUpdateProposal(lock, backed_proposal_);
+}
+
+
+void MasterElection::UpdateProposalView(
+    const vector<EtcdClient::Node>& updates) {
+  for (const auto& update : updates) {
+    if (!update.deleted_) {
+      VLOG(1) << my_proposal_path_
+              << ": Proposal updated: " << update.ToString();
+      proposals_[update.key_] = update;
+    } else {
+      VLOG(1) << my_proposal_path_
+              << ": Proposal deleted: " << update.ToString();
+      CHECK_EQ(static_cast<size_t>(1), proposals_.erase(update.key_))
+          << my_proposal_path_
+          << ": Unknown proposal deleted: " << update.ToString();
+    }
+  }
+}
+
+
+bool MasterElection::DetermineApparentMaster(
+    EtcdClient::Node* apparent_master) const {
+  EtcdClient::Node tmp_master(INT_MAX, INT_MAX, "", false, "", {}, true);
+  bool found(false);
+  for (const auto& pair : proposals_) {
+    CHECK_EQ(pair.first, pair.second.key_);
+    if (pair.second.created_index_ < tmp_master.created_index_) {
+      found = true;
+      tmp_master = pair.second;
+    }
+  }
+  if (found) {
+    *apparent_master = tmp_master;
+  }
+  return found;
+}
+
+
+void MasterElection::OnProposalUpdate(
+    const vector<EtcdClient::Node>& updates) {
+  unique_lock<mutex> lock(mutex_);
+  CHECK_GE(updates.size(), static_cast<size_t>(1));
+  VLOG(1) << my_proposal_path_ << ": Got " << updates.size() << " update(s)";
+  if (!running_) {
+    VLOG(1) << my_proposal_path_
+            << ": But we're not running so bailing on updates.";
+    return;
+  }
+
+  // First, update our view of the proposals:
+  UpdateProposalView(updates);
+
+  // Now figure out who we think the master should be based on proposal
+  // creation indicies:
+  EtcdClient::Node apparent_master;
+  if (!DetermineApparentMaster(&apparent_master)) {
+    // Doesn't look like there are any proposals, so nothing to do.
+    // Probably shouldn't really happen, but it could be that our proposal got
+    // cleaned up because we failed to refresh it before the TTL expired.
+    VLOG(1) << my_proposal_path_
+            << ": No proposals to consider; no master currently";
+    // Since nobody is a master, that includes us:
+    is_master_ = false;
+    is_master_gauge->Set(0);
+    return;
+  }
+
+  // Do we have to update our public statement about who we're backing?
+  if (backed_proposal_ != apparent_master.key_) {
+    // Yep, looks like the situation has changed
+    VLOG(1) << my_proposal_path_ << ": Backed proposal (" << backed_proposal_
+            << ") != apparent_master (" << apparent_master.key_ << "), "
+            << is_master_;
+    // Try to update our proposal to show our support of the apparent master.
+    // If this fails it'll be because there's already an update in-flight, so
+    // we'll get notified of that shortly and end up here agin, at which point
+    // we can try again.
+    if (MaybeUpdateProposal(lock, apparent_master.key_)) {
+      // We managed to send the the update so store our backing here so we
+      // don't continually fire off 'updates' saying the same thing
+      backed_proposal_ = apparent_master.key_;
+    }
+    // Since we changed our mind about who to back, that means there's not
+    // currently consensus, so we can't be a master either.
+    // Strictly this might not be true - if everyone else already voted for us
+    // we could short circuit and set this true here, but there's no really
+    // anything to be gained from that other than more complex code.
+    is_master_ = false;
+    is_master_gauge->Set(0);
+    return;
+  }
+
+  // Check to see whether the apparent master from the previous stage is backed
+  // by all participating nodes:
+  CHECK(!proposals_.empty());
+  // Check if everyone is in agreement about who the master is:
+  for (const auto& pair : proposals_) {
+    // Discount any participant who has explicitly abstained from the vote.
+    // This is because participants who have just joined the election will not
+    // have had a chance to decide who to back, this would cause temporary
+    // blibs to No Master for the election each time a new participant joined,
+    // so we allow them to abstain from the vote, they should then analyze the
+    // situation and update their proposal with new backing info, at which
+    // point everybody will run OnProposalUpdate() and check for
+    // consensus again.
+    if (pair.second.value_ == kNoBacking) {
+      continue;
+    }
+    if (pair.second.value_ != apparent_master.key_) {
+      // Whoops, we don't have agreement: nobody is a master at the moment.
+      // In effect, we're now waiting for everybody to update their proposals
+      // an reach agreement for who the master is, or, possibly, for the
+      // dissenting participants (who have probably just crashed/wedged) to
+      // have their proposals expired by etcd.
+      VLOG(1) << my_proposal_path_ << ": No master currently, " << is_master_;
+      VLOG(1) << my_proposal_path_ << ": Apparent master is "
+              << apparent_master.key_ << " but " << pair.first
+              << " is backing: " << pair.second.value_;
+      // No master, so we can't be master
+      is_master_ = false;
+      is_master_gauge->Set(0);
+      return;
+    }
+  }
+
+  // There must be consensus about who the master is now.
+  VLOG(2) << my_proposal_path_ << ": Agreed that master is "
+          << apparent_master.key_;
+  current_master_ = apparent_master;
+
+  // Finally, determine if we're the master, and wake up anyone blocked in
+  // WaitToBecomeMaster() if so:
+  is_master_ = running_ &&
+               (apparent_master.key_ == my_proposal_path_ &&
+                apparent_master.created_index_ == my_proposal_create_index_);
+  if (is_master_) {
+    LOG(INFO) << my_proposal_path_ << ": Became master";
+    is_master_gauge->Set(1);
+    is_master_cv_.notify_all();
+  }
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/masterelection.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/masterelection.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/masterelection.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/masterelection.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,169 @@
+#ifndef CERT_TRANS_UTIL_MASTERELECTION_H_
+#define CERT_TRANS_UTIL_MASTERELECTION_H_
+
+#include <stdint.h>
+#include <condition_variable>
+#include <memory>
+#include <mutex>
+#include <string>
+#include <thread>
+#include <vector>
+
+#include "util/etcd.h"
+#include "util/sync_task.h"
+
+
+namespace cert_trans {
+
+class PeriodicClosure;
+
+// Implements a simple MasterElection scheme.
+//
+// Candidates participate by creating a proposal at |my_proposal_path_|, this
+// will have an associated creation index (stored in my_proposal_create_index_)
+// assigned by etcd.
+//
+// In order for a participant to become master, firstly it must have the
+// proposal with the lowest creation index (this favours more stable
+// participants), and secondly all other participants must agree that it should
+// be master by updating their proposal files to contain the path of the
+// winning candidate's proposal file.  This provides some protection against
+// there being multiple masters due to some classes of bug or network issues.
+//
+// Proposals are created with a TTL, after which, if they've not had their TTL
+// updated in the meantime, they will be automatically deleted by etcd.
+// This helps to detect failed candidates and clear up after them.
+// In order to keep this from happening to live candidates, each instance
+// maintains a periodic callback whose sole job is to update the TTL on its
+// proposal file.
+//
+// TODO(alcutter): Some enhancements:
+//   - Recover gracefully from a crash where an old proposal exists for this
+//     node (e.g. recover and continue, or delete it, or wait, ...)
+class MasterElection {
+ public:
+  // No transfer of ownership.
+  MasterElection(const std::shared_ptr<libevent::Base>& base,
+                 EtcdClient* client, const std::string& lock_dir,
+                 const std::string& node_id);
+
+  virtual ~MasterElection();
+
+  // Signals that we want to participate in the election.
+  virtual void StartElection();
+
+  // Signals that we no longer want to participate in the election.
+  // Should never be called from the libevent thread.
+  virtual void StopElection();
+
+  // Blocks until this instance has become master or the election has been
+  // stopped.
+  // Returns true iff we're master at the time the call returns.
+  virtual bool WaitToBecomeMaster() const;
+
+  // Returns true iff this instance is currently master at the time of the
+  // call.
+  virtual bool IsMaster() const;
+
+ protected:
+  MasterElection();
+
+ private:
+  // The states that the proposal can be in:
+  enum class ProposalState {
+    NONE,               // There is no proposal
+    AWAITING_CREATION,  // We want to create a proposal
+    CREATING,           // We're in the process of creating the proposal
+    UP_TO_DATE,         // The proposal is current
+    AWAITING_UPDATE,    // We'd like to update the proposal
+    UPDATING,           // We're updating the proposal
+    AWAITING_DELETE,    // We'd like to delete the proposal
+    DELETING,           // We're deleting the proposal
+  };
+
+  // Performs a transition between the current proposal state, and |to|.
+  // Checks that the requested transition is valid.
+  void Transition(const std::unique_lock<std::mutex>& lock,
+                  const ProposalState to);
+
+  // Creates the proposal.
+  // This should only be called on the base_ event thread.
+  void CreateProposal();
+
+  // Called once our proposal file has been created.
+  void ProposalCreateDone(EtcdClient::Response* resp, util::Task* task);
+
+  // Will call UpdateProposal iff there is currently no other proposal update
+  // in-flight.  |backed| should contain the id of the proposal this node is
+  // backing.
+  bool MaybeUpdateProposal(const std::unique_lock<std::mutex>& lock,
+                           const std::string& backed);
+
+  // Updates this node's proposal.  |backed| should contain the id of the
+  // proposal this node is backing.
+  // This should only be called on the base_ event thread.
+  void UpdateProposal(const std::string& backed);
+
+  // Called when our proposal file has been refreshed by the KeepAlive thread.
+  void ProposalUpdateDone(EtcdClient::Response* resp, util::Task* task);
+
+  // Deletes this node's proposal.
+  // This should only be called on the base_ event thread.
+  void DeleteProposal();
+
+  // Called once our proposal file has been deleted from the proposal
+  // directory.
+  void ProposalDeleteDone(util::Task* task);
+
+  // Thread entry point for the periodic callback to refresh the proposal TTL.
+  void ProposalKeepAliveCallback();
+
+  // Updates our local view of the election proposals.
+  void UpdateProposalView(const std::vector<EtcdClient::Node>& updates);
+
+  // Works out which proposal /should/ be master based on created_index_.
+  // Returns true iff there was an apparent master, false otherwise.
+  bool DetermineApparentMaster(EtcdClient::Node* apparent_master) const;
+
+  // Called by the EtcdClient whenever there's been a change in one or
+  // more of the proposal files.
+  void OnProposalUpdate(const std::vector<EtcdClient::Node>& updates);
+
+  // Internal non-locking accessor for is_master_
+  bool IsMaster(const std::unique_lock<std::mutex>& lock) const;
+
+  const std::shared_ptr<libevent::Base> base_;
+  EtcdClient* const client_;  // Not owned by us.
+  const std::string proposal_dir_;
+  const std::string my_proposal_path_;
+
+  mutable std::mutex mutex_;
+  ProposalState proposal_state_;
+  mutable std::condition_variable proposal_state_cv_;
+
+  // Any thread wanting to know whether we're master should wait on this CV.
+  mutable std::condition_variable is_master_cv_;
+  bool running_;
+
+  std::unique_ptr<PeriodicClosure> proposal_refresh_callback_;
+  std::unique_ptr<util::SyncTask> proposal_watch_;
+
+  // Our local copy of the proposals
+  std::map<std::string, EtcdClient::Node> proposals_;
+
+  int64_t my_proposal_create_index_;
+  int64_t my_proposal_modified_index_;
+
+  std::string backed_proposal_;
+
+  bool is_master_;
+  EtcdClient::Node current_master_;
+
+  friend class ElectionTest;
+  friend std::ostream& operator<<(std::ostream& output, ProposalState state);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_MASTERELECTION_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/masterelection_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/masterelection_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/masterelection_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/masterelection_test.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,332 @@
+#include "util/masterelection.h"
+
+#include <event2/thread.h>
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <atomic>
+#include <map>
+#include <string>
+
+#include "base/notification.h"
+#include "util/etcd.h"
+#include "util/fake_etcd.h"
+#include "util/periodic_closure.h"
+#include "util/status_test_util.h"
+#include "util/testing.h"
+#include "util/thread_pool.h"
+
+DECLARE_string(trusted_root_certs);
+DEFINE_string(cert_dir, "test/testdata/urlfetcher_test_certs",
+              "Directory containing the test certs.");
+
+namespace cert_trans {
+
+using cert_trans::Notification;
+using std::atomic;
+using std::bind;
+using std::chrono::seconds;
+using std::function;
+using std::make_shared;
+using std::map;
+using std::placeholders::_1;
+using std::placeholders::_2;
+using std::shared_ptr;
+using std::string;
+using std::thread;
+using std::to_string;
+using std::unique_ptr;
+using std::vector;
+using testing::AllOf;
+using testing::Contains;
+using testing::InvokeArgument;
+using testing::Pair;
+using testing::_;
+using util::Status;
+using util::SyncTask;
+
+
+const char kProposalDir[] = "/master/";
+
+DEFINE_string(etcd, "", "etcd server address");
+DEFINE_int32(etcd_port, 4001, "etcd server port");
+DECLARE_int32(master_keepalive_interval_seconds);
+DECLARE_int32(masterelection_retry_delay_seconds);
+
+
+// Simple helper class, represents a thread of interest in participating in
+// an election.
+struct Participant {
+  // Constructs a new MasterElection object, and immediately starts
+  // participating in the election.
+  Participant(const string& dir, const string& id,
+              const shared_ptr<libevent::Base>& base, EtcdClient* client)
+      : base_(base),
+        client_(CHECK_NOTNULL(client)),
+        election_(new MasterElection(base_, client_, dir, id)),
+        dir_(dir),
+        id_(id),
+        mastership_count_(0) {
+    EXPECT_FALSE(election_->IsMaster()) << id_;
+  }
+
+  void StartElection() {
+    election_->StartElection();
+  }
+
+  void StopElection() {
+    VLOG(1) << id_ << " about to StopElection().";
+    election_->StopElection();
+    VLOG(1) << id_ << " completed StopElection().";
+    EXPECT_FALSE(election_->IsMaster()) << id_;
+  }
+
+  // Wait to become the boss!
+  void ElectLikeABoss() {
+    StartElection();
+    VLOG(1) << id_ << " about to WaitToBecomeMaster().";
+    election_->WaitToBecomeMaster();
+    EXPECT_TRUE(election_->IsMaster()) << id_;
+    ++mastership_count_;
+    VLOG(1) << id_ << " completed WaitToBecomeMaster().";
+  }
+
+  bool WaitToBecomeMaster() {
+    return election_->WaitToBecomeMaster();
+  }
+
+  bool IsMaster() {
+    return election_->IsMaster();
+  }
+
+  void ElectionMania(int num_rounds,
+                     const vector<unique_ptr<Participant>>* all_participants) {
+    notification_.reset(new Notification);
+    mania_thread_.reset(new thread([this, num_rounds, all_participants]() {
+      for (int round(0); round < num_rounds; ++round) {
+        VLOG(1) << id_ << " starting round " << round;
+        ElectLikeABoss();
+
+        int num_masters(0);
+        for (const auto& participant : *all_participants) {
+          if (participant->election_->IsMaster()) {
+            ++num_masters;
+          }
+        }
+        // There /could/ be no masters if an update happened after we came
+        // out of WaitToBecomeMaster, it's unlikely but possible.
+        // There definitely shouldn't be > 1 master EVER, though.
+        CHECK_LE(num_masters, 1) << "From the PoV of " << id_;
+        StopElection();
+        VLOG(1) << id_ << " finished round " << round;
+        // Restarting an existing MasterElection and creating a new
+        // one should both work, so test both cases on various rounds.
+        if ((round % 2) == 0) {
+          election_.reset(new MasterElection(base_, client_, dir_, id_));
+        }
+      }
+      VLOG(1) << id_ << " Mania over!";
+      notification_->Notify();
+    }));
+  }
+
+  void WaitForManiaToEnd() {
+    CHECK(notification_);
+    notification_->WaitForNotification();
+    mania_thread_->join();
+    mania_thread_.reset();
+  }
+
+  const shared_ptr<libevent::Base>& base_;
+  EtcdClient* const client_;
+  unique_ptr<MasterElection> election_;
+  unique_ptr<Notification> notification_;
+  unique_ptr<thread> mania_thread_;
+  const string dir_;
+  const string id_;
+  atomic<int> mastership_count_;
+};
+
+
+class ElectionTest : public ::testing::Test {
+ public:
+  ElectionTest()
+      : base_(make_shared<libevent::Base>()),
+        event_pump_(base_),
+        pool_(),
+        url_fetcher_(base_.get(), &pool_),
+        client_(FLAGS_etcd.empty()
+                    ? new FakeEtcdClient(base_.get())
+                    : new EtcdClient(&pool_, &url_fetcher_, FLAGS_etcd,
+                                     FLAGS_etcd_port)) {
+  }
+
+
+ protected:
+  void KillProposalRefresh(Participant* p) {
+    p->election_->proposal_refresh_callback_.reset();
+  }
+
+
+  shared_ptr<libevent::Base> base_;
+  libevent::EventPumpThread event_pump_;
+  ThreadPool pool_;
+  UrlFetcher url_fetcher_;
+  atomic<bool> running_;
+  const unique_ptr<EtcdClient> client_;
+};
+
+
+typedef class ElectionTest ElectionDeathTest;
+
+
+TEST_F(ElectionTest, SingleInstanceBecomesMaster) {
+  Participant one(kProposalDir, "1", base_, client_.get());
+  EXPECT_FALSE(one.IsMaster());
+
+  one.ElectLikeABoss();
+  EXPECT_TRUE(one.IsMaster());
+
+  one.StopElection();
+  EXPECT_FALSE(one.IsMaster());
+}
+
+
+TEST_F(ElectionTest, MultiInstanceElection) {
+  Participant one(kProposalDir, "1", base_, client_.get());
+  one.ElectLikeABoss();
+  EXPECT_TRUE(one.IsMaster());
+
+  Participant two(kProposalDir, "2", base_, client_.get());
+  two.StartElection();
+  sleep(1);
+  EXPECT_FALSE(two.IsMaster());
+
+  Participant three(kProposalDir, "3", base_, client_.get());
+  three.StartElection();
+  sleep(1);
+  EXPECT_FALSE(three.IsMaster());
+
+  EXPECT_TRUE(one.IsMaster());
+
+  one.StopElection();
+  EXPECT_FALSE(one.IsMaster());
+
+  EXPECT_TRUE(two.WaitToBecomeMaster());
+  EXPECT_FALSE(one.IsMaster());
+  EXPECT_TRUE(two.IsMaster());
+  EXPECT_FALSE(three.IsMaster());
+
+  two.StopElection();
+  EXPECT_FALSE(two.IsMaster());
+
+  EXPECT_TRUE(three.WaitToBecomeMaster());
+  EXPECT_FALSE(one.IsMaster());
+  EXPECT_FALSE(two.IsMaster());
+  EXPECT_TRUE(three.IsMaster());
+
+  three.StopElection();
+  EXPECT_FALSE(three.IsMaster());
+
+  sleep(2);
+  EXPECT_FALSE(one.IsMaster());
+  EXPECT_FALSE(two.IsMaster());
+  EXPECT_FALSE(three.IsMaster());
+}
+
+
+TEST_F(ElectionTest, RejoinElection) {
+  Participant one(kProposalDir, "1", base_, client_.get());
+  EXPECT_FALSE(one.IsMaster());
+
+  one.ElectLikeABoss();
+  EXPECT_TRUE(one.IsMaster());
+
+  one.StopElection();
+  EXPECT_FALSE(one.IsMaster());
+
+  // Join in again:
+  one.ElectLikeABoss();
+  EXPECT_TRUE(one.IsMaster());
+
+  one.StopElection();
+  EXPECT_FALSE(one.IsMaster());
+}
+
+
+TEST_F(ElectionTest, OkToCallStartAndStopElectionMultipleTimes) {
+  Participant one(kProposalDir, "1", base_, client_.get());
+  one.StartElection();
+  one.WaitToBecomeMaster();
+  EXPECT_TRUE(one.IsMaster());
+  one.StartElection();
+  EXPECT_TRUE(one.IsMaster());
+
+  one.StopElection();
+  EXPECT_FALSE(one.IsMaster());
+  one.StopElection();
+  EXPECT_FALSE(one.IsMaster());
+}
+
+
+TEST_F(ElectionTest, RetresCreatingProposal) {
+  FLAGS_masterelection_retry_delay_seconds = 1;
+  {
+    EtcdClient::Response resp;
+    SyncTask task(base_.get());
+    client_->Create(string(kProposalDir) + "1", "", &resp, task.task());
+    task.Wait();
+    ASSERT_OK(task.status());
+  }
+
+  Participant one(kProposalDir, "1", base_, client_.get());
+  one.StartElection();
+  sleep(2);
+  EXPECT_FALSE(one.IsMaster());
+
+  {
+    SyncTask task(base_.get());
+    client_->ForceDelete(string(kProposalDir) + "1", task.task());
+    task.Wait();
+    ASSERT_OK(task.status());
+  }
+
+  sleep(2);
+
+  EXPECT_TRUE(one.IsMaster());
+  one.StopElection();
+}
+
+
+TEST_F(ElectionTest, ElectionMania) {
+  const int kNumRounds(20);
+  const int kNumParticipants(20);
+  vector<unique_ptr<Participant>> participants;
+  participants.reserve(kNumParticipants);
+  for (int i = 0; i < kNumParticipants; ++i) {
+    participants.emplace_back(
+        new Participant(kProposalDir, to_string(i), base_, client_.get()));
+  };
+
+  for (int i = 0; i < kNumParticipants; ++i) {
+    participants[i]->ElectionMania(kNumRounds, &participants);
+  }
+
+  for (int i = 0; i < kNumParticipants; ++i) {
+    LOG(INFO) << i << " became master " << participants[i]->mastership_count_
+              << " times.";
+    participants[i]->WaitForManiaToEnd();
+  }
+}
+
+
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  // Default value of trusted root certs may not be correct on all platforms
+  FLAGS_trusted_root_certs = FLAGS_cert_dir + "/ca-cert.pem";
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/mock_etcd.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/mock_etcd.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/mock_etcd.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/mock_etcd.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,47 @@
+#ifndef CERT_TRANS_UTIL_MOCK_ETCD_H_
+#define CERT_TRANS_UTIL_MOCK_ETCD_H_
+
+#include <gmock/gmock.h>
+
+#include "util/etcd.h"
+
+namespace cert_trans {
+
+
+class MockEtcdClient : public EtcdClient {
+ public:
+  MOCK_METHOD3(Get,
+               void(const Request& req, GetResponse* resp, util::Task* task));
+  MOCK_METHOD4(Create, void(const std::string& key, const std::string& value,
+                            Response* resp, util::Task* task));
+  MOCK_METHOD5(CreateWithTTL,
+               void(const std::string& key, const std::string& value,
+                    const std::chrono::seconds& ttl, Response* resp,
+                    util::Task* task));
+  MOCK_METHOD5(Update, void(const std::string& key, const std::string& value,
+                            const int64_t previous_index, Response* resp,
+                            util::Task* task));
+  MOCK_METHOD6(UpdateWithTTL,
+               void(const std::string& key, const std::string& value,
+                    const std::chrono::seconds& ttl,
+                    const int64_t previous_index, Response* resp,
+                    util::Task* task));
+  MOCK_METHOD4(ForceSet, void(const std::string& key, const std::string& value,
+                              Response* resp, util::Task* task));
+  MOCK_METHOD5(ForceSetWithTTL,
+               void(const std::string& key, const std::string& value,
+                    const std::chrono::seconds& ttl, Response* resp,
+                    util::Task* task));
+  MOCK_METHOD3(Delete, void(const std::string& key,
+                            const int64_t current_index, util::Task* task));
+  MOCK_METHOD2(ForceDelete, void(const std::string& key, util::Task* task));
+  MOCK_METHOD2(GetStoreStats,
+               void(EtcdClient::StatsResponse* resp, util::Task* task));
+  MOCK_METHOD3(Watch, void(const std::string& key, const WatchCallback& cb,
+                           util::Task* task));
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_MOCK_ETCD_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/mock_masterelection.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/mock_masterelection.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/mock_masterelection.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/mock_masterelection.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,23 @@
+#ifndef CERT_TRANS_UTIL_MOCK_MASTERELECTION_H_
+#define CERT_TRANS_UTIL_MOCK_MASTERELECTION_H_
+
+#include <gmock/gmock.h>
+
+#include "util/masterelection.h"
+
+namespace cert_trans {
+
+class MockMasterElection : public MasterElection {
+ public:
+  MockMasterElection() = default;
+
+  MOCK_METHOD0(StartElection, void());
+  MOCK_METHOD0(StopElection, void());
+  MOCK_CONST_METHOD0(WaitToBecomeMaster, bool());
+  MOCK_CONST_METHOD0(IsMaster, bool());
+};
+
+}  // namespace cert_trans
+
+
+#endif  // CERT_TRANS_UTIL_MOCK_MASTERELECTION_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/openssl_scoped_ssl_types.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/openssl_scoped_ssl_types.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/openssl_scoped_ssl_types.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/openssl_scoped_ssl_types.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,17 @@
+#ifndef CERT_TRANS_UTIL_OPENSSL_SSL_SCOPED_TYPES_H_
+#define CERT_TRANS_UTIL_OPENSSL_SSL_SCOPED_TYPES_H_
+
+#include <openssl/ssl.h>
+
+#include "util/openssl_scoped_types.h"
+
+namespace cert_trans {
+
+
+using ScopedSSL = ScopedOpenSSLType<SSL, SSL_free>;
+using ScopedSSL_CTX = ScopedOpenSSLType<SSL_CTX, SSL_CTX_free>;
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_OPENSSL_SSL_SCOPED_TYPES_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/openssl_scoped_types.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/openssl_scoped_types.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/openssl_scoped_types.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/openssl_scoped_types.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,188 @@
+/* Copyright (c) 2015, Google Inc.
+ *
+ * Permission to use, copy, modify, and/or distribute this software for any
+ * purpose with or without fee is hereby granted, provided that the above
+ * copyright notice and this permission notice appear in all copies.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+ * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+ * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
+ * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+ * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
+ * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
+ * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. */
+
+#ifndef CERT_TRANS_UTIL_OPENSSL_SCOPED_TYPES_H_
+#define CERT_TRANS_UTIL_OPENSSL_SCOPED_TYPES_H_
+
+#include <stdint.h>
+#include <stdio.h>
+#include <memory>
+
+#ifdef OPENSSL_IS_BORINGSSL
+#include <openssl/aead.h>
+#endif  // OPENSSL_IS_BORINGSSL
+#include <openssl/bio.h>
+#include <openssl/bn.h>
+#include <openssl/cmac.h>
+#include <openssl/dh.h>
+#include <openssl/ec.h>
+#ifdef OPENSSL_IS_BORINGSSL
+#include <openssl/ec_key.h>
+#endif  // OPENSSL_IS_BORINGSSL
+#include <openssl/ecdsa.h>
+#include <openssl/evp.h>
+#include <openssl/hmac.h>
+#ifdef OPENSSL_IS_BORINGSSL
+#include <openssl/mem.h>
+#endif  // OPENSSL_IS_BORINGSSL
+#ifdef OPENSSL_IS_BORINGSSL
+#include <openssl/pkcs8.h>
+#endif  // OPENSSL_IS_BORINGSSL
+#include <openssl/rsa.h>
+#include <openssl/stack.h>
+#include <openssl/x509.h>
+#include <openssl/x509v3.h>
+
+namespace cert_trans {
+
+
+template <typename T, void (*func)(T*)>
+struct OpenSSLDeleter {
+  void operator()(T* obj) {
+    func(obj);
+  }
+};
+
+template <typename StackType, typename T, void (*func)(T*)>
+struct OpenSSLStackDeleter {
+  void operator()(StackType* obj) {
+    sk_pop_free(reinterpret_cast<_STACK*>(obj),
+                reinterpret_cast<void (*)(void*)>(func));
+  }
+};
+
+template <typename StackType>
+struct OpenSSLWeakStackDeleter {
+  void operator()(StackType* obj) {
+    sk_free(reinterpret_cast<_STACK*>(obj));
+  }
+};
+
+template <typename T>
+struct OpenSSLFree {
+  void operator()(T* buf) {
+    OPENSSL_free(buf);
+  }
+};
+
+struct FileCloser {
+  void operator()(FILE* file) {
+    fclose(file);
+  }
+};
+
+template <typename T, void (*func)(T*)>
+using ScopedOpenSSLType = std::unique_ptr<T, OpenSSLDeleter<T, func>>;
+
+template <typename StackType, typename T, void (*func)(T*)>
+using ScopedOpenSSLStack =
+    std::unique_ptr<StackType, OpenSSLStackDeleter<StackType, T, func>>;
+
+// Deletes *only* the stack object, not its contents.
+template <typename StackType>
+using ScopedWeakOpenSSLStack =
+    std::unique_ptr<StackType, OpenSSLWeakStackDeleter<StackType>>;
+
+template <typename T, typename CleanupRet, void (*init_func)(T*),
+          CleanupRet (*cleanup_func)(T*)>
+class ScopedOpenSSLContext {
+ public:
+  ScopedOpenSSLContext() {
+    init_func(&ctx_);
+  }
+  ScopedOpenSSLContext(const ScopedOpenSSLContext& other) = delete;
+  ScopedOpenSSLContext(ScopedOpenSSLContext&& other) = delete;
+
+  ~ScopedOpenSSLContext() {
+    cleanup_func(&ctx_);
+  }
+
+  T* get() {
+    return &ctx_;
+  }
+  const T* get() const {
+    return &ctx_;
+  }
+
+  void Reset() {
+    cleanup_func(&ctx_);
+    init_func(&ctx_);
+  }
+
+ private:
+  T ctx_;
+};
+
+using ScopedASN1_OCTET_STRING =
+    ScopedOpenSSLType<ASN1_OCTET_STRING, ASN1_OCTET_STRING_free>;
+using ScopedBASIC_CONSTRAINTS =
+    ScopedOpenSSLType<BASIC_CONSTRAINTS, BASIC_CONSTRAINTS_free>;
+using ScopedBIO = ScopedOpenSSLType<BIO, BIO_vfree>;
+using ScopedBIGNUM = ScopedOpenSSLType<BIGNUM, BN_free>;
+using ScopedBN_CTX = ScopedOpenSSLType<BN_CTX, BN_CTX_free>;
+using ScopedBN_MONT_CTX = ScopedOpenSSLType<BN_MONT_CTX, BN_MONT_CTX_free>;
+using ScopedCMAC_CTX = ScopedOpenSSLType<CMAC_CTX, CMAC_CTX_free>;
+using ScopedDH = ScopedOpenSSLType<DH, DH_free>;
+using ScopedECDSA_SIG = ScopedOpenSSLType<ECDSA_SIG, ECDSA_SIG_free>;
+using ScopedEC_GROUP = ScopedOpenSSLType<EC_GROUP, EC_GROUP_free>;
+using ScopedEC_KEY = ScopedOpenSSLType<EC_KEY, EC_KEY_free>;
+using ScopedEC_POINT = ScopedOpenSSLType<EC_POINT, EC_POINT_free>;
+using ScopedEVP_PKEY = ScopedOpenSSLType<EVP_PKEY, EVP_PKEY_free>;
+using ScopedEVP_PKEY_CTX = ScopedOpenSSLType<EVP_PKEY_CTX, EVP_PKEY_CTX_free>;
+using ScopedEXTENDED_KEY_USAGE =
+    ScopedOpenSSLType<EXTENDED_KEY_USAGE, EXTENDED_KEY_USAGE_free>;
+using ScopedPKCS8_PRIV_KEY_INFO =
+    ScopedOpenSSLType<PKCS8_PRIV_KEY_INFO, PKCS8_PRIV_KEY_INFO_free>;
+#ifdef OPENSSL_IS_BORINGSSL
+using ScopedPKCS12 = ScopedOpenSSLType<PKCS12, PKCS12_free>;
+#endif  // OPENSSL_IS_BORINGSSL
+using ScopedRSA = ScopedOpenSSLType<RSA, RSA_free>;
+using ScopedX509 = ScopedOpenSSLType<X509, X509_free>;
+using ScopedX509_ALGOR = ScopedOpenSSLType<X509_ALGOR, X509_ALGOR_free>;
+using ScopedX509_EXTENSION =
+    ScopedOpenSSLType<X509_EXTENSION, X509_EXTENSION_free>;
+using ScopedX509_NAME = ScopedOpenSSLType<X509_NAME, X509_NAME_free>;
+using ScopedX509_SIG = ScopedOpenSSLType<X509_SIG, X509_SIG_free>;
+
+using ScopedASN1_TYPEStack =
+    ScopedOpenSSLStack<STACK_OF(ASN1_TYPE), ASN1_TYPE, ASN1_TYPE_free>;
+using ScopedGENERAL_NAMEStack =
+    ScopedOpenSSLStack<STACK_OF(GENERAL_NAME), GENERAL_NAME,
+                       GENERAL_NAME_free>;
+using ScopedX509Stack = ScopedOpenSSLStack<STACK_OF(X509), X509, X509_free>;
+using ScopedWeakX509Stack = ScopedWeakOpenSSLStack<STACK_OF(X509)>;
+
+#ifdef OPENSSL_IS_BORINGSSL
+using ScopedCBB = ScopedOpenSSLContext<CBB, void, CBB_zero, CBB_cleanup>;
+using ScopedEVP_AEAD_CTX =
+    ScopedOpenSSLContext<EVP_AEAD_CTX, void, EVP_AEAD_CTX_zero,
+                         EVP_AEAD_CTX_cleanup>;
+#endif  // OPENSSL_IS_BORINGSSL
+using ScopedEVP_CIPHER_CTX =
+    ScopedOpenSSLContext<EVP_CIPHER_CTX, int, EVP_CIPHER_CTX_init,
+                         EVP_CIPHER_CTX_cleanup>;
+using ScopedEVP_MD_CTX =
+    ScopedOpenSSLContext<EVP_MD_CTX, int, EVP_MD_CTX_init, EVP_MD_CTX_cleanup>;
+using ScopedHMAC_CTX =
+    ScopedOpenSSLContext<HMAC_CTX, void, HMAC_CTX_init, HMAC_CTX_cleanup>;
+
+using ScopedOpenSSLBytes = std::unique_ptr<uint8_t, OpenSSLFree<uint8_t>>;
+using ScopedOpenSSLString = std::unique_ptr<char, OpenSSLFree<char>>;
+
+using ScopedFILE = std::unique_ptr<FILE, FileCloser>;
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_OPENSSL_SCOPED_TYPES_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/openssl_util.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/openssl_util.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/openssl_util.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/openssl_util.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,46 @@
+#include "util/openssl_util.h"
+
+#include <openssl/bio.h>
+#include <openssl/err.h>
+#include <openssl/pem.h>
+#include <string>
+
+using std::string;
+
+namespace util {
+
+string DumpOpenSSLErrorStack() {
+  if (ERR_peek_error() == 0)
+    return "No OpenSSL errors left on stack";
+
+  string stack_dump("OpenSSL errors left on stack:");
+  unsigned long error;
+  char error_string[256];
+  while ((error = ERR_get_error()) != 0) {
+    stack_dump.append("\n\t");
+    ERR_error_string_n(error, error_string, 256);
+    stack_dump.append(error_string);
+  }
+  return stack_dump;
+}
+
+void ClearOpenSSLErrors() {
+  ERR_clear_error();
+}
+
+string ReadBIO(BIO* bio) {
+  int size = BIO_pending(bio);
+  char* buffer = new char[size];
+  int bytes_read = BIO_read(bio, buffer, size);
+  if (bytes_read != size) {
+    LOG(ERROR) << "Read " << bytes_read << " bytes; expected " << size;
+    delete[] buffer;
+    return string();
+  }
+
+  string ret(buffer, bytes_read);
+  delete[] buffer;
+  return ret;
+}
+
+}  // namespace util
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/openssl_util.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/openssl_util.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/openssl_util.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/openssl_util.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,35 @@
+#ifndef CERT_TRANS_UTIL_OPENSSL_UTIL_H_
+#define CERT_TRANS_UTIL_OPENSSL_UTIL_H_
+
+#include <glog/logging.h>
+#include <openssl/err.h>
+#include <string>
+
+namespace util {
+
+// Dump all OpenSSL errors and clear the stack. Use like so:
+// LOG(level) << DumpOpenSSLErrorStack();
+// to avoid doing unnecessary work when the requested logging level
+// is not enabled. (However note that in this case the error stack
+// should be cleared separately.)
+//
+// Call ERR_load_crypto_strings()/ERR_load_ssl_strings() first to get
+// human-readable strings.
+std::string DumpOpenSSLErrorStack();
+
+void ClearOpenSSLErrors();
+
+std::string ReadBIO(BIO* bio);
+
+}  // namespace util
+
+// Convenience macro to help automatically clear the stack regardless of
+// whether the requested logging level is high enough.
+// Defined as macro so that logging happens locally where the error occurred.
+#define LOG_OPENSSL_ERRORS(severity)                \
+  do {                                              \
+    LOG(severity) << util::DumpOpenSSLErrorStack(); \
+    util::ClearOpenSSLErrors();                     \
+  } while (0);
+
+#endif  // CERT_TRANS_UTIL_OPENSSL_UTIL_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/periodic_closure.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/periodic_closure.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/periodic_closure.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/periodic_closure.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,41 @@
+#include "util/periodic_closure.h"
+
+#include <glog/logging.h>
+#include <functional>
+
+using std::bind;
+using std::chrono::duration_cast;
+using std::function;
+using std::shared_ptr;
+
+namespace cert_trans {
+
+
+PeriodicClosure::PeriodicClosure(const shared_ptr<libevent::Base>& base,
+                                 const std::chrono::duration<double>& period,
+                                 const function<void()>& closure)
+    : base_(base),
+      period_(duration_cast<clock::duration>(period)),
+      closure_(closure),
+      event_(*base_, -1, 0, bind(&PeriodicClosure::Run, this)),
+      target_run_time_(clock::now() + period_) {
+  LOG_IF(WARNING, !clock::is_steady)
+      << "clock used for PeriodicClosure is not steady";
+
+  event_.Add(target_run_time_ - clock::now());
+}
+
+
+void PeriodicClosure::Run() {
+  closure_();
+
+  const clock::time_point now(clock::now());
+  while (target_run_time_ <= now) {
+    target_run_time_ += period_;
+  }
+
+  event_.Add(target_run_time_ - now);
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/periodic_closure.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/periodic_closure.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/periodic_closure.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/periodic_closure.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,45 @@
+#ifndef CERT_TRANS_UTIL_PERIODIC_CLOSURE_H_
+#define CERT_TRANS_UTIL_PERIODIC_CLOSURE_H_
+
+#include <chrono>
+#include <functional>
+#include <memory>
+
+#include "base/macros.h"
+#include "util/libevent_wrapper.h"
+
+namespace cert_trans {
+
+
+// Arranges for "closure" to be called every "period". If "closure"
+// runs for too long, it will skip to the next period that is in the
+// future.
+//
+// This object should always be destroyed either from a libevent
+// callback, or while the libevent dispatcher is not running. It
+// should also NOT be destroyed from within "closure".
+class PeriodicClosure {
+ public:
+  PeriodicClosure(const std::shared_ptr<libevent::Base>& base,
+                  const std::chrono::duration<double>& period,
+                  const std::function<void()>& closure);
+
+ private:
+  typedef std::chrono::steady_clock clock;
+
+  void Run();
+
+  const std::shared_ptr<libevent::Base> base_;
+  const clock::duration period_;
+  const std::function<void()> closure_;
+
+  libevent::Event event_;
+  clock::time_point target_run_time_;
+
+  DISALLOW_COPY_AND_ASSIGN(PeriodicClosure);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_PERIODIC_CLOSURE_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/protobuf_util.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/protobuf_util.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/protobuf_util.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/protobuf_util.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,51 @@
+#include "util/protobuf_util.h"
+
+#include <google/protobuf/io/coded_stream.h>
+#include <google/protobuf/io/zero_copy_stream_impl.h>
+#include <google/protobuf/message.h>
+
+namespace cert_trans {
+
+using google::protobuf::MessageLite;
+using google::protobuf::io::CodedOutputStream;
+using google::protobuf::io::OstreamOutputStream;
+using google::protobuf::io::ZeroCopyOutputStream;
+
+
+// Implements the MessageLite.writeDelimitedTo() method from the Java proto
+// API, which is strangely absent from the C++ library.
+// This code was pinched from a response by Kenton Varda (ex Protobuf
+// developer) to a question about this topic here:
+//   http://stackoverflow.com/a/22927149
+bool WriteDelimitedTo(const MessageLite& message,
+                      ZeroCopyOutputStream* rawOutput) {
+  // We create a new coded stream for each message.  Don't worry, this is fast.
+  CodedOutputStream output(rawOutput);
+
+  // Write the size.
+  const int size = message.ByteSize();
+  output.WriteVarint32(size);
+
+  uint8_t* buffer = output.GetDirectBufferForNBytesAndAdvance(size);
+  if (buffer != NULL) {
+    // Optimization:  The message fits in one buffer, so use the faster
+    // direct-to-array serialization path.
+    message.SerializeWithCachedSizesToArray(buffer);
+  } else {
+    // Slightly-slower path when the message is multiple buffers.
+    message.SerializeWithCachedSizes(&output);
+    if (output.HadError())
+      return false;
+  }
+
+  return true;
+}
+
+
+bool WriteDelimitedToOstream(const MessageLite& message, std::ostream* os) {
+  OstreamOutputStream oos(os);
+  return WriteDelimitedTo(message, &oos);
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/protobuf_util.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/protobuf_util.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/protobuf_util.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/protobuf_util.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,35 @@
+#ifndef CERT_TRANS_UTIL_PROTOBUF_UTIL_H_
+#define CERT_TRANS_UTIL_PROTOBUF_UTIL_H_
+
+#include <ostream>
+
+namespace google {
+namespace protobuf {
+namespace io {
+class ZeroCopyOutputStream;
+}  // namespace io
+
+class MessageLite;
+}  // namespace protobuf
+}  // namespace google
+
+
+namespace cert_trans {
+
+// Implements the MessageLite.writeDelimitedTo() method from the Java proto
+// API, which is strangly absent from the C++ library.
+// This code was pinched from a response by Kenton Varda (ex Protobuf
+// developer) to a question about this topic here:
+//   http://stackoverflow.com/a/22927149
+bool WriteDelimitedTo(const google::protobuf::MessageLite& message,
+                      google::protobuf::io::ZeroCopyOutputStream* rawOutput);
+
+
+bool WriteDelimitedToOstream(const google::protobuf::MessageLite& message,
+                             std::ostream* os);
+
+
+}  // namespace cert_trans
+
+
+#endif  // CERT_TRANS_UTIL_PROTOBUF_UTIL_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/read_key.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/read_key.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/read_key.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/read_key.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,59 @@
+#include "util/read_key.h"
+
+#include <openssl/pem.h>
+#include <memory>
+
+using std::unique_ptr;
+
+namespace cert_trans {
+
+namespace {
+
+
+void FileCloser(FILE* fp) {
+  if (fp) {
+    fclose(fp);
+  }
+}
+
+
+}  // namespace
+
+
+util::StatusOr<EVP_PKEY*> ReadPrivateKey(const std::string& file) {
+  unique_ptr<FILE, void (*)(FILE*)> fp(fopen(file.c_str(), "r"), FileCloser);
+
+  if (!fp) {
+    return util::Status(util::error::NOT_FOUND, "key file not found: " + file);
+  }
+
+  // No password.
+  EVP_PKEY* retval(nullptr);
+  PEM_read_PrivateKey(fp.get(), &retval, nullptr, nullptr);
+  if (!retval)
+    return util::Status(util::error::FAILED_PRECONDITION,
+                        "invalid key: " + file);
+
+  return retval;
+}
+
+
+util::StatusOr<EVP_PKEY*> ReadPublicKey(const std::string& file) {
+  unique_ptr<FILE, void (*)(FILE*)> fp(fopen(file.c_str(), "r"), FileCloser);
+
+  if (!fp) {
+    return util::Status(util::error::NOT_FOUND, "key file not found: " + file);
+  }
+
+  // No password.
+  EVP_PKEY* retval(nullptr);
+  PEM_read_PUBKEY(fp.get(), &retval, nullptr, nullptr);
+  if (!retval)
+    return util::Status(util::error::FAILED_PRECONDITION,
+                        "invalid key: " + file);
+
+  return retval;
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/read_key.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/read_key.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/read_key.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/read_key.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,19 @@
+#ifndef CERT_TRANS_UTIL_READ_KEY_H_
+#define CERT_TRANS_UTIL_READ_KEY_H_
+
+#include <openssl/evp.h>
+#include <string>
+
+#include "util/statusor.h"
+
+namespace cert_trans {
+
+
+util::StatusOr<EVP_PKEY*> ReadPrivateKey(const std::string& file);
+
+util::StatusOr<EVP_PKEY*> ReadPublicKey(const std::string& file);
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_READ_KEY_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/status.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/status.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/status.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/status.cc	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,131 @@
+// Copyright 2013 Google Inc. All Rights Reserved.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#include <sstream>
+
+#include "util/status.h"
+
+using ::std::ostream;
+using ::std::string;
+
+namespace util {
+
+namespace {
+
+
+const Status& GetOk() {
+  static const Status status;
+  return status;
+}
+
+const Status& GetCancelled() {
+  static const Status status(::util::error::CANCELLED, "");
+  return status;
+}
+
+const Status& GetUnknown() {
+  static const Status status(::util::error::UNKNOWN, "");
+  return status;
+}
+
+
+}  // namespace
+
+
+Status::Status() : code_(::util::error::OK), message_("") {
+}
+
+Status::Status(::util::error::Code error, const string& error_message)
+    : code_(error), message_(error_message) {
+  if (code_ == ::util::error::OK) {
+    message_.clear();
+  }
+}
+
+Status::Status(const Status& other)
+    : code_(other.code_), message_(other.message_) {
+}
+
+Status& Status::operator=(const Status& other) {
+  code_ = other.code_;
+  message_ = other.message_;
+  return *this;
+}
+
+const Status& Status::OK = GetOk();
+const Status& Status::CANCELLED = GetCancelled();
+const Status& Status::UNKNOWN = GetUnknown();
+
+string Status::ToString() const {
+  if (code_ == ::util::error::OK) {
+    return "OK";
+  }
+
+  std::ostringstream oss;
+  oss << code_ << ": " << message_;
+  return oss.str();
+}
+
+string ErrorCodeString(util::error::Code error) {
+  switch (error) {
+    case util::error::OK:
+      return "OK";
+    case util::error::CANCELLED:
+      return "CANCELLED";
+    case util::error::UNKNOWN:
+      return "UNKNOWN";
+    case util::error::INVALID_ARGUMENT:
+      return "INVALID_ARGUMENT";
+    case util::error::DEADLINE_EXCEEDED:
+      return "DEADLINE_EXCEEDED";
+    case util::error::NOT_FOUND:
+      return "NOT_FOUND";
+    case util::error::ALREADY_EXISTS:
+      return "ALREADY_EXISTS";
+    case util::error::PERMISSION_DENIED:
+      return "PERMISSION_DENIED";
+    case util::error::RESOURCE_EXHAUSTED:
+      return "RESOURCE_EXHAUSTED";
+    case util::error::FAILED_PRECONDITION:
+      return "FAILED_PRECONDITION";
+    case util::error::ABORTED:
+      return "ABORTED";
+    case util::error::OUT_OF_RANGE:
+      return "OUT_OF_RANGE";
+    case util::error::UNIMPLEMENTED:
+      return "UNIMPLEMENTED";
+    case util::error::INTERNAL:
+      return "INTERNAL";
+    case util::error::UNAVAILABLE:
+      return "UNAVAILABLE";
+    case util::error::DATA_LOSS:
+      return "DATA_LOSS";
+  }
+  // Avoid using a "default" in the switch, so that the compiler can
+  // give us a warning, but still provide a fallback here.
+  return std::to_string(error);
+}
+
+extern ostream& operator<<(ostream& os, util::error::Code code) {
+  os << ErrorCodeString(code);
+  return os;
+}
+
+extern ostream& operator<<(ostream& os, const Status& other) {
+  os << other.ToString();
+  return os;
+}
+
+
+}  // namespace util
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/status.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/status.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/status.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/status.h	2017-01-15 10:56:31.048591151 +0100
@@ -0,0 +1,187 @@
+// Copyright 2013 Google Inc. All Rights Reserved.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+//
+//
+// This code was unceremoniously lifted from the version at
+// github.com/google/lmctfy with a few minor modifications mainly to reduce the
+// dependencies.
+
+#ifndef CERT_TRANS_UTIL_STATUS_H_
+#define CERT_TRANS_UTIL_STATUS_H_
+
+#include <string>
+
+namespace util {
+
+namespace error {
+
+
+// These values match the error codes in the codes.proto file of the original.
+enum Code {
+  // Not an error; returned on success
+  OK = 0,
+
+  // The operation was cancelled (typically by the caller).
+  CANCELLED = 1,
+
+  // Unknown error.
+  UNKNOWN = 2,
+
+  // Client specified an invalid argument.  Note that this differs
+  // from FAILED_PRECONDITION.  INVALID_ARGUMENT indicates arguments
+  // that are problematic regardless of the state of the system
+  // (e.g., a malformed file name).
+  INVALID_ARGUMENT = 3,
+
+  // Deadline expired before operation could complete.
+  DEADLINE_EXCEEDED = 4,
+
+  // Some requested entity (e.g., file or directory) was not found.
+  NOT_FOUND = 5,
+
+  // Some entity that we attempted to create (e.g., file or directory)
+  // already exists.
+  ALREADY_EXISTS = 6,
+
+  // The caller does not have permission to execute the specified
+  // operation.
+  PERMISSION_DENIED = 7,
+
+  // Some resource has been exhausted, perhaps a per-user quota, or
+  // perhaps the entire file system is out of space.
+  RESOURCE_EXHAUSTED = 8,
+
+  // Operation was rejected because the system is not in a state
+  // required for the operation's execution.  For example, directory
+  // to be deleted may be non-empty, an rmdir operation is applied to
+  // a non-directory, etc.
+  //
+  // A litmus test that may help a service implementor in deciding
+  // between FAILED_PRECONDITION, ABORTED, and UNAVAILABLE:
+  //  (a) Use UNAVAILABLE if the client can retry just the failing call.
+  //  (b) Use ABORTED if the client should retry at a higher-level
+  //      (e.g., restarting a read-modify-write sequence).
+  //  (c) Use FAILED_PRECONDITION if the client should not retry until
+  //      the system state has been explicitly fixed.  E.g., if an "rmdir"
+  //      fails because the directory is non-empty, FAILED_PRECONDITION
+  //      should be returned since the client should not retry unless
+  //      they have first fixed up the directory by deleting files from it.
+  FAILED_PRECONDITION = 9,
+
+  // The operation was aborted, typically due to a concurrency issue
+  // like sequencer check failures, transaction aborts, etc.
+  //
+  // See litmus test above for deciding between FAILED_PRECONDITION,
+  // ABORTED, and UNAVAILABLE.
+  ABORTED = 10,
+
+  // Operation was attempted past the valid range.  E.g., seeking or
+  // reading past end of file.
+  //
+  // Unlike INVALID_ARGUMENT, this error indicates a problem that may
+  // be fixed if the system state changes. For example, a 32-bit file
+  // system will generate INVALID_ARGUMENT if asked to read at an
+  // offset that is not in the range [0,2^32-1], but it will generate
+  // OUT_OF_RANGE if asked to read from an offset past the current
+  // file size.
+  OUT_OF_RANGE = 11,
+
+  // Operation is not implemented or not supported/enabled in this service.
+  UNIMPLEMENTED = 12,
+
+  // Internal errors.  Means some invariants expected by underlying
+  // system has been broken.  If you see one of these errors,
+  // something is very broken.
+  INTERNAL = 13,
+
+  // The service is currently unavailable.  This is a most likely a
+  // transient condition and may be corrected by retrying with
+  // a backoff.
+  //
+  // See litmus test above for deciding between FAILED_PRECONDITION,
+  // ABORTED, and UNAVAILABLE.
+  UNAVAILABLE = 14,
+
+  // Unrecoverable data loss or corruption.
+  DATA_LOSS = 15,
+};
+
+
+}  // namespace error
+
+
+// A Status is a combination of an error code and a string message (for non-OK
+// error codes).
+class Status {
+ public:
+  // Creates an OK status
+  Status();
+
+  // Make a Status from the specified error and message.
+  Status(::util::error::Code error, const ::std::string& error_message);
+
+  Status(const Status& other);
+  Status& operator=(const Status& other);
+
+  // Some pre-defined Status objects
+  static const Status& OK;  // Identical to 0-arg constructor
+  static const Status& CANCELLED;
+  static const Status& UNKNOWN;
+
+  // Accessors
+  bool ok() const {
+    return code_ == ::util::error::OK;
+  }
+  int error_code() const {
+    return code_;
+  }
+  ::util::error::Code CanonicalCode() const {
+    return code_;
+  }
+  const ::std::string& error_message() const {
+    return message_;
+  }
+
+  bool operator==(const Status& x) const;
+  bool operator!=(const Status& x) const;
+
+  // NoOp
+  void IgnoreError() const {
+  }
+
+  ::std::string ToString() const;
+
+ private:
+  ::util::error::Code code_;
+  ::std::string message_;
+};
+
+inline bool Status::operator==(const Status& other) const {
+  return (this->code_ == other.code_) && (this->message_ == other.message_);
+}
+
+inline bool Status::operator!=(const Status& other) const {
+  return !(*this == other);
+}
+
+extern ::std::string ErrorCodeString(util::error::Code error);
+
+extern ::std::ostream& operator<<(::std::ostream& os,
+                                  ::util::error::Code code);
+extern ::std::ostream& operator<<(::std::ostream& os, const Status& other);
+
+
+}  // namespace util
+
+#endif  // CERT_TRANS_UTIL_STATUS_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/statusor.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/statusor.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/statusor.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/statusor.h	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,140 @@
+// Copyright 2013 Google Inc. All Rights Reserved.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+#ifndef CERT_TRANS_UTIL_STATUSOR_H_
+#define CERT_TRANS_UTIL_STATUSOR_H_
+
+#include <utility>
+
+#include "glog/logging.h"
+#include "util/status.h"
+
+namespace util {
+
+// A StatusOr holds a Status (in the case of an error), or a value T.
+template <typename T>
+class StatusOr {
+ public:
+  // Has status UNKNOWN.
+  inline StatusOr();
+
+  // Builds from a non-OK status. Crashes if an OK status is specified.
+  inline StatusOr(const ::util::Status& status);  // NOLINT
+
+  // Builds from the specified value.
+  inline StatusOr(const T& value);  // NOLINT
+  inline StatusOr(T&& value);       // NOLINT
+
+  // Copy constructor.
+  inline StatusOr(const StatusOr& other);
+
+  // Move constructor.
+  inline StatusOr(StatusOr&& other);
+
+  // Conversion copy constructor, T must be copy constructible from U.
+  template <typename U>
+  inline StatusOr(const StatusOr<U>& other);
+
+  // Assignment operator.
+  inline const StatusOr& operator=(const StatusOr& other);
+
+  // Conversion assignment operator, T must be assignable from U
+  template <typename U>
+  inline const StatusOr& operator=(const StatusOr<U>& other);
+
+  // Accessors.
+  inline const ::util::Status& status() const {
+    return status_;
+  }
+
+  // Shorthand for status().ok().
+  inline bool ok() const {
+    return status_.ok();
+  }
+
+  // Returns value or crashes if ok() is false.
+  inline const T& ValueOrDie() const {
+    CHECK(ok()) << "Attempting to fetch value of non-OK StatusOr";
+    return value_;
+  }
+  inline T& ValueOrDie() {
+    CHECK(ok()) << "Attempting to fetch value of non-OK StatusOr";
+    return value_;
+  }
+
+  template <typename U>
+  friend class StatusOr;
+
+ private:
+  Status status_;
+  T value_;
+};
+
+// Implementation.
+
+template <typename T>
+inline StatusOr<T>::StatusOr() : status_(::util::error::UNKNOWN, "") {
+}
+
+template <typename T>
+inline StatusOr<T>::StatusOr(const ::util::Status& status) : status_(status) {
+  CHECK(!status.ok()) << "Status::OK is not a valid argument to StatusOr";
+}
+
+template <typename T>
+inline StatusOr<T>::StatusOr(const T& value) : value_(value) {
+}
+
+template <typename T>
+inline StatusOr<T>::StatusOr(T&& value) : value_(std::move(value)) {
+}
+
+template <typename T>
+inline StatusOr<T>::StatusOr(const StatusOr& other)
+    : status_(other.status_), value_(other.value_) {
+}
+
+template <typename T>
+inline StatusOr<T>::StatusOr(StatusOr&& other)
+    : status_(other.status_), value_(std::move(other.value_)) {
+}
+
+template <typename T>
+template <typename U>
+inline StatusOr<T>::StatusOr(const StatusOr<U>& other)
+    : status_(other.status_), value_(other.value_) {
+}
+
+template <typename T>
+inline const StatusOr<T>& StatusOr<T>::operator=(const StatusOr& other) {
+  status_ = other.status_;
+  if (status_.ok()) {
+    value_ = other.value_;
+  }
+  return *this;
+}
+
+template <typename T>
+template <typename U>
+inline const StatusOr<T>& StatusOr<T>::operator=(const StatusOr<U>& other) {
+  status_ = other.status_;
+  if (status_.ok()) {
+    value_ = other.value_;
+  }
+  return *this;
+}
+
+}  // namespace util
+
+#endif  // CERT_TRANS_UTIL_STATUSOR_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/status_test_util.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/status_test_util.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/status_test_util.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/status_test_util.h	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,94 @@
+#ifndef CERT_TRANS_UTIL_STATUS_TEST_UTIL_H_
+#define CERT_TRANS_UTIL_STATUS_TEST_UTIL_H_
+
+#include <gmock/gmock-matchers.h>
+
+#include "util/status.h"
+#include "util/statusor.h"
+#include "util/sync_task.h"
+#include "util/task.h"
+
+namespace util {
+namespace testing {
+
+
+class StatusIsMatcher : public ::testing::MatcherInterface<Status> {
+ public:
+  StatusIsMatcher(const ::testing::Matcher<error::Code>& code_matcher,
+                  const ::testing::Matcher<std::string>& message_matcher)
+      : code_matcher_(code_matcher), message_matcher_(message_matcher) {
+  }
+
+  bool MatchAndExplain(
+      Status status, ::testing::MatchResultListener* listener) const override {
+    if (!code_matcher_.MatchAndExplain(status.CanonicalCode(), listener)) {
+      return false;
+    }
+
+    if (!message_matcher_.MatchAndExplain(status.error_message(), listener)) {
+      return false;
+    }
+
+    return true;
+  }
+
+  void DescribeTo(std::ostream* os) const override {
+    *os << "util::Status(code ";
+    code_matcher_.DescribeTo(os);
+    *os << " and message ";
+    message_matcher_.DescribeTo(os);
+    *os << ")";
+  }
+
+ private:
+  const ::testing::Matcher<error::Code> code_matcher_;
+  const ::testing::Matcher<std::string> message_matcher_;
+};
+
+
+::testing::Matcher<Status> StatusIs(
+    const ::testing::Matcher<error::Code>& code_matcher,
+    const ::testing::Matcher<std::string>& message_matcher) {
+  return ::testing::MakeMatcher(
+      new StatusIsMatcher(code_matcher, message_matcher));
+}
+
+
+::testing::Matcher<Status> StatusIs(
+    const ::testing::Matcher<error::Code>& code_matcher) {
+  return ::testing::MakeMatcher(
+      new StatusIsMatcher(code_matcher, ::testing::_));
+}
+
+
+inline ::util::Status ToStatus(const ::util::Status& status) {
+  return status;
+}
+
+
+inline ::util::Status ToStatus(::util::Task* task) {
+  return task->status();
+}
+
+
+inline ::util::Status ToStatus(const ::util::SyncTask& task) {
+  return task.status();
+}
+
+
+template <class T>
+::util::Status ToStatus(const ::util::StatusOr<T>& statusor) {
+  return statusor.status();
+}
+
+
+#define EXPECT_OK(expr) \
+  EXPECT_EQ(util::Status::OK, util::testing::ToStatus(expr))
+#define ASSERT_OK(expr) \
+  ASSERT_EQ(util::Status::OK, util::testing::ToStatus(expr))
+
+
+}  // namespace testing
+}  // namespace util
+
+#endif  // CERT_TRANS_UTIL_STATUS_TEST_UTIL_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/sync_task.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/sync_task.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/sync_task.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/sync_task.cc	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,39 @@
+#include "util/sync_task.h"
+
+#include <glog/logging.h>
+
+using cert_trans::Notification;
+using std::bind;
+
+namespace util {
+
+
+SyncTask::SyncTask(Executor* executor)
+    : task_(bind(&Notification::Notify, &notifier_), CHECK_NOTNULL(executor)) {
+}
+
+
+SyncTask::~SyncTask() {
+  CHECK(IsDone());
+}
+
+
+bool SyncTask::IsDone() const {
+  // We should not use task_.IsDone(), because it becomes true before
+  // the callback is called, and a user could then decide to delete
+  // the SyncTask, which could cause a crash.
+  return notifier_.HasBeenNotified();
+}
+
+
+void SyncTask::Wait() const {
+  notifier_.WaitForNotification();
+}
+
+
+void SyncTask::Cancel() {
+  task_.Cancel();
+}
+
+
+}  // namespace util
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/sync_task.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/sync_task.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/sync_task.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/sync_task.h	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,50 @@
+#ifndef CERT_TRANS_UTIL_SYNC_TASK_H_
+#define CERT_TRANS_UTIL_SYNC_TASK_H_
+
+#include "base/macros.h"
+#include "base/notification.h"
+#include "util/task.h"
+
+namespace util {
+
+
+// Helper class to allow using a util::Task in a synchronous manner.
+class SyncTask {
+ public:
+  SyncTask(Executor* executor);
+
+  // REQUIRES: IsDone() returns true.
+  ~SyncTask();
+
+  Task* task() {
+    return &task_;
+  }
+
+  // Returns true once the task is completed.
+  bool IsDone() const;
+
+  // Returns the status of the task.
+  // REQUIRES: IsDone() returns true.
+  Status status() const {
+    return task_.status();
+  }
+
+  // Blocks until IsDone() returns true.
+  void Wait() const;
+
+  // Request the task to cancel itself and return. This does not
+  // block, so the task should not be deleted until IsDone() returns
+  // true.
+  void Cancel();
+
+ private:
+  cert_trans::Notification notifier_;
+  Task task_;
+
+  DISALLOW_COPY_AND_ASSIGN(SyncTask);
+};
+
+
+}  // namespace util
+
+#endif  // CERT_TRANS_UTIL_SYNC_TASK_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/sync_task_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/sync_task_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/sync_task_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/sync_task_test.cc	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,94 @@
+#include <gtest/gtest.h>
+#include <chrono>
+#include <thread>
+
+#include "util/sync_task.h"
+#include "util/testing.h"
+#include "util/thread_pool.h"
+
+using cert_trans::ThreadPool;
+using std::bind;
+using std::chrono::milliseconds;
+using std::this_thread::sleep_for;
+
+namespace {
+
+
+TEST(SyncTaskTest, StateChange) {
+  ThreadPool pool;
+  util::SyncTask s(&pool);
+  EXPECT_FALSE(s.IsDone());
+
+  util::Status status(util::error::INTERNAL, "my own private status");
+  s.task()->Return(status);
+  s.Wait();
+
+  EXPECT_TRUE(s.IsDone());
+  EXPECT_EQ(status, s.status());
+}
+
+
+void DelayReturn(util::Task* task, const util::Status& status) {
+  sleep_for(milliseconds(100));
+  task->Return(status);
+}
+
+
+TEST(SyncTaskTest, Wait) {
+  ThreadPool pool;
+  util::SyncTask s(&pool);
+  EXPECT_FALSE(s.IsDone());
+
+  util::Status status(util::error::INTERNAL, "my own private status");
+  pool.Add(bind(DelayReturn, s.task(), status));
+  s.Wait();
+
+  EXPECT_TRUE(s.IsDone());
+  EXPECT_EQ(status, s.status());
+}
+
+
+void CancelTask(util::Task* task) {
+  task->Return(util::Status::CANCELLED);
+}
+
+
+TEST(SyncTaskTest, CancelBefore) {
+  ThreadPool pool;
+  util::SyncTask s(&pool);
+  EXPECT_FALSE(s.IsDone());
+
+  s.task()->WhenCancelled(bind(CancelTask, s.task()));
+  s.Cancel();
+  s.Wait();
+
+  EXPECT_TRUE(s.IsDone());
+  EXPECT_EQ(util::Status::CANCELLED, s.status());
+}
+
+
+TEST(SyncTaskTest, CancelAfter) {
+  ThreadPool pool;
+  util::SyncTask s(&pool);
+  EXPECT_FALSE(s.IsDone());
+
+  s.task()->WhenCancelled(bind(CancelTask, s.task()));
+
+  util::Status status(util::error::INTERNAL, "my own private status");
+  s.task()->Return(status);
+
+  s.Cancel();
+  s.Wait();
+
+  EXPECT_TRUE(s.IsDone());
+  EXPECT_EQ(status, s.status());
+}
+
+
+}  // namespace
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/task.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/task.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/task.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/task.cc	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,280 @@
+#include "util/task.h"
+
+#include <glog/logging.h>
+
+using std::bind;
+using std::function;
+using std::lock_guard;
+using std::make_shared;
+using std::mutex;
+using std::ostream;
+using std::placeholders::_1;
+using std::shared_ptr;
+using std::unique_lock;
+using std::vector;
+
+namespace util {
+
+
+Task::Task(const function<void(Task*)>& done_callback, Executor* executor)
+    : done_callback_(done_callback),
+      executor_(CHECK_NOTNULL(executor)),
+      state_(ACTIVE),
+      cancelled_(false),
+      holds_(0) {
+}
+
+
+Task::~Task() {
+  CHECK_EQ(state_, DONE);
+  CHECK(cancel_callbacks_.empty());
+}
+
+
+void Task::Cancel() {
+  unique_lock<mutex> lock(lock_);
+
+  if (state_ == DONE || cancelled_) {
+    return;
+  }
+
+  cancelled_ = true;
+
+  vector<function<void()>> cancel_callbacks;
+  cancel_callbacks_.swap(cancel_callbacks);
+
+  // Add a hold for each cancellation callback, so that we do not go
+  // into the DONE state until they all have completed.
+  holds_ += cancel_callbacks.size();
+
+  // Take a copy of the child tasks before giving back the lock. Since
+  // these are shared_ptrs, having a copy will protect us in case some
+  // of them complete and get removed (which will free them). Any
+  // child tasks created after giving back the lock will be already
+  // cancelled, so no need to cancel them here.
+  const vector<shared_ptr<Task>> child_tasks(child_tasks_);
+
+  // Give up the lock, in case the executor is synchronous.
+  lock.unlock();
+
+  for (const auto& child_task : child_tasks) {
+    child_task->Cancel();
+  }
+
+  for (const auto& cb : cancel_callbacks) {
+    executor_->Add(bind(&Task::RunCancelCallback, this, cb));
+  }
+}
+
+
+Status Task::status() const {
+  lock_guard<mutex> lock(lock_);
+  CHECK_NE(state_, ACTIVE);
+  return status_;
+}
+
+
+bool Task::Return(const Status& status) {
+  unique_lock<mutex> lock(lock_);
+
+  if (state_ != ACTIVE) {
+    return false;
+  }
+
+  status_ = status;
+  state_ = PREPARED;
+  cancel_callbacks_.clear();
+
+  // Take a copy of the child tasks, so we can still access it after
+  // calling TryDoneTransition(). See Task::Cancel() for more
+  // explanation.
+  const vector<shared_ptr<Task>> child_tasks(child_tasks_);
+
+  // Do not touch any members after this, as the task object might be
+  // deleted by the time this method returns.
+  TryDoneTransition(&lock);
+
+  // If we still have the lock (we are not in the DONE state yet),
+  // give it up.
+  if (lock.owns_lock()) {
+    lock.unlock();
+  }
+
+  for (const auto& child_task : child_tasks) {
+    child_task->Cancel();
+  }
+
+  return true;
+}
+
+
+void Task::AddHold() {
+  lock_guard<mutex> lock(lock_);
+  CHECK_NE(state_, DONE);
+  ++holds_;
+}
+
+
+void Task::RemoveHold() {
+  unique_lock<mutex> lock(lock_);
+
+  CHECK_GT(holds_, 0);
+  CHECK_NE(state_, DONE);
+  --holds_;
+
+  // Do not touch any members after this, as the task object might be
+  // deleted by the time this method returns.
+  TryDoneTransition(&lock);
+}
+
+
+bool Task::IsActive() const {
+  lock_guard<mutex> lock(lock_);
+  return state_ == ACTIVE;
+}
+
+
+bool Task::IsDone() const {
+  lock_guard<mutex> lock(lock_);
+  return state_ == DONE;
+}
+
+
+bool Task::CancelRequested() const {
+  lock_guard<mutex> lock(lock_);
+  return cancelled_;
+}
+
+
+void Task::WhenCancelled(const std::function<void()>& cancel_cb) {
+  unique_lock<mutex> lock(lock_);
+
+  if (state_ != ACTIVE) {
+    return;
+  }
+
+  if (!cancelled_) {
+    cancel_callbacks_.emplace_back(cancel_cb);
+  } else {
+    ++holds_;
+
+    // Give up the lock, in case the executor is synchronous.
+    lock.unlock();
+    executor_->Add(bind(&Task::RunCancelCallback, this, cancel_cb));
+  }
+}
+
+
+Task* Task::AddChildWithExecutor(const function<void(Task*)>& done_callback,
+                                 Executor* executor) {
+  const shared_ptr<Task> child_task(make_shared<Task>(
+      bind(&Task::RunChildDoneCallback, this, done_callback, _1),
+      CHECK_NOTNULL(executor)));
+  bool cancel;
+
+  {
+    lock_guard<mutex> lock(lock_);
+    CHECK_NE(state_, DONE);
+
+    child_tasks_.emplace_back(child_task);
+    ++holds_;
+
+    cancel = state_ != ACTIVE || cancelled_;
+  }
+
+  if (cancel) {
+    child_task->Cancel();
+  }
+
+  return child_task.get();
+}
+
+
+void Task::CleanupWhenDone(const function<void()>& cleanup_cb) {
+  lock_guard<mutex> lock(lock_);
+  CHECK_NE(state_, DONE);
+
+  cleanup_callbacks_.emplace_back(cleanup_cb);
+}
+
+
+// After calling this method, the task object might have become
+// invalid, if the transition to DONE worked, as the done callback is
+// allowed to delete it. So make sure not to use any more member
+// variables after calling this.
+//
+// It will also release "*lock", if that transition succeeds.
+void Task::TryDoneTransition(unique_lock<mutex>* lock) {
+  CHECK(lock->owns_lock());
+  CHECK_NE(state_, DONE);
+
+  if (state_ != PREPARED || holds_ > 0) {
+    return;
+  }
+
+  state_ = DONE;
+
+  // Give up the lock, as the callback is allowed to delete us. We
+  // also do not want to cause a deadlock, in the possibility that the
+  // executor is synchronous.
+  lock->unlock();
+
+  // Once this is called, the task might get deleted.
+  executor_->Add(bind(&Task::RunCleanupAndDoneCallbacks, this));
+}
+
+
+void Task::RunCancelCallback(const std::function<void()>& cb) {
+  cb();
+  RemoveHold();
+}
+
+
+void Task::RunCleanupAndDoneCallbacks() {
+  vector<function<void()>> cleanup_callbacks;
+
+  {
+    lock_guard<mutex> lock(lock_);
+    cleanup_callbacks_.swap(cleanup_callbacks);
+  }
+
+  // We call the cleanup callbacks (and thus, any deleters) before
+  // calling the done callback, which adds a little bit of latency,
+  // but it exposes any misuse of CleanupWhenDone/DeleteWhenDone, and
+  // is simpler to implement (no need to make the list of callbacks
+  // last longer than the task object, for example).
+  for (const auto& cb : cleanup_callbacks) {
+    cb();
+  }
+
+  // Once this is called, the task might get deleted.
+  done_callback_(this);
+}
+
+
+void Task::RunChildDoneCallback(const function<void(Task*)>& done_callback,
+                                Task* child_task) {
+  done_callback(child_task);
+
+  unique_lock<mutex> lock(lock_);
+  vector<shared_ptr<Task>>::iterator it;
+  for (it = child_tasks_.begin(); it != child_tasks_.end(); ++it) {
+    if (it->get() == child_task) {
+      break;
+    }
+  }
+
+  CHECK(it != child_tasks_.end());
+  CHECK_GT(holds_, 0);
+  CHECK_NE(state_, DONE);
+
+  child_tasks_.erase(it);
+  --holds_;
+
+  // Do not touch any members after this, as the task object might be
+  // deleted by the time this method returns.
+  TryDoneTransition(&lock);
+}
+
+
+}  // namespace util
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/task.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/task.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/task.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/task.h	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,209 @@
+// This class is used to coordinate asynchronous work. It runs a
+// callback once the work is done, and also supports cancellation, as
+// well as memory management.
+//
+// Typically, a function/method that starts an asynchronous operation
+// will take a pointer to a util::Task. The caller keeps ownership of
+// the util::Task, and once the operation is complete, the callee
+// calls util::Task::Return(), with the status in case of an
+// error.
+//
+// The task object can help with the implementation of the callee, by
+// providing memory management, and notifying it when a cancellation
+// has been requested.
+//
+// A task is provided with a util::Executor which it will use to run
+// its callbacks. The executor will not be accessed after the done
+// callback has started.
+//
+// Once util::Task::Return() is called, the done callback is run on
+// the executor.
+
+#ifndef CERT_TRANS_UTIL_TASK_H_
+#define CERT_TRANS_UTIL_TASK_H_
+
+#include <functional>
+#include <memory>
+#include <mutex>
+#include <vector>
+
+#include "base/macros.h"
+#include "util/executor.h"
+#include "util/status.h"
+
+namespace util {
+
+// The task can be in one of three states: ACTIVE (the initial state),
+// PREPARED (the task has a status), or DONE (the done callback can
+// run).
+//
+// A task enters the PREPARED state on the first Return() call.
+//
+// The task changes from PREPARED to DONE when the following
+// conditions are met:
+//
+//  - there are no remaining holds on the task
+//  - all cancellation callbacks have returned
+//  - all child task done callbacks have returned
+//
+class Task {
+ public:
+  Task(const std::function<void(Task*)>& done_callback, Executor* executor);
+
+  // REQUIRES: task is in DONE state.
+  // Tasks can be deleted in their done callback.
+  ~Task();
+
+  // Returns the executor passed into the constructor, which will be
+  // used for callbacks.
+  Executor* executor() const {
+    return executor_;
+  }
+
+  // Requests that the asynchronous operation (and all its
+  // descendants) be cancelled. There is no guarantee that the task is
+  // PREPARED or DONE by the time this method returns. Also, the
+  // cancellation is merely a request, and could be completely
+  // ignored.
+  void Cancel();
+
+  // REQUIRES: Return() has been called, which can be verified by
+  // calling IsActive().
+  Status status() const;
+
+  // Methods used by the implementer of an asynchronous operation (the
+  // callee).
+
+  // If the task is ACTIVE, prepares it with the specified Status
+  // object, returning true. If the task is no longer ACTIVE (meaning
+  // that Return() has already been called), the task is not changed,
+  // and false is returned.
+  //
+  // Note that once Return() is called, the task can reach the DONE
+  // state asynchronously and run the callbacks for this task, which
+  // might delete the task and state used by the callee. So you must
+  // be careful with what is used after calling Return(), including
+  // through destructors of locally scoped objects (such as
+  // std::lock_guard, for example). An option is to use a TaskHold to
+  // ensure the task does not reach the DONE state prematurely.
+  bool Return(const Status& status = Status::OK);
+
+  // This can be used to prevent the task from advancing to the DONE
+  // state.
+  void AddHold();
+  void RemoveHold();
+
+  // These two methods allow inspecting the current state of the task.
+  bool IsActive() const;
+  bool IsDone() const;
+
+  // Returns true once Cancel() is called.
+  bool CancelRequested() const;
+
+  // The "cancel_cb" callback will be called the first time Cancel()
+  // is called. If Cancel() is never called, then it will just be
+  // destroyed without being called. So this function could be called
+  // zero or one time, and should thus not be solely responsible for
+  // memory management.
+  //
+  // It is okay to call WhenCancelled() more than once on the same
+  // task. There is no ordering guarantee, and since they are called
+  // using the executor, they could even be run concurrently.
+  //
+  // If this method is called after the Cancel() has been called, the
+  // callback will be sent to the executor immediately. If the task is
+  // not ACTIVE anymore (in other words, if Return() has already been
+  // called), the callback will not be run.
+  //
+  // All cancellation callbacks will be complete before the task
+  // enters the DONE state. Effectively, each cancellation callback
+  // has a hold on the task while they are running. That hold is
+  // removed once the cancellation callback returns, but the callback
+  // is allowed to take a hold of its own, if it wants to delay the
+  // DONE state further.
+  void WhenCancelled(const std::function<void()>& cancel_cb);
+
+  // Child tasks are owned by this task (the child task will be
+  // deleted automatically after their done callback has run). All
+  // child tasks will be cancelled automatically if this task is
+  // cancelled or enters the PREPARED state (when Return() is
+  // called). Each child task has a hold on this task that is released
+  // once the child's done callback returns, so the parent task will
+  // not reach the DONE state until all of its child tasks have
+  // finished running. The executor of the child task is the same as
+  // that of the parent.
+  Task* AddChild(const std::function<void(Task*)>& done_callback) {
+    return AddChildWithExecutor(done_callback, executor_);
+  }
+
+  // Variant of AddChild() that allows setting a different executor.
+  Task* AddChildWithExecutor(const std::function<void(Task*)>& done_callback,
+                             Executor* executor);
+
+  // Functions to call once the task is DONE. This could be called
+  // before, during, or after the done callback, and so cannot rely on
+  // the task itself. An example would be to free the memory that was
+  // used to execute the asynchronous operation.
+  void CleanupWhenDone(const std::function<void()>& cleanup_cb);
+
+  // Arranges to delete the object once the task is DONE. As this
+  // could be run before the done callback, this is meant to be used
+  // by the implementation of the asynchronous operation, rather than
+  // for data used by the caller.
+  template <class T>
+  void DeleteWhenDone(T* obj) {
+    CleanupWhenDone(std::bind(std::default_delete<T>(), obj));
+  }
+
+ private:
+  enum State {
+    ACTIVE = 0,
+    PREPARED = 1,
+    DONE = 2,
+  };
+
+  void TryDoneTransition(std::unique_lock<std::mutex>* lock);
+  void RunCancelCallback(const std::function<void()>& cb);
+  void RunCleanupAndDoneCallbacks();
+  void RunChildDoneCallback(const std::function<void(Task*)>& done_callback,
+                            Task* child_task);
+
+  const std::function<void(Task*)> done_callback_;
+  Executor* const executor_;
+
+  mutable std::mutex lock_;
+  State state_;
+  Status status_;  // not protected by lock_
+  bool cancelled_;
+  int holds_;
+  // References to child tasks are kept as shared pointers to avoid
+  // some races.
+  std::vector<std::shared_ptr<Task>> child_tasks_;
+  std::vector<std::function<void()>> cancel_callbacks_;
+  std::vector<std::function<void()>> cleanup_callbacks_;
+
+  DISALLOW_COPY_AND_ASSIGN(Task);
+};
+
+
+// Helper class, that adds a hold on a task, and automatically removes
+// it when it goes out of scope.
+class TaskHold {
+ public:
+  TaskHold(Task* task) : task_(task) {
+    task_->AddHold();
+  }
+  ~TaskHold() {
+    task_->RemoveHold();
+  }
+
+ private:
+  Task* const task_;
+
+  DISALLOW_COPY_AND_ASSIGN(TaskHold);
+};
+
+
+}  // namespace util
+
+#endif  // CERT_TRANS_UTIL_TASK_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/task_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/task_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/task_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/task_test.cc	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,464 @@
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <atomic>
+#include <functional>
+#include <thread>
+
+#include "base/notification.h"
+#include "util/executor.h"
+#include "util/status_test_util.h"
+#include "util/task.h"
+#include "util/testing.h"
+#include "util/thread_pool.h"
+
+using cert_trans::Notification;
+using cert_trans::ThreadPool;
+using std::atomic_fetch_add;
+using std::atomic_int;
+using std::bind;
+using std::chrono::milliseconds;
+using std::placeholders::_1;
+using std::this_thread::sleep_for;
+using std::unique_ptr;
+
+DEFINE_int32(task_test_jiffy_ms, 100,
+             "amount of time (in milliseconds) after which \"things ought to "
+             "be done\"");
+
+namespace {
+
+
+class InlineExecutor : public util::Executor {
+  void Add(const std::function<void()>& closure) override {
+    closure();
+  }
+  void Delay(const std::chrono::duration<double>& delay,
+             util::Task* task) override {
+    LOG(FATAL) << "Not Implemented.";
+  }
+};
+
+
+void Delay() {
+  sleep_for(milliseconds(FLAGS_task_test_jiffy_ms));
+}
+
+
+class DeleteMarker {
+ public:
+  explicit DeleteMarker(Notification* notifier)
+      : notifier_(CHECK_NOTNULL(notifier)) {
+  }
+  ~DeleteMarker() {
+    notifier_->Notify();
+  }
+
+ private:
+  Notification* const notifier_;
+
+  DISALLOW_COPY_AND_ASSIGN(DeleteMarker);
+};
+
+
+template <class T>
+class TaskTest : public ::testing::Test {};
+
+
+typedef ::testing::Test TaskDeathTest;
+
+
+template <class TestExecutor, bool sync_done>
+class TaskTester {
+ public:
+  TaskTester()
+      : executor_(new TestExecutor),
+        task_(bind(&TaskTester::DoneCallback, this, _1), executor_.get()) {
+    if (sync_done) {
+      ContinueDone();
+    }
+  }
+
+  ~TaskTester() {
+    EXPECT_TRUE(done_started_.WaitForNotificationWithTimeout(
+        milliseconds(FLAGS_task_test_jiffy_ms)));
+    if (!done_continue_.HasBeenNotified()) {
+      done_continue_.Notify();
+    }
+    EXPECT_TRUE(done_finished_.WaitForNotificationWithTimeout(
+        milliseconds(FLAGS_task_test_jiffy_ms)));
+  }
+
+  util::Task* task() {
+    return &task_;
+  }
+
+  void WaitForDoneToStart() {
+    EXPECT_TRUE(done_started_.WaitForNotificationWithTimeout(
+        milliseconds(FLAGS_task_test_jiffy_ms)));
+  }
+
+  bool HasDoneStarted() {
+    return done_started_.HasBeenNotified();
+  }
+
+  void ContinueDone() {
+    if (!done_continue_.HasBeenNotified()) {
+      done_continue_.Notify();
+    }
+  }
+
+  void WaitForDoneToFinish() {
+    EXPECT_TRUE(done_finished_.WaitForNotificationWithTimeout(
+        milliseconds(FLAGS_task_test_jiffy_ms)));
+  }
+
+ private:
+  void DoneCallback(util::Task* task) {
+    CHECK(!task->IsActive());
+    CHECK(task->IsDone());
+    done_started_.Notify();
+    EXPECT_TRUE(done_continue_.WaitForNotificationWithTimeout(
+        milliseconds(FLAGS_task_test_jiffy_ms)));
+    done_finished_.Notify();
+  }
+
+  const unique_ptr<TestExecutor> executor_;
+  util::Task task_;
+  Notification done_started_;
+  Notification done_continue_;
+  Notification done_finished_;
+
+  DISALLOW_COPY_AND_ASSIGN(TaskTester);
+};
+
+
+typedef ::testing::Types<TaskTester<ThreadPool, false>,
+                         TaskTester<InlineExecutor, true>> MyTypes;
+TYPED_TEST_CASE(TaskTest, MyTypes);
+
+
+void DoNothing(util::Task* task) {
+}
+
+
+TEST_F(TaskDeathTest, DestroyIncompleteTask) {
+  InlineExecutor executor;
+
+  EXPECT_DEATH(util::Task(DoNothing, &executor),
+               "Check failed: state_ == DONE");
+}
+
+
+template <class TypeParam>
+void WaitForReturnCallback(TypeParam* s, Notification* notifier) {
+  s->WaitForDoneToStart();
+  EXPECT_FALSE(s->task()->IsActive());
+  EXPECT_TRUE(s->task()->IsDone());
+  EXPECT_FALSE(s->task()->CancelRequested());
+  EXPECT_OK(s->task()->status());
+  s->ContinueDone();
+  notifier->Notify();
+}
+
+
+TYPED_TEST(TaskTest, StateChanges) {
+  ThreadPool pool;
+  TypeParam s;
+
+  EXPECT_TRUE(s.task()->IsActive());
+  EXPECT_FALSE(s.task()->IsDone());
+  EXPECT_FALSE(s.task()->CancelRequested());
+
+  Notification notifier;
+  pool.Add(bind(&WaitForReturnCallback<TypeParam>, &s, &notifier));
+  EXPECT_TRUE(s.task()->Return());
+
+  EXPECT_TRUE(notifier.WaitForNotificationWithTimeout(
+      milliseconds(FLAGS_task_test_jiffy_ms)));
+}
+
+
+TYPED_TEST(TaskTest, DeleteWhenDone) {
+  Notification n1;
+  Notification n2;
+  TypeParam s;
+
+  s.task()->DeleteWhenDone(new DeleteMarker(&n1));
+  s.task()->DeleteWhenDone(new DeleteMarker(&n2));
+
+  EXPECT_FALSE(n1.HasBeenNotified());
+  EXPECT_FALSE(n2.HasBeenNotified());
+  s.task()->Return();
+  s.ContinueDone();
+  EXPECT_TRUE(n1.WaitForNotificationWithTimeout(
+      milliseconds(FLAGS_task_test_jiffy_ms)));
+  EXPECT_TRUE(n2.WaitForNotificationWithTimeout(
+      milliseconds(FLAGS_task_test_jiffy_ms)));
+}
+
+
+TYPED_TEST(TaskTest, Return) {
+  TypeParam s;
+  util::Status status(util::error::INVALID_ARGUMENT, "expected status");
+
+  EXPECT_TRUE(s.task()->Return(status));
+  EXPECT_FALSE(s.task()->IsActive());
+
+  s.WaitForDoneToStart();
+  EXPECT_EQ(status, s.task()->status());
+}
+
+
+TYPED_TEST(TaskTest, HoldBlocksDone) {
+  TypeParam s;
+  EXPECT_TRUE(s.task()->IsActive());
+  EXPECT_FALSE(s.task()->IsDone());
+
+  s.task()->AddHold();
+  EXPECT_TRUE(s.task()->IsActive());
+  EXPECT_FALSE(s.task()->IsDone());
+
+  s.task()->Return();
+  EXPECT_FALSE(s.task()->IsActive());
+  EXPECT_FALSE(s.task()->IsDone());
+
+  s.task()->RemoveHold();
+  EXPECT_FALSE(s.task()->IsActive());
+  EXPECT_TRUE(s.task()->IsDone());
+}
+
+
+TYPED_TEST(TaskTest, MultipleReturn) {
+  TypeParam s;
+  util::Status status1(util::error::INVALID_ARGUMENT, "expected status");
+  util::Status status2(util::error::DEADLINE_EXCEEDED, "unexpected status");
+  EXPECT_NE(status1, status2);
+
+  EXPECT_TRUE(s.task()->Return(status1));
+  EXPECT_FALSE(s.task()->Return(status2));
+  EXPECT_FALSE(s.task()->IsActive());
+
+  s.WaitForDoneToStart();
+  EXPECT_EQ(status1, s.task()->status());
+}
+
+
+TYPED_TEST(TaskTest, Cancel) {
+  TypeParam s;
+  EXPECT_FALSE(s.task()->CancelRequested());
+  s.task()->Cancel();
+  EXPECT_TRUE(s.task()->CancelRequested());
+  s.task()->Return();
+}
+
+
+TYPED_TEST(TaskTest, CancelAfterReturn) {
+  TypeParam s;
+  EXPECT_FALSE(s.task()->CancelRequested());
+  s.task()->Return();
+  s.task()->Cancel();
+  EXPECT_FALSE(s.task()->CancelRequested());
+}
+
+
+TYPED_TEST(TaskTest, MultipleCancels) {
+  TypeParam s;
+  EXPECT_FALSE(s.task()->CancelRequested());
+  s.task()->Cancel();
+  s.task()->Cancel();
+  EXPECT_TRUE(s.task()->CancelRequested());
+  s.task()->Return();
+}
+
+
+TYPED_TEST(TaskTest, CancelCallback) {
+  TypeParam s;
+  Notification notifier;
+
+  s.task()->WhenCancelled(bind(&Notification::Notify, &notifier));
+
+  Delay();
+  EXPECT_FALSE(notifier.HasBeenNotified());
+
+  s.task()->Cancel();
+  EXPECT_TRUE(notifier.WaitForNotificationWithTimeout(
+      milliseconds(FLAGS_task_test_jiffy_ms)));
+  EXPECT_TRUE(notifier.HasBeenNotified());
+
+  s.task()->Return();
+}
+
+
+void NotifyAndWait(Notification* cancelled, Notification* finish_cancel) {
+  cancelled->Notify();
+  // Wait for up to two jiffies, because there's a delay of one jiffy
+  // in WaitForCancelAndReturn().
+  EXPECT_TRUE(finish_cancel->WaitForNotificationWithTimeout(
+      milliseconds(FLAGS_task_test_jiffy_ms) * 2));
+}
+
+
+template <class TypeParam>
+void WaitForCancelAndReturn(TypeParam* s, Notification* cancelled,
+                            Notification* finish_cancel) {
+  EXPECT_TRUE(cancelled->WaitForNotificationWithTimeout(
+      milliseconds(FLAGS_task_test_jiffy_ms)));
+  s->task()->Return();
+  Delay();
+  EXPECT_FALSE(s->task()->IsDone());
+  EXPECT_FALSE(s->HasDoneStarted());
+  finish_cancel->Notify();
+  s->ContinueDone();
+}
+
+
+TYPED_TEST(TaskTest, CancelCallbackBlocksDone) {
+  ThreadPool pool;
+  Notification cancelled;
+  Notification finish_cancel;
+  // This object must be defined after the two Notification above,
+  // because it will be using them all (so they should live at least
+  // as long).
+  TypeParam s;
+
+  s.task()->WhenCancelled(bind(NotifyAndWait, &cancelled, &finish_cancel));
+  pool.Add(
+      bind(WaitForCancelAndReturn<TypeParam>, &s, &cancelled, &finish_cancel));
+  s.task()->Cancel();
+
+  // Make sure everything is completed.
+  Delay();
+}
+
+
+TYPED_TEST(TaskTest, CancelCallbackNotCalledOnReturn) {
+  TypeParam s;
+  Notification notifier;
+
+  s.task()->WhenCancelled(bind(&Notification::Notify, &notifier));
+
+  s.task()->Return();
+  s.ContinueDone();
+  s.WaitForDoneToFinish();
+
+  EXPECT_FALSE(notifier.HasBeenNotified());
+}
+
+
+TYPED_TEST(TaskTest, CancelCallbackNotCalledAfterReturn) {
+  TypeParam s;
+  Notification notifier;
+
+  s.task()->Return();
+  s.task()->WhenCancelled(bind(&Notification::Notify, &notifier));
+  s.ContinueDone();
+  s.WaitForDoneToFinish();
+
+  EXPECT_FALSE(notifier.HasBeenNotified());
+}
+
+
+TYPED_TEST(TaskTest, CancelCallbackAfterCancel) {
+  TypeParam s;
+  Notification notifier;
+
+  s.task()->Cancel();
+  s.task()->WhenCancelled(bind(&Notification::Notify, &notifier));
+  Delay();
+  s.task()->Return();
+
+  EXPECT_TRUE(notifier.WaitForNotificationWithTimeout(
+      milliseconds(FLAGS_task_test_jiffy_ms)));
+}
+
+
+TYPED_TEST(TaskTest, ReturnStillRunsCancelCallbacks) {
+  TypeParam s;
+  Notification notifier;
+
+  s.task()->Cancel();
+  s.task()->WhenCancelled(bind(&Notification::Notify, &notifier));
+  s.task()->Return();
+
+  EXPECT_TRUE(notifier.WaitForNotificationWithTimeout(
+      milliseconds(FLAGS_task_test_jiffy_ms)));
+}
+
+
+void Increment(atomic_int* atomic) {
+  atomic->fetch_add(1);
+}
+
+
+TYPED_TEST(TaskTest, MultiCancel) {
+  TypeParam s;
+  atomic_int count(0);
+  const int kRuns(3);
+
+  for (int i = 0; i < kRuns; ++i) {
+    s.task()->WhenCancelled(bind(Increment, &count));
+  }
+
+  s.task()->Cancel();
+  s.task()->Return();
+  s.WaitForDoneToStart();
+  EXPECT_EQ(kRuns, count.load());
+}
+
+
+TYPED_TEST(TaskTest, ChildBlocksDone) {
+  TypeParam s;
+
+  util::Task* const child_task(s.task()->AddChild(DoNothing));
+  EXPECT_FALSE(s.task()->CancelRequested());
+  EXPECT_TRUE(s.task()->IsActive());
+  EXPECT_FALSE(s.task()->IsDone());
+  EXPECT_FALSE(child_task->IsDone());
+
+  s.task()->Return();
+  EXPECT_FALSE(s.task()->IsActive());
+  EXPECT_FALSE(s.task()->IsDone());
+
+  child_task->Return();
+}
+
+
+TYPED_TEST(TaskTest, ChildCancel) {
+  TypeParam s;
+
+  util::Task* const child_task(s.task()->AddChild(DoNothing));
+  EXPECT_FALSE(s.task()->CancelRequested());
+  EXPECT_FALSE(child_task->CancelRequested());
+
+  s.task()->Cancel();
+  EXPECT_TRUE(s.task()->CancelRequested());
+  EXPECT_TRUE(child_task->CancelRequested());
+
+  child_task->Return();
+  s.task()->Return();
+}
+
+
+TYPED_TEST(TaskTest, ChildReturn) {
+  TypeParam s;
+
+  util::Task* const child_task(s.task()->AddChild(DoNothing));
+  EXPECT_FALSE(s.task()->CancelRequested());
+  EXPECT_FALSE(child_task->CancelRequested());
+
+  s.task()->Return();
+  EXPECT_FALSE(s.task()->CancelRequested());
+  EXPECT_TRUE(child_task->CancelRequested());
+
+  child_task->Return();
+}
+
+
+}  // namespace
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/test_db.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/test_db.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/test_db.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/test_db.h	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,70 @@
+#ifndef CERT_TRANS_UTIL_TEST_DB_H_
+#define CERT_TRANS_UTIL_TEST_DB_H_
+
+#include <gflags/gflags.h>
+#include <glog/logging.h>
+#include <stdlib.h>
+
+#include "base/macros.h"
+#include "util/util.h"
+
+DEFINE_string(database_test_dir, "/tmp",
+              "Test directory for databases that use the disk. We attempt to "
+              "remove all created files and directories but data may be left "
+              "behind if the program does not exit cleanly.");
+
+class TmpStorage {
+ public:
+  TmpStorage() : tmp_dir_(FLAGS_database_test_dir) {
+    file_base_ = util::CreateTemporaryDirectory(tmp_dir_ + "/ctlogXXXXXX");
+    CHECK_EQ(tmp_dir_ + "/ctlog", file_base_.substr(0, tmp_dir_.size() + 6));
+    CHECK_EQ(tmp_dir_.size() + 12, file_base_.length());
+  }
+
+  ~TmpStorage() {
+    // Check again that it is safe to empty file_base_.
+    CHECK_EQ(tmp_dir_ + "/ctlog", file_base_.substr(0, tmp_dir_.size() + 6));
+    CHECK_EQ(tmp_dir_.size() + 12, file_base_.length());
+
+    std::string command = "rm -r " + file_base_;
+    CHECK_ERR(system(command.c_str()))
+        << "Failed to delete temporary directory in " << file_base_;
+  }
+
+  std::string TmpStorageDir() const {
+    return file_base_;
+  }
+
+ private:
+  std::string tmp_dir_;
+  std::string file_base_;
+};
+
+// Helper for generating test instances of the databases for typed tests.
+template <class T>
+class TestDB {
+ public:
+  TestDB() : tmp_() {
+    Setup();
+  }
+
+  void Setup();
+
+  T* db() const {
+    return db_.get();
+  }
+
+  // Build a second database from the current disk state. Caller owns result.
+  // Meant to be used for testing resumes from disk.
+  // Concurrent behaviour is undefined (depends on the Database
+  // implementation).
+  T* SecondDB();
+
+ private:
+  TmpStorage tmp_;
+  std::unique_ptr<T> db_;
+
+  DISALLOW_COPY_AND_ASSIGN(TestDB);
+};
+
+#endif  // CERT_TRANS_UTIL_TEST_DB_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/testing.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/testing.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/testing.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/testing.cc	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,34 @@
+#include "util/testing.h"
+
+#include <event2/thread.h>
+#include <evhtp.h>
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+
+#include "config.h"
+
+DEFINE_string(test_srcdir, TEST_SRCDIR, "top-level of the source tree");
+
+namespace cert_trans {
+namespace test {
+
+void InitTesting(const char* name, int* argc, char*** argv,
+                 bool remove_flags) {
+  ::testing::InitGoogleTest(argc, *argv);
+  google::ParseCommandLineFlags(argc, argv, remove_flags);
+  google::InitGoogleLogging(name);
+  google::InstallFailureSignalHandler();
+  evthread_use_pthreads();
+
+  // Set-up OpenSSL for multithreaded use:
+  evhtp_ssl_use_threads();
+
+  OpenSSL_add_all_algorithms();
+  ERR_load_BIO_strings();
+  ERR_load_crypto_strings();
+  SSL_load_error_strings();
+  SSL_library_init();
+}
+
+}  // namespace test
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/testing.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/testing.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/testing.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/testing.h	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,16 @@
+#ifndef CERT_TRANS_UTIL_TESTING_H_
+#define CERT_TRANS_UTIL_TESTING_H_
+
+#include <gflags/gflags.h>
+
+DECLARE_string(test_srcdir);
+
+namespace cert_trans {
+namespace test {
+
+void InitTesting(const char* name, int* argc, char*** argv, bool remove_flags);
+
+}  // namespace test
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_TESTING_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/thread_pool.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/thread_pool.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/thread_pool.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/thread_pool.cc	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,185 @@
+#include "util/thread_pool.h"
+#include "util/task.h"
+
+#include <glog/logging.h>
+#include <condition_variable>
+#include <mutex>
+#include <queue>
+#include <thread>
+#include <vector>
+
+using std::chrono::duration;
+using std::chrono::duration_cast;
+using std::chrono::seconds;
+using std::chrono::steady_clock;
+using std::condition_variable;
+using std::function;
+using std::get;
+using std::lock_guard;
+using std::mutex;
+using std::priority_queue;
+using std::thread;
+using std::tuple;
+using std::unique_lock;
+using std::vector;
+
+namespace cert_trans {
+namespace {
+
+typedef tuple<steady_clock::time_point, function<void()>, util::Task*>
+    QueueEntry;
+
+
+struct QueueOrdering {
+  bool operator()(const QueueEntry& lhs, const QueueEntry& rhs) const {
+    return get<0>(lhs) > get<0>(rhs);
+  }
+};
+
+
+}  // namespace
+
+
+class ThreadPool::Impl {
+ public:
+  ~Impl();
+
+  void Worker();
+
+  // TODO(pphaneuf): I'd like this to be const, but it required
+  // jumping through a few more hoops, keeping it simple for now.
+  vector<thread> threads_;
+
+  mutex queue_lock_;
+  condition_variable queue_cond_var_;
+  priority_queue<QueueEntry, vector<QueueEntry>, QueueOrdering> queue_;
+};
+
+
+ThreadPool::Impl::~Impl() {
+  // Start by sending an empty closure to every thread (and notify
+  // them), to have them exit cleanly.
+  {
+    lock_guard<mutex> lock(queue_lock_);
+    for (int i = threads_.size(); i > 0; --i)
+      queue_.emplace(
+          make_tuple(steady_clock::time_point(), function<void()>(), nullptr));
+  }
+  // Notify all the threads *after* adding all the empty closures, to
+  // avoid any races.
+  queue_cond_var_.notify_all();
+
+  // Wait for the threads to exit.
+  for (auto& thread : threads_) {
+    thread.join();
+  }
+
+  // Workers should've drained everything from the queue.
+  CHECK(queue_.empty());
+}
+
+
+void ThreadPool::Impl::Worker() {
+  while (true) {
+    QueueEntry entry;
+
+    {
+      unique_lock<mutex> lock(queue_lock_);
+      while (queue_.empty() || get<0>(queue_.top()) > steady_clock::now()) {
+        if (queue_.empty()) {
+          // If there's nothing to do, wait until there is.
+          queue_cond_var_.wait(lock);
+        } else {
+          // Otherwise, wait until the next thing we currently know about is
+          // ready.
+          const steady_clock::duration duration(get<0>(queue_.top()) -
+                                                steady_clock::now());
+          queue_cond_var_.wait_for(lock, duration);
+        }
+      }
+
+      entry = queue_.top();
+      queue_.pop();
+
+      // If we received an empty entry, exit cleanly.
+      if (!get<1>(entry)) {
+        // Anything left in the queue must be either other exit sentinels, or
+        // future (delayed) tasks, so we'll cancel anything we find, up until
+        // either the next exit sentinel, or the end of the queue.
+        VLOG(1) << "Cancelling delayed tasks...";
+        vector<util::Task*> to_be_cancelled;
+        while (!queue_.empty() && get<2>(queue_.top())) {
+          to_be_cancelled.push_back(CHECK_NOTNULL(get<2>(queue_.top())));
+          queue_.pop();
+        }
+
+        // Cancel the callbacks below outside of the lock to avoid deadlocking
+        // anyone who tries to Add() more stuff when they're cancelled.
+        // Anyone who does that is going to cause a CHECK fail in the d'tor of
+        // the pool anyway, but at least they'll know about it that way.
+        lock.unlock();
+
+        for (const auto& t : to_be_cancelled) {
+          t->Return(util::Status::CANCELLED);
+        }
+
+        VLOG(1) << "Cancelled " << to_be_cancelled.size() << " delayed tasks.";
+        return;
+      }
+    }
+
+    // Make sure not to hold the lock while calling the closure.
+    get<1>(entry)();
+  }
+}
+
+
+ThreadPool::ThreadPool()
+    : ThreadPool(thread::hardware_concurrency() > 0
+                     ? thread::hardware_concurrency()
+                     : 1) {
+}
+
+
+ThreadPool::ThreadPool(size_t num_threads) : impl_(new Impl) {
+  CHECK_GT(num_threads, static_cast<size_t>(0));
+  LOG(INFO) << "ThreadPool starting with " << num_threads << " threads";
+  for (int i = 0; i < static_cast<int64_t>(num_threads); ++i)
+    impl_->threads_.emplace_back(thread(&Impl::Worker, impl_.get()));
+}
+
+
+ThreadPool::~ThreadPool() {
+  // Need to have this method defined where the definition of
+  // ThreadPool::Impl is visible.
+}
+
+
+void ThreadPool::Add(const function<void()>& closure) {
+  // Empty closures signal a thread to exit, don't allow that (also,
+  // it doesn't make sense).
+  if (!closure) {
+    return;
+  }
+
+  {
+    lock_guard<mutex> lock(impl_->queue_lock_);
+    impl_->queue_.emplace(make_tuple(steady_clock::now(), closure, nullptr));
+  }
+  impl_->queue_cond_var_.notify_one();
+}
+
+
+void ThreadPool::Delay(const duration<double>& delay, util::Task* task) {
+  CHECK_NOTNULL(task);
+  {
+    lock_guard<mutex> lock(impl_->queue_lock_);
+    impl_->queue_.emplace(make_tuple(
+        steady_clock::now() + duration_cast<std::chrono::microseconds>(delay),
+        [task]() { task->Return(); }, task));
+  }
+  impl_->queue_cond_var_.notify_one();
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/thread_pool.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/thread_pool.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/thread_pool.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/thread_pool.h	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,45 @@
+#ifndef CERT_TRANS_UTIL_THREAD_POOL_H_
+#define CERT_TRANS_UTIL_THREAD_POOL_H_
+
+#include <chrono>
+#include <functional>
+#include <map>
+#include <memory>
+
+#include "base/macros.h"
+#include "util/executor.h"
+
+namespace cert_trans {
+
+
+// Provides a fixed size thread pool to run closures on. The pool is
+// sized according to the number of cores in the system.
+class ThreadPool : public util::Executor {
+ public:
+  // Creates the threads.
+  ThreadPool();
+
+  // Creates the threads.
+  ThreadPool(size_t num_threads);
+
+  // The destructor will wait for any outstanding closures to finish.
+  ~ThreadPool();
+
+  // Arranges for "closure" to be called in the thread pool. The
+  // function must not be empty.
+  void Add(const std::function<void()>& closure) override;
+
+  void Delay(const std::chrono::duration<double>& delay,
+             util::Task* task) override;
+
+ private:
+  class Impl;
+  const std::unique_ptr<Impl> impl_;
+
+  DISALLOW_COPY_AND_ASSIGN(ThreadPool);
+};
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_THREAD_POOL_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/thread_pool_test.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/thread_pool_test.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/thread_pool_test.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/thread_pool_test.cc	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,99 @@
+#include "util/thread_pool.h"
+
+#include <glog/logging.h>
+#include <gtest/gtest.h>
+#include <atomic>
+#include <memory>
+
+#include "base/notification.h"
+#include "util/sync_task.h"
+#include "util/testing.h"
+
+namespace cert_trans {
+
+using std::chrono::milliseconds;
+using std::chrono::system_clock;
+using std::unique_ptr;
+using util::SyncTask;
+
+class ThreadPoolTest : public ::testing::Test {
+ public:
+  ThreadPoolTest() : pool_of_one_(1) {
+  }
+
+ protected:
+  ThreadPool pool_of_one_;
+};
+
+typedef class ThreadPoolTest ThreadPoolDeathTest;
+
+
+TEST_F(ThreadPoolTest, Delay) {
+  SyncTask task(&pool_of_one_);
+  pool_of_one_.Delay(milliseconds(200), task.task());
+  EXPECT_FALSE(task.IsDone());
+  task.Wait();
+}
+
+
+TEST_F(ThreadPoolDeathTest, AddingMoreTasksAfterClosedGoesBang) {
+  unique_ptr<ThreadPool> my_pool_of_one(new ThreadPool(1));
+  SyncTask task(my_pool_of_one.get());
+  my_pool_of_one->Delay(milliseconds(200), task.task());
+  EXPECT_DEATH(my_pool_of_one.reset(), "queue_\\.empty()");
+  task.Wait();
+}
+
+
+TEST_F(ThreadPoolTest, DelayDoesNotBlockAThread) {
+  SyncTask delay_task(&pool_of_one_);
+  pool_of_one_.Delay(milliseconds(200), delay_task.task());
+
+  Notification inner_done;
+  pool_of_one_.Add([&inner_done]() {
+    LOG(WARNING) << "Inner running";
+    inner_done.Notify();
+  });
+
+  inner_done.WaitForNotification();
+
+  EXPECT_FALSE(delay_task.IsDone());
+
+  delay_task.Wait();
+}
+
+
+TEST_F(ThreadPoolTest, NaturalOrderingPreserved) {
+  SyncTask task1(&pool_of_one_);
+  SyncTask task2(&pool_of_one_);
+
+  pool_of_one_.Delay(milliseconds(200), task2.task());
+  pool_of_one_.Delay(milliseconds(100), task1.task());
+
+  task1.Wait();
+  EXPECT_FALSE(task2.IsDone());
+  task2.Wait();
+}
+
+
+TEST_F(ThreadPoolTest, CancelsDelayTasks) {
+  unique_ptr<ThreadPool> pool(new ThreadPool(1));
+
+  SyncTask task1(&pool_of_one_);
+
+  pool->Delay(milliseconds(500), task1.task());
+  pool.reset();
+
+  task1.Wait();
+  EXPECT_EQ(util::Status::CANCELLED, task1.status());
+}
+
+
+}  // namespace cert_trans
+
+
+int main(int argc, char** argv) {
+  cert_trans::test::InitTesting(argv[0], &argc, &argv, true);
+  ::testing::FLAGS_gtest_death_test_style = "threadsafe";
+  return RUN_ALL_TESTS();
+}
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/util.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/util.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/util.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/util.cc	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,216 @@
+#include "util/util.h"
+
+#include <glog/logging.h>
+#include <netinet/in.h>  // for resolv.h
+#include <resolv.h>      // for b64_ntop
+#include <stdint.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <sys/time.h>
+#include <unistd.h>
+#include <cstring>
+#include <fstream>
+#include <iostream>
+#include <sstream>
+#include <string>
+#include <vector>
+
+#include "log/ct_extensions.h"
+#include "version.h"
+
+using std::getline;
+using std::move;
+using std::string;
+using std::stringstream;
+using std::vector;
+
+namespace util {
+
+namespace {
+const char nibble[] = "0123456789abcdef";
+
+char ByteValue(char high, char low) {
+  CHECK(('0' <= high && high <= '9') || ('a' <= high && high <= 'f'));
+  char ret;
+  if (high <= '9')
+    ret = (high - '0') << 4;
+  else
+    ret = (high - 'W') << 4;  // 'a' - 'W' = 0x61 - 0x57 = 0x0a
+  if (low <= '9')
+    ret += low - '0';
+  else
+    ret += low - 'W';
+  return ret;
+}
+
+}  // namespace
+
+string HexString(const string& data) {
+  string ret;
+  for (unsigned int i = 0; i < data.size(); ++i) {
+    ret.push_back(nibble[(data[i] >> 4) & 0xf]);
+    ret.push_back(nibble[data[i] & 0xf]);
+  }
+  return ret;
+}
+
+string HexString(const string& data, char byte_delimiter) {
+  string ret;
+  if (data.empty())
+    return ret;
+  for (unsigned int i = 0; i < data.size(); ++i) {
+    if (i != 0)
+      ret.push_back(byte_delimiter);
+    ret.push_back(nibble[(data[i] >> 4) & 0xf]);
+    ret.push_back(nibble[data[i] & 0xf]);
+  }
+  return ret;
+}
+
+string BinaryString(const string& hex_string) {
+  string ret;
+  CHECK(!(hex_string.size() % 2));
+  for (size_t i = 0; i < hex_string.size(); i += 2)
+    ret.push_back(ByteValue(hex_string[i], hex_string[i + 1]));
+  return ret;
+}
+
+static char* ReadFileStreamToBuffer(std::ifstream& in, int* length) {
+  CHECK(in.good());
+
+  in.seekg(0, std::ios::end);
+  int file_length = in.tellg();
+  // Rewind.
+  in.seekg(0, std::ios::beg);
+
+  // Now write the proof.
+  char* buf = new char[file_length];
+  in.read(buf, file_length);
+  CHECK(!in.bad());
+  CHECK_EQ(in.gcount(), file_length);
+  in.close();
+
+  *length = file_length;
+  return buf;
+}
+
+bool ReadTextFile(const string& file, string* contents) {
+  int file_length;
+  std::ifstream in(file.c_str(), std::ios::in);
+  if (!in.good())
+    return false;
+  char* buf = ReadFileStreamToBuffer(in, &file_length);
+  contents->assign(string(buf, file_length));
+
+  delete[] buf;
+  return true;
+}
+
+bool ReadBinaryFile(const string& file, string* contents) {
+  int file_length;
+  std::ifstream in(file.c_str(), std::ios::in | std::ios::binary);
+  if (!in.good())
+    return false;
+
+  char* buf = ReadFileStreamToBuffer(in, &file_length);
+  contents->assign(string(buf, file_length));
+
+  delete[] buf;
+  return true;
+}
+
+string WriteTemporaryBinaryFile(const string& file_template,
+                                const string& data) {
+  size_t strlen = file_template.size() + 1;
+  char* template_buf = new char[strlen];
+  memcpy(template_buf, file_template.data(), file_template.size());
+  template_buf[strlen - 1] = '\0';
+  int fd = mkstemp(template_buf);
+  string tmp_file;
+  if (fd >= 0) {
+    tmp_file = string(template_buf);
+    ssize_t bytes_written =
+        write(fd, reinterpret_cast<const char*>(data.data()), data.length());
+    close(fd);
+    if (bytes_written < 0 ||
+        static_cast<size_t>(bytes_written) < data.length()) {
+      // Write failed; try to clean up.
+      remove(tmp_file.c_str());
+      tmp_file.clear();
+    }
+  }
+  delete[] template_buf;
+  return tmp_file;
+}
+
+string CreateTemporaryDirectory(const string& dir_template) {
+  size_t strlen = dir_template.size() + 1;
+  char* template_buf = new char[strlen];
+  memcpy(template_buf, dir_template.data(), dir_template.size());
+  template_buf[strlen - 1] = '\0';
+  char* tmpdir = mkdtemp(template_buf);
+  string ret;
+  if (tmpdir != NULL)
+    ret = string(tmpdir);
+  delete[] template_buf;
+  return ret;
+}
+
+uint64_t TimeInMilliseconds() {
+  struct timeval tv;
+  gettimeofday(&tv, NULL);
+  return static_cast<uint64_t>(tv.tv_sec) * 1000 +
+         static_cast<uint64_t>(tv.tv_usec) / 1000;
+}
+
+string RandomString(size_t min_length, size_t max_length) {
+  size_t length = min_length == max_length
+                      ? min_length
+                      : rand() % (max_length - min_length) + min_length;
+
+  string ret;
+  for (; length > 0; --length)
+    ret.append(1, rand() & 0xff);
+
+  return ret;
+}
+
+string FromBase64(const char* b64) {
+  size_t length = strlen(b64);
+  // Lazy: base 64 encoding is always >= in length to decoded value
+  // (equality occurs for zero length).
+  u_char* buf = new u_char[length];
+  int rlength = b64_pton(b64, buf, length);
+  // Treat decode errors as empty strings.
+  if (rlength < 0)
+    rlength = 0;
+  string ret(reinterpret_cast<char*>(buf), rlength);
+  delete[] buf;
+  return ret;
+}
+
+string ToBase64(const string& from) {
+  // base 64 is 4 output bytes for every 3 input bytes (rounded up).
+  size_t length = ((from.size() + 2) / 3) * 4;
+  char* buf = new char[length + 1];
+  length =
+      b64_ntop((const u_char*)from.data(), from.length(), buf, length + 1);
+  string ret(buf, length);
+  delete[] buf;
+  return ret;
+}
+
+vector<string> split(const string& in, char delim) {
+  vector<string> ret;
+  string item;
+
+  stringstream ss(in);
+  while (getline(ss, item, delim)) {
+    if (!item.empty()) {
+      ret.emplace_back(move(item));
+    }
+  }
+  return ret;
+}
+
+}  // namespace util
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/util.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/util.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/util.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/util.h	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,43 @@
+#ifndef CERT_TRANS_UTIL_UTIL_H_
+#define CERT_TRANS_UTIL_UTIL_H_
+
+#include <stdint.h>
+#include <string>
+#include <vector>
+
+namespace util {
+
+std::string HexString(const std::string& data);
+
+std::string HexString(const std::string& data, char byte_delimiter);
+
+std::string BinaryString(const std::string& hex_string);
+
+bool ReadTextFile(const std::string& file, std::string* result);
+
+bool ReadBinaryFile(const std::string& file, std::string* result);
+
+// Write to a temporary file and return the filename, or an
+// empty string on error.
+std::string WriteTemporaryBinaryFile(const std::string& file_template,
+                                     const std::string& data);
+
+// Create a temporary directory, and return the dirname, or an
+// empty string on error.
+std::string CreateTemporaryDirectory(const std::string& dir_template);
+
+uint64_t TimeInMilliseconds();
+
+// Return a non-cryptographic random string. Caller needs to ensure
+// srand() is called if needed.
+std::string RandomString(size_t min_length, size_t max_length);
+
+std::string FromBase64(const char* b64);
+
+std::string ToBase64(const std::string& from);
+
+std::vector<std::string> split(const std::string& in, char delim = ',');
+
+}  // namespace util
+
+#endif  // CERT_TRANS_UTIL_UTIL_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/uuid.cc src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/uuid.cc
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/uuid.cc	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/uuid.cc	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,43 @@
+#include <iomanip>
+#include <random>
+#include <sstream>
+
+#include "util/uuid.h"
+
+using std::hex;
+using std::mt19937;
+using std::nouppercase;
+using std::random_device;
+using std::setw;
+using std::setfill;
+using std::string;
+using std::stringstream;
+using std::uniform_int_distribution;
+
+namespace cert_trans {
+
+string UUID4() {
+  random_device rd;
+  mt19937 twister(rd());
+  uniform_int_distribution<uint32_t> distribution(0, UINT32_MAX);
+
+  const uint32_t a((distribution(twister) & 0xFFFFFFFFUL));
+  const uint32_t b((distribution(twister) & 0xFFFF0FFFUL) | 0x00004000UL);
+  const uint32_t c((distribution(twister) & 0x3FFFFFFFUL) | 0x80000000UL);
+  const uint32_t d((distribution(twister) & 0xFFFFFFFFUL));
+
+  stringstream oss;
+  oss << hex << nouppercase << setfill('0');
+
+  oss << setw(8) << (a) << '-';
+  oss << setw(4) << (b >> 16) << '-';
+  oss << setw(4) << (b & 0xFFFF) << '-';
+  oss << setw(4) << (c >> 16) << '-';
+  oss << setw(4) << (c & 0xFFFF);
+  oss << setw(8) << d;
+
+  return oss.str();
+}
+
+
+}  // namespace cert_trans
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/uuid.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/uuid.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/util/uuid.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/util/uuid.h	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,13 @@
+#ifndef CERT_TRANS_UTIL_UUID_H_
+#define CERT_TRANS_UTIL_UUID_H_
+
+#include <string>
+
+namespace cert_trans {
+
+// Generates a type 4 (128bit random) UUID:
+std::string UUID4();
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_UTIL_UUID_H_
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/version.cc.in src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/version.cc.in
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/version.cc.in	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/version.cc.in	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,4 @@
+#include "version.h"
+
+
+const char cert_trans::kBuildVersion[] = "%BUILD_VERSION%";
diff -Naur src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/version.h src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/version.h
--- src/github.com/cloudflare/a/vendor/github.com/google/certificate-transparency/cpp/version.h	1970-01-01 01:00:00.000000000 +0100
+++ src/github.com/cloudflare/cfssl/vendor/github.com/google/certificate-transparency/cpp/version.h	2017-01-15 10:56:31.049591151 +0100
@@ -0,0 +1,12 @@
+#ifndef CERT_TRANS_VERSION_H_
+#define CERT_TRANS_VERSION_H_
+
+namespace cert_trans {
+
+
+extern const char kBuildVersion[];
+
+
+}  // namespace cert_trans
+
+#endif  // CERT_TRANS_VERSION_H_
